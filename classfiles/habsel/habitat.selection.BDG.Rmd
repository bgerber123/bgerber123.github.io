---
title: "Habitat Selection Availability Sensitivity"
author: "Brian Gerber"
date: "2024-11-25"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Getting the data ready

```{r,packages,include=FALSE}
  library(amt)
  library(terra)
  library(raster)
  library(MASS)
  library(sp)
  data("deer")
  forest.cover = readRDS("sp.layer.forest")
  shrub.cover = readRDS("sp.layer.shrub")
```

```{r,data}
#Look at deer data and spatial layers to be used as covariates

  plot(forest.cover,main="Forest Cover")
  points(deer$x_,deer$y_,col=0)

  plot(shrub.cover,main="Standaradized Shrub Cover")
  points(deer,col="white")
```


## Assignment (Part 1)

Conduct a sensitivity analysis to investigate how many available samples are needed for the slope coeficients to be estimated with minimal approximation error. Consider a range of sizes for the available sample between 50 and 500,000. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coeficients for the variables 'forest' and 'cover'. Creat an x-y line plot with these estimates (y-axis) and the size of the available sample (x-axis). Determine generally when the coefficient estimates stabilize. A common recommendation in the literature is to used a 1:1 ratio between used locations and available samples. If you had only fit the model with this size of available how off would your estimates be from the correct/converged/well approximated estimates when using a large available sample. 

```{r,sim,cache=TRUE}

# Define the home range with MCP and buffer by 5000m
  hr <- hr_mcp(deer) |> hr_isopleths() |> sf::st_buffer(dist = 5000)

# Take a really large sample of available locations (the zeros)
  rsf.dat.large <- random_points(hr, n = 4000000, presence = deer) |> 
                   extract_covariates(forest.cover) |>
                   extract_covariates(shrub.cover) 

# Decide on how to subset the available samples
  availables = c(50,100,500,1000,10000,100000,1000000,2000000,3000000,4000000)

# Find the indices of where the deer locations are (index.1)  and the available samples (index.0)
  index.0 = which(rsf.dat.large$case_==0)
  index.1 = which(rsf.dat.large$case_==1)
  coef.mat=NULL

# Loop through the numbers of available samples and iteratively grab an increase set of zeros. Combine
# these zeros with the used locations of deer and then fit the model 
  for(i in 1:length(availables)){
    rsf.smaller =  rbind(rsf.dat.large[index.1,],rsf.dat.large[index.0[1:availables[i]],])
    fit = glm(case_~forest+shrub.cover, data=rsf.smaller,family=binomial(link="logit"))
    coef.mat=rbind(coef.mat,coef(fit)[c(2,3)])
    remove(fit)
  }

  remove(rsf.dat.large)
  
  knitr::kable(cbind(availables,coef.mat))
```

Let's plot these coefficients by the available sample size

```{r}
plot(availables,coef.mat[,1],lwd=3,xlab="Available Sample Size",ylab="Coeficient",type="b",ylim=c(-1,4))
lines(availables,coef.mat[,2],lwd=3,col=2,type="b")
```


We can see that the first and second decimal place values converge for both coefficients by 2,000,000 available samples. 

Next, lets specifically compare the converged estimated coefficients to estimates when using a 1:1 ratio of used:available.

```{r, comparison}
rsf.dat <- random_points(hr, n = nrow(deer), presence = deer) |> 
             extract_covariates(forest.cover) |>
             extract_covariates(shrub.cover) 

fit = glm(case_~forest+shrub.cover, 
          data=rsf.dat,
          family=binomial(link="logit"))
summary(fit)

# Absolute difference b/w converged and non-converged estimates
(coef.mat[10,] - coef(fit)[2:3])
```

We can see that if we had used a 1:1 ratio of used to available, we would have underestimated the effect of forest and overestimated the effect of shrub cover.

## Assignment (Part 2)

```{r,message=FALSE}
 
### Setup environment
# Include time of day variable
  deer = time_of_day(deer)
  head(deer)
```

### Setup available sample

```{r}
# Create MCP home rnage with 5000 m bufer
hr <- hr_mcp(deer) |> hr_isopleths() |> 
  sf::st_buffer(dist =5000)


# Draw random available samples
  set.seed(5454)
  rsf1 <- random_points(hr, n=20000, presence = deer) |> 
    extract_covariates(forest.cover)  
  table(rsf1$case_)

plot(rsf1)

```
### Create data set with time of day

```{r}
# find where the used locations are and the available locations
  index.1=which(rsf1$case_==1)
  index.0=which(rsf1$case_==0)

# Create a new column for 'time of day', tod
# Put temporary values
  rsf1$tod="temp"

#For the used locations, put in the observed time of day
  rsf1$tod[index.1] = as.character(deer$tod_)
  
#For the available samples make these all 'day'  
  rsf1$tod[index.0] = "day"

#Now, we need to replicate the available sample but for 'night'
  temp = rsf1[index.0,]
  temp$tod="night"

#Combine the used locations, available sample with 'day', and the available sample with 'night'  
  rsf.combined = rbind(rsf1,temp)
```



### Fit Model

```{r glm}
rsf2 = glm(case_~forest*tod, 
           data=rsf.combined,
           family=binomial(link="logit"))
summary(rsf2)
```

First, we know the intercept doesn't mean anything. The effect of forest coefficient is positive and indicates that selection increases with forest cover during the day time (i.e., not night). The `todnight` covariate indicates selection at a forest cover of zero during the night. Since this coefficient is negative, we know that deer are avoiding these open areas during the night. Both those coefficients are statistically clear. The interaction is not statistically clear, and thus there is no statistically clear difference of selection at night versus during the day for increasing forest cover.


### Predictions

```{r pred}

# Create dataframes of covariate combinations
  newdata1 = data.frame(forest = seq(0,1,by=0.1), tod="night")
  newdata2 = data.frame(forest = seq(0,1,by=0.1), tod="day")

# Make sure the intercept is zero and not included in the predictions  
  rsf2$coefficients[1] = 0 
  coef(rsf2)

# Combine linear terms of covariates and coeficients  
  preds.link.night = predict(rsf2,newdata=newdata1, type="link")
  preds.link.day = predict(rsf2,newdata=newdata2, type="link")

  
# Exponentiate linear terms  
  relative.prob.night = exp(preds.link.night)
  relative.prob.day = exp(preds.link.day)

# Plot relative intensity of seleciton by forest cover during the day and night  
  plot(newdata1$forest,relative.prob.night,type="l",lwd=3,xlab="Forest Cover",ylab="Relative Intensity of Selection",ylim=c(0,12))
  lines(newdata2$forest,relative.prob.day,type="l",lwd=3,col=2)
  abline(h=1,lwd=3,col=3,lty=3)
  legend("topleft",lwd=3,col=c(1,2,3),legend=c("Night","Day"))
  text(0.9,1.4,"Selection")
  text(0.9,0.7,"Avoidance")

```

