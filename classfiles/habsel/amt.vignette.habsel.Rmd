---
title: "Resource Selection Functions (RSF) with `amt`"
author: "Johannes Signer (major modifications by BDG)"
date: "2024-10-30"
output: html_document
---

```{r, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


## About

This vignette briefly introduces how one can fit a Resource-Selection Function (RSF) with the `amt` package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map.

## Getting the data ready

First we load the required libraries and the relocation data (called `deer`)

```{r,packages}
  library(amt)
  library(terra)
  library(raster)
  data("deer")
  deer
```


Next, we have to get the environmental covariates. A forest layer is included in the package. Note, that this a regular `SpatRast`. 

```{r, layer1}
# Note, I have made some modifications from the spatial layer provided in the package.
# Plot deer locations on top (i.e., the used sample)
  forest.cover = readRDS("sp.layer.forest")
  plot(forest.cover,main="Forest Cover")
  points(deer$x_,deer$y_,col=0)
  
```

Load a second layer. Notice that this layer has been standardized to a mean of 0 and variance and standard deviation of one. 

```{r,layer2}
  shrub.cover = readRDS("sp.layer.shrub")
  plot(shrub.cover,main="Standaradized Shrub Cover")
  points(deer$x_,deer$y_,col=0)
  
```

## Prepare Data for RSF

### Random Points

Before fitting a RSF we have to do some data preparation. We have to generate random points, points that we think the animal could have used. The random points define the availability domain. In `amt` the function `random_points` is designed to do just that. The function can be used in 3 different ways, depending to the type of object that is passed to the function call. 

1. A `track_*` (such as the `deer` object) can be passed to the function `random_points`. The function then calculates a home range (the home-range estimator can be controlled with argument `hr`). Within this home range `n` random points are generated. The default value of `n` is ten times the number of present points.
2. If a `hr`-object (i.e., the result of a home-range estimation in `amt`) is passed to `random_points`, points are generated within the home range. This allows to generate random points within any home range that was previously estimated in `amt`. Note, that this could be a home range of multiple animals. In this case, the function `random_points` has one additional argument called `presence`. This argument takes a `trk_*` with the presence points and adds these points for convenience to the random points. 
3. A `SpatialPolygons*`-object or `sf`-object. The latter must contain `POLYGON`s or `MULTIPOLYGON`s as features. This can be useful in situation where a home range needs to be buffered, or when other geographical features are considered as the availability domain. As before, this method for `random_points` also takes the argument `presence` to optionally add the observed points to the output.

Lets now illustrate the three different situations. First we take random points from a `track_xy`

```{r, fig.width=4, fig.width=8}
r1 <- random_points(deer)
plot(r1)
```

With the argument `n` we can control the number of random points (remember that the default is ten times as many points as we observed points). 


```{r, fig.width=4, fig.width=8}
r1 <- random_points(deer, n = 100)
plot(r1)
```

Here, we can also add the observed points: 

```{r, fig.width=4, fig.width=8}
hr <- hr_mcp(deer)
r1 <- random_points(hr, n = 500, presence = deer)
plot(r1)
```

Finally, we can work with the home range and for example a buffer and then generate random points within the this new polygon. And we can also add the observed points.


```{r, fig.width=4, fig.width=8}
hr <- hr_mcp(deer) |> hr_isopleths() |> 
  sf::st_buffer(dist =3e4) # add a 30km buffer
r1 <- random_points(hr, n = 500, presence = deer)
plot(r1)
```

Of course we are not restricted to the `sf::st_buffer` function. All geometric operations from the `sf` package can be used to generate arbitrarily complex availability domains. 


### Extract covariates

As the next step we have to extract the covariates at point. We can do this with `extract_covariates`. Buffer MCP home range by 1000 m.

```{r}

hr <- hr_mcp(deer) |> hr_isopleths() |> 
  sf::st_buffer(dist =5000)

set.seed(5454)

rsf1 <- random_points(hr, n=20000, presence = deer) |> 
  extract_covariates(forest.cover)  |> 
  extract_covariates(shrub.cover) 
table(rsf1$case_)

plot(rsf1)

```


## Fitting RSF

Now all pieces are there to fit a RSF. We will use `fit_rsf`, which is just a wrapper around `stats::glm` with `family = binomial(link = "logit")`.

```{r}
rsf1 |> fit_rsf(case_ ~ forest+shrub.cover) |> 
  summary()
```

Fit the same model with the glm function directly

```{r glm}
  rsf2 = glm(case_~forest+shrub.cover, 
             data=rsf1,
             family=binomial(link="logit"))
  summary(rsf2)
```

Let's next interpret the coefficients. For a full understanding, please see

Fieberg, J., Signer, J., Smith, B., & Avgar, T. (2021). A ‘How to’guide for interpreting parameters in habitat‐selection analyses. Journal of Animal Ecology, 90(5), 1027-1043.

We are modeling the relative intensity of selection. Since we are defining the zeros here, it turns out that the intercept has no meaningful interpretation. The intercept is related to the ratio of used to available locations and that's all. We can interpret the slope coefficients! Here, a coefficient at or really close to zero (no statistically clarity) indicate that the variable is being selected for in proportion to available. 


Looking at our results, we can see that the coefficient for percent forest is positive, thus  as percent forest cover increases, the relative intensity of selection increases. In other words, in relative terms, more cover is selected for more than less cover. The opposite is true for the effects of shrub cover, which the coefficient is negative. Remember, this covariate is standardized. As shrub cover increases from the mean, we expect that deer will increasing select for these areas less than available. Also, as shrub cover decreases from the mean, we expect increasing selection to what is available by the deer. 

## Plot Predicted Relative Selection

```{r pred1}
# Decide on covariate values to predict to. Here we will create a plot of how relative intensity of selection
# varies by forest cover at the mean value of shrub cover.

 newdata =  data.frame(shrub.cover=0,forest=seq(0,1,by=0.01))

#Predict to the link scale- do not predict to probability scale, as
#we are actually fitting an exponential linked model
  
  rsf2$coefficients[1] = 0 
  coef(rsf2)

  preds.link = predict(rsf2,newdata=newdata,
                       type="link")
  
  relative.prob = exp(preds.link)
  
plot(newdata$forest,relative.prob,type="l",lwd=3,xlab="Forest Cover",ylab="Relative Intensity of Selection")

```

A common output of interest is the relative selection strength (RSS) between two areas or values of covariate. See, 

Avgar T, Lele SR, Keim JL, Boyce MS. Relative Selection Strength: Quantifying effect size in habitat- and step-selection inference. Ecol Evol. 2017; 7: 5322–5330. https://doi.org/10.1002/ece3.3122

```{r}
# Let's compare the RSS between a location with complete forest cover (1) and no forest cover (0) at the mean value of shrub cover (0).

#See formula in Avgar et al. 2017, section 2.1
  exp(coef(rsf2)[2] * (1-0) + coef(rsf2)[3]*0)

```

This value indicates that there is a 4.15 increase in relative selection at complete forest cover versus no cover. 

Next, lets consider shrub cover relative selection and relative selection strength.

```{r pred2}
# Here we will create a plot of how relative intensity of selection
# varies by shrub cover at the mean value of forest cover.

 newdata =  data.frame(shrub.cover=seq(-3,3,by=0.1),forest=mean(values(forest.cover)))

#Predict to the link scale- do not predict to probability scale, as
#we are actually fitting an exponential linked model
  rsf2$coefficients[1] = 0 
  coef(rsf2)

  preds.link = predict(rsf2,newdata=newdata,
                       type="link")
  
  relative.prob = exp(preds.link)
  
plot(newdata$shrub.cover,relative.prob,type="l",lwd=3,xlab="Forest Cover",ylab="Relative Intensity of Selection")
abline(h=1,lwd=2,lty=3,col=2)
text(2.5, 1.2,"Selection")
text(2.5, 0.8,"Avoidance")
```



```{r pred3}
# Decide on covariate values to predict to. Here we will use all values from both
# covariates, so we can predict relative intesnsity of selection to the whole landscape
 newdata =  data.frame(shrub.cover=values(shrub.cover),forest=values(forest.cover))
#Predict to the link scale- do not predict to probability scale, as
#we are actually fitting an exponential linked model
  
rsf2$coefficients[1] = 0 
coef(rsf2)
  preds.link = predict(rsf2,newdata=newdata,
                       type="link")
  
  relative.prob = exp(preds.link)
  
# Create new spatial layer and then
# plug in the predictions
  preds.map = forest.cover
  values(preds.map) = relative.prob
  plot(preds.map,main="Relative Probability/Intensity of Selection")
  plot(hr$geometry,add=TRUE,lwd=3)
```

Values below 1 indicate avoidance (use less than available) and values greater than 1 indicate selection (use greater than selection). These values are called the relative intensity of selection or relative probability of selection. 

## This model fitting process is sensitive to the size of the available sample

```{r sensitive}
# Draw random available samples (0's) in equal proportion to the number of deer locations
set.seed(5454)
rsf.data1 <- random_points(hr, n = nrow(deer), presence = deer) |> 
  extract_covariates(forest.cover)|>
  extract_covariates(shrub.cover) 

rsf.fit1 = glm(case_~forest+shrub.cover, data=rsf.data1,family=binomial(link="logit"))
summary(rsf.fit1)

```

Note that these estimated slope coefficients are not the same as when fitting the same model using the data from `rsf1` where there are 20,000 available samples. The intercept is very noticeably has the biggest difference, which is something we expect. The intercept is not meaningfully interpretable in this type of model. It essentially represents the ratio of used to available samples. As we increase the available sample, the intercept will get smaller. What we should be concerned about are the slope coefficient estimates. As we increase the available sample, we should see these estimates stabilize, as with their p-values. 



## Our inference is also sensitive to how we define the avilable sample

Remember, we get to decide on what is available to the animal. We need to be very thoughtful how we do this. Above, we fit our model using an available sample extend of the home-range (MCP) buffered by 5000 m. Here are the estimated coeficients:

```{r}
  coef(rsf2)
```


Now, lets decrease the buffer of the home range and look at the coeficients. 

```{r}
hr2 <- hr_mcp(deer) |> hr_isopleths() |> 
  sf::st_buffer(dist =100)

set.seed(5454)

rsf1 <- random_points(hr2, n=20000, presence = deer) |> 
  extract_covariates(forest.cover)  |> 
  extract_covariates(shrub.cover) 

plot(rsf1)

rsf.fit3 = glm(case_~forest+shrub.cover, data=rsf1,family=binomial(link="logit"))

coef(rsf.fit3)

```

