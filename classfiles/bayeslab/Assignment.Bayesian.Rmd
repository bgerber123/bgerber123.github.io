---
title: "Bayesian Assignment"
author: "Brian D. Gerber"
date: "2024-8-27"
output: html_document
---

<style type="text/css">
  body{
  font-size: 12pt;
}
pre{
  font-size: 20px; 
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### **Objective**: To understand Bayesian inference and computation.

### **Background**

In lecture, we were able to draw samples from the posterior distribution of $p$, the probability of hippo survival, because of the conjugacy of the Binomial likelihood and Beta prior probability distribution of $p$.

Another conjugate relationship is between a Poisson likelihood and a Gamma prior probability on $\lambda$ (the mean of the Poisson).

$$
\begin{align*}
\textbf{y} \sim& \text{Poisson}(\lambda)\\
\lambda \sim& \text{Gamma}(\kappa,\theta)
\end{align*}
$$
where, the posterior distribution of lambda is

$$
\begin{align*}
[\lambda|\textbf{y}] \sim& \text{Gamma}(\kappa^*,\theta^*).
\end{align*}
$$

#### **Data**

![](mouselemur.png){width=350px}


I am providing two data sets of counts of Brown mouse lemurs (*Microcebus rufus*) with different sample sizes. We know in the sampling area that this primate is rare. This *prior knowledge* should inform how we specify the prior probability distribution.

### **Part 1**

Fit a Bayesian model to the two data sets provided, each using two different prior distributions on $\lambda$.

Fit the model by sampling from the posterior distribution of $\lambda$ directly (called Gibbs sampling). You can do this by using the [Wikipedia Conjugate Page](https://en.wikipedia.org/wiki/Conjugate_prior) to look up the posterior hyperparameters.

To decide on your two different prior probability distributions, you need to understand the shape ($\kappa$) and scale ($\theta$) parameters of the Gamma distribution. I suggest looking at the [Gamma distribution wikipedia page](https://en.wikipedia.org/wiki/Gamma_distribution), choosing values, and then plotting the distributions. The two prior probability distribution you choose should be a 'highly informative' and a 'low/less informative' prior distribution. Investigate possible prior probability distributions before looking at the data. 

### The markdown should include

-   code of the model fitting

-   Two plots of the prior probability distributions

-   Four plots of posterior distributions (2 for each data set using each of the two priors).

-   A table or list of the posterior means or medians along with 95\% credible intervals, as well as a description of what these intervals mean.

-   A description of how the different priors influenced the first and second data sets. Did each prior have the same importance with each data set? Why? To help understnad the influence of the prior, make sure your plots have the sam x-axis range and you plot a vertical line for the maximum likelihood estimate of the expected/mean counts (which is not influence by the prior). How do we get the mle? Just take the mean of the data or fit a generalized linear model to get the mean of lambda.

### **Part 2**

Here, the goal is to replicate one of the analyses from above (1 data set and 1 set of priors) using JAGS via the r pacakge 'rjags' or Stan via the rpackage 'rstanarm'; if you use rstanarm, setting the priors is rather complicated. For the the purpose of this exercise, it is okay to use the default priors. Looking the attributes of the fitted model object from stan to figure out what the default prior is and plot it. 

For JAGS, you will need to setup a model.jags file that has the likelihood and prior. Note, that the probability density functions in JAGS for Gamma and Poisson are dgamma, and dpois, respectively.

For Stan, use the code provided and adapt it based on what you know from the GLM homework. 

### The markdown should include

-   code of the model fitting

-   A plot of the posterior distribution of lambda .


