{
  "hash": "7c0b9b117cd9093f719c2762fa47774d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle:  <span style=\"color:black\">Big Picture <br> and Probability</span>\ntitle-slide-attributes:\n  data-background-image: /img/thinking.png\n  background-opacity: \"0.45\"\nformat: \n  revealjs:\n    theme: simple\n    slide-number: true\n    show-slide-number: all\n    chalkboard: true\n    multiplex: true\n---\n\n\n## Sections\n\n- Hypotheses and Predictions\n\n- Two frameworks of Sampling\n\n- Inference and Prediction\n\n- Probability and Markdown\n\n## Hypotheses/Predictions\n\n#### Study Objective\n\n#### Hypothesis\n\n#### Prediction\n\n\n## Do we need study designs anymore to do research?\n\n\n```{=html}\n<style type=\"text/css\">\n\nbody, td {\n   font-size: 14px;\n}\ncode.r{\n  font-size: 30px;\n}\n\npre {\n  font-size: 45px;\n}\n</style>\n<br>\n<center>Data is everywhere; it is the era of <span style=\"color:#FF0000\";> BIG DATA </span></center>\n```\n\n![](/img/BigData.png){fig-align=\"center\" width=\"469\"}\n\n## Big Data Problems\n\n<br>\n\n[\"*The hidden Biases of Big Data*\" by Kate Crawford](https://hbr.org/2013/04/the-hidden-biases-in-big-data)\n\n**Harvard Business Review (2013)**\n\n\n\n. . .\n\n\n```{=html}\n<br><span style=\"color:#FF0000\";><center><em>\"Can numbers actually speak for themselves?\"</center></em></span>\n```\n\n![](/img/spreadsheet.png){fig-align=\"center\" width=\"500\"}\n\n## Big Data Problems\n\n<br>\n\n[\"*The hidden Biases of Big Data*\" by Kate Crawford](https://hbr.org/2013/04/the-hidden-biases-in-big-data)\n\n**Harvard Business Review (2013)**\n\n\n\n```{=html}\n<br><span style=\"color:#FF0000\";><center><em>\"Data and data sets are not objective;\"</center></em></span>\n```\n\n. . .\n\n\n```{=html}\n<span style=\"color:#FF0000\";><center><em>\"they are creations of human design.\"</center></em></span>\n```\n\n![](/img/thinking.png){fig-align=\"center\" width=\"459\"}\n\n## Big Data Problems {.scrollable}\n\n<br>\n\n[**The Annals of Applied Statistics (2018); Xiao Li Meng,**](https://projecteuclid.org/journals/annals-of-applied-statistics/volume-12/issue-2/Statistical-paradises-and-paradoxes-in-big-data-I--Law/10.1214/18-AOAS1161SF.full)\n\n\n```{=html}\n<br><center><span><em>The Big Data Paradox: </em></span></center>\n```\n\n\n. . .\n\n\n```{=html}\n<center><span style=\"color:#FF0000\";><em>\n\"the bigger the data, the surer we fool ourselves”</em></span> ... when we fail to account for our sampling process. </center>\n```\n\n\n. . .\n\n<br>\n<center>\nSampling Processes == Human Design\n</center>\n\n. . .\n\n<br>\n\n**What is worse?**\n\n-   a very precise inaccurate result <br>\n-   an accurate imprecise result\n\n\n## Big Data Problems\n\n<br>\n\n![[link](https://www.nature.com/articles/s41586-021-04198-4)](Information_files/survey.data.png){fig-align=\"center\" width=\"1000\"}\n\n. . .\n\n\n```{=html}\n<br><center><span style=\"color:#FF0000\";><em>\"...data quality matters more than data quantity, and that compensating the former with the latter is a mathematically provable losing proposition.\"</em></span>   </center>\n```\n\n## Big Data Problems {.scrollable}\n\nUsing eBird data w/o accounting for sampling biases.\n\n. . .\n\n![](Information_files/ebird.png){fig-align=\"center\" fig-width=\"500\"}\n\n[Link1](https://www.pnas.org/doi/10.1073/pnas.2023170118). [Link2](https://www.pnas.org/doi/10.1073/pnas.2113862119). \n\n. . .\n\n\n```{=html}\n<br><center><span style=\"color:#FF0000\";><em>\"eBird reporting rates also depend heavily on species’ overlap with the activity of eBird users, which also varies by region, time, and habitat.\"</em></span>   </center>\n```\n\n\n. . .\n\n## The Questioning Scientist {.scrollable}\n\n<br>\n\nIn regard to *data* and *statistical models*, [21^st^ century scientists should be pragmatic, excited, and questioning.]{style=\"color:red\"}\n\n::: {.fragment .fade-in-then-semi-out}\n-   How and why did these data come to be?\n    -   *understand the study design*\n    -   *ask this even when you design the study, after data collection*\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n-   What do these data look like?\n    -   *visualize the data in many dimensions*\n    -   *keep in mind - not all outcomes are visible in data -- example?*\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n-   How does this statistical model work?\n    -   *statistical notation, explicit and implicit assumptions*, *optimization*\n:::\n\n::: {.fragment .fade-in-then-semi-out}\n-   How does this statistical model fail in theory and in practice?\n    -   *statistical robustness and identifiability*\n:::\n\n## Data vs. Information\n\n\n```{=html}\n<span style=\"color:#FF0000\";><center>Data = Numbers/Groupings<br><br>\nData ≠ Information\n</center>\n</span>\n```\n\n\n. . .\n\n\n![](Information_files/info_diagram.png){fig-align=\"center\"}\n\n## Information\n\n\n```{=html}\nData contains <span><u>information</u></span>, depending on ...\n```\n\n::: incremental\n-   the question being asked of the data\n-   how the data came to be\n-   the goal of the question\n:::\n\n## The question and the data\n\n<br>\n\nEcological surveillance monitoring will often have *low quality information* regarding post-hoc hypotheses.\n\n<br>\n\n\n```{=html}\n<span style=\"color:#FF0000\";><center>\nExample?\n</center>\n</span>\n```\n\n\n. . .\n\n![](Information_files/banding.png){fig-align=\"center\" width=\"494\"}\n\n## The goal of the question\n\n::: incremental\n-   learn about the data (<span style=\"color:red\">data summary</span>)\n-   apply learning outside of the data (<span style=\"color:red\">inference</span>)\n-   learn about conditions relevant to but not observed in the data (<span style=\"color:red\">prediction</span>)\n:::\n\n<br>\n\n. . .\n\n\n```{=html}\n<center>\n<span style=\"color:#FF0000\";>\n<em>inference</em></span></span> and <span style=\"color:#FF0000\";><em>prediction</em></span> are different goals, <em>optimally</em> requiring different data and statistical models, but  <br>\n</span>\n<br>\nare also <u>not mutually exclusive</u>.\n</center>\n```\n\n## Inference and Prediction \n\n\n```{=html}\n<br>\n<p style=\"font-size:45px; font-family:Garamond;\">\n<a href=\"https://www.jstor.org/stable/27836590\">From \"The strategy of model building in population biology\" by Richard Levins (American Scientists, 1966) </a>:\n</p>\n<br>\n```\n\n```{=html}\n\"It is of course desirable to work with manageable models which maximize generality, realism, and precision toward the overlapping but not identical goals of <span style=\"color:#FF0000\";><u>understanding</u></span>, <span style=\"color:#FF0000\";><u>predicting</u></span>, and <span style=\"color:#FF0000\";><u>modifying nature</u></span>. But this cannot be done.\"\n```\n\n\n## Infernence and Prediction {.scrollable}\n\n\n```{=html}\n<br>\n<p style=\"font-size:45px; font-family:Garamond;\">\n<a href=\"https://projecteuclid.org/journals/statistical-science/volume-25/issue-3/To-Explain-or-to-Predict/10.1214/10-STS330.full\">From \"To Explain or to Predict\" by Galit Shmueli (Statistical Science, 2010)</a>:\n</p>\n```\n\n\nExplanatory modeling focuses on minimizing bias to obtain the most accurate representation of the underlying theory.\n\n<br>\n\n. . .\n\nPredictive modeling focuses on minimizing both bias and estimation variance;\n\n<br>\n\n. . .\n\nthis may sacrifice theoretical accuracy for improved empirical precision.\n\n## Infernence and Prediction\n\n\n```{=html}\n<span style=\"color:#0000FF\";>This leads to a strange result: </span>\n```\n\n<br>\n\n\n```{=html}\nthe <span style=\"color:#FF0000\";>\"wrong\" </span> statistical model can predict better than the correct one.\n```\n\n. . .\n\n<br>\n\n\n```{=html}\n<span style=\"color:#FF0000\";><center>\nWhy?\n</center>\n</span>\n```\n\n\n## Statistical Information {.scrollable}\n\nLet's turn to the field of statistics to understand *Information*\n\n\n<br>\n\n. . .\n\n[Likelihood principle](https://en.wikipedia.org/wiki/Likelihood_principle)\n\nGiven a *statistical model*, all the evidence/information in a sample ($\\textbf{y}$, i.e., data) relevant to model parameters ($\\theta$) is contained in the *likelihood function*.\n\n. . .\n\n[Fisher Information](https://en.wikipedia.org/wiki/Fisher_information)\n\nThe information an observable random variable ($\\textbf{y}$) has about an unknown parameter $\\theta$ upon which the probability of $\\textbf{y}$ $(f(\\textbf{y};\\theta)$ depends.\n\n<br>\n\n. . .\n\n\n```{=html}\n<br><span style=\"color:#FF0000\";><center><em>Information is conditional</center></em></span><br> \n```\n\n. . .\n\nTo learn about $\\theta$ from $\\textbf{y}$, we need to link them together via a special function, $f(\\textbf{y};\\theta)$\n\n## Statistical Information\n\n<br> The pieces:\n\n::: incremental\n-   The sample data, $\\textbf{y}$\n\n-   A probability function for $\\textbf{y}$:\n\n    -   $f(\\textbf{y};\\theta)$\n\n    -   $[\\textbf{y}|\\theta]$\n\n\n\n-   The unknown parameter: $\\theta$\n\n    -   specified in the probability function\n\n:::\n\n## Statistical Information (an example)\n\nWe want to know the proportion of a wetlands that contain a rare plant species. We can not sample the whole area.\n\n![](Information_files/wetlands.png){fig-align=\"center\" width=\"494\"}\n\n## Rare Plant Data\n\nWe randomly select plots and look for our plant.\\\nOur data are\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"1|2,3\"}\ny <- c(0,1,1,1,1,0,1,0,0,0)\nn <- length(y)\nn\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10\n```\n\n\n:::\n:::\n\n\n. . .\n\n<br>\n\n$\\textbf{y}$ is a random variable as it depends on random events.\n\n<br>\n\n. . .\n\nIn this case, when we induced a random selection of sites.\n\n## Probability/Likelihood Function\n\n$f(\\textbf{y};\\theta)$ describes the probability for each $i^{th}$ data, $y_i$. \n\nBut, not just for the data we observed, for all possible data that could be observed.\n\n. . .\n\n**Rules about our data:** <br> $y \\in \\{0,1\\}$,\n\n. . .\n\n\n```{=html}\n<p style=\"font-size:25px\">\nwhere the curly brackets imply discrete values in our \"set\".\n```\n\n. . .\n\n**Not this:** $y \\in [0,1]$,\n\n\n```{=html}\n<p style=\"font-size:25px\">\nwhere the square brackets indicate all real numbers from 0 to 1, including 0 and 1.\n```\n\n\n. . .\n\n**Not this:** $y \\in (0,1)$,\n\n\n```{=html}\n<p style=\"font-size:25px\">\nwhere the parantheses indicate all real numbers from 0 to 1, not including 0 and 1.\n```\n\n\n\n## Probability Function {.scrollable}\n\nTwo outcomes, 0 or 1, so we need two probabilities to describe our random variable.\n\n. . .\n\n$$\n  f(y;\\theta) = [y|\\theta]= \n  \\begin{cases}\n    \\theta     & \\text{if $y = 1$}, \\\\\n    1 - \\theta & \\text{if $y = 0$}.\n  \\end{cases}\n$$\n\n. . .\n\nAlso,\n\n$$\nf(y;\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n$$\n\n. . .\n\nAlso,\n\n$$\n  \\begin{align}\n        P(Y=1) &= \\theta \\\\\n        P(Y=0) &= 1-\\theta  \n  \\end{align}\n$$\n\n\n```{=html}\n<center>\nThis probability function is called ________?\n</center>\n```\n\n## Probability Function\n\nProbabilities, such as our parameter, have rules:\n\n::: incremental\n-   $0 \\leq \\theta \\leq 1$\n\n-   $0 \\leq (1 - \\theta) \\leq 1$\n\n-   $\\theta + (1-\\theta) = 1$\n\n:::\n\n## Probability Function {.scrollable}\n\nHow do we find $\\theta$ for our data?\n\n. . .\n\nWe can use our probability function to calculate the likelihood of a parameter, given our data.\n\n. . .\n\n$$\n\\mathcal{L}(\\theta|y) = \\prod_{i=1}^{n} p(y_{i};\\theta)\n$$\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"2|5|8|11|14|17|20\"}\n#Bernoulli probability function\n  prob.function=function(theta){prod(theta^y*(1-theta)^y)}\n\n#possible probabilities\n  theta.guess=matrix(seq(0.01,0.99,by=0.01))\n\n#implement function\n  likelihood=apply(theta.guess,1,prob.function)\n  \n#Find maximum likelood\n  max.index=which.max(likelihood)\n\n#Theta that maximizes our probability function\n  theta.est=theta.guess[max.index]\n\n#Define other probability\n  q.est <- 1-theta.est\n\n#Alternative estimation\n  theta.est2 <- sum(y)/n\n```\n:::\n\n\n. . .\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](BigPicture_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n## Statistical Information (an example)\n\nLet's combine 1 observation of our random variable, our probability function, and $\\theta$ to quantify the Fisher information ([Link](https://en.wikipedia.org/wiki/Fisher_information#Single-parameter_Bernoulli_experiment)\n):\n\n. . .\n\n\n```{=tex}\n\\begin{align}\nI(\\theta) &= -E\\left[\\frac{\\partial^2}{\\partial\\theta^2}\\text{log}(\\theta^y(1-\\theta)^{1-y}) \\right]\\\\\n\\end{align}\n```\n\n. . .\n\nFor all samples (n), this is reduced to\n\n\n```{=tex}\n\\begin{align}\nI(\\theta) &= \\frac{n}{\\theta(1-\\theta)}\\\\\n\\end{align}\n```\n\n\n\n\n## Statistical Information (an example)\n\nTherefore, for our sample\n\n\n::: {.cell}\n\n```{.r .cell-code}\nI = n/(theta.est*q.est)\nI\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 40\n```\n\n\n:::\n:::\n\n\n. . .\n\nConsider how information varies by $\\theta$ for a given sample size....\n\n## Statistical Information (an example) {.scrollable}\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1|3|5,6|8\"}\nthetas=seq(0.05,0.95,0.1)\n\nInformation <- n/(thetas*(1-thetas))\n\npar(cex.lab=2.5,cex.axis=2.5,mar=c(5,5,2,2))\nplot(thetas,Information,type=\"b\",lwd=8)\n\nabline(v=theta.est,col=2,lwd=8)\n```\n\n::: {.cell-output-display}\n![](BigPicture_files/figure-revealjs/unnamed-chunk-5-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\n## Statistical Information (an example) {.scrollable}\n\nFunny enough, Fisher Information is the reciprocal of the variance of our estimate of $\\theta$,$$Var[\\hat{\\theta}] = \\frac{\\hat{\\theta}  (1-\\hat{\\theta})}{n}$$\n\n## Statistical Information (an example)\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code  code-line-numbers=\"1|3|4,5|6\"}\nthetas=seq(0.05,0.95,0.1)\n\nVar.theta <- (thetas*(1-thetas))/n\npar(cex.main=2.5,cex.axis=2.5,cex.lab=2.5,mar=c(5,5,2,2))\nplot(thetas,Var.theta,type=\"b\",lwd=8)\nabline(v=theta.est,col=2,lwd=8)\n```\n\n::: {.cell-output-display}\n![](BigPicture_files/figure-revealjs/unnamed-chunk-6-1.png){fig-align='center' width=1152}\n:::\n:::\n\n\n. . .\n\nHow does this knowledge about this probability function inform the design of a study?\n\n## Statistics\n\nA field dedicated to observing the real world to gain informational data.\n\n. . .\n\n\n```{=html}\n<span style=\"color:#FF0000\";><center>BUT</center></span>\n```\n\nOften statistics classes only focus on Power Analysis.\n\n. . .\n\n\n```{=html}\nTo obtain <span style=\"color:#FF0000\";>informational data</span> , we need to think about\n```\n\n::: incremental\n-   how our data will be created\n-   our question of the data\n-   a probability function to use and its parameters\n-   the goal of the question\n:::\n\n## Reading\n\n![](Information_files/reading0.png){fig-align=\"left\" width=\"1000\"} \n\n<br>\n\n[Link](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010033)",
    "supporting": [
      "BigPicture_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}