{
  "hash": "06b915d4a5d19e09788bbc5d77d6781a",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Probability Lab\"\nauthor: \"Brian D. Gerber\"\ndate: \"2024-08-02\"\noutput: html_document\n---\n\n\n<style type=\"text/css\">\n\nbody, td {\n   font-size: 16px;\n}\ncode.r{\n  font-size: 16px;\n}\npre {\n  font-size: 16px\n}\n</style>\n\n\n\n\n\n\n\n## Objectives / Exercises\n\n-   Objective 1) Get acquainted with the [Bernoulli/Binomial](https://en.wikipedia.org/wiki/Binomial_distribution) probability mass function (PMF)\n-   Exercise 1a) Evaluate sample size requirements for tagging studies to asses survival\n-   Exercise 1b) Evaluate the robustness of our findings by varying the true value\n\n\\hline\n\n-   Objective 2) Get acquainted with the [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution) PMF\n-   Exercise 2) Evaluate sample size requirements for assessing a species' mean relative abundance\n\n\\hline\n\n-   Objective 3) Get acquainted with a probability function you do not know well and additional markdown features\n-   Exercise 3) Use markdown to create a summary of a chosen probability function\n\n## Objective 1\n\nLets explore the [Bernoulli/Binomial](https://en.wikipedia.org/wiki/Binomial_distribution) probability mass function (PMF). \nImagine doing a tagging study to estimate the survival of [sandhill cranes](https://www.allaboutbirds.org/guide/Sandhill_Crane/overview) \nin New Mexico over the winter. We want to use the PMF to connect the ideas of generating data via a probability distribution that is defined by parameters. \n\nIn this situation, we are interested in simulating samples or observations  (or more generally, generate synthetic data) of where cranes either lived ($y = 1$) or died (*y = 0*) over our period of interest (winter). If we use the Bernoulli PMF our focus is typically on each i$^th$ crane, while if we are interested in the sum of the number of cranes that lived ($\\sum_{i}^n y_i$) than we would use the Binomial PMF. Either way, we need to define the parameter associeted with both function, which is the probability of observing a 1 ($P(Y=1)$), which we will define here as $\\theta$. To make this a useful exercise, we want to decide on $\\theta$ could be *in real life*. \n\nRemember, estimation is turning the process around and having data to inform the parameter. Before we do estimation, we want to understand probability functions through simulating/generating synthetic data so we have a better idea of what we are assuming about our empirical data when we use probability functions to estimate parameters. Plus, this process can help us guide our design of future studies. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define sandhill crane over winter survival probability (P(Y=1))\n theta = 0.8\n```\n:::\n\n\nThe Bernoulli PMF is useful when thinking about a single event, happening once. Remember, this is a limiting case of the Binomial PMF. We will use the same function, but change the inputs.\n\nLets observe/generate a single data point where a crane dies (y = 0) or lives (y = 1). In a sense, we are flipping a theoretical coin with probability theta (i.e., $P(Y = 1) = \\theta$) to observe/sample whether this tagged crane dies or lives.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 1,prob = theta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n\nConsider 10 tagged cranes to get a sample of the number of alive cranes (success' or 1's) at the end of the study\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrbinom(n = 1, size = 10, prob = theta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8\n```\n\n\n:::\n:::\n\n\nNow, consider 10 tagged cranes and you want to keep track of each bird and whether they lived or died (not just the sum of the alive ones).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  rbinom(n = 10, size = 1,prob = theta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 1 1 1 0 1 1 1\n```\n\n\n:::\n:::\n\n  \nNotice that changing the arguments 'size' and 'n' either focuses on the individual event of\n0 and 1's (size = 1) or the sum of the 1's (size > 1). n controls how many of those outputs you would like to have\n\nWhat if we wanted to generate synthetic data of mortality, rather than survival? Well, we just change our setup. Still assuming survival probability is 0.80, than the equivalent mortality probability would be $\\theta = 1 - 0.80 = 0.20$, such the we are saying the probability a crane dies is $P(Y = 1) = \\theta = 0.2$ Now, we can generate data of cranes that have died (1) and that have lived (0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheta = 0.2\nrbinom(n = 10, size = 1,prob = theta)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 0 0 0 0 0 0 0 1 0 1\n```\n\n\n:::\n:::\n\n\nWhat  is `rbinom` really doing? Well, the [code](https://github.com/SurajGupta/r-source/blob/master/src/nmath/rbinom.c) is actually calling a function using the C programming language because it is fast. But, we can understand more simply what the binomial sampling process looks like by using the generic `sample` function.\n\nThe code here defines the outcomes of the stochastic process as either a 0 or 1; `x` is the argument name of the function. We are asking for 10 trials using `size`. The `replace` argument is telling the sampler that we are allowing it sample each outcome (0 and 1) more than one time. Lastly, we are defining the $P(y = 1)$ to be 0.80 and the $P(y = 0)$ to be 0.20. This code replicates the same process as the code above: `rbinom(n = 10, size = 1,prob = theta)`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsample(x = c(1,0),\n       size = 10, \n       replace=TRUE,\n       prob = c(0.8,0.2)\n       )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 1 1 0 1 1 1 1 1 0\n```\n\n\n:::\n:::\n\n\n\n### Exercise 1a\n\nUse your knowledge of the Binomial PMF and investigate the study design trade offs of a tagging study to estimate the survival of sandhill cranes.\nConsider 3 sample sizes of tagged individuals (N): 100, 250, and 500. Define the survival probability as `$\\theta$ = 0.80`. For each sample, estimate the probability\nof survival using the estimator $\\sum(y)/N$, where `y` is the number of alive cranes at the end of the study and `N` is the number of total tagged cranes. \nWe will justify this decision at a later point, but logically this should be a good estimator. For each sample size, you want\nto approximate the sampling distribution of the estimator. Once you have each sampling distribution, \n\n-   display the three sampling distributions on a single plot\n-   evaluate estimator bias and relative bias. Is the estimator biased?\n-   estimate the probability a given sample mean will be within 10% of the true values (`theta`). \n-   determine the most cost efficient number of tags to use such that there is 0.90 probability that a single sample mean is within 10% of the true value\n\nNote: make sure you use enough replicates such that the sampling distribution appears well approximated (i.e., symmetric). \n\n\n::: {.cell}\n\n```{.r .cell-code}\n  n.sim = 5000\n  n = c(100,250,500)\n  theta = 0.8\n  theta.hat=matrix(NA, nrow=n.sim, ncol=length(n))\n\n  theta.hat[,1]=rbinom(n.sim, n[1], theta)/n[1]\n  theta.hat[,2]=rbinom(n.sim, n[2], theta)/n[2]\n  theta.hat[,3]=rbinom(n.sim, n[3], theta)/n[3]\n\n  plot.data = data.frame(theta.hat = c(theta.hat), N = c(rep(\"10\",n.sim),rep(\"100\",n.sim),rep(\"1000\",n.sim)))\n\n\n  ggplot(plot.data,aes(theta.hat,fill=N))+\n     scale_fill_manual(values=c(\"red\",\"blue\",\"green\"))+\n     geom_density(alpha=0.5,binwidth=0.05,position=\"identity\") + \n    theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning in geom_density(alpha = 0.5, binwidth = 0.05, position = \"identity\"):\nIgnoring unknown parameters: `binwidth`\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\nThe estimated bias and relative bias show that the estimator is unbiased. \n\n::: {.cell}\n\n```{.r .cell-code}\nbias = apply(theta.hat,2,mean)-theta\nbias\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.0006680 -0.0000856 -0.0001304\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nr.bias = (apply(theta.hat,2,mean)-theta)/theta\nr.bias\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.000835 -0.000107 -0.000163\n```\n\n\n:::\n:::\n\n\nA sample size of 250 tags is the best choice to minimize costs and meet the objective of having a 0.90 probability of being within 10% of the true value of $\\theta$.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  limits.truth=c(theta-theta*0.05,\n                 theta+theta*0.05\n                 )\n  my.func = function(x){length(which(x>=limits.truth[1] & \n                                     x<=limits.truth[2]))/length(x)\n                        }\n  prob.truth = apply(theta.hat, 2,FUN = my.func)\n  data.frame(n = n, prob = prob.truth)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    n   prob\n1 100 0.7322\n2 250 0.9046\n3 500 0.9780\n```\n\n\n:::\n:::\n\n\n\n### Exercise 1b\n\nWhat if we are wrong about the assumed probability of survival? Well, we can evaluate this assumption! Rather than considering a single truth ($\\theta = 0.80$), we can instead consider a range of true values. This way we can evaluate the **robustness** of our findings. Meaning, if we find that a sample size of 250 meets our objective (0.90 probability of being within 10% of the true $\\theta$) across a range of assumed survival probabilities, we are can be confident in our recommendation of tagging 250 cranes. Keep in mind there is a lot of real world factors we have not accounted for yet! \n\nUsing a sample size of 250, evaluate whether there is at least 0.90 probability of being within 10% of the true $\\theta$ where $\\theta$ varies from 0.80 to 1.0 by increments of 0.05. For example, `theta = seq(0.7, 1, by = 0.05)`.\n\n-   for each value of $\\theta$, generate the sampling distribution of estimates of $\\theta$ and then calculate the probability of being within 10% of that given values of $\\theta$\n-   plot these probabilities on a x-y line graph where the x axis is the true value ($\\theta$) and the y-axis is the estimated probabilities of interest\n-   using the plot, decide whether the findings are robust to the choice of $\\theta$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  n.sim = 5000\n  n = 250\n  theta = seq(0.8, 1, by=0.05)\n  prob.obj=rep(NA, length(theta))\n\n  for(i in 1:length(theta)){\n    theta.hat=rbinom(n.sim, n, theta[i])/n\n    \n    limits.truth=c(theta[i]-theta[i]*0.05,\n                   theta[i]+theta[i]*0.05\n                   )\n\n    prob.obj[i] = length(which(theta.hat>=limits.truth[1] & \n                 theta.hat<=limits.truth[2]))/length(theta.hat)\n  }  \n\n  plot(theta, prob.obj,type=\"b\",lwd=3,ylim=c(0.5,1),\n       xlab=expression(paste(theta)),\n       ylab=\"Probability of Objective\")\n  abline(h=0.90,lwd=3,col=3)\n```\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\nWe see that our objective (green horizontal line) is met or is higher at all values of $\\theta$ ranging from 0.80 to 1.0. \n\n\n## Objective 2\n\nThe [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution) PMF is often the distribution used first when considering count data. For example, counts of plants or animals within a given area. Its always a goog choice when needing to consider rates, such as counts per unit effort. Note that we are not going to think about detection probability at this point. Assuming constant detection probability, we can think of these counts as a measure of relative abundance. \n\nLet's say we are interested in counts of [American Pika](American Pika) in 10x10 m plots throughout boulder fields in the Rocky Mountains. First, we need to define the mean count, defined as $\\lambda$. Then, we need to decide on how many plots to sample (`n`).\n\n\nSample 10 plots, count pika in each, where the true mean is 100.\n\n::: {.cell}\n\n```{.r .cell-code}\nrpois(n = 10, lambda = 100)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1]  90  99  91  96 109  98 100 119 110  99\n```\n\n\n:::\n:::\n\n\nSample 10 plots where the mean is 2\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrpois(n = 10, lambda = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 3 3 1 0 2 2 1 3 0 2\n```\n\n\n:::\n:::\n\n\nWhen considering the Poisson distribution, notice how few plots have zero pika. In ecological and wildlife sampling, zero counts are common for a variety of reasons. This is one reason people tend to model counts with two components - a Poisson distribution and a zero-inflated part. More about this later. \n\nOne of the interesting properties of the Poisson PMF is that it can be fully described with only one parameter ($\\lambda$), which defines the mean and variance as equivalent. This parameter governs the central tendency of the observations and how much it varies.\n\nLets look at this property by simulating 10000 counts and estimating the mean and variance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  set.seed(43243)\n  y = rpois(n = 100000, lambda = 10)\n  mean(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10.00741\n```\n\n\n:::\n\n```{.r .cell-code}\n  var(y)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10.0551\n```\n\n\n:::\n:::\n\n\nSo, when using the Poisson distribution, we need to consider that the mean and variance will be assumed equal. \n\n### Exercise 2\n\nEvaluate the sampling distribution of the estimator $\\sum(y)/N$, where `y` are the counts and `N` is the number of counts. Assuming $\\lambda = 100$, determine how many sample plots are needed such that the probability a sample is within 5% of the mean is at least 95%. Once this is completed, change to $\\lambda  = 25$. How does your evaluation of the sample size change? Do you need the same, more, or less samples to achieve the same objective?\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Define inputs and outputs\n  lambda = 100\n  n = seq(10,500,by=5)\n  n.sim = 10000\n  mean.mat =matrix(NA, nrow=n.sim, ncol=length(n))\n\n# loop over the different sample sizes - n\nfor(i in 1:length(n)){\n  y.temp = matrix(\n                  replicate(n.sim,\n                            rpois(n[i],lambda=lambda)\n                            ), nrow=n[i],byrow = TRUE\n                  )\n  #Estimate mean of each sample\n  mean.temp = apply(y.temp, 2, mean)\n  mean.mat[,i] = mean.temp\n}\n\ndim(mean.mat)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 10000    99\n```\n\n\n:::\n\n```{.r .cell-code}\n#Define 5% around truth\n  limits.truth=c(lambda-lambda*0.025,\n                 lambda+lambda*0.025\n                 )\n\n#Estimate probability of being within 5%\n  probs = apply(mean.mat,2,FUN=function(x){length(which(x>=limits.truth[1] &\n                                                        x<= limits.truth[2]\n                                                        )\n                                                  ) / n.sim \n                                         }\n             )\n\n# Plot the probability versus the sample size\n  plot(n,probs,type=\"l\",lwd=3,col=1)\n  abline(h=0.90,lwd=3,col=3)\n```\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe need 45 samples to achieve our objective.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\nChanging to $\\lambda = 25$, we see that a lot more samples are needed to achieve the same objective (>100).\n\n## Objective 3\n\nThere are a lot of probability functions that are commonly used in wildlife and ecological modeling. Generally, a lot these functions fall within the [exponential family](https://en.wikipedia.org/wiki/Exponential_family) of probability functions. The objective is to become a bit more familiar with a new probability function and to use the nice features of markdown to describe the function and its various properties. \n\n### Exercise 3\n\nCreate a summary of a probability function of your choosing. If you aren't sure pick from here: [Binomial](https://en.wikipedia.org/wiki/Binomial_distribution), [Poisson](https://en.wikipedia.org/wiki/Poisson_distribution), [Log-Normal](https://en.wikipedia.org/wiki/Log-normal_distribution), [Beta](https://en.wikipedia.org/wiki/Beta_distribution), or [Gamma](https://en.wikipedia.org/wiki/Gamma_distribution). If you feel comfortable with these distributions then choose from a long list  of options from [wikipedia](https://en.wikipedia.org/wiki/List_of_probability_distributions).\n\nFollow the example below for the Discrete Uniform probability distribution and ...\n\n-   Define the random variable $y$ that is $iid$ from your distribution\n-   Define the sample space and parameter space for each parameter\n-   Include the equation of the probability density/mass function\n-   Define the expected value (mean) and variance of the distribution (if they exist in closed form)\n-   Visualize (plot outputs) the pdf/pmf using at least 2 sets of parameters \n-   Demonstrate using code how to calculate the probability of data over certain ranges  (e.g. pnorm).\n-   Demonstrate how to find the values of data pertaining to a certain probability (e.g. qnorm).\n-   Plot a small and  large sample from the distribution. Comment on whether the samples looks like the PDF.\n-   Provide an example of what type of data this probability function could be useful for\n\nFor simplicity, use the setup below and swap in code and notation for your chosen probability function. \n\n---\n\n---\n\n\n## Discrete Uniform \nThe discrete uniform distribution defines probabilities for a set of integer values ranging from a lower bound to an upper bound.\n\n$$\ny \\sim \\text{Uniform}(a,b)\n$$\n\n### **Support**\nThe support of the random variable $y$ is\n$$\ny \\in \\{a, a+1,..., b-1, b\\}\n$$\n\nThe support of the parameters $a$ and $b$ are all integers, where $b \\geq a$, and $n = b-a+1$.\n\n### **Probability Function**\n\n$$\nf(y|a,b) = \\frac{1}{n}\n$$\n\n### **Mean/Variance**\n\n$$\nE[y] = \\frac{a+b}{2}\\\\\nVar[Y] = \\frac{n^2-1}{12}\n$$\n\n### **Plotting**\nExample 1\n\n::: {.cell}\n\n```{.r .cell-code}\n#Parameters\n  a=1; b=5\n# Sample Space of RV\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass  \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=3,\n     ylab=\"f(y)\",xlab=c(\"a = 1, b = 5\"))\n     abline(v=(a+b)/2,lwd=3,col=4)\n     legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n```\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nExample 2\n\n::: {.cell}\n\n```{.r .cell-code}\n#Parameters\n  a=10; b=100\n#Sample Space\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass    \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=1,\n     ylab=\"f(y)\",xlab=c(\"a = 10, b = 100\"))\n  abline(v=(a+b)/2,lwd=3,col=4)\n  legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n```\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-18-1.png){width=672}\n:::\n:::\n\n\n### **Probability**\nThe probability of observing samples $\\geq$ 60 when $a$ = 10 and $b$ =100 is,\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Parameters\n  a=10; b=100\n#Sample space\n  x=seq(a,b,by=1)\n  n=length(x)\n#Probability of any one value\n  p=1/n\n  p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01098901\n```\n\n\n:::\n\n```{.r .cell-code}\n#Add probabilities for all the integers >=60\n  length(which(x>=60))*p\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.4505495\n```\n\n\n:::\n:::\n\n\n### **Sampling**\n\n::: {.cell}\n\n```{.r .cell-code}\n#Parameters\n  a=10; b=100\n\n#Sample at different sample sizes\n  sample.size=100\n  sample.size2=10000\n  \n  y=round(runif(sample.size,a,b),digits=0)\n  y2=round(runif(sample.size2,a,b),digits=0)\n\n#plotting samples with True probability\n  par(mfrow=c(1,2))\n  \n  hist(y,main=\"N = 100\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n  \n  hist(y2,main=\"N = 10000\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n```\n\n::: {.cell-output-display}\n![](problab_BDG_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\nEven at a sample size of 10000, the probabilities are still a bit wonky from the truth, but close. Certainly a lot close to the sample size at 100. \n\n### **Ecological Data**\n\nThe discrete uniform is not a very useful probability distribution for data. However, it is commonly used as a prior probability distribution when fitting a model using Bayesian inference for parameters that can only be integers within a given range.\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}