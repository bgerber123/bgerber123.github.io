{
  "hash": "be03550dcd99df98664fff0da4f50659",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Resource Selection Functions (RSF) with `amt`\"\nauthor: \"Johannes Signer (major modifications by BDG)\"\ndate: \"2024-10-30\"\noutput: html_document\n---\n\n\n\n\n\n\n## About\n\nThis vignette briefly introduces how one can fit a Resource-Selection Function (RSF) with the `amt` package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map.\n\n## Getting the data ready\n\nFirst we load the required libraries and the relocation data (called `deer`)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(amt)\nlibrary(terra)\ndata(\"deer\")\ndeer\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 826 × 4\n         x_       y_ t_                  burst_\n *    <dbl>    <dbl> <dttm>               <dbl>\n 1 4314068. 3445807. 2008-03-30 00:01:47      1\n 2 4314053. 3445768. 2008-03-30 06:00:54      1\n 3 4314105. 3445859. 2008-03-30 12:01:47      1\n 4 4314044. 3445785. 2008-03-30 18:01:24      1\n 5 4313015. 3445858. 2008-03-31 00:01:23      1\n 6 4312860. 3445857. 2008-03-31 06:01:45      1\n 7 4312854. 3445856. 2008-03-31 12:01:11      1\n 8 4312858. 3445858. 2008-03-31 18:01:55      1\n 9 4312745. 3445862. 2008-04-01 00:01:24      1\n10 4312651. 3446024. 2008-04-01 06:00:54      1\n# ℹ 816 more rows\n```\n\n\n:::\n:::\n\n\n\n\nNext, we have to get the environmental covariates. A forest layer is included in the package. Note, that this a regular `SpatRast`. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nforest.cover = readRDS(\"sp.layer.forest\")\nplot(forest.cover,main=\"Forest Cover\")\npoints(deer$x_,deer$y_,col=0)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n### Load additinal layer\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshrub.cover = readRDS(\"sp.layer.shrub\")\nplot(shrub.cover,main=\"Standaradized Shrub Cover\")\npoints(deer$x_,deer$y_,col=0)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n## Prepare Data for RSF\n\n### Random Points\n\nBefore fitting a RSF we have to do some data preparation. We have to generate random points, points that we think the animal could have used. The random points define the availability domain. In `amt` the function `random_points` is designed to do just that. The function can be used in 3 different ways, depending to the type of object that is passed to the function call. \n\n1. A `track_*` (such as the `deer` object) can be passed to the function `random_points`. The function then calculates a home range (the home-range estimator can be controlled with argument `hr`). Within this home range `n` random points are generated. The default value of `n` is ten times the number of present points.\n2. If a `hr`-object (i.e., the result of a home-range estimation in `amt`) is passed to `random_points`, points are generated within the home range. This allows to generate random points within any home range that was previously estimated in `amt`. Note, that this could be a home range of multiple animals. In this case, the function `random_points` has one additional argument called `presence`. This argument takes a `trk_*` with the presence points and adds these points for convenience to the random points. \n3. A `SpatialPolygons*`-object or `sf`-object. The latter must contain `POLYGON`s or `MULTIPOLYGON`s as features. This can be useful in situation where a home range needs to be buffered, or when other geographical features are considered as the availability domain. As before, this method for `random_points` also takes the argument `presence` to optionally add the observed points to the output.\n\nLets now illustrate the three different situations. First we take random points from a `track_xy`\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr1 <- random_points(deer)\nplot(r1)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-5-1.png){width=384}\n:::\n:::\n\n\n\nWith the argument `n` we can control the number of random points (remember that the default is ten times as many points as we observed points). \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nr1 <- random_points(deer, n = 100)\nplot(r1)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-6-1.png){width=384}\n:::\n:::\n\n\n\nHere, we can also add the observed points: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhr <- hr_mcp(deer)\nr1 <- random_points(hr, n = 500, presence = deer)\nplot(r1)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-7-1.png){width=384}\n:::\n:::\n\n\n\nFinally, we can work with the home range and for example a buffer and then generate random points within the this new polygon. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhr <- hr_mcp(deer) |> hr_isopleths() |> \n  sf::st_buffer(dist =3e4) # add a 30km buffer\nr1 <- random_points(hr, n = 500)\nplot(r1)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-8-1.png){width=384}\n:::\n:::\n\n\n\nAnd we can also add the observed points.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhr <- hr_mcp(deer) |> hr_isopleths() |> \n  sf::st_buffer(dist =3e4) # add a 30km buffer\nr1 <- random_points(hr, n = 500, presence = deer)\nplot(r1)\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/unnamed-chunk-9-1.png){width=384}\n:::\n:::\n\n\n\nOf course we are not restricted to the `sf::st_buffer` function. All geometric operations from the `sf` package can be used to generate arbitrarily complex availability domains. \n\n\n### Extract covariates\n\nAs the next step we have to extract the covariates at point. We can do this with `extract_covariates`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(5454)\nrsf1 <- deer |> random_points(n=20000, presence = deer) |> \n  extract_covariates(forest.cover)  |> \n  extract_covariates(shrub.cover) \ntable(rsf1$case_)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFALSE  TRUE \n20000   826 \n```\n\n\n:::\n:::\n\n\n\n\n## Fitting RSF\n\nNow all pieces are there to fit a RSF. We will use `fit_rsf`, which is just a wrapper around `stats::glm` with `family = binomial(link = \"logit\")`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsf1 |> fit_rsf(case_ ~ forest+shrub.cover) |> \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nstats::glm(formula = formula, family = stats::binomial(link = \"logit\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.14260    0.05440 -57.770  < 2e-16 ***\nforest       0.15508    0.12828   1.209 0.226676    \nshrub.cover -0.15246    0.04483  -3.401 0.000671 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6950.4  on 20825  degrees of freedom\nResidual deviance: 6931.6  on 20823  degrees of freedom\nAIC: 6937.6\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n## Additional (BDG)\n\n\n### Fit the same model with the glm function directly\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  rsf2 = glm(case_~forest+shrub.cover, \n             data=rsf1,\n             family=binomial(link=\"logit\"))\n  summary(rsf2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = case_ ~ forest + shrub.cover, family = binomial(link = \"logit\"), \n    data = rsf1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -3.14260    0.05440 -57.770  < 2e-16 ***\nforest       0.15508    0.12828   1.209 0.226676    \nshrub.cover -0.15246    0.04483  -3.401 0.000671 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6950.4  on 20825  degrees of freedom\nResidual deviance: 6931.6  on 20823  degrees of freedom\nAIC: 6937.6\n\nNumber of Fisher Scoring iterations: 6\n```\n\n\n:::\n:::\n\n\n\nLet's next interpret the coefficients. For a full understading, please see\n\nFieberg, J., Signer, J., Smith, B., & Avgar, T. (2021). A ‘How to’guide for interpreting parameters in habitat‐selection analyses. Journal of Animal Ecology, 90(5), 1027-1043.\n\nWe are modeling the relative intensity of selection. Since we are defining the zeros here, it turns out that the intercept has no meaningful interpretation. The intercept is related to the ratio of used to available locations and that's all. We can interpret the slope coefficients! Here, a coefficient at or really close to zero (no statistically clarity) indicate that the variable is being selected for in proportion to available. \n\n\nLooking at our results, we can see that the coefficient for percent forest is positive, thus  as percent forest cover increases, the relative intensity of selection increases. In other words, in relative terms, more cover is selected for more than less cover. The opposite is true for the effects of shrub cover, which the coefficient is negative. Remember, this covariate is standardized. As shrub cover increases from the mean, we expect that deer will increasing select for these areas less than available. Also, as shrub cover decreases from the mean, we expect increasing selection to what is available by the deer. \n\n### Plot Predicted Relative Selection\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decide on covariate values to predict to. Here we will create a plot of how relative intensity of selection\n# varies by forest cover at the mean value of shrub cover.\n\n newdata =  data.frame(shrub.cover=0,forest=seq(0,1,by=0.01))\n\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  \n  rsf2$coefficients[1] = 0 \n  coef(rsf2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n```\n\n\n:::\n\n```{.r .cell-code}\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \nplot(newdata$forest,relative.prob,type=\"l\",lwd=3,xlab=\"Forest Cover\",ylab=\"Relative Intensity of Selection\")\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/pred1-1.png){width=672}\n:::\n:::\n\n\n\nA common output of interest is the relative selection strength (RSS) between two areas or values of covariate. See, \n\nAvgar T, Lele SR, Keim JL, Boyce MS. Relative Selection Strength: Quantifying effect size in habitat- and step-selection inference. Ecol Evol. 2017; 7: 5322–5330. https://doi.org/10.1002/ece3.3122\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's compare the RSS between a location with complete forest cover (1) and no forest cover (0) at the mean value of shrub cover (0).\n\n#See formula in Avgar et al. 2017, section 2.1\n  exp(coef(rsf2)[2] * (1-0) + coef(rsf2)[3]*0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  forest \n1.167756 \n```\n\n\n:::\n:::\n\n\n\nThis value indicates that there is a 1.16 increase in relative selection at complete forest cover versus no cover. Not a large difference in relative selection! Also, looking at the statistical clarity, there is not clear evidence that `forest` is selected for or against more than available.\n\nNext, lets conisder shrub cover relative selection and relative selection strength.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Here we will create a plot of how relative intensity of selection\n# varies by shrub cover at the mean value of forest cover.\n\n newdata =  data.frame(shrub.cover=seq(-3,3,by=0.1),forest=mean(values(forest.cover)))\n\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  rsf2$coefficients[1] = 0 \n  coef(rsf2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n```\n\n\n:::\n\n```{.r .cell-code}\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \nplot(newdata$shrub.cover,relative.prob,type=\"l\",lwd=3,xlab=\"Forest Cover\",ylab=\"Relative Intensity of Selection\")\nabline(h=1,lwd=2,lty=3,col=2)\ntext(2.5, 1.1,\"Selection\")\ntext(2.5, 0.9,\"Avoidance\")\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/pred2-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Let's compare the RSS between a location with very low shrub cover (-3) and very high shrub cover (3) at the mean value of forest cover (0).\n\n#See formula in Avgar et al. 2017, section 2.1\n  exp(coef(rsf2)[2] * mean(values(forest.cover)) + coef(rsf2)[3]*(-3 - 3))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  forest \n2.526219 \n```\n\n\n:::\n:::\n\n\n\nAn area with very low shrub cover is much more likely to be selected than high shrub cover with a RSS of 2.5.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Decide on covariate values to predict to. Here we will use all values from both\n# covariates, so we can predict relative intesnsity of selection to the whole landscape\n newdata =  data.frame(shrub.cover=values(shrub.cover),forest=values(forest.cover))\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  \nrsf2$coefficients[1] = 0 \ncoef(rsf2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n```\n\n\n:::\n\n```{.r .cell-code}\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \n# Create new spatial layer and then\n# plug in the predictions\n  preds.map = forest.cover\n  values(preds.map) = relative.prob\n  plot(preds.map,main=\"Relative Probability of Selection\")\n```\n\n::: {.cell-output-display}\n![](amt.vignette.habsel_files/figure-html/pred3-1.png){width=672}\n:::\n:::\n\n\n\nValues below 1 indicate avoidance (use less than available) and values greater than 1 indicate selection (use greater than selection). These values are called the relative intenity of selection or relative probability of selection. \n\n## This model fitting process is sensitive to the number available locations (0's or 'FALSE')\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Draw random available samples (0's) in equal proportion to the number of deer locations\nset.seed(5454)\nrsf.data1 <- random_points(deer, n = nrow(deer), presence = deer) |> \n  extract_covariates(forest.cover)|>\n  extract_covariates(shrub.cover) \n\nhead(rsf.data1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 × 5\n  case_       x_       y_ forest shrub.cover\n* <lgl>    <dbl>    <dbl>  <dbl>       <dbl>\n1 FALSE 4310495. 3444563. 0.0156     -0.969 \n2 FALSE 4314429. 3447738. 0           1.31  \n3 FALSE 4312423. 3447310. 0           0.794 \n4 FALSE 4318130. 3450293. 0.0278      0.963 \n5 FALSE 4311328. 3443957. 0.732       0.0435\n6 FALSE 4312433. 3446426. 0.403       0.656 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(rsf.data1$case_)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFALSE  TRUE \n  826   826 \n```\n\n\n:::\n\n```{.r .cell-code}\nrsf.fit1 = glm(case_~forest+shrub.cover, data=rsf.data1,family=binomial(link=\"logit\"))\nsummary(rsf.fit1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nglm(formula = case_ ~ forest + shrub.cover, family = binomial(link = \"logit\"), \n    data = rsf.data1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)   \n(Intercept)  0.04698    0.07606   0.618  0.53682   \nforest       0.19889    0.17533   1.134  0.25664   \nshrub.cover -0.17372    0.06437  -2.699  0.00696 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2290.2  on 1651  degrees of freedom\nResidual deviance: 2277.7  on 1649  degrees of freedom\nAIC: 2283.7\n\nNumber of Fisher Scoring iterations: 3\n```\n\n\n:::\n:::\n\n\n\nNote that these estimated slope coefficients are not the same as when fitting the same model using the data from `rsf1` where there are 20,000 available samples. The intercept is very noticeably has the biggest difference, which is something we expect. The intercept is not meaningfully interpretable in this type of model. It essentially represents the ratio of used to available samples. As we increase the available sample, the intercept will get smaller. What we should be concerned about are the slope coefficient estimates. As we increase the available sample, we should see these estimates stabilize, as with their p-values. \n\n\n## Assignment\n\nConduct a sensitivity analysis to investigate how many available samples are needed for the slope coeficient estimates to stabilize. Essentially, you want to increase the available sample until the estimated slopes no longer change. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coeficients for the variables 'forest' and 'shurb.cover'. Create a table of coeficient estimates along with the available sample size used. Determine generally when the coefficient estimates stabilize. A common recommendation in the literature is to used a 1:1 ratio between used locations and available samples. If you had only fit the model with this size of available, how would your estimates compare to the estimates you get when using a very large available sample?\n\n### Note\n\nHow you setup this sensitivity analysis will affect your ability to get estimates to converge. For example, if you take separate random samples, it might take a very large number to get the estimates to converge. This is because there is not consistency between random draws. This stochasticity adds some additional variation when estimating. Ideally, we would create systematic samples at smaller and smaller cell sizes\n\n\n",
    "supporting": [
      "amt.vignette.habsel_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}