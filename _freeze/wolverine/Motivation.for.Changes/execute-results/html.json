{
  "hash": "018d0be0f6f717e188afc9b6135ba04d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Motivation for and changes to data in 2017 and 2022 for modeling wolverine occupancy\"\nauthor: \"Jacob S. Ivan\"\ndate: \"2025-05-22\"\noutput: html_document\n---\n\n\n\n\n<style type=\"text/css\">\n  body{\n  font-size: 14pt;\n}\n</style>\n\n\n\n\n\n\n\n\n<br>\n\n**Context:** For the spatial occupancy model used to predict wolverine occurrence, there are two input files for each survey:  One summarizes the visit data (i.e., detection history) for all of the cells we actually surveyed. The second summarizes attributes of all cells in the sampling frame that we are trying to project/predict to with the fitted model. Over the course of the 2 surveys (2017, 2022), we have accumulated 4 input files.  In comparing these files, we found the following anomalies that had to be rectified:\n\n### **CHANGES**\n\n1. At least 3 different datums were used among the files, therefore coordinate fields did not match between some spatial layers.  This is critical because the spatial occupancy model relies on coordinates during the model-fitting process.  This has been rectified and all input files use the same coordinates/coordinate system.  One of the coordinate systems was `USA Contiguous Albers Equal Area Conic USGS.`  Our GIS shop suggested this was most appropriate for the west-wide grid, so that's the one we chose to match to and that's what all \"official\" layers we've built are projected in.\n\n1. We used at least 3 different ID fields to identify cells across the 4 input files.  These have all been matched up via spatial joins and rectified.  We propose using `GRID_ID` field from the layer that depicts all 18,000+ cells that cover the entire western U.S.  This is probably not the ID most have used in the past; from what I've seen most states are using an ID that enumerates only the cells in the wolverine sampling frame. The `GRID_ID` field\" is the only identifier that will work seamlessly moving forward if we need to add states, add provinces, drop cells, add replacement cells, etc.  More on this and a repository for spatial data layers later. \n\n1. The 'habitat' covariate used in the 2017 non-spatial analysis was actually the Copeland et al. 2010 snow model, not the union of that and the Inman et al. 2013 habitat model.  We are pretty sure we meant to use the Copeland+Inman habitat layer as the covariate as that was the one used to define the sampling frame in the first place. This didn't noticeably change the estimates of wolverine occupancy or the estimated coefficient of the habitat covariate by much compared to what we published in the 2020 JWM paper, but it has been updated so it matches the 2022 analysis.\n\n1. Our 2020 manuscript (survey 2017) says we drew a GRTS sample of `n = 185` and missed two cells we actually sampled, thus `n = 183`. In reality, we added some cells beyond the GRTS draw, and missed more than two for a grand total of `n = 188` actually visited.  We can't go back and re-write that paper, but those sentences are incorrect. We'll state them correctly this time around. \n\n1. In the most recent version of our draft manuscript (survey 2022) we were using a version of the 2017 sampling frame that only had `601` cells rather than `633` cells, so the part of the analysis comparing occupancy between years was a bit of an apples and oranges comparison. The discrepancy was an old layer floating around that represented the sampling frame prior to the room of experts adding 32 cells to it at the Salmon meeting. This has been rectified and Katie re-ran the covariates to include those previously missing 32 cells.  \n\n1. Table 2 in the most recent version of the draft manuscript (survey 2022) states there were `n = 151` cells in CO for the 2022 survey.  This is the number for the entire state, but we chose to only survey north of I-70, so the actual number of total cells we picked a sample from was `n = 45`.\n\n1. Table 2 in the most recent version of the draft manuscript (survey 2022) indicates WA sampled 26 cells but one camera failed, so 25 cells total.  The map in figure 1 shows that 14 cells were missed. Due to time constraints these 14 cells weren't coded within CPW PhotoWarehouse, but the cells were sampled, photos reviewed, and no detections occurred. The visit input file for 2022 has been updated to reflect 14 additional cells with zero detections.  We also removed an additional cell that was added by accident.\n\n1. For each year, the \"state\" assigned to each cell in the input file was based on which state submitted the data.  However, for border cells, states help each other out and sometimes cover cells that are technically in the adjoining state.  This resulted in another apples and oranges comparison as the states associated with each cell changed somewhat between surveys, so our occupancy estimates for a given state weren't based on summing the same cells for each survey.  This has been rectified so that the state assigned to a cell is based on the centroid of the cell.  If you prefer some other metric (e.g., majority area in a given state, which might change ownership of a couple of cells), we can do that.  We just need to decide and lock that in.  \n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}