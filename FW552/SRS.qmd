---
title: <span style="color:orange">Simple Random Sampling</span>
title-slide-attributes:
  data-background-image: /img/srs.png
  background-opacity: "0.45"
format:
  revealjs:
    scrollable: true
    slide-level: 1
    theme: simple
    slide-number: true
    show-slide-number: all
    html:
         page-layout: full
---

## [Goal]{style="color:#078BCD;"}


```{=html}
<style type="text/css">

code.r{
  font-size: 30px;
}
</style>
```

```{r,echo=FALSE,warning=FALSE,results='hide'}
library(tidyverse)
library(kableExtra)
library(magrittr)
library(knitr)
```

**Goal:** to know the mean number of boreal toad egg masses per pond in RMNP

- different egg masses per pond is meaningful why?


![](../img/borealtoad.png)


# [SRS]{style="color:#078BCD;"}

## Conceptual Walkthrough

:::: {.columns}

::: {.column width="50%"}

- We have a known population of ponds, N = 6

- We have enough to money for n = 2

- Will use SRS


:::

::: {.column width="50%"}

```{r, echo=FALSE}

ponds = data.frame(matrix(nrow=6,ncol=2))
colnames(ponds)=c("Pond","egg.mass")

ponds$Pond=LETTERS[1:6]
ponds$egg.mass = c(2,6,8,10,10,12)

ponds %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)

```



:::

::::

<!-- ![](../img/borealtoad.png) -->


# [SRS]{style="color:#078BCD;"}

Population Parameters: 

- $\mu = 8$
- $N = 6$
- $\sigma^2 = 12.8$ 

```{r,echo=FALSE}
mu = mean(ponds$egg.mass)
```

# [SRS]{style="color:#078BCD;"}

How many possible unique samples are there (w/o replacement)

$$
{N}\choose{n} 
$$

. . .

$$
\frac{N!}{n!(N-n)!}
$$

. . .

*R*

```{r,echo=TRUE}
choose(6,2)
```



# [SRS]{style="color:#078BCD;"}

What is the probability of any one particular sample?

<br>

. . .

SRS: all samples have the same probability!

<br>

. . .

<span style="color:red">Convenient Sampling</span>: What is the probability of one particular sample?



# [SRS]{style="color:#078BCD;"}

What is the probability pond "A" will be sampled"? Pond "B"?

<br>

. . .

Look at all possible combinations:

```{r, echo=TRUE}
utils::combn(LETTERS[1:6],2)
```


# [SRS]{style="color:#078BCD;"}

```{r, echo=FALSE}
ponds.letters=t(utils::combn(LETTERS[1:6],2))
ponds.numbers=utils::combn(1:6,2)

ponds.all=data.frame(cbind(matrix(1:15,ncol=1),ponds.letters,matrix(ponds$egg.mass[ponds.numbers],ncol=2,byrow = TRUE)))
colnames(ponds.all)=c("Sample.Number","First Pond","Second Pond","First Value","Second Value")

ponds.all %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 20)

```

. . .

What is the probability pond "A" will be sampled"? Pond "B"?

# [SRS]{style="color:#078BCD;"}

Is it okay to not like your random sample and resample?

```{r,echo=TRUE}
sample(LETTERS[1:6],2)
```

. . .

```{r,echo=TRUE}
sample(LETTERS[1:6],2)
```

. . .

```{r,echo=TRUE}
sample(LETTERS[1:6],2)
```

. . .

Yes, but why don't you like it? Maybe SRS is not what you want.

<br>
<br>


# [SRS]{style="color:#078BCD;"}

Consider the sample mean $\hat{\mu}$ for each sample

```{r, echo=FALSE}
#library(kableExtra)
#library(tidyr)
ponds.all$Sample.Mean = apply(matrix(ponds$egg.mass[ponds.numbers],ncol=2,byrow = TRUE),1,mean)

ponds.all$Absolute.Deviation = abs(ponds.all$Sample.Mean-8)

#knitr::kable(ponds.all)


ponds.all %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 20)

```


# [SRS]{style="color:#078BCD;"}

:::: {.columns}

::: {.column width="50%"}

```{r, echo=FALSE}
ponds.simple = data.frame(Sample.Number = ponds.all$Sample.Number,
                          Sample.Mean = ponds.all$Sample.Mean,
                          Deviance.Truth = ponds.all$Sample.Mean-8
                          )
ponds.simple %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 20)

```



:::

::: {.column width="50%"}



$$ \frac{1}{15}\times\sum_{i=1}^{15} (\hat{\mu}_{i}) = 8$$ 


```{r, echo=FALSE,results='hide'}
#result above
mean(ponds.simple$Sample.Mean)
```


$$\sum_{i=1}^N(\hat{\mu}_{i}-\mu) = 0 $$ 

```{r, echo=FALSE, results='hide'}
#result above
sum(ponds.simple$Deviance.Truth)
```


Estimator Bias?

:::

::::

# [SRS]{style="color:#078BCD;" .scrollable}

```{r, echo=FALSE}

temp=data.frame(table(ponds.simple$Sample.Mean))
colnames(temp)=c("Sample.Mean","Frequency")
temp$Relative.Freq= temp$Frequency/sum(temp$Frequency)
temp$Mean.times.Rel.Freq= as.numeric(as.character(temp$Sample.Mean))*temp$Relative.Freq

temp$Sample.Mean=as.character(temp$Sample.Mean)
temp[9,]=c("Sum","15","1","8")

temp$Relative.Freq = as.numeric(temp$Relative.Freq)
temp$Mean.times.Rel.Freq = as.numeric(temp$Mean.times.Rel.Freq)
temp %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"',
        digits = 3) %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)


# temp2=data.frame("SUM",sum(as.numeric(temp$Frequency[1:8])),sum(as.numeric(temp$Relative.Freq[1:8])),sum(as.numeric(temp$Mean.times.Rel.Freq[1:8])))
# colnames(temp2)=NULL
# 
# temp2 %>% 
#   kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
#   kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 40)

```
. . .

$$
E[\mu] = \sum_{q=1}^{Q} p_i \times \hat{\mu}_{i} = 8
$$

- $Q$ = number of unique sample means

- $p_i$ = probability of obtaining a given sample / relative frequency



# [SRS]{style="color:#078BCD;"}

```{r, echo=FALSE}
temp=data.frame(table(ponds.simple$Sample.Mean))
colnames(temp)=c("Sample.Mean","Frequency")
temp$Relative.Freq= temp$Frequency/sum(temp$Frequency)
temp$Mean.times.Rel.Freq= as.numeric(as.character(temp$Sample.Mean))*temp$Relative.Freq

hist(ponds.simple$Sample.Mean,freq=TRUE,breaks=10,
     main="Sampling Distribution",
     xlab="Sample Mean")

```

<!-- . . . -->

<!-- - Sum of deviations = 0 -->
<!-- - Estimator of $\mu$ is unbiased -->
<!-- -  -->

# [Sampling Disribution]{style="color:#078BCD;"}

::: incremental
- Sample mean formula is an <span style="color:red">estimator</span> of the population mean (<span style="color:red">parameter</span> )
- Sample mean is a <span style="color:red">random variable</span> with a sampling distribution
  - sample mean varies from sample-to-sample becasue of the sampling process
- The sampling distribution is specific to an estimator - has known outcomes and relative frequencies of values

:::


# [Sampling Disribution]{style="color:#078BCD;"}

- judge an estimator by its sampling distribution
- What properties do we want?



```{r, echo=FALSE}
hist(ponds.simple$Sample.Mean,freq=TRUE,breaks=10,
     main="Sampling Distribution",
     xlab="Sample Mean")

```



# [Estimator Properties]{style="color:#078BCD;"}

- Precise and unbiased estimator
- Is our estimator precise? 


```{r,echo=FALSE}
hist(ponds.simple$Sample.Mean,freq=TRUE,breaks=10,
     main="Sampling Distribution",
     xlab="Sample Mean")
```

# [Variance of Sampling Distribution]{style="color:#078BCD;"}

```{r,echo=FALSE}
ponds.simple %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 20)
```

```{r,echo=TRUE}
var(ponds.simple$Sample.Mean)
```


# [Population Variance]{style="color:#078BCD;"}

The variance of all sample units

$$
\sigma^{2} = \frac{1}{N-1}\sum_{i=1}^{N} \left(y_{i}-\mu\right)^{2}
$$


$$
\sigma^{2} = \frac{1}{6-1}\sum_{i=1}^{6} \left(y_{i}-8\right)^{2}
$$

```{r,echo=TRUE,results='markup'}
(1/(6-1))*sum((ponds$egg.mass-8)^2)
```

# [Sample Variance]{style="color:#078BCD;"}

**Estimate population variance** from each sample


$$
\hat{\sigma}^{2} = \frac{1}{n-1}\sum_{i=1}^{n} \left(y_{i}-\hat{\mu}\right)^{2}
$$


```{r,echo=TRUE,results='markup'}
var.per.sample = apply(
                       cbind(ponds.all$`First Value`,ponds.all$`Second Value`),
                       1,
                       var
                       )
# Expected value of population variance
  mean(var.per.sample)
```

```{r, echo=FALSE}
#variance for sample mean
mean ( (N-2)/N * var.per.sample/2 )

```

# [Sample Variance]{style="color:#078BCD;"}

```{r,echo=FALSE}
 hist(var.per.sample,xlab="Sample Variance")
 abline(v=mean(var.per.sample),lwd=3)
```


- Unbiased estimate of the population variance.
- Individual values will deviate from the population variance.


# [Connect these two ]{style="color:#078BCD;"}

- **Population variance** - variation among sample units; estimate from sample variance
- **Var. Sampling Distribution** - variance of mean values from each possible sample

# [Connect these two]{style="color:#078BCD;"}

Variance of all units vs variance of all sample means

```{r,echo=FALSE}
par(mfrow=c(2,1))
hist(ponds$egg.mass,freq=TRUE,breaks=10,
     main="",
     xlab="Sample Units (egg masses)")
hist(ponds.simple$Sample.Mean,freq=TRUE,breaks=10,
     main="",
     xlab="Sample Mean")
```

# [Connect these two]{style="color:#078BCD;"}

- As the sample size (n) increases the sample variance declines by **1/n**
- Finite-population correction factor

$$
\left(\frac{N-n}{N}\right)
$$

. . .


$$
E[\text{Sampling Distribution Variance}] = \frac{1}{n} \left(\frac{N-n}{N}\right) \times \text{Population Variance}
$$


# [Connect these two]{style="color:#078BCD;"}

:::{.incremental}

- Sample size (n) = 2
- Total units (N) = 6
- E[pop var] = 12.8
- E[sample dist. var] = 4.27
- 1/n = 0.5
- Finite correction factor = 0.67
- **E[pop var] $\times$ 1/n $\times$ FCF = 4.27**

:::


# [Connect these two]{style="color:#078BCD;"}

$$
E[\text{Sampling Distribution Variance}] = \\\frac{1}{n} \left(\frac{N-n}{N}\right) \times \text{Population Variance}
$$

:::{.incremental}

- As  n--> N, (N-n)/(N) approaches zero.
- n = N then no sampling distribution variance
- n << N then correction factor ~1 and expected sampling distribution variance is related to the population variance by 1/n

:::

# [Connect these two]{style="color:#078BCD;"}

### **Why does this matter?**

# [Connect these two]{style="color:#078BCD;"}

If you know the E[pop var] ...

- you have a mechanism to understand the variation of sample distribution of the means
- the more variation in $y$, the more variation in sampling dist. of means.


# [Sample Size]{style="color:#078BCD;"}

$$
E[\text{Sampling Distribution Variance}]
$$

:::: {.columns}

::: {.column width="30%"}

- n = 2 --> 4.27
- n = 3 --> 2.13
- n = 4 --> 1.06
- n = 5 --> 0.43
- n = 6 --> 0

:::

::: {.column width="70%"}

```{r, fig.width=15}
#sampling distribution of n=4
  ponds.numbers2=t(utils::combn(1:6,4))
  ponds.all2=matrix(ponds$egg.mass[c(ponds.numbers2)],ncol=4,byrow = FALSE)

  ponds.numbers3=t(utils::combn(1:6,6))
  ponds.all3=matrix(ponds$egg.mass[c(ponds.numbers2)],ncol=5,byrow = FALSE)

  
#expected variance of sampling distributiuon

hist(ponds.simple$Sample.Mean,breaks=10,xlim=c(3,12),ylim=c(0,4),xlab="Sample Means",main="Sampling Distributions \n of the Mean",cex = 2,cex.axis=2,cex.lab=2,cex.main=2)
hist(apply(ponds.all2,1,mean),add=TRUE,col=grDevices::adjustcolor("red",alpha.f = 0.5)  ,breaks=10,cex = 2,cex.axis=2,cex.lab=2)
hist(apply(ponds.all3,1,mean),add=TRUE,col=grDevices::adjustcolor("purple",alpha.f = 0.5)  ,breaks=10,cex = 2,cex.axis=2,cex.lab=2)
legend("topleft",legend=c("n=2","n=4","n=5"),col=c("grey",2,"purple"),lwd=5,cex = 2)
abline(v=8,lty=1,col=1,lwd=4)
```
:::

::::

# [Sample Size]{style="color:#078BCD;"}

 Not pond example; When N is large enough . . .


```{r,echo=FALSE}
 sample.mean.fn = function(target,n){
                                     mean(
                                         sample(target,n)
                                          )
                                     }

#z = rnorm(100,100,10)

set.seed(34234)
z=(rgamma(1000,1,0.01))

#random sample many means n= 10
n = 10
  mu.hat1 = replicate(20000,
                     sample.mean.fn(z,n)
                     )
n = 20  
  mu.hat2 = replicate(20000,
                     sample.mean.fn(z,n)
                     )
n = 50  
  mu.hat3 = replicate(20000,
                     sample.mean.fn(z,n)
                     )
n = 100    
  mu.hat4 = replicate(20000,
                     sample.mean.fn(z,n)
                     )
  
  
par(mfrow=c(2,2))
hist(mu.hat1,col=2,breaks=10,freq = TRUE,xlab="Sample Means",main="n = 10",xlim=c(30,200))
abline(v=100,col=1,lwd=3)
hist(mu.hat2,col=grDevices::adjustcolor("red",alpha.f = 0.5),add=FALSE,breaks=10,freq = TRUE,xlab="Sample Means",main="n = 20",xlim=c(30,200))
abline(v=100,col=1,lwd=3)
hist(mu.hat3,col=grDevices::adjustcolor("purple",alpha.f = 0.5),add=FALSE,breaks=10,freq = TRUE,xlab="Sample Means",main="n = 50",xlim=c(30,200))
abline(v=100,col=1,lwd=3)
hist(mu.hat4,col=grDevices::adjustcolor("orange",alpha.f = 0.5),add=FALSE,breaks=20,freq = TRUE,xlab="Sample Means",main="n = 100",xlim=c(30,200))
abline(v=100,col=1,lwd=3)
```

# [Sample Size]{style="color:#078BCD;"}{.scollable}

- Sampling distribution is less variable
- Sampling distribution centers on population mean
- As n increases, the distribution becomes 'Normal'

. . .

This is because of the Central limit theorem (CLT)

- CLT relies on random/prob. based sampling
- leads to parameter unbiasedness
- Does not depend on distribution of samples
- allows estimation of precision of parameters
- allows estimation of confidence intervals


# [The TOTAL]{style="color:#078BCD;"}

*Extrapolate the sample to the total population*

$$
\hat{\tau} = N \times \hat{\mu} = \frac{N}{n}\sum_{i=1}^{n}(y_i)
$$

# [The TOTAL]{style="color:#078BCD;"}

## Back to ponds example

```{r,echo=FALSE}
tau.est = ponds.simple$Sample.Mean * 6
hist(tau.est,main="",xlab="Totals per Sample")
abline(v=sum(ponds$egg.mass),lwd=5,col=1,lty=1)
abline(v=mean(ponds.simple$Sample.Mean) * 6,lwd=5,lty=3,col=3)
legend("topleft",col=c(1,3),legend=c("truth","expectation"),lwd=4)

```


# [The TOTAL]{style="color:#078BCD;"}

Variance of the total

$$
\text{var}(\hat{\tau}) = N\times(N-1) \times \frac{\hat{\sigma}^2}{n}
$$

# [Probabilty of ]{style="color:#078BCD;"}

Whenever you have the sampling distribution, frame *precision* in terms of what matters to you.


```{r,echo=FALSE}
hist(ponds.simple$Sample.Mean * 6,main="",xlab="Totals per Sample")
```

# [Probabilty of ]{style="color:#078BCD;"}

$$
P(\hat{\tau}\leq 2 \times \tau) 
$$

```{r,echo=TRUE}
length(which( tau.est <=  2*48))/length(tau.est)
```

# [Sample Size]{style="color:#078BCD;"}

But what $n$?

- $n$ impacts variation in estimates
- variation in $y$ impacts the influence of $n$
- objective probably impacts $n$ the most
- higher $n$ is not always better


```{r,echo=FALSE, results='hide'}
#Output code into R file
knitr::purl(input="../FW552/SRS.qmd",output="../FW552/SRS.r")
```


<!-- # [Confidence Intervals]{style="color:#078BCD;"} -->

<!-- **Another measure of precision and accuracy!** -->

<!-- . . . -->

<!-- - uses one sample  -->
<!-- - assumes distribution of all possible samples -->
<!-- - provides an estimated interval -->
<!-- - the interval is a measure related to the true population parameter (which is unknow) -->
