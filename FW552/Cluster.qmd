---
title: <span style="color:orange"></span>
title-slide-attributes:
  data-background-image: /img/cluster.png
  background-opacity: "0.45"
format:
  revealjs:
    scrollable: true
#    slide-level: 1
    theme: simple
    slide-number: true
    show-slide-number: all
    html:
         page-layout: full
---


## [Cluster and systematic sampling]{style="color:#078BCD;"}

```{=html}
<style type="text/css">

code.r{
  font-size: 30px;
}
</style>
```

```{r knitr, echo=FALSE,results='hide'}
library(tidyverse)
library(kableExtra)
library(magrittr)
library(knitr)
#knitr::purl(input="../FW552/Cluster.qmd",output="../FW552/Proportions.r")
```

Appear to be opposites

- [Cluster]{style="color:red;"}: units are clumped together
- [Systematic]{style="color:red;"}: units spaced out

. . .

Both partition sampling into *primary* and *secondary* units

. . .

- [Cluster]{style="color:red;"}: primary units consist of cluster of secondary units
- [Systematic]{style="color:red;"}: primary unit consists of secondary units that are arranged via a rule set


## [Cluster and systematic sampling]{style="color:#078BCD;"}


![](../img/cluster2.png)

## [Boreal Toad Case Study]{style="color:#078BCD;"}

:::: {.columns}

::: {.column width="50%"}

```{r, echo=FALSE}
ponds = data.frame(matrix(nrow=6,ncol=2))
colnames(ponds)=c("Pond","egg.mass")

ponds$Pond=LETTERS[1:6]
ponds$egg.mass = c(2,6,8,10,10,12)
ponds$cluster = c(1,2,1,2,3,3)
ponds %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)

```

:::

::: {.column width="50%"}

- N = 3
- $\mu =8$
- n = 1
- $M_i$ = 2 (secondary/primary)
- $M = \sum_{\forall i} M_i$ 
:::

::::

![](../img/borealtoad.png)


## [Cluster Estimators]{style="color:#078BCD;"}

- $i^{th}$ primary and $j^{th} secondary$

$$
y_i = \sum_{j=1}^{M_i} y_{ij}
$$

$$
\bar{y} = \hat{\mu}_{\text{primary}} = \frac{1}{n}\sum_{i=1}^{n} y_{i}
$$

$$
\hat{\tau} = \hat{\sigma}^2_{\mu} = \frac{1}{n-1} \sum_{i=1}^n(y_i -\hat{\mu})^2
$$



## [Boreal toad]{style="color:#078BCD;"}{.scrollable}


#### Cluster sampling scheme A

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterA= c(1,2,3)
cluster.df$member1 = c(2,6,10)
cluster.df$member2 = c(8,10,12)
cluster.df$mean = c(5,8,11)
cluster.df$dev2 = c(9,0,9)
cluster.df$var = c(9,0,9)*1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```


$$\sum_{i=1}^3(\hat{\mu}_{i}-\mu) = 0 $$ 


## [Boreal toad]{style="color:#078BCD;"}{.scrollable}


#### Cluster sampling scheme A

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterA= c(1,2,3)
cluster.df$member1 = c(2,6,10)
cluster.df$member2 = c(8,10,12)
cluster.df$mean = c(5,8,11)
cluster.df$dev2 = c(9,0,9)
cluster.df$var = c(9,0,9)*1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```


$$
E[\hat{\sigma}^{2}_{\mu}] = 3\\
$$


## [Cluster Sampling]{style="color:#078BCD;"}

Superficial resemblance to stratification: 'clustered' sample units are grouped like a stratum

**Selection process is different**

- [stratification]{style="color:#078BCD;"}: every strata is part of the sampling process
    - not all units in each strata are sampled
- [cluster]{style="color:#078BCD;"}: select among clusters in same way as SRS
    - then observe all units within cluster

. . .

**Cluster sampling is really SRS applied to groups of population members**


## [Cluster sampling scheme B]{style="color:#078BCD;"}

*Make cluster of similar values*

```{r, echo=FALSE}
ponds = data.frame(matrix(nrow=6,ncol=2))
colnames(ponds)=c("Pond","egg.mass")

ponds$Pond=LETTERS[1:6]
ponds$egg.mass = c(2,6,8,10,10,12)
ponds$clusterB = c(1,1,2,2,3,3)
ponds %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)

```

## [Cluster sampling scheme B]{style="color:#078BCD;"}

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterB= c(1,2,3)
cluster.df$member1 = c(2,8,10)
cluster.df$member2 = c(6,10,12)
cluster.df$mean = c(4,9,11)
cluster.df$dev2 = c(16,1,9) 
cluster.df$var = c(16,1,9)  *1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```

$$\sum_{i=1}^3(\hat{\mu}_{i}-\mu) = 0 $$ 

## [Cluster sampling scheme B]{style="color:#078BCD;"}

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterB= c(1,2,3)
cluster.df$member1 = c(2,8,10)
cluster.df$member2 = c(6,10,12)
cluster.df$mean = c(4,9,11)
cluster.df$dev2 = c(16,1,9)
cluster.df$var = c(16,1,9)  *1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```


$$
E[\hat{\sigma}^{2}_{\mu}] = 8.67
$$


## [Cluster sampling scheme C]{style="color:#078BCD;"}

*Make clusters of dissimilar values*

```{r, echo=FALSE}
ponds = data.frame(matrix(nrow=6,ncol=2))
colnames(ponds)=c("Pond","egg.mass")

ponds$Pond=LETTERS[1:6]
ponds$egg.mass = c(2,6,8,10,10,12)
ponds$clusterC = c(1,2,3,3,2,1)
ponds %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)

```

## [Cluster sampling scheme C]{style="color:#078BCD;"}

*Make clusters of dissimilar values*

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterC= c(1,2,3)
cluster.df$member1 = c(2,6,8)
cluster.df$member2 = c(12,10,10)
cluster.df$mean = c(7,8,9)
cluster.df$dev2 = c(1,0,1)  
cluster.df$var = c(1,0,1)  *1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```


$$\sum_{i=1}^3(\hat{\mu}_{i}-\mu) = 0 $$ 


## [Cluster sampling scheme C]{style="color:#078BCD;"}

*Make clusters of dissimilar values*

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterC= c(1,2,3)
cluster.df$member1 = c(2,6,8)
cluster.df$member2 = c(12,10,10)
cluster.df$mean = c(7,8,9)
cluster.df$dev2 = c(1,0,1)
cluster.df$var = c(1,0,1)  *1/(3-1)
cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```



$$
E[\hat{\sigma}^{2}_{\mu}] = 0.67
$$


## [Cluster sampling scheme D]{style="color:#078BCD;"}

*Clusters of dissimilar values and size*

```{r, echo=FALSE}
ponds = data.frame(matrix(nrow=6,ncol=2))
colnames(ponds)=c("Pond","egg.mass")

ponds$Pond=LETTERS[1:6]
ponds$egg.mass = c(2,6,8,10,10,12)
ponds$clusterD = c(1,1,1,2,2,3)
ponds %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)

```

## [Cluster sampling scheme D]{style="color:#078BCD;"}

*Clusters of dissimilar values and size*

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterD= c(1,2,3)
cluster.df$member1 = c(2,10,12)
cluster.df$member2 = c(6,10,NA)
cluster.df$member3 = c(8,NA,NA)
cluster.df$mean = c(5.33,10,12)

cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```

- mean(c(5.33,10,12)) = 9.11
- 9.11 - 8 = 1.11 (biased)

## [Cluster sampling scheme D]{style="color:#078BCD;"}

*Need to incorporate cluster size*

```{r, echo=FALSE}
cluster.df=NULL
cluster.df$clusterD= c(1,2,3)
cluster.df$mean = c(5.33,10,12)
cluster.df$clusterSize = c(3,2,1)
cluster.df$SizeXMean = c(16,20,12)
cluster.df$divide.avg.cluster.size = c(8,10,6)
cluster.df$dev2 = c(0,4,4)
cluster.df$var = c(0,4,4)*1/(3-1)

cluster.df=data.frame(cluster.df)
cluster.df %>% 
  kable(table.attr = 'data-quarto-disable-processing="true"') %>% 
  kableExtra::kable_styling(bootstrap_options = c("striped"), full_width = FALSE,font_size = 30)
```

- mean(c(8,10,6)) = 8
- 8 - 8 = 0 (unbiased)
- $\hat{\sigma}^{2} = 1.33$

## [Variable-sizeed clusters]{style="color:#078BCD;"}

**We randomly select the primary units**

- the number of secondary units may be quite different and not in our control (i.e., random variable)

<br>

. . .

You want to know something about households

- sample home addresses (building is cluster; primary unit)
- the number of secondary units depends on building type 
    - single-family house, condo/duplex, apartment complex


## [Cluster sampling]{style="color:#078BCD;"}

- Maximize precision by forming clusters that have varying values within secondary units
- Overall cluster values (e.g., mean) are similar (aggregated secondary units)

## [But....]{style="color:#078BCD;"}


In our field we often think of forming clusters by location

. . .

<br>

**First Law of Geography**: "*everything is related to everything else, but near things are more related than distant things*." - Waldo Tobler

. . . 

<br>

This contradicts the principal and utility of cluster sampling.

## [Cluster sampling]{style="color:#078BCD;"}

But also need to consider costs b/w SRS and cluster.

. . .

**Which do you think is more likely to less costly?**


<!-- ## [Cluster sampling vs SRS]{style="color:#078BCD;"} -->

<!-- ![](../img/mushroom.png) -->

<!-- Colleague wants to take a sample of n = 100 plots to measure *mushroom abundance* -->

<!-- ## [Cluster sampling vs SRS]{style="color:#078BCD;"} -->

<!-- - Could take random sample of 100 plots -->
<!-- - Could take random sample of 50 clusters (primary) with 2 plots each (secondary). -->

<!-- **WHAT DO YOU RECOMMEND?** -->



## [Pika Case Study]{style="color:#078BCD;"}

We are interested in the total population size of pika across 10 mountains

![](../img/pika2.png)

## [Pika Case Study]{style="color:#078BCD;"}

**Goal:** Compare Cluster and SR sampling

. . .

- 10 Mtns
- Each mtn can be divide into 100 plots based on talus slopes (piles of rocks and boulders)
- a total (N) of 10 x 100 sample units (in a SRS sense).

. . .

- we expect the most deviation to occur across mountains, rather than in them.
- we will cluster our samples across mountains (aggregate plots across mtns)

## [Pika Case Study]{style="color:#078BCD;"}

```{r, echo = TRUE}
# Simulate a true population
  N.plots= 100 # talus slope plots
  N.mtns= 10 # mtns

# Create matrix of counts
  pop = matrix(NA, N.plots, N.mtns)

# Consider each mtn has a different mean abundance
# This forces the mtns to vary in pika abundance
  mu = seq(1,100,length.out = N.mtns)

# Loop over each mountain and draw N.plots random values from that specific mean
# log transform the mean and the exponentiate then round to make them counts 
# and to ensure values are never negative
for(j in 1:N.mtns){
  set.seed(143453543+j)
  pop[,j] = round(
                  exp(
                      rnorm(N.plots,
                            log(mu[j]),
                            0.1
                            )
                      ),
                  digits=0
                  )
}
```


## [Pika Case Study]{style="color:#078BCD;"}

```{r,echo=FALSE}
fields::image.plot(matrix((data=pop), ncol=10, nrow=100),
                   axes=F, xlab="Plot #",
                   ylab="Mtn #")
axis(2, at=seq(0,1,length.out=10),lab=1:10)
axis(1, at=seq(0,1,length.out=100),lab=1:100)

```

- SRS $n = 100$ random units

## [Pika Case Study]{style="color:#078BCD;"}

```{r,echo=FALSE}
fields::image.plot(matrix((data=pop), ncol=10, nrow=100),
                   axes=F, xlab="Plot #",
                   ylab="Mtn #")
axis(2, at=seq(0,1,length.out=10),lab=1:10)
axis(1, at=seq(0,1,length.out=100),lab=1:100)

```

- clusters are columns 


## [Pika Case Study]{style="color:#078BCD;"}

```{r,echo=FALSE}
fields::image.plot(matrix((data=pop), ncol=10, nrow=100),
                   axes=F, xlab="Plot #",
                   ylab="Mtn #")
axis(2, at=seq(0,1,length.out=10),lab=1:10)
axis(1, at=seq(0,1,length.out=100),lab=1:100)

```

- $N_\text{Primary Cluster} = 100$ with $N_\text{Secondary} = 10$ 
- $n_\text{Primary Cluster} = 10$ with $n_\text{Secondary} = 10$ 


## [Pika Case Study]{style="color:#078BCD;"}

```{r,echo=FALSE}
# Get true population parameters
  mu = mean(pop)
  tau = sum(pop)
```

- **The same number of total units are sampled:  100**

- $\mu =$ `r mu`

- $\tau =$ `r options(scipen=999); tau`

## [Setup Simulation]{style="color:#078BCD;"}

```{r,echo=TRUE}
# SRS
  # Total number of secondary sample units for SRS
    N = N.plots*N.mtns
  # Sample size of secondary units for SRS  
    n=100

# Clusters
   # Number of primary units (plot across mtns)
    N.primary = 100

  # Plots per cluster (mtn); seconary unit
    N.secondary = 10
```

  


## [SRS]{style="color:#078BCD;"}

```{r,echo=TRUE}
#Number of simulated studies / replicate samples  
n.sim= 10000
  
# Create SRS function  
srs.fun = function(pop){
  
  # Get a sample of indices
  index=sample(1:(N.plots*N.mtns),size=n)
  
  # Use those indices to get our population counts in each sample unit
  y = c(pop)[index]
  
  #Total estimate
  tau.est=mean(y)*N
  
  #Standard deviation of total 
  tau.sd=sqrt(N*(N-n)*(var(y)/n))

  list(tau.est=tau.est,
       tau.sd=tau.sd)
}

# replicate!
srs.total.dist=replicate(n.sim, srs.fun(pop))

```


## [SRS]{style="color:#078BCD;"}

```{r}
hist(unlist(srs.total.dist[1,]),
     main="SRS Tau Estimate",xlab="Total Population Size")
abline(v=tau,col=2,lwd=3)
```

$\sigma_{\hat{\tau},SRS} =$ `r round(sd(unlist(srs.total.dist[1,])),digits=2)`

## [Cluster]{style="color:#078BCD;"}

```{r,echo=TRUE}
cluster.fun = function(pop){
  #Get index of plots (clusters) to sample across mtn rnages and sample all within that cluster
  index=sample(1:N.primary, size = 10)
  
  y = pop[index,] # this is 10x10 (total of 100 sample units)
  y.sum = apply(y,1,sum)
  
  tau.est = N.primary*mean(y.sum)

  #Standard deviation of total 
  var.primary= var(y.sum)
  tau.sd = sqrt(N.primary*(N.primary-N.secondary)*(var.primary/N.secondary))
  
  list(tau.est=tau.est,
       tau.sd=tau.sd)
    
}

# Replicate!!!!
  cluster.total.dist=replicate(n.sim, cluster.fun(pop))
```

## [Cluster]{style="color:#078BCD;"}

```{r}
  hist(unlist(cluster.total.dist[1,]),breaks=20,
         main="Tau Estimate")
  abline(v=tau,col=2,lwd=3)
```

$\sigma_{\hat{\tau},Cluster} =$ `r round(sd(unlist(cluster.total.dist[1,])),digits=2)`

## [SRS vs Cluster]{style="color:#078BCD;"}

```{r,echo=FALSE}
  hist(unlist(srs.total.dist[1,]),breaks=20,
         main="Tau Estimate",xlab="Population Estimate")
  abline(v=tau,col=2,lwd=3)
  # Add plot of Cluster
  hist(unlist(cluster.total.dist[1,]),
       col=grDevices::adjustcolor("red",alpha.f=0.1),
       breaks=20,
       add=TRUE)
```


## [SRS vs Cluster]{style="color:#078BCD;"}


```{r,echo=FALSE}
  hist(unlist(srs.total.dist[2,]),breaks=20,
         main="Tau Variance",xlim=c(0,4000),xlab="Population Variance")
  abline(v=tau,col=2,lwd=3)
  # Add plot of Cluster
  hist(unlist(cluster.total.dist[2,]),
       col=grDevices::adjustcolor("red",alpha.f=0.1),
       breaks=20,
       add=TRUE)

```

## [Why did Clusters work so well?]{style="color:#078BCD;"}

Thompson pg. 137: "The relative efficiency of the cluster (or systematic) sample to the simple random sample of equivalent sample size, defined as the ratio of variances",

$$
\frac{\text{var}(\tau_{srs})}{\text{var}(\tau_{\mu})} = \frac{\text{var}(\text{across all values in population})}{\text{var}(\text{across secondary units})}
$$

. . .

#### Numerator

```{r}
var(c(pop))
```

#### Denominator

```{r}
var(apply(pop,1,sum))
```


## [Take home]{style="color:#078BCD;"}

Cluster sampling will lead to more precise estimates than SRS (at the same sample size) when units within clusters vary more than on average than do the units in the whole sampling frame. 

<br>

. . .

The greater variation within clusters, the grater precision of cluster sampling; **opposite of stratified sampling**

<br>



## [Take home]{style="color:#078BCD;"}

**Beware**

<br>

Clusters require good knowledge of the system. 

A poor choice could lead to increasing sampling distribution variance. 


## [Systematic Sample]{style="color:#078BCD;"}

![](../img/ferret.png)

Black-footed ferret breeding program for release into the wild.

. . .

- 10 groups of 10 animals (separate colonies)
- each as a number 1 to 10


## [Systematic Sample]{style="color:#078BCD;"}

*How do we choose which two individuals to release into the wild?*

- randomly select a number... 3
- randomly select a new number w/o replacement... 7

. . .

You systematically have selected individual 3 and 7 for release from each colony/group.


## [Systematic Sample]{style="color:#078BCD;"}

![](../img/systematic.grid.png)

- people like the "spatial balance"

## [Systematic Sample]{style="color:#078BCD;"}

- Can be biased
    - plots may be more dissimilar than random
      - mean is unbiased
      - variance is too large
    - periodicity (ridge/valley/ridge...)
      - mean is biased
      - variance is underestimated
      