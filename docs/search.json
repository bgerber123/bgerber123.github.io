[
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Download current CV"
  },
  {
    "objectID": "photography/index.html",
    "href": "photography/index.html",
    "title": "Photography",
    "section": "",
    "text": "As a wizard and scholar of Middle-earth, I have been studying the magic of the natural world for centuries. Through my self-portraits, I aim to capture the essence of my own being and reflect on my own journey through time. Each photograph is a reflection of my own experiences and emotions. Through my photography, I hope to offer a glimpse into my life as a scholar and adventurer, and inspire others to reflect on their own journeys through the world.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Current Projects",
    "section": "",
    "text": "Using unmarked modeling to estimate New England Cottaintail Abundance\nObjectives 1) Use eBird occurrence and richness predictions to evaluate spatial overlap with predicted renewable energy development in Colorado, and 2) create a decision tool to evaluate tradeoffs in optimizing renewable energy development areas that minimizes conflicts with birds.\nTeam: Jonathon Crossley (M.S. Student), Brian Gerber (PI), and Casey Setash from Colorado Parks and Wildlife.\n\n\nUsing unmarked modeling to estimate New England Cottaintail Abundance\nObjectives 1) Evaluate the attributes of the spatial count statistical model to estimate abundance using simulation, and 2) integrate spatial count and telemetry data to estimate the abundance of New England cottontails to inform translocation decisions.\nTeam: Edwige Bellier (Postdoctoral Researcher), Amy Mayer (Research Associate), Brian Gerber (PI), David Kalb, and Dylan Ferreira and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nSemi-Aquatic Mammal Distribution in Rhode Island\n\nObjective: To understand the limiting factors associated with the distribution of muskrats, beavers, and river otters in Rhode Island.\nTeam: John Crockett (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nAnimal Diel Ecology\n\nObjective: 1) To understand how wild animal’s change their activity and behavior across the 24-hour light-dark cycle to carryout their life history strategy and 2) to develop flexible and conceptually-based modeling approaches to make inference and predictions on animals diel activity use and selection."
  },
  {
    "objectID": "projects/index.html#the-languages-of-middle-earth",
    "href": "projects/index.html#the-languages-of-middle-earth",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint | Code\nOver the centuries, I have devoted countless hours to deciphering and translating the ancient scripts and dialects of the various peoples of Middle-earth. My goal is to gain a deeper understanding of the cultures and histories of these peoples by studying their languages. Currently, I am working on a monograph that explores the linguistic roots of the Elvish languages. Through extensive research and analysis, I hope to shed light on the connections between the different dialects of Elvish and their origins. This project has been particularly challenging, as Elvish is a complex and nuanced language, but I am determined to see it through to completion."
  },
  {
    "objectID": "projects/index.html#the-history-of-the-war-of-the-ring",
    "href": "projects/index.html#the-history-of-the-war-of-the-ring",
    "title": "Projects",
    "section": "The History of the War of the Ring",
    "text": "The History of the War of the Ring\n\narXiv Preprint | Code\nI am creating a comprehensive and detailed history of the conflict that goes beyond the surface-level events. By gathering information from a variety of sources, including my own memories, written accounts, and oral histories, I hope to shed new light on this important period in Middle-earth’s history and provide valuable insights into the motivations and actions of the various players involved.\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Who and What",
    "section": "",
    "text": "Scholar\n  \n  \n    \n     RG\n  \n  \n    \n     Github\n  \n  \n    \n     Email\n  \n\n\n\n\nWho and What\nI am a research scientist with the United States Geological Survey (USGS), Assistant Unit Leader at the Colorado Cooperative Fish and Wildlife Research Unit, and an Associate Professor in the Department of Fish, Wildlife, and Conservation Biology and a faculty member of the Graduate Degree Program in Ecology at Colorado State University.\nMy focus is on collaborative science:\nWith my lab and colleagues - we work with scientists and resource and land managers to help learn through data to provide inferential or predictive knowledge or decision-support that is used for empirically informed conservation management of biodiversity.\n\nOur research focus includes\n\nWildlife Population Demography and Distribution\nConservation Decision Making\nAnimal Behavior (especially on the diel niche)\nHierarchical Bayesian Modeling\nAnimal Movement and Habitat Selection\nOptimal Prediction via Statistical Regularization\n\n\n\n\nNews\n\nNovember, 2024\n\nNew OA Publication: A ‘how-to’ guide for estimating animal diel activity using hierarchical models from Dr. Fabiola Iannarilli on improving the modeling of animal diel activity. Data and code can be viewed online here, downloaded here at Github, and archived at DRUM and USGS.\n\n\n\nOctober, 2024\n\nMaria Carolina T. D. Belotti from Colorado State University presents at the American Ornithological Society’s Annual Meeting in Estes Park, CO. Title: Comparison of swallow and martin population trends from three large-scale data sources.\nBrian presents at the 31\\(^{st}\\) annual Wildlife Society Conference in Batlimtore, MD. Title: A framework to define and estimate animal diel activity.\nNew Publication: Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines from John Crockett on Muskrat and wetland change in Rhode Island, USA. Download. Data and code can be found at Zenodo.\nNew OA Publication: Fisher activity patterns show potential for behavioral adaptations to human modified landscapes from Dr. Laken Ganoe on spatial, temporal, and demographic effects on fisher activity levels. Data and code can be found at Zenodo.\n\n\n\nAugust, 2024\n\nBrian co-instructed an Introduction to R workshop with Georgia Titcomb and Kyle Horton at CSU for graduate students and state and federal agencies.\nNew Publication: Habitat selection of non-breeding American black ducks in an urban estuary from Tori Mezebish Quinn on the influence of shellfish aquaculture on the spatial ecology of American black ducks. Download.\nNew OA Publication: Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes from Kim Rivera on using hierarchical modeling to understand how people in Rhode Island value coyotes. Data and code can be found at GitHub.\n\n\n\nJuly, 2024\n\nNew OA Publication: Mesocarnivore sensitivity to natural and anthropogenic disturbance leads to declines in occurrence and concern for species persistence from Dr. Laken Ganoe on mesocarnivore response to disturbance in Rhode Island, USA. Data and code can be found at Zenodo.\n\n\n\nJune, 2024\n\nNew OA Publication: A statistical population reconstruction model for wildlife populations: A case study with white-tailed deer and fisher from Dr. Edwige Bellier on a novel hierarchical Bayesian model to recover population variables from age-at-harvest data. Code and data can be found on FigShare.\nBrian presents at the 103rd American Society of Mammalogists meeting in Boulder, CO.\nTitle: A framework to define and estimate animal diel activity.\nBrian co-instructs a 10-day short course ‘Bayesian Model for Ecologists’ at Colorado State University along with Drs. Tom Hobbs, Mevin Hooten, Becky Tang, and Alison Ketz. This is an NSF funded course (Award 2042028).\n\n\n\nApril, 2024\n\nLaken Ganoe passes her dissertation defense! and Nicole Defelice passes her thesis defense!\n\n\n\nMarch, 2024\n\nNew OA Publication: Influence of resource gradients and habitat edges on density variation in tiger populations in a multi-use landscape from Dr. Pranav Chanchani examining drivers of Bengal Tiger populations.\n\n\n\nFebruary, 2024\n\nBrian travels to Norway to be an external PhD examiner at the Norwegian Univeristy of Life Sciences and visits the Norwegian Institute for Nature Research.\n\n\n\nJanuary, 2024\n\nNew OA Publication: A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package from the Global Animal Diel Activity Project. Download. We propose a conceptual and modeling framework to connect data and hypotheses to make inference about animal diel phenotypes (e.g., diurnal, nocturnal). The Diel.Niche R package can be found on Github and a shiny version can be found here. We also wrote a blog about our paper that is intended for a more general audience.\n\n\n\nPast News"
  },
  {
    "objectID": "index.html#november-2023",
    "href": "index.html#november-2023",
    "title": "News",
    "section": "November, 2023",
    "text": "November, 2023\nNew Publication: Diel activity structures the occurrence of a mammal community in a human-dominated landscape led by Amy Mayer.\n\nSeptember, 2023: New Publication: Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains\nAugust, 2023: I officially started with the Colorado Cooperative Fish and Wildlife Research Unit. Prior, I was an associate professor at the University of Rhode Island in the Department of Natural Resources Science.\n\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "projects/index.html#project-1",
    "href": "projects/index.html#project-1",
    "title": "Projects",
    "section": "",
    "text": "arXiv Preprint | Code\nText"
  },
  {
    "objectID": "projects/index.html#project-2",
    "href": "projects/index.html#project-2",
    "title": "Projects",
    "section": "Project 2",
    "text": "Project 2\n\narXiv Preprint | Code\ntext"
  },
  {
    "objectID": "lab/index.html",
    "href": "lab/index.html",
    "title": "Lab",
    "section": "",
    "text": "Current\n\nLibby Mojica, PhD Student. Co-advised with Dr. Liba Pejchar. Researching the spatial ecology of Ferruginous hawk.\nDr. Edwige Bellier, Postdoctoral Researcher. Developed hierarchical Bayesian stochastic population reconstruction models to learn about fisher and white-tailed deer population demography. Currently working on evaluating the robustness of spatially explicit encounter models to estimate the population size of New England Cottontails.\nAmy Mayer, Research Associate. Amy does everything. Currently focused on estimating white-tailed deer populations in Rhode Island via forward-looking infrared aerial surveys.\nJohn Crockett, PhD Candidate. Researching the spatial occurence of river otter (Lontra canadensis), beaver (Castor canadensis), and muksrat (Ondatra zibethicus) within Rhode Islands’s watershed. Outcomes will inform state harvest decisions and land-management strategies.\nLe Tan Quy, MS Candidate. Researching the spatial ecology of the Silver-backed chevrotain (Tragulus versicolor)\n\n\n\nFormer\nNicole Defelice, MS. Graduated 2024.\nResearching the use of olfactory scents as misinformation to reduce exposure of beach nesting shorebirds to predators.\nLaken Ganoe, PhD. Graduated 2024.\nResearching Fisher (Pekania pennanti) spatial and population ecology within Rhode Island, USA to inform management strategies. Project details can be found on Laken’s project page.\nDr. Kadambari Devarajan, Postdoctoral Researcher. 2021-2023.\nLed the investigation of the Global Animal Diel Activity Project\nDylan Ferreira, MS, Graduated 2022.\nThesis: Population monitoring of white-tailed deer in Rhode Island.\nKylie Rezendes, BS, Graduated 2022\nContributed to several research projects and led the camera-trap survey in Rhode Island as part of Snapshot USA.\nDr. Wales Carter, Postdoctoral Researcher. 2020-2023\nFocused on habitat selection and diet of New England Cottontails.\nKimberly Rivera, MS, Graduated 2021.\nThesis: Rethinking habitat and how we study human-wildlife relationships.\nJuliana Massseloux, MS, Graduated 2021.\nThesis: Forest structure shapes tropical terrestrial and arboreal mesomammal communities under moderate disturbance\nErin Wampole, MS, Graduated 2021.\nThesis: Examining anthropogenic pressures on Madagascar carnivorans\nRuby Nguyen, BS, Graduated 2021\nInvestigated wildlife usage of forest rock walls in New England and coordinated camera-trap deployments as part of Snapshot USA.\nJess Burr, BS, Graduated 2022.\nLab Manager, investigated wildlife usage of forest rock walls in New England, coordinated camera-trap deployments as part of Snapshot USA, and was a research technician in Vietnam studying meso-mammals.\nNicole Keefner, MS, Graduated 2020.\nThesis: Temporal effectiveness of biodiversity surrogates in coral reefs in the British Virgin Islands"
  },
  {
    "objectID": "projects/index.html#fisher-spatial-and-population-ecology-in-rhode-island.",
    "href": "projects/index.html#fisher-spatial-and-population-ecology-in-rhode-island.",
    "title": "Projects",
    "section": "",
    "text": "Objective: To understand the factors that limit fishers population and movement in a highly developed and highly forested area.\nCollaborators: Laken Ganoe (PhD student), Amy Mayer (research associate), and RI Department of Environmental Management, Fish and Wildlife Division.\n\narXiv Preprint | Code\ntext"
  },
  {
    "objectID": "projects/index.html#animal-diel-ecology",
    "href": "projects/index.html#animal-diel-ecology",
    "title": "Projects",
    "section": "Animal Diel Ecology",
    "text": "Animal Diel Ecology\n\narXiv Preprint | Code\nText"
  },
  {
    "objectID": "projects/index.html#fisher-spatial-and-population-ecology-in-rhode-island",
    "href": "projects/index.html#fisher-spatial-and-population-ecology-in-rhode-island",
    "title": "Projects",
    "section": "Fisher Spatial and Population Ecology in Rhode Island",
    "text": "Fisher Spatial and Population Ecology in Rhode Island\nObjective: To understand the factors that limit fishers population and movement in a highly developed and highly forested area.\nTeam: Laken Ganoe (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division."
  },
  {
    "objectID": "projects/index.html#semi-aquatic-mammal-distribution-in-rhode-island",
    "href": "projects/index.html#semi-aquatic-mammal-distribution-in-rhode-island",
    "title": "Projects",
    "section": "Semi-Aquatic Mammal Distribution in Rhode Island",
    "text": "Semi-Aquatic Mammal Distribution in Rhode Island\nObjective: To understand the limiting factors associated with the distribution of muskrats, beavers, and river otters in Rhode Island.\nTeam: John Crockett (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division."
  },
  {
    "objectID": "projects/index.html#estimating-white-tailed-deer-abundance",
    "href": "projects/index.html#estimating-white-tailed-deer-abundance",
    "title": "Projects",
    "section": "",
    "text": "Objectives 1) To develop a stochastic population reconstruction model to estimate deer abundance using harvest data, and 2) consider design implications of a forward-looking infraed aerial survey of deer.\nTeam: Amy Mayer (Research Associate), Brian Gerber (PI), David Kalb, and Dylan Ferreira and the RI Department of Environmental Management, Fish and Wildlife Division."
  },
  {
    "objectID": "publications/index.html",
    "href": "publications/index.html",
    "title": "Publications",
    "section": "",
    "text": "Estimating White-tailed Deer Abundance\nObjectives 1) To develop a stochastic population reconstruction model to estimate deer abundance using harvest data, and 2) consider design implications of a forward-looking infraed aerial survey of deer.\nTeam: Edwige Bellier (Postdoctoral Researcher), Amy Mayer (Research Associate), Brian Gerber (PI), David Kalb, and Dylan Ferreira and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nFisher Spatial and Population Ecology in Rhode Island\n\nObjective: To understand the factors that limit fishers population and movement in a highly developed and highly forested area.\nTeam: Laken Ganoe (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nSemi-Aquatic Mammal Distribution in Rhode Island\n\nObjective: To understand the limiting factors associated with the distribution of muskrats, beavers, and river otters in Rhode Island.\nTeam: John Crockett (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nAnimal Diel Ecology\n\nObjective: 1) To understand how wild animal’s change their activity and behavior across the 24-hour light-dark cycle to carryout their life history strategy and 2) to develop flexible and conceptually-based modeling approaches to make inference and predictions on animals diel activity use and selection."
  },
  {
    "objectID": "presentations/index.html",
    "href": "presentations/index.html",
    "title": "Publications",
    "section": "",
    "text": "Estimating White-tailed Deer Abundance\nObjectives 1) To develop a stochastic population reconstruction model to estimate deer abundance using harvest data, and 2) consider design implications of a forward-looking infraed aerial survey of deer.\nTeam: Edwige Bellier (Postdoctoral Researcher), Amy Mayer (Research Associate), Brian Gerber (PI), David Kalb, and Dylan Ferreira and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nFisher Spatial and Population Ecology in Rhode Island\n\nObjective: To understand the factors that limit fishers population and movement in a highly developed and highly forested area.\nTeam: Laken Ganoe (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nSemi-Aquatic Mammal Distribution in Rhode Island\n\nObjective: To understand the limiting factors associated with the distribution of muskrats, beavers, and river otters in Rhode Island.\nTeam: John Crockett (PhD student), Amy Mayer (Research Associate), Brian Gerber (PI), and Charlie Brown and the RI Department of Environmental Management, Fish and Wildlife Division.\n\n\n\nAnimal Diel Ecology\n\nObjective: 1) To understand how wild animal’s change their activity and behavior across the 24-hour light-dark cycle to carryout their life history strategy and 2) to develop flexible and conceptually-based modeling approaches to make inference and predictions on animals diel activity use and selection."
  },
  {
    "objectID": "publications/publications.html",
    "href": "publications/publications.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Publications\n  \n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Author\n        \n         \n          Publication\n        \n         \n          Year\n        \n     \n  \n    \n      \n      \n    \n\n\n\n  \n    A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package\n    Brian D Gerber, Kadambari Devarajan, Zach J. Farris, Mason Fidino\n    Journal of Animal Ecology\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A statistical population reconstruction model for wildlife populations: A case study with white-tailed deer and fisher\n    Edwige Bellier, Dylan C. Ferreira, David M. Kalb, Laken S. Ganoe, Amy E. Mayer, and Brian D. Gerber\n    Ecosphere\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A ‘how-to’ guide for estimating animal diel activity usinghierarchical models\n    Fabiola Iannarilli, Brian D. Gerber, John Erb 4, and John R. Fiebegr\n    Journal of Animal Ecology\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human's valuation of and interactions with coyotes\n    Kimberly Rivera, Carlos Garcia-Quijano, Virginie Sonnet, and Brian D Gerber\n    Conservation Science and Practice\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Climate, food and humans predict communities of mammals inthe United States\n    Kays, R., Snider, M. H., Hess, G., Cove, M. V., Jensen, A., Shamon, H., McShea, W. J., Rooney, B., Allen, M. L., Pekins, C. E., Wilmers, C. C., Pendergast, M. E., Green, A. M., Suraci, J., Leslie, M. S., Nasrallah, S., Farkas, D., Jordan, M., Grigione, M., … Parsons, A.\n    Diversity and Distributions\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Fisher activity patterns show potential for behavioral adaptations to human modified landscapes\n    Laken S. Ganoe, Amy E. Mayer, Charles Brown, Brian D. Gerber\n    Global Ecology and Conservation\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Habitat selection of non-breeding American black ducks in an urban estuary\n    Mezebish Quinn, T., P. W. Paton, B. D. Gerber, J. E. Kilburn, and S. R. McWilliams\n    Journal of Wildlife Management\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Mammal responses to global changes in human activity vary by trophic group and landscape\n    Burton, A.C., Beirne, C., Gaynor, K.M. et al. \n    Nature Ecology and Evolution\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Mesocarnivore sensitivity to natural and anthropogenic disturbance leads to declines in occurrence and concern for species persistence\n    Laken S. Ganoe, Amy E. Mayer, Charles Brown, Brian D. Gerber\n    Ecology and Evolution\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines\n    John G. Crockett, Charles Brown, Brian D. Gerber\n    Journal of Wildlife Management\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States\n    Shamon, Hila, Roi Maor, Michael V. Cove, Roland Kays, Jessie Adley, et al.\n    Ecology\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Using global remote camera data of a solitary species complex to evaluate the drivers of group formation\n    Joshua P. Twining, Chris Sutherland, Andrzej Zalewski, Michael V. Cove, et al.\n    Proceedings of the National Academy of Sciences\n    (2024)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Diel activity structures the occurrence of a mammal community in a human‐dominated landscape\n    Amy E Mayer, Laken S Ganoe, Charles Brown, Brian D Gerber\n    Ecology and Evolution\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains\n    Jacob S Ivan, Eric S Newkirk, Brian D Gerber\n    Forest Ecology and Management\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Estimating arboreality and the effects of forest structure on tropical tree‐dwelling mesomammals using arboreal camera traps\n    Juliana Masseloux, Que Tan Le, Jessica Burr, Brian D Gerber\n    Animal Conservation\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Forest carnivores living on the edge with invasive predators\n    Erin M Wampole, Zach J Farris, Prisca Razafy, Brian D Gerber\n    Animal Conservation\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail\n    Wales A Carter, Thomas J McGreevy Jr, Brian D Gerber, Amy E Mayer, Mary E Sullivan, Brian C Tefft, Thomas P Husband\n    Journal of Fish and Wildlife Management\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease\n    Brian D Gerber, Brittany A Mosher, Larissa L Bailey, Erin Muths, Harry J Crockett, Sarah J Converse\n    Animal Conservation\n    (2023)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n    \n       Materials\n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Camera Trapping Madagascar\n    Zach J Farris, Brian D Gerber, Asia Murphy, and Erin Wampole.\n    The new natural history of Madagascar\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n  \n\n  \n    Camera Trapping Madagascar\n    Kim Rivera, Brian D Gerber, Zach J Farris.\n    The new natural history of Madagascar\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n  \n\n  \n    Conceptual and methodological advances in habitat‐selection modeling: guidelines for ecology and evolution\n    Joseph M Northrup, Eric Vander Wal, Maegwin Bonar, John Fieberg, Michel P Laforge, Martin Leclerc, Christina M Prokopenko, Brian D Gerber\n    Ecological Applications\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Cryptoprocta ferox, fosa\n    Brian D Gerber, Clare E. Hawkins\n    The new natural history of Madagascar\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n  \n\n  \n    Estimating road mortality hotspots while accounting for imperfect detection: A case study with amphibians and reptiles\n    Noah Hallisey, Scott W Buchanan, Brian D Gerber, Liam S Corcoran, Nancy E Karraker\n    Land\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Forest degradation drives widespread avian habitat and population declines\n    Matthew G Betts, Zhiqiang Yang, Adam S Hadley, Adam C Smith, Josée S Rousseau, Joseph M Northrup, Joseph J Nocera, Noel Gorelick, Brian D Gerber\n    Nature Ecology & Evolution\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Forest structure and seasonally inundated grassland shape tropical mammal communities under moderate disturbance\n    Juliana Masseloux, Quy Tan Le, Jessica Burr, Brian D Gerber\n    Ecosphere\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Madagascar Terrestrial Camera Survey Database 2021: A collation of protected forest camera surveys from 2007–2021\n    Erin M Wampole, Brian D Gerber, Zach J Farris et al.\n    Ecology\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Mammals adjust diel activity across gradients of urbanization\n    Travis Gallo, Mason Fidino, Brian Gerber, et al.\n    Elife\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Occupancy models – single-species\n    Brian D Gerber, Brittany Mosher, Daniel Martin, Larissa Bailey, Thierry Chambert\n    Program MARK – a ‘gentle introduction\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Rapidly declining body size in an insectivorous bat is associated with increased precipitation and decreased survival\n    Christina M Davy, Valerie von Zuben, Piia M Kukka, Brian D Gerber, Brian G Slough, Thomas S Jung\n    Ecological Applications\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Rethinking habitat occupancy modeling and the role of diel activity in an anthropogenic world\n    Kimberly Rivera, Mason Fidino, Zach J Farris, Seth B Magle, Asia Murphy, Brian D Gerber\n    The American Naturalist\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic\n    Roland Kays et al.\n    Ecology\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion\n    Zach J Farris, Brian D Gerber, Sarah Karpanty, Felix Ratelolahy, Vonjy Andrianjakarivelo, Marcella J Kelly\n    Small Carnivores: Evolution, Ecology, Behaviour, and Conservation\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Transient persistence of bobcat (Lynx rufus) occurrence throughout a human‐dominated landscape\n    Amy E Mayer, Thomas J McGreevy Jr, Charles Brown, Laken S Ganoe, Brian D Gerber\n    Population Ecology\n    (2022)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A synthesis of life‐history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae\n    Erin M Wampole, Zach J Farris, Brian D Gerber\n    Mammal Review\n    (2021)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Behavioral and demographic responses of mule deer to energy development on winter range\n    Joseph M Northrup, Charles R Anderson Jr, Brian D Gerber, George Wittemyer\n    Wildlife Monographs\n    (2021)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England\n    Amy E Mayer, Thomas J McGreevy Jr, Mary E Sullivan, Charles Brown, Thomas P Husband, Brian D Gerber\n    Northeastern Naturalist\n    (2021)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States\n    Michael V Cove, Roland Kays, et al.\n    Ecology\n    (2021)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar\n    Patrick H Ross, Erik Patel, Barry Ferguson, Rojo Nandrianina Ravelijaona, Guy Irenel Raoloniana, Erin Wampole, Brian D Gerber, Zach J Farris\n    Endangered Species Research\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Contrasting effects of climate change on seasonal survival of a hibernating mammal\n    Line S Cordes, Daniel T Blumstein, Kenneth B Armitage, Paul J CaraDonna, Dylan Z Childs, Brian D Gerber, Julien GA Martin, Madan K Oli, Arpat Ozgul\n    Proceedings of the National Academy of Sciences\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Decision-Making and Monitoring Strategies in Natural Resource Management and Conservation\n    Brian D Gerber, Perry J Williams\n    Terrestrial Ecosystems and Biodiversity\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation\n    Zach J Farris, Brian D Gerber, Sarah Karpanty, Asia Murphy, Erin Wampole, Felix Ratelolahy, Marcella J Kelly\n    Biological Invasions\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Improving spatial predictions of animal resource selection to guide conservation decision making\n    Brian D Gerber, Joseph M Northrup\n    Ecology\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Power pole density and avian electrocution risk in the western United States\n    James F Dwyer, Brian D Gerber, Paul Petersen, William E Armstrong, Richard E Harness\n    Journal of Raptor Research\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar\n    Andrea L Baden, Jelisa Oliveras, Brian D Gerber\n    Folia Primatologica\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Squeezed by a habitat split: Warm ocean conditions and old‐forest loss interact to reduce long‐term occupancy of a threatened seabird\n    Matthew G Betts, Joseph M Northrup, Jennifer A Bailey Guerrero, Lindsay J Adrean, S Kim Nelson, Jennifer L Fisher, Brian D Gerber, Marie‐Sophie Garcia‐Heras, Zhiqiang Yang, Daniel D Roby, James W Rivers\n    Conservation Letters\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    The Mysterious case of the disappering Javan Rhino: Uing clues from Rhinos everyday habits and hobbies to figure out how to help them recover\n    Erin Rose Harrington, Brian Daniel Gerber\n    Frontier for Young Minds\n    (2020)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment\n    Brian D. Gerber, Mevin B. Hooten, Christopher P. Peck, Mindy B Rice, James H. Gammonley, Anthony D. Apa, Amy J. Davis\n    Functional Ecology\n    (2019)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little‐studied Malagasy carnivore\n    Asia Murphy, Brian D Gerber, Zach J Farris, Sarah Karpanty, Felix Ratelolahy, Marcella J Kelly\n    Animal Conservation\n    (2019)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A comment on priors for Bayesian occupancy models\n    Joseph M Northrup, Brian D Gerber\n    PLoS One\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Accounting for location uncertainty in azimuthal telemetry data improves ecological inference\n    Brian D Gerber, Mevin B Hooten, Christopher P Peck, Mindy B Rice, James H Gammonley, Anthony D Apa, Amy J Davis\n    Movement Ecology\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Adaptive management of animal populations with significant unknowns and uncertainties: a case study\n    Brian D Gerber, William L Kendall\n    Ecological Applications\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Elevated potential for intraspecific competition in territorial carnivores occupying fragmented landscapes\n    Pranav Chanchani, Brian D Gerber, Barry R Noon\n    Biological Conservation\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Identifying species conservation strategies to reduce disease‐associated declines\n    Brian D Gerber, Sarah J Converse, Erin Muths, Harry J Crockett, Brittany A Mosher, Larissa L Bailey\n    Conservation Letters\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Preventing global extinction of the Javan rhino: tsunami risk and future conservation direction\n    Ridwan Setiawan, Brian D Gerber, Ujang Mamat Rahmat, Daryan Daryan, Asep Yayus Firdaus, Mohammad Haryono, Kurnia Okhtavia Khairani, Yuyun Kurniawan, Barney Long, Arnaud Lyet, Muhiban Muhiban, Rois Mahmud, Aom Muhtarom, Elisabet Purastuti, Widodo S Ramono, Dadan Subrata, Sunarto Sunarto\n    Conservation Letters\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards\n    Anna V Vitkalova, Limin Feng, Alexander N Rybin, Brian D Gerber, Dale G Miquelle, Tianming Wang, Haitao Yang, Elena I Shevtsova, Vladimir V Aramilev, Jianping Ge\n    Conservation Letters\n    (2018)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A biogeographical perspective on the variation in mouse lemur density throughout Madagascar\n    Casey M Setash, Sarah Zohdy, Brian D Gerber, Caitlin J Karanewsky\n    Mammal Review\n    (2017)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    A model to inform management actions as a response to chytridiomycosis-associated decline\n    Sarah J Converse, Larissa L Bailey, Brittany A Mosher, W Chris Funk, Brian D Gerber, Erin Muths\n    EcoHealth\n    (2017)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line\n    Adrian Seymour, Mark Tarrant, Brian Gerber, Alex Sharp, Jamie Woollam, Ruth Cox\n    Journal of Zoology\n    (2017)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes\n    Brian Gerber, William Kendall\n    Condor: Ornithological Applications\n    (2017)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Threats to a rainforest carnivore community: A multi-year assessment of occupancy and co-occurrence in Madagascar\n    Zach J. Farris, Brian D Gerber, Kim Valenta, Radoniaina Rafaliarison, Jean Claude Razafimahaimodison, Eileen Larney, Tsiky Rajaonarivelo, Zoavina Randriana, Patricia C. Wright, Colin A Chapman\n    Biological Conservation\n    (2017)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Considering transient population dynamics in the conservation of slow life-history species: An application to the sandhill crane\n    Brian Gerber, William Kendall\n    Biological Conservation\n    (2016)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion\n    Kerry Brown, Zach Farris, Gabriel Yesuf, Brian Gerber, Fidisoa Rasambainarivo, Sarah Karpanty, Marcella Kelly, Jean Claude Razafimahaimodison, Eileen Larney, Patricia Wright, Steig Johnson\n    Biodiversity and Conservation\n    (2016)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Power Pole Density Informs Spatial Prioritization for Mitigating Avian Electrocution\n    James F. Dwyer, Rick E. Harness, Brian D. Gerber, Melissa A. Landon, Paul Petersen, Daryl D. Austin, Brian Woodbridge, Gary E. Williams, Duncan Eccleston\n    Journal of Wildlife Management\n    (2016)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Assessing carnivore distribution from local knowledge across a human‐dominated landscape in central‐southeastern M adagascar\n    Mary Kotschwar Logan, Brian D Gerber, Sarah M Karpanty, S Justin, FN Rabenahy\n    Animal Conservation\n    (2015)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations\n    Brian Gerber, William Kendall, Mevin Hooten, James Dubovsky, Roderick Drewien\n    Journal of Animal Ecology\n    (2015)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    When carnivores roam: temporal patterns and overlap among Madagascar's native and exotic carnivores\n    Zach Farris, Brian Gerber, Sarah Karpanty, Asia Murphy, Vonjy Andrianjakarivelo, Felix Ratelolahy, Marcella Kelly\n    Journal of Zoology\n    (2015)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small\n    Brian D Gerber, Jacob S Ivan, Kenneth P Burnham\n    Population Ecology\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota\n    Misti K Sporer, James F Dwyer, Brian D Gerber, Richard E Harness, Arun K Pandey\n    Wildlife Society Bulletin\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Primates and cameras: Noninvasive sampling to make population-level inferences while accounting for imperfect detection\n    Brian D Gerber, Perry J Williams, Larissa L Bailey\n    International Journal of Primatology\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data\n    Graeme Shannon, Jesse S Lewis, Brian D Gerber\n    PeerJ\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Sandhill Crane (Antigone canadensis)\n    Gerber, BD, Dwyer, JD, Nesbitt, SA, Drewien, RC, Littlefield CD, Tacha, TC, and Vohs, PA. \n    Birds of the World\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n  \n\n  \n    Spatial capture-recapture model performance with known small-mammal densities\n    Brian Gerber, Robert Parmenter\n    Ecological Applications\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Teeth, sex, and testosterone: aging in the world's smallest primate\n    Sarah Zohdy, Brian D Gerber, Stacey Tecot, Marina B Blanco, Julia M Winchester, Patricia C Wright, Jukka Jernvall\n    PLoS One\n    (2014)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur\n    Stacey R Tecot, Brian D Gerber, Stephen J King, Jennifer L Verdolin, Patricia C Wright\n    Behavioral Ecology\n    (2013)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence\n    Brian D. Gerber, Sarah M. Karpanty, Johny Randrianantenaina\n    Journal of Mammalogy\n    (2012)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?\n    Brian D Gerber, Summer Arrigo-Nelson, Sarah M Karpanty, Mary Kotschwar, Patricia C Wright\n    International Journal of Primatology\n    (2012)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar's rainforests\n    Brian D. Gerber, Sarah M. Karpanty, Johny Randrianantenaina\n    Oryx\n    (2012)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA\n    Jonathan B Cohen, Brian D Gerber, Sarah M Karpanty, James D Fraser, Barry R Truitt\n    Waterbirds\n    (2011)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet\n    Brian D Gerber, Sarah M Karpanty, Marcella J Kelly\n    Population Ecology\n    (2011)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n  \n    An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps\n    Brian Gerber, Sarah M Karpanty, Charles Crawford, Mary Kotschwar, Johnny Randrianantenaina\n    Oryx\n    (2010)\n    \n      Details\n    \n    \n    \n      DOI\n    \n    \n    \n    \n     \n    \n       Download\n    \n    \n  \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications/articles/test.html",
    "href": "publications/articles/test.html",
    "title": "Reconsidering the Duchenne smile: Formalizing and testing hypotheses about eye constriction and positive emotion",
    "section": "",
    "text": "Girard, J. M., Cohn, J. F., Yin, L., & Morency, L.-P. (2021). Reconsidering the Duchenne smile: Formalizing and testing hypotheses about eye constriction and positive emotion. Affective Science, 2(1), 32–47."
  },
  {
    "objectID": "publications/articles/test.html#citation-apa-7",
    "href": "publications/articles/test.html#citation-apa-7",
    "title": "Reconsidering the Duchenne smile: Formalizing and testing hypotheses about eye constriction and positive emotion",
    "section": "",
    "text": "Girard, J. M., Cohn, J. F., Yin, L., & Morency, L.-P. (2021). Reconsidering the Duchenne smile: Formalizing and testing hypotheses about eye constriction and positive emotion. Affective Science, 2(1), 32–47."
  },
  {
    "objectID": "publications/articles/test.html#abstract",
    "href": "publications/articles/test.html#abstract",
    "title": "Reconsidering the Duchenne smile: Formalizing and testing hypotheses about eye constriction and positive emotion",
    "section": "Abstract",
    "text": "Abstract\nThe common view of emotional expressions is that certain configurations of facial-muscle movements reliably reveal certain categories of emotion. The principal exemplar of this view is the Duchenne smile, a configuration of facial-muscle movements (i.e., smiling with eye constriction) that has been argued to reliably reveal genuine positive emotion. In this paper, we formalized a list of hypotheses that have been proposed regarding the Duchenne smile, briefly reviewed the literature weighing on these hypotheses, identified limitations and unanswered questions, and conducted two empirical studies to begin addressing these limitations and answering these questions. Both studies analyzed a database of 751 smiles observed while 136 participants completed experimental tasks designed to elicit amusement, embarrassment, fear, and physical pain. Study 1 focused on participants’ self-reported positive emotion and Study 2 focused on how third-party observers would perceive videos of these smiles. Most of the hypotheses that have been proposed about the Duchenne smile were either contradicted by or only weakly supported by our data. Eye constriction did provide some information about experienced positive emotion, but this information was lacking in specificity, already provided by other smile characteristics, and highly dependent on context. Eye constriction provided more information about perceived positive emotion, including some unique information over other smile characteristics, but context was also important here as well. Overall, our results suggest that accurately inferring positive emotion from a smile requires more sophisticated methods than simply looking for the presence/absence (or even the intensity) of eye constriction."
  },
  {
    "objectID": "publications/articles/bowdring2021.html",
    "href": "publications/articles/bowdring2021.html",
    "title": "In the eye of the beholder: A comprehensive analysis of stimulus type, perceiver, and target in physical attractiveness perceptions",
    "section": "",
    "text": "Bowdring, M. A., Sayette, M. A., Girard, J. M., & Woods, W. C. (2021). In the eye of the beholder: A comprehensive analysis of stimulus type, perceiver, and target in physical attractiveness perceptions. Journal of Nonverbal Behavior, 45(2), 241–259."
  },
  {
    "objectID": "publications/articles/bowdring2021.html#citation-apa-7",
    "href": "publications/articles/bowdring2021.html#citation-apa-7",
    "title": "In the eye of the beholder: A comprehensive analysis of stimulus type, perceiver, and target in physical attractiveness perceptions",
    "section": "",
    "text": "Bowdring, M. A., Sayette, M. A., Girard, J. M., & Woods, W. C. (2021). In the eye of the beholder: A comprehensive analysis of stimulus type, perceiver, and target in physical attractiveness perceptions. Journal of Nonverbal Behavior, 45(2), 241–259."
  },
  {
    "objectID": "publications/articles/bowdring2021.html#abstract",
    "href": "publications/articles/bowdring2021.html#abstract",
    "title": "In the eye of the beholder: A comprehensive analysis of stimulus type, perceiver, and target in physical attractiveness perceptions",
    "section": "Abstract",
    "text": "Abstract\nPhysical attractiveness plays a central role in psychosocial experiences. One of the top research priorities has been to identify factors affecting perceptions of physical attractiveness (PPA). Recent work suggests PPA derives from different sources (e.g., target, perceiver, stimulus type). Although smiles in particular are believed to enhance PPA, support has been surprisingly limited. This study comprehensively examines the effect of smiles on PPA and, more broadly, evaluates the roles of target, perceiver, and stimulus type in PPA variation. Perceivers (n=181) rated both static images and 5-s videos of targets displaying smiling and neutral-expressions. Smiling images were rated as more attractive than neutral-expression images (regardless of stimulus motion format). Interestingly, perceptions of physical attractiveness were based more on the perceiver than on either the target or format in which the target was presented. Results clarify the effect of smiles, and highlight the significant role of the perceiver, in PPA."
  },
  {
    "objectID": "publications/articles/gerber2019.html",
    "href": "publications/articles/gerber2019.html",
    "title": "1Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/gerber2019.html#citation-apa-7",
    "href": "publications/articles/gerber2019.html#citation-apa-7",
    "title": "Alexithymia – not autism – is associated with frequency of social interactions in adults",
    "section": "",
    "text": "Gerber, A. H., Girard, J. M., Scott, S. B., & Lerner, M. D. (2019). Alexithymia – Not autism – is associated with frequency of social interactions in adults. Behaviour Research and Therapy, 123, 103477."
  },
  {
    "objectID": "publications/articles/gerber2019.html#abstract",
    "href": "publications/articles/gerber2019.html#abstract",
    "title": "1Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "Abstract",
    "text": "Abstract\nAnthropogenic developments alter the environment and resources available to wildlife communities. In response to these real or perceived threats from this development, species may adjust their spatial occurrence. Additionally, wildlife species may adjust when in diel time (24-h light–dark cycle) they occupy sites on the landscape to adapt to changing conditions. However, many wildlife studies only focus on where a species does and does not occur, ignoring how species may shift their diel activity at sites to mitigate threats. We used a multi-state diel occupancy modeling framework to investigate how a community of mammals (mesocarnivores, urban-adapted omnivores, and herbivore/small mammals) respond to differing levels of anthropogenic development and forest cover across two climatic seasons. We collected camera trap data at 240 survey locations across the summer and winter of 2021–2022. We modeled multi-state diel occupancy for 14 mammal species with extent of development/forest and season hypothesized to influence diel occupancy and season hypothesized to influence the probability of detection. We found that all species displayed heterogeneity in both diel occupancy and detection either by extent of development/forest and or season. Within the mesocarnivore species group, coyote and red fox were less sensitive to development and had higher occupancy probability at these sites in general but used them more during the night, while more sensitive mesocarnivores including fisher and bobcat occupied the day state only when there was increasing forest cover. Our results highlight the importance of incorporating diel activity in habitat modeling to better understand the relationship between a species and its landscape, particularly in a region that is vulnerable to increased anthropogenic pressure."
  },
  {
    "objectID": "publications/articles/mayer2023.html",
    "href": "publications/articles/mayer2023.html",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/mayer2023.html#citation",
    "href": "publications/articles/mayer2023.html#citation",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/mayer2023.html#abstract",
    "href": "publications/articles/mayer2023.html#abstract",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "Abstract",
    "text": "Abstract\nAnthropogenic developments alter the environment and resources available to wildlife communities. In response to these real or perceived threats from this development, species may adjust their spatial occurrence. Additionally, wildlife species may adjust when in diel time (24-h light–dark cycle) they occupy sites on the landscape to adapt to changing conditions. However, many wildlife studies only focus on where a species does and does not occur, ignoring how species may shift their diel activity at sites to mitigate threats. We used a multi-state diel occupancy modeling framework to investigate how a community of mammals (mesocarnivores, urban-adapted omnivores, and herbivore/small mammals) respond to differing levels of anthropogenic development and forest cover across two climatic seasons. We collected camera trap data at 240 survey locations across the summer and winter of 2021–2022. We modeled multi-state diel occupancy for 14 mammal species with extent of development/forest and season hypothesized to influence diel occupancy and season hypothesized to influence the probability of detection. We found that all species displayed heterogeneity in both diel occupancy and detection either by extent of development/forest and or season. Within the mesocarnivore species group, coyote and red fox were less sensitive to development and had higher occupancy probability at these sites in general but used them more during the night, while more sensitive mesocarnivores including fisher and bobcat occupied the day state only when there was increasing forest cover. Our results highlight the importance of incorporating diel activity in habitat modeling to better understand the relationship between a species and its landscape, particularly in a region that is vulnerable to increased anthropogenic pressure."
  },
  {
    "objectID": "publications/articles/gerber2019.html#citation",
    "href": "publications/articles/gerber2019.html#citation",
    "title": "1Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/swartz2023.html",
    "href": "publications/articles/swartz2023.html",
    "title": "2Randomized trial of brief interpersonal psychotherapy and cognitive behavioral therapy for depression delivered both in-person and by telehealth",
    "section": "",
    "text": "Swartz, H. A., Bylsma, L. M., Fournier, J. C., Girard, J. M., Spotts, C., Cohn, J. F., & Morency, L.-P. (2023). Randomized trial of brief interpersonal psychotherapy and cognitive behavioral therapy for depression delivered both in-person and by telehealth. Journal of Affective Disorders, 333, 543–552."
  },
  {
    "objectID": "publications/articles/swartz2023.html#citation-apa-7",
    "href": "publications/articles/swartz2023.html#citation-apa-7",
    "title": "2Randomized trial of brief interpersonal psychotherapy and cognitive behavioral therapy for depression delivered both in-person and by telehealth",
    "section": "",
    "text": "Swartz, H. A., Bylsma, L. M., Fournier, J. C., Girard, J. M., Spotts, C., Cohn, J. F., & Morency, L.-P. (2023). Randomized trial of brief interpersonal psychotherapy and cognitive behavioral therapy for depression delivered both in-person and by telehealth. Journal of Affective Disorders, 333, 543–552."
  },
  {
    "objectID": "publications/articles/swartz2023.html#abstract",
    "href": "publications/articles/swartz2023.html#abstract",
    "title": "2Randomized trial of brief interpersonal psychotherapy and cognitive behavioral therapy for depression delivered both in-person and by telehealth",
    "section": "Abstract",
    "text": "Abstract\nBackground: Expert consensus guidelines recommend Cognitive Behavioral Therapy (CBT) and Interpersonal Psychotherapy (IPT), interventions that were historically delivered face-to-face, as first-line treatments for Major Depressive Disorder (MDD). Despite the ubiquity of telehealth following the COVID-19 pandemic, little is known about differential outcomes with CBT versus IPT delivered in-person (IP) or via telehealth (TH) or whether working alliance is affected.\nMethods: Adults meeting DSM-5 criteria for MDD were randomly assigned to either 8 sessions of IPT or CBT (group). Mid-trial, COVID-19 forced a change of therapy delivery from IP to TH (study phase). We compared changes in Hamilton Rating Scale for Depression (HRSD-17) and Working Alliance Inventory (WAI) scores for individuals by group and phase: CBT-IP (n = 24), CBT-TH (n = 11), IPT-IP (n = 25) and IPT-TH (n = 17).\nResults: HRSD-17 scores declined significantly from pre to post treatment (pre: M = 17.7, SD = 4.4 vs. post: M = 11.7, SD = 5.9; p &lt; .001; d = 1.45) without significant group or phase effects. WAI scores did not differ by group or phase. Number of completed therapy sessions was greater for TH (M = 7.8, SD = 1.2) relative to IP (M = 7.2, SD = 1.6) (Mann-Whitney U = 387.50, z = 2.24, p = .025).\nLimitations: Participants were not randomly assigned to IP versus TH. Sample size is small.\nConclusions: This study provides preliminary evidence supporting the efficacy of both brief IPT and CBT, delivered by either TH or IP, for depression. It showed that working alliance is preserved in TH, and delivery via TH may improve therapy adherence. Prospective, randomized controlled trials are needed to definitively test efficacy of brief IPT and CBT delivered via TH versus IP."
  },
  {
    "objectID": "publications/articles/Ivan2023.html",
    "href": "publications/articles/Ivan2023.html",
    "title": "Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains",
    "section": "",
    "text": "Ivan, J. S., Newkirk, E. S., & Gerber, B. D. (2023). Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains. Forest Ecology and Management, 544, 121147."
  },
  {
    "objectID": "publications/articles/Ivan2023.html#citation",
    "href": "publications/articles/Ivan2023.html#citation",
    "title": "Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains",
    "section": "",
    "text": "Ivan, J. S., Newkirk, E. S., & Gerber, B. D. (2023). Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains. Forest Ecology and Management, 544, 121147."
  },
  {
    "objectID": "publications/articles/Ivan2023.html#abstract",
    "href": "publications/articles/Ivan2023.html#abstract",
    "title": "Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains",
    "section": "Abstract",
    "text": "Abstract\nSpruce beetles (Dendroctonus rufipennis) have impacted millions of acres of Engelmann spruce (Picea engelmannii) – subalpine fir (Abies lasiocarpa) forest in North America over the past decade, resulting in the most extensive outbreak in recorded history. This dramatic alteration of forest composition and structure has precipitated numerous changes to forest ecology and ecosystem services. Among the least studied of these changes are impacts to wild mammals, including snowshoe hares (Lepus americanus) and red squirrels (Tamiasciurus hudsonicus). We sampled a chronosequence of spruce-fir stands along a gradient of ‘years elapsed since spruce beetle outbreak’ (YSO) in order to estimate impacts to abundance of these two species in the southern Rocky Mountains. Snowshoe hare abundance was not related to YSO, at least in the first decade post-outbreak. Instead, hare abundance during this period was positively related to horizontal cover, especially that due to stem density of small diameter subalpine fir. Notably, snowshoe hare abundance was negatively related to stem density of small diameter Engelmann spruce, suggesting that elements of horizontal cover may not be uniformly beneficial to hares. Hare abundance was also negatively related to ground cover, which could help explain the lack of relationship to YSO, assuming reduction in overstory canopy would lead to increases in ground cover. Red squirrel abundance was negatively related to YSO and outbreak severity (i.e., basal area of large diameter dead trees). This was likely due to diminished cone crops in impacted areas, which red squirrels cache and rely on heavily to sustain them through the winter. Basal area of remaining large live fir trees was not related to squirrel abundance, suggesting that regeneration of spruce and associated cone crops may be necessary for recovery of red squirrels, which may take several decades."
  },
  {
    "objectID": "publications/articles/Masseloux2023.html",
    "href": "publications/articles/Masseloux2023.html",
    "title": "Estimating arboreality and the effects of forest structure on tropical tree‐dwelling mesomammals using arboreal camera traps",
    "section": "",
    "text": "Masseloux, J., Le, Q.T., Burr, J. and Gerber, B.D. (2023), Estimating arboreality and the effects of forest structure on tropical tree-dwelling mesomammals using arboreal camera traps. Anim Conserv, 26: 140-153. https://doi.org/10.1111/acv.12822"
  },
  {
    "objectID": "publications/articles/Masseloux2023.html#citation",
    "href": "publications/articles/Masseloux2023.html#citation",
    "title": "Estimating arboreality and the effects of forest structure on tropical tree‐dwelling mesomammals using arboreal camera traps",
    "section": "",
    "text": "Masseloux, J., Le, Q.T., Burr, J. and Gerber, B.D. (2023), Estimating arboreality and the effects of forest structure on tropical tree-dwelling mesomammals using arboreal camera traps. Anim Conserv, 26: 140-153. https://doi.org/10.1111/acv.12822"
  },
  {
    "objectID": "publications/articles/Masseloux2023.html#abstract",
    "href": "publications/articles/Masseloux2023.html#abstract",
    "title": "Estimating arboreality and the effects of forest structure on tropical tree‐dwelling mesomammals using arboreal camera traps",
    "section": "Abstract",
    "text": "Abstract\nTropical forests are the most species-rich biomes in the world but suffer high rates of logging and conversion. Tropical tree-dwelling (arboreal and semi-arboreal) mesomammals reliant on old-growth forest structures are especially vulnerable. The degree of behavioral arboreality of semi-arboreal mammals can be related to forest structure and perceived terrestrial threats. Paired arboreal and terrestrial camera traps are a promising new method for estimating the arboreality of cryptic and nocturnal species. Our study aimed to (1) model the effects of forest structure and anthropogenic disturbance on the detection and occurrence of arboreal and semi-arboreal mesomammals and (2) evaluate differences in occurrence and detection between paired arboreal and terrestrial camera trap sites for semi-arboreal mammals while estimating the degree of arboreality. We set 20 terrestrial and arboreal camera trap pairs in eastern Cat Tien National Park (Nam Cat Tien), Vietnam, from June 2019 to September 2020. We evaluated the effects of forest structure and proximity to roads on nine arboreal mesomammal species using single-season occupancy models. We used multi-scale occupancy modeling to estimate the degree of arboreality for four semi-arboreal mammals. All models were fit using hierarchical Bayesian modeling and compared using WAIC. We detected most arboreal and terrestrial mesomammal species currently known to inhabit Nam Cat Tien, including rare and cryptic species. Canopy connectivity and other mature forest characteristics were important for explaining the detection and occurrence of highly arboreal species, while the effect of a tree and focal limb characteristics on detection was species-specific. All semi-arboreal species had a greater probability of terrestrial station use than arboreal, suggesting a greater vulnerability to terrestrial threats, though the degree of arboreality varied by species. Using one sampling method underestimated occupancy for most semi-arboreal species. Multi-method sampling designs with multi-scale occupancy modeling can improve estimates of species distribution and habitat use for guiding management and conservation decisions."
  },
  {
    "objectID": "publications/articles/Snapshort2023.html",
    "href": "publications/articles/Snapshort2023.html",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "",
    "text": "Kays, Roland, Michael V. Cove, Jose Diaz, Kimberly Todd, Claire Bresnan, Matt Snider, Thomas E. Lee Jr, et al. 2022. “ SNAPSHOT USA 2020: A Second Coordinated National Camera Trap Survey of the United States during the COVID-19 Pandemic.” Ecology 103(10): e3775. https://doi.org/10.1002/ecy.3775"
  },
  {
    "objectID": "publications/articles/Snapshort2023.html#citation",
    "href": "publications/articles/Snapshort2023.html#citation",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "",
    "text": "Kays, Roland, Michael V. Cove, Jose Diaz, Kimberly Todd, Claire Bresnan, Matt Snider, Thomas E. Lee Jr, et al. 2022. “ SNAPSHOT USA 2020: A Second Coordinated National Camera Trap Survey of the United States during the COVID-19 Pandemic.” Ecology 103(10): e3775. https://doi.org/10.1002/ecy.3775"
  },
  {
    "objectID": "publications/articles/Snapshort2023.html#abstract",
    "href": "publications/articles/Snapshort2023.html#abstract",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "Abstract",
    "text": "Abstract\nManaging wildlife populations in the face of global change requires regular data on the abundance and distribution of wild animals, but acquiring these over appropriate spatial scales in a sustainable way has proven challenging. Here we present the data from Snapshot USA 2020, a second annual national mammal survey of the USA. This project involved 152 scientists setting camera traps in a standardized protocol at 1485 locations across 103 arrays in 43 states for a total of 52,710 trap-nights of survey effort. Most (58) of these arrays were also sampled during the same months (September and October) in 2019, providing a direct comparison of animal populations in 2 years that includes data from both during and before the COVID-19 pandemic. All data were managed by the eMammal system, with all species identifications checked by at least two reviewers. In total, we recorded 117,415 detections of 78 species of wild mammals, 9236 detections of at least 43 species of birds, 15,851 detections of six domestic animals and 23,825 detections of humans or their vehicles. Spatial differences across arrays explained more variation in the relative abundance than temporal variation across years for all 38 species modeled, although there are examples of significant site-level differences among years for many species. Temporal results show how species allocate their time and can be used to study species interactions, including between humans and wildlife. These data provide a snapshot of the mammal community of the USA for 2020 and will be useful for exploring the drivers of spatial and temporal changes in relative abundance and distribution, and the impacts of species interactions on daily activity patterns. There are no copyright restrictions, and please cite this paper when using these data, or a subset of these data, for publication."
  },
  {
    "objectID": "publications/articles/Farris2022.html",
    "href": "publications/articles/Farris2022.html",
    "title": "Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion",
    "section": "",
    "text": "Farris, Z. J., Gerber, B. D., Karpanty, S., Ratelolahy, F., Andrianjakarivelo, V., & Kelly, M. J. (2022). Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion. Small Carnivores: Evolution, Ecology, Behaviour, and Conservation, 259-274."
  },
  {
    "objectID": "publications/articles/Farris2022.html#citation",
    "href": "publications/articles/Farris2022.html#citation",
    "title": "Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion",
    "section": "",
    "text": "Farris, Z. J., Gerber, B. D., Karpanty, S., Ratelolahy, F., Andrianjakarivelo, V., & Kelly, M. J. (2022). Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion. Small Carnivores: Evolution, Ecology, Behaviour, and Conservation, 259-274."
  },
  {
    "objectID": "publications/articles/Farris2022.html#abstract",
    "href": "publications/articles/Farris2022.html#abstract",
    "title": "Spatio‐temporal overlap between a native and an exotic carnivore in Madagascar: evidence of spatial exclusion",
    "section": "Abstract",
    "text": "Abstract\nThe exclusion or local extirpation of native species by exotic or introduced carnivores is a burgeoning issue for conservation. Exotic carnivores may indeed present a serious threat as they have the potential to negatively influence and/or interact with native wildlife via exploitative or interference competition, intraguild predation and/or transmission of pathogens. So far, studies investigating co-occurrence have failed to include both a spatial and temporal component which is likely to lead to improper inference. Here, we used a novel approach to investigate the relationship between native and exotic carnivores across both space and time and provide insight on the spatial exclusion of the native spotted fanaloka, Fossa fossana (listed as Vulnerable by the IUCN), by the exotic small Indian civet, Viverricula indica , across Madagascar’s eastern rainforest ecosystem. We combined both spatial (single-species and two-species occupancy analyses) and temporal (kernel density estimation) analyses to investigate potential spatio-temporal interactions across the landscape, comparing degraded and non-degraded forests. We found that the exotic Indian civet negatively influenced spotted fanaloka occupancy, which resulted in a strong decrease in occupancy across degraded forests. Further, spotted fanaloka occupancy decreased by 40% at sites where Indian civet were present, resulting in a strong lack of co-occurrence between these two species. Finally, we recorded strong spatio-temporal overlap during the nocturnal time period within degraded, patchy forests. As a result, we suggest that this reveals evidence of spatial exclusion of the spotted fanaloka. This novel approach provides a unique investigation across both space and time – allowing us to identify more accurately the precise locations where co-occurring carnivores are potentially interacting – and has wide-ranging implications for conservation managers working to address the negative impacts of exotic species on native wildlife."
  },
  {
    "objectID": "publications/articles/Carter2023.html",
    "href": "publications/articles/Carter2023.html",
    "title": "High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail",
    "section": "",
    "text": "Carter, W. A., McGreevy Jr, T. J., Gerber, B. D., Mayer, A. E., Sullivan, M. E., Tefft, B. C., & Husband, T. P. (2023). High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail. Journal of Fish and Wildlife Management, 14(1), 62-74."
  },
  {
    "objectID": "publications/articles/Carter2023.html#citation",
    "href": "publications/articles/Carter2023.html#citation",
    "title": "High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail",
    "section": "",
    "text": "Carter, W. A., McGreevy Jr, T. J., Gerber, B. D., Mayer, A. E., Sullivan, M. E., Tefft, B. C., & Husband, T. P. (2023). High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail. Journal of Fish and Wildlife Management, 14(1), 62-74."
  },
  {
    "objectID": "publications/articles/Carter2023.html#abstract",
    "href": "publications/articles/Carter2023.html#abstract",
    "title": "High Similarity in Winter Diet between Imperiled New England Cottontail and Invasive Eastern Cottontail",
    "section": "Abstract",
    "text": "Abstract\nOngoing declines in the imperiled New England cottontail Sylvilagus transitionalis have coincided with the introduction and expansion of the closely related eastern cottontail Sylvilagus floridanus. These paired population trends have led to the inference of competition between the two species. Competition between native and introduced species has often involved overlapping use of food resources, but limited effort has been spent to analyze the diets of New England cottontail and eastern cottontail and to evaluate the potential for resource competition. We used microhistologic analysis of fecal pellets to assess the winter diets of both species and we compared diet composition with available plant communities to evaluate their preferences for dietary items across southern New England and southeastern New York. We found no differences in diets between New England cottontail and eastern cottontail, although diets did differ between regions within the study area. Diet preferences also were consistent between the species and largely excluded nonnative plant genera. Our results demonstrate that these species are generalist herbivores and that there is high potential for competition for food resources in the winter between them, although the present lack of diet partitioning may indicate the presence of other factors limiting competition. This study highlights the need for careful evaluation of interactions between native and nonnative species, a prerequisite for developing conservation plans that appropriately account for interspecific competition."
  },
  {
    "objectID": "publications/articles/Davy2022.html",
    "href": "publications/articles/Davy2022.html",
    "title": "Rapidly declining body size in an insectivorous bat is associated with increased precipitation and decreased survival",
    "section": "",
    "text": "Davy, Christina M., Valerie von Zuben, Piia M. Kukka, Brian D. Gerber, Brian G. Slough, and Thomas S. Jung. 2022. “Rapidly Declining Body Size in an Insectivorous Bat is Associated with Increased Precipitation and Decreased Survival.” Ecological Applications 32(7): e2639. https://doi.org/10.1002/eap.2639"
  },
  {
    "objectID": "publications/articles/Davy2022.html#citation",
    "href": "publications/articles/Davy2022.html#citation",
    "title": "Rapidly declining body size in an insectivorous bat is associated with increased precipitation and decreased survival",
    "section": "",
    "text": "Davy, Christina M., Valerie von Zuben, Piia M. Kukka, Brian D. Gerber, Brian G. Slough, and Thomas S. Jung. 2022. “Rapidly Declining Body Size in an Insectivorous Bat is Associated with Increased Precipitation and Decreased Survival.” Ecological Applications 32(7): e2639. https://doi.org/10.1002/eap.2639"
  },
  {
    "objectID": "publications/articles/Davy2022.html#abstract",
    "href": "publications/articles/Davy2022.html#abstract",
    "title": "Rapidly declining body size in an insectivorous bat is associated with increased precipitation and decreased survival",
    "section": "Abstract",
    "text": "Abstract\nReduced food availability is implicated in declines in avian aerial insectivores, but the effect of nutritional stress on mammalian aerial insectivores is unclear. Unlike birds, insectivorous bats provision their young through lactation, which might protect nursing juveniles when prey availability is low but could increase the energetic burden on lactating females. We analyzed a 15-year capture–mark–recapture data set from 5312 individual little brown myotis (Myotis lucifugus) captured at 11 maternity colonies in northwestern Canada, to test the hypothesis that nutritional stress is impacting these mammalian aerial insectivores. We used long-bone (forearm [FA]) length as a proxy for relative access to nutrition during development, and body mass as a proxy for access to nutrition prior to capture. Average FA length and body mass both decreased significantly over the study period in adult females and juveniles, suggesting decreased access to nutrition. Effect sizes were very small, similar to those reported for declining body size in avian aerial insectivores. Declines in juvenile body mass were only observed in individuals captured in late summer when they were foraging independently, supporting our hypothesis that lactation provides some protection to nursing young during periods of nutritional stress. Potential drivers of the decline in bat size include one or both of (1) declining insect (prey) abundance, and (2) declining prey availability. Echolocating insectivorous bats cannot forage effectively during rainfall, which is increasing in our study area. The body mass of captured adult females and juveniles in our study was lower, on average, after periods of high rainfall, and higher after warmer-than-average periods. Finally, survival models revealed a positive association between FA length and survival, suggesting a fitness consequence to declines in body size. Our study area has not yet been impacted by bat white-nose syndrome (WNS), but research elsewhere has suggested that fatter bats are more likely to survive infection. We found evidence for WNS-independent shifts in the body size of little brown myotis, which can inform studies investigating population responses to WNS. More broadly, the cumulative effects of multiple stressors (e.g., disease, nutritional stress, climate change, and other pressures) on mammalian aerial insectivores require urgent attention."
  },
  {
    "objectID": "publications/articles/Gerber2023.html",
    "href": "publications/articles/Gerber2023.html",
    "title": "Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease",
    "section": "",
    "text": "Gerber, B.D., Mosher, B.A., Bailey, L.L., Muths, E., Crockett, H.J. and Converse, S.J. (2023), Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease. Anim. Conserv. https://doi.org/10.1111/acv.12877"
  },
  {
    "objectID": "publications/articles/Gerber2023.html#citation",
    "href": "publications/articles/Gerber2023.html#citation",
    "title": "Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease",
    "section": "",
    "text": "Gerber, B.D., Mosher, B.A., Bailey, L.L., Muths, E., Crockett, H.J. and Converse, S.J. (2023), Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease. Anim. Conserv. https://doi.org/10.1111/acv.12877"
  },
  {
    "objectID": "publications/articles/Gerber2023.html#abstract",
    "href": "publications/articles/Gerber2023.html#abstract",
    "title": "Optimal management decisions are robust to unknown dynamics in an amphibian metapopulation plagued by disease",
    "section": "Abstract",
    "text": "Abstract\nIdentifying conservation actions to recover threatened species can be challenging due to many ecological uncertainties. For example, major threats to a species’ conservation are commonly known or suspected, but the specific impacts on population or metapopulation dynamics can be uncertain. This is frequently the case with emerging infectious diseases, including chytridiomycosis, a global driver of amphibian population declines caused by the fungal pathogens Batrachochytrium dendrobatidis (Bd) and Batrachochytrium salamandrivorans. While these diseases are known to cause amphibian declines and extirpations, the mechanisms of their landscape-scale spread are still largely unknown. Such uncertainty can lead to inaction which may jeopardize timely recovery of a species. Decision analysis is a pragmatic approach to making transparent and defensible decisions while dealing with uncertainties. We investigated whether optimal actions aimed at recovering boreal toad (Anaxyrus boreas boreas) metapopulations in the southern Rocky Mountains are robust to the unknown dynamics of Bd spread using value of information and regret analyses. Value of information is a decision-analytic tool for calculating the value of new information in terms of performance on management objectives, while regret measures the cost of acting under incorrect information. We further conducted a stochastic sensitivity analysis to identify the relative effects of metapopulation parameters on system dynamics. We found optimal actions were robust to the unknown dynamics of Bd spread. While boreal toad breeding occurrence is highly sensitive to Bd distribution, the optimal decision is not. Resolving the unknown dynamics of Bd spread would lead to a minimal gain of less than one breeding toad subpopulation at the end of 50 years, given the currently available management actions. Applying a decision-analytic framework coupled with value of information and regret analyses can help frame how uncertainties affect decisions in a way that empowers decision makers."
  },
  {
    "objectID": "publications/articles/Mayer2022.html",
    "href": "publications/articles/Mayer2022.html",
    "title": "Transient persistence of bobcat (Lynx rufus) occurrence throughout a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., McGreevy, T. J. Jr, Brown, C., Ganoe, L. S., & Gerber, B. D. (2022). Transient persistence of bobcat (Lynx rufus) occurrence throughout a human-dominated landscape. Population Ecology, 64(4), 323–335. https://doi.org/10.1002/1438-390X.12123"
  },
  {
    "objectID": "publications/articles/Mayer2022.html#citation",
    "href": "publications/articles/Mayer2022.html#citation",
    "title": "Transient persistence of bobcat (Lynx rufus) occurrence throughout a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., McGreevy, T. J. Jr, Brown, C., Ganoe, L. S., & Gerber, B. D. (2022). Transient persistence of bobcat (Lynx rufus) occurrence throughout a human-dominated landscape. Population Ecology, 64(4), 323–335. https://doi.org/10.1002/1438-390X.12123"
  },
  {
    "objectID": "publications/articles/Mayer2022.html#abstract",
    "href": "publications/articles/Mayer2022.html#abstract",
    "title": "Transient persistence of bobcat (Lynx rufus) occurrence throughout a human‐dominated landscape",
    "section": "Abstract",
    "text": "Abstract\nHuman developments have detrimental effects on wildlife populations globally with carnivores being particularly sensitive. The bobcat (Lynx rufus) is often considered an adaptable mesocarnivore that occurs throughout varied landcover types within its wide distribution and may be less susceptible to the negative effects of development. Our objectives were to investigate the landscape occupancy dynamics of bobcats in a highly developed and densely populated region of the northeastern United States to evaluate the sensitivity of bobcat occurrence to natural and anthropogenic landscape features. We established a large-scale camera trapping survey throughout Rhode Island, USA, sampling from 2018 to 2020. Using dynamic occupancy models, we found initial site occupancy was positively influenced by the amount of forested wetland habitat, while increasing road density and shrub cover negatively influenced the probability of site colonization. Surprisingly, we found no hypothesized variables to influence site-level extirpation probability, or any seasonal effects on dynamic parameters. Lastly, we found that forest cover and road density negatively influenced the probability of detection. The probability of occupancy was high, &gt;0.8, throughout much of the study area (49%), but we also found relatively high site transients, with the probability a site would change occurrence status from season to season at ≈0.27 in the majority of the study area (70%). Our results show that although bobcats can persist in human-dominated landscapes, they require contiguous natural areas to do so. Future expansion of road infrastructure may reduce habitat connectivity and increase road mortalities, thus jeopardizing the population."
  },
  {
    "objectID": "publications/articles/Rivera2022.html",
    "href": "publications/articles/Rivera2022.html",
    "title": "Rethinking habitat occupancy modeling and the role of diel activity in an anthropogenic world",
    "section": "",
    "text": "Rethinking Habitat Occupancy Modeling and the Role of Diel Activity in an Anthropogenic World. Rivera, K, Fidino, M, Farris, zj, Magle, SB, Murohy, A, Gerber, BD. The American Naturalist 2022 200:4, 556-570"
  },
  {
    "objectID": "publications/articles/Rivera2022.html#citation",
    "href": "publications/articles/Rivera2022.html#citation",
    "title": "Rethinking habitat occupancy modeling and the role of diel activity in an anthropogenic world",
    "section": "",
    "text": "Rethinking Habitat Occupancy Modeling and the Role of Diel Activity in an Anthropogenic World. Rivera, K, Fidino, M, Farris, zj, Magle, SB, Murohy, A, Gerber, BD. The American Naturalist 2022 200:4, 556-570"
  },
  {
    "objectID": "publications/articles/Rivera2022.html#abstract",
    "href": "publications/articles/Rivera2022.html#abstract",
    "title": "Rethinking habitat occupancy modeling and the role of diel activity in an anthropogenic world",
    "section": "Abstract",
    "text": "Abstract\nCurrent methods to model species habitat use through space and diel time are limited. Development of such models is critical when considering rapidly changing habitats where species are forced to adapt to anthropogenic change, often by shifting their diel activity across space. We use an occupancy modeling framework to specify the multistate diel occupancy model (MSDOM), which can evaluate species diel activity against continuous response variables that may impact diel activity within and across seasons or years. We used two case studies, fosas in Madagascar and coyotes in Chicago, Illinois, to conceptualize the application of this model and to quantify the impacts of human activity on species spatial use in diel time. We found support that both species varied their habitat use by diel states—in and across years and by human disturbance. Our results exemplify the importance of understanding animal diel activity patterns and how human disturbance can lead to temporal habitat loss. The MSDOM will allow more focused attention in ecology and evolution studies on the importance of the short temporal scale of diel time in animal-habitat relationships and lead to improved habitat conservation and management."
  },
  {
    "objectID": "publications/articles/Snapshort2022.html",
    "href": "publications/articles/Snapshort2022.html",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "",
    "text": "Kays, Roland, Michael V. Cove, Jose Diaz, Kimberly Todd, Claire Bresnan, Matt Snider, Thomas E. Lee Jr, et al. 2022. “ SNAPSHOT USA 2020: A Second Coordinated National Camera Trap Survey of the United States during the COVID-19 Pandemic.” Ecology 103(10): e3775. https://doi.org/10.1002/ecy.3775"
  },
  {
    "objectID": "publications/articles/Snapshort2022.html#citation",
    "href": "publications/articles/Snapshort2022.html#citation",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "",
    "text": "Kays, Roland, Michael V. Cove, Jose Diaz, Kimberly Todd, Claire Bresnan, Matt Snider, Thomas E. Lee Jr, et al. 2022. “ SNAPSHOT USA 2020: A Second Coordinated National Camera Trap Survey of the United States during the COVID-19 Pandemic.” Ecology 103(10): e3775. https://doi.org/10.1002/ecy.3775"
  },
  {
    "objectID": "publications/articles/Snapshort2022.html#abstract",
    "href": "publications/articles/Snapshort2022.html#abstract",
    "title": "SNAPSHOT USA 2020: A second coordinated national camera trap survey of the United States during the COVID‐19 pandemic",
    "section": "Abstract",
    "text": "Abstract\nManaging wildlife populations in the face of global change requires regular data on the abundance and distribution of wild animals, but acquiring these over appropriate spatial scales in a sustainable way has proven challenging. Here we present the data from Snapshot USA 2020, a second annual national mammal survey of the USA. This project involved 152 scientists setting camera traps in a standardized protocol at 1485 locations across 103 arrays in 43 states for a total of 52,710 trap-nights of survey effort. Most (58) of these arrays were also sampled during the same months (September and October) in 2019, providing a direct comparison of animal populations in 2 years that includes data from both during and before the COVID-19 pandemic. All data were managed by the eMammal system, with all species identifications checked by at least two reviewers. In total, we recorded 117,415 detections of 78 species of wild mammals, 9236 detections of at least 43 species of birds, 15,851 detections of six domestic animals and 23,825 detections of humans or their vehicles. Spatial differences across arrays explained more variation in the relative abundance than temporal variation across years for all 38 species modeled, although there are examples of significant site-level differences among years for many species. Temporal results show how species allocate their time and can be used to study species interactions, including between humans and wildlife. These data provide a snapshot of the mammal community of the USA for 2020 and will be useful for exploring the drivers of spatial and temporal changes in relative abundance and distribution, and the impacts of species interactions on daily activity patterns. There are no copyright restrictions, and please cite this paper when using these data, or a subset of these data, for publication."
  },
  {
    "objectID": "publications/articles/Betts2022.html",
    "href": "publications/articles/Betts2022.html",
    "title": "Forest degradation drives widespread avian habitat and population declines",
    "section": "",
    "text": "Betts, M.G., Yang, Z., Hadley, A.S. et al. Forest degradation drives widespread avian habitat and population declines. Nat Ecol Evol 6, 709–719 (2022). https://doi.org/10.1038/s41559-022-01737-8"
  },
  {
    "objectID": "publications/articles/Betts2022.html#citation",
    "href": "publications/articles/Betts2022.html#citation",
    "title": "Forest degradation drives widespread avian habitat and population declines",
    "section": "",
    "text": "Betts, M.G., Yang, Z., Hadley, A.S. et al. Forest degradation drives widespread avian habitat and population declines. Nat Ecol Evol 6, 709–719 (2022). https://doi.org/10.1038/s41559-022-01737-8"
  },
  {
    "objectID": "publications/articles/Betts2022.html#abstract",
    "href": "publications/articles/Betts2022.html#abstract",
    "title": "Forest degradation drives widespread avian habitat and population declines",
    "section": "Abstract",
    "text": "Abstract\nIn many regions of the world, forest management has reduced old forest and simplified forest structure and composition. We hypothesized that such forest degradation has resulted in long-term habitat loss for forest-associated bird species of eastern Canada (130,017 km2) which, in turn, has caused bird-population declines. Despite little change in overall forest cover, we found substantial reductions in old forest as a result of frequent clear-cutting and a broad-scale transformation to intensified forestry. Back-cast species distribution models revealed that breeding habitat loss occurred for 66% of the 54 most common species from 1985 to 2020 and was strongly associated with reduction in old age classes. Using a long-term, independent dataset, we found that habitat amount predicted population size for 94% of species, and habitat loss was associated with population declines for old-forest species. Forest degradation may therefore be a primary cause of biodiversity decline in managed forest landscapes."
  },
  {
    "objectID": "publications/articles/Wampole2022.html",
    "href": "publications/articles/Wampole2022.html",
    "title": "Madagascar Terrestrial Camera Survey Database 2021: A collation of protected forest camera surveys from 2007–2021",
    "section": "",
    "text": "Wampole, Erin M., Brian D. Gerber, Zach J. Farris, Jean Claude Razafimahaimodison, Mahandry Hugues Andrianarisoa, Claude Jacquot Ralazampirenena, Patricia C. Wright, et al. 2022. “ Madagascar Terrestrial Camera Survey Database 2021: A Collation of Protected Forest Camera Surveys from 2007–2021.” Ecology 103(6): e3687. https://doi.org/10.1002/ecy.3687"
  },
  {
    "objectID": "publications/articles/Wampole2022.html#citation",
    "href": "publications/articles/Wampole2022.html#citation",
    "title": "Madagascar Terrestrial Camera Survey Database 2021: A collation of protected forest camera surveys from 2007–2021",
    "section": "",
    "text": "Wampole, Erin M., Brian D. Gerber, Zach J. Farris, Jean Claude Razafimahaimodison, Mahandry Hugues Andrianarisoa, Claude Jacquot Ralazampirenena, Patricia C. Wright, et al. 2022. “ Madagascar Terrestrial Camera Survey Database 2021: A Collation of Protected Forest Camera Surveys from 2007–2021.” Ecology 103(6): e3687. https://doi.org/10.1002/ecy.3687"
  },
  {
    "objectID": "publications/articles/Wampole2022.html#abstract",
    "href": "publications/articles/Wampole2022.html#abstract",
    "title": "Madagascar Terrestrial Camera Survey Database 2021: A collation of protected forest camera surveys from 2007–2021",
    "section": "Abstract",
    "text": "Abstract\nMadagascar is a threatened global biodiversity hotspot and conservation priority, yet we lack broad-scale surveys to assess biodiversity across space and time. To fill this gap, we collated camera trap surveys, capturing species occurrences within Madagascar into a single standardized database. This data set includes nine distinct protected areas of Madagascar and encompasses 13 subprojects, 38 camera arrays, and 1156 sampling units (independent camera site per survey) within two important biodiversity eco-regions: western dry deciduous forest and eastern humid rainforest. Camera surveys were conducted from June 2007 to January 2021. The final data set includes 17 unique families of mammals (Bovidae, Canidae, Cheirogaleidae, Daubentoniidae, Equidae, Eupleridae, Felidae, Hominidae, Indriidae, Lemuridae, Lepilemuridae, Muridae, Nesomyidae, Pteropodidae, Soricidae, Suidae, Tenrecidae) comprising 45 species and 27 unique families of birds (Accipitridae, Acrocephalidae, Alcedinidae, Bernieridae, Brachypteraciidae, Caprimulgidae, Cisticolidae, Columbidae, Coraciidae, Corvidae, Cuculidae, Dicruridae, Mesitornithidae, Monarchidae, Motacillidae, Muscicapidae, Numididae, Phasianidae, Rallidae, Sarothruridae, Strigidae, Sturnidae, Sulidae, Threskiornithidae, Upupidae, Vangidae, Zosteropidae) comprising 58 species. Images were processed and verified by individual project data set creators and camera operation and species tables were then collated. The final product represents the first broad-scale freely available standardized formal faunal database for Madagascar. Data are available through this publication and at DOI: 10.5281/zenodo.5801806. These data will be useful for examining species-level and community-level trends in occurrence across space or time within Madagascar and globally, evaluating native and invasive species dynamics, and will aid in determining species conservation status and planning for at-risk species. There are no copyright restrictions; please cite this paper when using the data for publication."
  },
  {
    "objectID": "publications/articles/Hallisey2022.html",
    "href": "publications/articles/Hallisey2022.html",
    "title": "Estimating road mortality hotspots while accounting for imperfect detection: A case study with amphibians and reptiles",
    "section": "",
    "text": "Hallisey N, Buchanan SW, Gerber BD, Corcoran LS, Karraker NE. Estimating Road Mortality Hotspots While Accounting for Imperfect Detection: A Case Study with Amphibians and Reptiles. Land. 2022; 11(5):739. https://doi.org/10.3390/land11050739"
  },
  {
    "objectID": "publications/articles/Hallisey2022.html#citation",
    "href": "publications/articles/Hallisey2022.html#citation",
    "title": "Estimating road mortality hotspots while accounting for imperfect detection: A case study with amphibians and reptiles",
    "section": "",
    "text": "Hallisey N, Buchanan SW, Gerber BD, Corcoran LS, Karraker NE. Estimating Road Mortality Hotspots While Accounting for Imperfect Detection: A Case Study with Amphibians and Reptiles. Land. 2022; 11(5):739. https://doi.org/10.3390/land11050739"
  },
  {
    "objectID": "publications/articles/Hallisey2022.html#abstract",
    "href": "publications/articles/Hallisey2022.html#abstract",
    "title": "Estimating road mortality hotspots while accounting for imperfect detection: A case study with amphibians and reptiles",
    "section": "Abstract",
    "text": "Abstract\nWildlife road mortality tends to aggregate spatially at locations commonly referred to as road mortality hotspots. Predictive models can be used to identify locations appropriate for mitigation measures that reduce road mortality. However, the influence of imperfect detection (e.g., false absences) during road mortality surveys can lead to inaccurate or imprecise spatial patterns of road mortality hotspots and suboptimal implementation of mitigation measures. In this research, we used amphibians and reptiles as a case study to address imperfect detection issues when estimating the probability of road mortality hotspots using occupancy detection modeling. In addition, we determined the survey effort needed to achieve a high probability of detecting large roadkill events. We also assessed whether vehicle travel reductions associated with the COVID-19 pandemic travel restrictions led to reductions in road mortality. We conducted surveys at 48 sites throughout Rhode Island, USA, from 2019–2021. In total, we observed 657 carcasses representing 19 of Rhode Island’s 37 native species. Of the 19 native species, eight species of frogs, four species of salamanders, four species of snakes, and three species of turtles were observed. We documented a reduction in roadkill density and the proportion of dead versus live amphibians and reptiles in pandemic years (2020 and 2021), but we were unable to link reductions in roadkill density to reductions in traffic volume. Our model results indicated that large roadkill events were more likely to occur on roads near wetlands and with low traffic volume and were more likely to be detected as daily precipitation increased. We determined that there was a low probability of detecting large roadkill events, suggesting that imperfect detection influences detection of large roadkill events, and many were likely missed during our surveys. Therefore, we recommend using occupancy modeling to account for the influence of imperfect detection when estimating road mortality hotspots. This approach will more effectively guide the implementation of mitigation measures."
  },
  {
    "objectID": "publications/articles/Gallo2022.html",
    "href": "publications/articles/Gallo2022.html",
    "title": "Mammals adjust diel activity across gradients of urbanization",
    "section": "",
    "text": "Gallo, Travis, Mason Fidino, Brian Gerber, Adam A. Ahlers, Julia L. Angstmann, Max Amaya, David Drake et al. Mammals adjust diel activity across gradients of urbanization. Elife, 11 (2022), e74756.https://doi.org/10.7554/eLife.74756"
  },
  {
    "objectID": "publications/articles/Gallo2022.html#citation",
    "href": "publications/articles/Gallo2022.html#citation",
    "title": "Mammals adjust diel activity across gradients of urbanization",
    "section": "",
    "text": "Gallo, Travis, Mason Fidino, Brian Gerber, Adam A. Ahlers, Julia L. Angstmann, Max Amaya, David Drake et al. Mammals adjust diel activity across gradients of urbanization. Elife, 11 (2022), e74756.https://doi.org/10.7554/eLife.74756"
  },
  {
    "objectID": "publications/articles/Gallo2022.html#abstract",
    "href": "publications/articles/Gallo2022.html#abstract",
    "title": "Mammals adjust diel activity across gradients of urbanization",
    "section": "Abstract",
    "text": "Abstract\nTime is a fundamental component of ecological processes. How animal behavior changes over time has been explored through well-known ecological theories like niche partitioning and predator–prey dynamics. Yet, changes in animal behavior within the shorter 24-hr light–dark cycle have largely gone unstudied. Understanding if an animal can adjust their temporal activity to mitigate or adapt to environmental change has become a recent topic of discussion and is important for effective wildlife management and conservation. While spatial habitat is a fundamental consideration in wildlife management and conservation, temporal habitat is often ignored. We formulated a temporal resource selection model to quantify the diel behavior of 8 mammal species across 10 US cities. We found high variability in diel activity patterns within and among species and species-specific correlations between diel activity and human population density, impervious land cover, available greenspace, vegetation cover, and mean daily temperature. We also found that some species may modulate temporal behaviors to manage both natural and anthropogenic risks. Our results highlight the complexity with which temporal activity patterns interact with local environmental characteristics, and suggest that urban mammals may use time along the 24-hr cycle to reduce risk, adapt, and therefore persist, and in some cases thrive, in human-dominated ecosystems."
  },
  {
    "objectID": "publications/articles/Masseloux2022.html",
    "href": "publications/articles/Masseloux2022.html",
    "title": "Forest structure and seasonally inundated grassland shape tropical mammal communities under moderate disturbance",
    "section": "",
    "text": "Masseloux, Juliana, Quy Tan Le, Jessica Burr, and Brian D. Gerber. 2022. “ Forest Structure and Seasonally Inundated Grassland Shape Tropical Mammal Communities under Moderate Disturbance.” Ecosphere 13(3): e3999. https://doi.org/10.1002/ecs2.3999"
  },
  {
    "objectID": "publications/articles/Masseloux2022.html#citation",
    "href": "publications/articles/Masseloux2022.html#citation",
    "title": "Forest structure and seasonally inundated grassland shape tropical mammal communities under moderate disturbance",
    "section": "",
    "text": "Masseloux, Juliana, Quy Tan Le, Jessica Burr, and Brian D. Gerber. 2022. “ Forest Structure and Seasonally Inundated Grassland Shape Tropical Mammal Communities under Moderate Disturbance.” Ecosphere 13(3): e3999. https://doi.org/10.1002/ecs2.3999"
  },
  {
    "objectID": "publications/articles/Masseloux2022.html#abstract",
    "href": "publications/articles/Masseloux2022.html#abstract",
    "title": "Forest structure and seasonally inundated grassland shape tropical mammal communities under moderate disturbance",
    "section": "Abstract",
    "text": "Abstract\nTropical biodiversity is threatened globally by anthropogenic disturbances, particularly forest degradation and overhunting. Where large mammals have been extirpated, smaller bodied “mesomammals” may play an important ecological role (e.g., as seed dispersers). However, these species are disproportionally affected by overhunting for wildlife trade markets and are routinely understudied as they tend to be rare, cryptic, and nocturnal. Few studies have examined spatiotemporal responses to anthropogenic disturbance by mesomammals at the community level, which may identify imbalances within an ecosystem that could threaten species persistence. We deployed camera traps throughout Cat Tien National Park (i.e., Nam Cat Tien area), southern Vietnam, to (1) identify long-term changes in terrestrial mesomammal richness and (2) evaluate the effects of forest structure and anthropogenic disturbance on an 18-species mesomammal community within a historically disturbed tropical forest using hierarchical Bayesian community occupancy models. We found that site occupancy was driven by the interaction between distance to seasonally inundated grassland and absolute forest cover (basal area per hectare). This may be due to the combination of intact forest benefits (refuge from predators and hunters, denning sites) and early successional grassland resources (forage quality), as well as high levels of tolerance for disturbed forest among the largely generalist mesomammal community of Nam Cat Tien. We found no negative effects of current anthropogenic factors at the community level. However, we did find that four disturbance-tolerant small carnivores have been extirpated since the 1990s and continued human presence in the park suggests that hunting and snaring remain an acute threat to native mesomammals. Without continued efforts to address the unsustainable harvest of wildlife, Southeast Asian’s remaining mesomammals are at risk of extirpation despite resilience to moderate levels of disturbance."
  },
  {
    "objectID": "publications/articles/Northrup2022.html",
    "href": "publications/articles/Northrup2022.html",
    "title": "Conceptual and methodological advances in habitat‐selection modeling: guidelines for ecology and evolution",
    "section": "",
    "text": "Northrup, J. M., E. Vander Wal, M. Bonar, J. Fieberg, M. P. Laforge, M. Leclerc, C. M. Prokopenko, and B. D. Gerber. 2022. Conceptual and methodological advances in habitat-selection modeling: guidelines for ecology and evolution. Ecological Applications 32(1):e02470. 10.1002/eap.2470"
  },
  {
    "objectID": "publications/articles/Northrup2022.html#citation",
    "href": "publications/articles/Northrup2022.html#citation",
    "title": "Conceptual and methodological advances in habitat‐selection modeling: guidelines for ecology and evolution",
    "section": "",
    "text": "Northrup, J. M., E. Vander Wal, M. Bonar, J. Fieberg, M. P. Laforge, M. Leclerc, C. M. Prokopenko, and B. D. Gerber. 2022. Conceptual and methodological advances in habitat-selection modeling: guidelines for ecology and evolution. Ecological Applications 32(1):e02470. 10.1002/eap.2470"
  },
  {
    "objectID": "publications/articles/Northrup2022.html#abstract",
    "href": "publications/articles/Northrup2022.html#abstract",
    "title": "Conceptual and methodological advances in habitat‐selection modeling: guidelines for ecology and evolution",
    "section": "Abstract",
    "text": "Abstract\nHabitat selection is a fundamental animal behavior that shapes a wide range of ecological processes, including animal movement, nutrient transfer, trophic dynamics and population distribution. Although habitat selection has been a focus of ecological studies for decades, technological, conceptual and methodological advances over the last 20 yr have led to a surge in studies addressing this process. Despite the substantial literature focused on quantifying the habitat-selection patterns of animals, there is a marked lack of guidance on best analytical practices. The conceptual foundations of the most commonly applied modeling frameworks can be confusing even to those well versed in their application. Furthermore, there has yet to be a synthesis of the advances made over the last 20 yr. Therefore, there is a need for both synthesis of the current state of knowledge on habitat selection, and guidance for those seeking to study this process. Here, we provide an approachable overview and synthesis of the literature on habitat-selection analyses (HSAs) conducted using selection functions, which are by far the most applied modeling framework for understanding the habitat-selection process. This review is purposefully non-technical and focused on understanding without heavy mathematical and statistical notation, which can confuse many practitioners. We offer an overview and history of HSAs, describing the tortuous conceptual path to our current understanding. Through this overview, we also aim to address the areas of greatest confusion in the literature. We synthesize the literature outlining the most exciting conceptual advances in the field of habitat-selection modeling, discussing the substantial ecological and evolutionary inference that can be made using contemporary techniques. We aim for this paper to provide clarity for those navigating the complex literature on HSAs while acting as a reference and best practices guide for practitioners."
  },
  {
    "objectID": "publications/articles/Mayer2021.html",
    "href": "publications/articles/Mayer2021.html",
    "title": "Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England",
    "section": "",
    "text": "Mayer, A. E., McGreevy Jr, T. J., Sullivan, M. E., Brown, C., Husband, T. P., & Gerber, B. D. (2021). Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England. Northeastern Naturalist, 28(4), 408-429."
  },
  {
    "objectID": "publications/articles/Mayer2021.html#citation",
    "href": "publications/articles/Mayer2021.html#citation",
    "title": "Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England",
    "section": "",
    "text": "Mayer, A. E., McGreevy Jr, T. J., Sullivan, M. E., Brown, C., Husband, T. P., & Gerber, B. D. (2021). Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England. Northeastern Naturalist, 28(4), 408-429."
  },
  {
    "objectID": "publications/articles/Mayer2021.html#abstract",
    "href": "publications/articles/Mayer2021.html#abstract",
    "title": "Population genetics and spatial ecology of bobcats (Lynx rufus) in a landscape with a high density of humans in New England",
    "section": "Abstract",
    "text": "Abstract\nLynx rufus (Bobcat) is a wide-ranging and highly adaptable predator whose populations are increasing throughout much of its natural range including in the New England states, yet there are only limited empirical ecological studies there. How Bobcats are responding to the unique modern landscape of southern New England with its highly forested landscape coupled with high density of humans is unknown. This lack of spatial and population ecological information impedes evaluating recovery and management objectives and identifying necessary management actions. Our objectives were to better understand the spatial and population structure of Bobcats in Rhode Island. We specifically examined space use, resource selection, and population genetics. We trapped Bobcats across 5 field seasons from April 2015 to March 2019, totaling 2232 trap nights. We captured 8 Bobcats, equipped GPS collars to a subset (n = 3), and collected locations for 4 to 9 months. We used GPS locations to estimate annual and seasonal home-range size and individual-level seasonal resource selection within the home range for each individual. Further, we used tissue samples collected from trapped individuals and opportunistically collected roadkill (n = 30) to examine the population genetic structure and effective population size of Bobcats in the state. We found the mean winter and summer home-range sizes were 219.3 km2 and 51.7 km2, respectively. Bobcats selected for forested wetland habitats and were associated with areas closer to wetlands and young forests, according to resource-selection models. They also selected for areas with higher road densities, yet avoided developed areas. We found that Bobcats in Rhode Island are part of 1 genetic population and estimated their effective population size to be 82 individuals (95% CI: 44–329). Our study highlights the importance of examining a widely distributed species at a local scale in order to employ evidence-based management practices."
  },
  {
    "objectID": "publications/articles/Wampole2021.html",
    "href": "publications/articles/Wampole2021.html",
    "title": "A synthesis of life‐history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J. and Gerber, B.D. (2021), A synthesis of life-history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae. Mam Rev, 51: 402-419. https://doi.org/10.1111/mam.12234"
  },
  {
    "objectID": "publications/articles/Wampole2021.html#citation",
    "href": "publications/articles/Wampole2021.html#citation",
    "title": "A synthesis of life‐history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J. and Gerber, B.D. (2021), A synthesis of life-history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae. Mam Rev, 51: 402-419. https://doi.org/10.1111/mam.12234"
  },
  {
    "objectID": "publications/articles/Wampole2021.html#abstract",
    "href": "publications/articles/Wampole2021.html#abstract",
    "title": "A synthesis of life‐history traits, functional traits, and consequences of anthropogenic pressures on Madagascar’s threatened carnivorans, Eupleridae",
    "section": "Abstract",
    "text": "Abstract\nMadagascar’s native carnivorans are an endemic monophyletic group of eight extant species belonging to the family Eupleridae. The International Union for Conservation of Nature (IUCN) currently classifies seven of the species as threatened (Vulnerable or Endangered), as their populations are in decline due to intensifying anthropogenic pressures. However, little is known about these species’ ecology and population trends, precluding forecasts of extinction risk. Life-history and functional traits govern species’ responses to environmental pressure and can be predictive of extinction risk. Incorporating relevant trait information can vastly improve risk assessments. Yet, information on the life-history and functional traits of the Eupleridae has never been compiled into a single framework. Our aims were to: 1) synthesise the current state of knowledge of the life-history and functional traits of euplerid species, 2) review empirical evidence of the effects of anthropogenic pressures on species, and 3) identify knowledge gaps and future research needs. We searched the published literature to compile life-history and functional trait information and known effects of anthropogenic pressures for Eupleridae. Our review indicates that Madagascar’s carnivorans have high-risk life-history and functional traits that increase their vulnerability to anthropogenic pressures. Publications reported negative effects on euplerids from habitat degradation and fragmentation, logging, non-native carnivorans, disease, and hunting and retaliatory killings. However, our synthesis revealed significant knowledge gaps, especially in species’ life-history traits and in the spatial variability in most traits. For most species, we currently do not have the robust data needed to assess trait-based risk dynamics. The culmination of reported traits, negative influence of ongoing anthropogenic pressures, and lack of robust metrics (e.g. population trends and trait variability) indicate that euplerids are at high risk, yet may reach the cusp of extinction without notice due to significant gaps in knowledge. Future research should prioritise filling gaps in knowledge of influential traits, evaluating anthropogenic pressures, and integrating trait information to improve risk assessments and extinction forecasts."
  },
  {
    "objectID": "publications/articles/Snapshort2021.html",
    "href": "publications/articles/Snapshort2021.html",
    "title": "SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States",
    "section": "",
    "text": "Cove, M. V., et al. 2021. SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States. Ecology 102(6):e03353. 10.1002/ecy.3353"
  },
  {
    "objectID": "publications/articles/Snapshort2021.html#citation",
    "href": "publications/articles/Snapshort2021.html#citation",
    "title": "SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States",
    "section": "",
    "text": "Cove, M. V., et al. 2021. SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States. Ecology 102(6):e03353. 10.1002/ecy.3353"
  },
  {
    "objectID": "publications/articles/Snapshort2021.html#abstract",
    "href": "publications/articles/Snapshort2021.html#abstract",
    "title": "SNAPSHOT USA 2019: a coordinated national camera trap survey of the United States",
    "section": "Abstract",
    "text": "Abstract\nWith the accelerating pace of global change, it is imperative that we obtain rapid inventories of the status and distribution of wildlife for ecological inferences and conservation planning. To address this challenge, we launched the SNAPSHOT USA project, a collaborative survey of terrestrial wildlife populations using camera traps across the United States. For our first annual survey, we compiled data across all 50 states during a 14-week period (17 August–24 November of 2019). We sampled wildlife at 1,509 camera trap sites from 110 camera trap arrays covering 12 different ecoregions across four development zones. This effort resulted in 166,036 unique detections of 83 species of mammals and 17 species of birds. All images were processed through the Smithsonian’s eMammal camera trap data repository and included an expert review phase to ensure taxonomic accuracy of data, resulting in each picture being reviewed at least twice. The results represent a timely and standardized camera trap survey of the United States. All of the 2019 survey data are made available herein. We are currently repeating surveys in fall 2020, opening up the opportunity to other institutions and cooperators to expand coverage of all the urban–wild gradients and ecophysiographic regions of the country. Future data will be available as the database is updated at eMammal.si.edu/snapshot-usa, as will future data paper submissions. These data will be useful for local and macroecological research including the examination of community assembly, effects of environmental and anthropogenic landscape variables, effects of fragmentation and extinction debt dynamics, as well as species-specific population dynamics and conservation action plans. There are no copyright restrictions; please cite this paper when using the data for publication."
  },
  {
    "objectID": "publications/articles/Northrup2021.html",
    "href": "publications/articles/Northrup2021.html",
    "title": "Behavioral and demographic responses of mule deer to energy development on winter range",
    "section": "",
    "text": "Northrup, J.M., Anderson, C.R., Jr., Gerber, B.D. and Wittemyer, G. (2021), Behavioral and Demographic Responses of Mule Deer to Energy Development on Winter Range. Wild. Mon., 208: 1-37. https://doi.org/10.1002/wmon.1060"
  },
  {
    "objectID": "publications/articles/Northrup2021.html#citation",
    "href": "publications/articles/Northrup2021.html#citation",
    "title": "Behavioral and demographic responses of mule deer to energy development on winter range",
    "section": "",
    "text": "Northrup, J.M., Anderson, C.R., Jr., Gerber, B.D. and Wittemyer, G. (2021), Behavioral and Demographic Responses of Mule Deer to Energy Development on Winter Range. Wild. Mon., 208: 1-37. https://doi.org/10.1002/wmon.1060"
  },
  {
    "objectID": "publications/articles/Northrup2021.html#abstract",
    "href": "publications/articles/Northrup2021.html#abstract",
    "title": "Behavioral and demographic responses of mule deer to energy development on winter range",
    "section": "Abstract",
    "text": "Abstract\nAnthropogenic habitat modification is a major driver of global biodiversity loss. In North America, one of the primary sources of habitat modification over the last 2 decades has been exploration for and production of oil and natural gas (hydrocarbon development), which has led to demographic and behavioral impacts to numerous wildlife species. Developing effective measures to mitigate these impacts has become a critical task for wildlife managers and conservation practitioners. However, this task has been hindered by the difficulties involved in identifying and isolating factors driving population responses. Current research on responses of wildlife to development predominantly quantifies behavior, but it is not always clear how these responses scale to demography and population dynamics. Concomitant assessments of behavior and population-level processes are needed to gain the mechanistic understanding required to develop effective mitigation approaches. We simultaneously assessed the demographic and behavioral responses of a mule deer population to natural gas development on winter range in the Piceance Basin of Colorado, USA, from 2008 to 2015. Notably, this was the period when development declined from high levels of active drilling to only production phase activity (i.e., no drilling). We focused our data collection on 2 contiguous mule deer winter range study areas that experienced starkly different levels of hydrocarbon development within the Piceance Basin.\nWe assessed mule deer behavioral responses to a range of development features with varying levels of associated human activity by examining habitat selection patterns of nearly 400 individual adult female mule deer. Concurrently, we assessed the demographic and physiological effects of natural gas development by comparing annual adult female and overwinter fawn (6-month-old animals) survival, December fawn mass, adult female late and early winter body fat, age, pregnancy rates, fetal counts, and lactation rates in December between the 2 study areas. Strong differences in habitat selection between the 2 study areas were apparent. Deer in the less-developed study area avoided development during the day and night, and selected habitat presumed to be used for foraging. Deer in the heavily developed study area selected habitat presumed to be used for thermal and security cover to a greater degree. Deer faced with higher densities of development avoided areas with more well pads during the day and responded neutrally or selected for these areas at night. Deer in both study areas showed a strong reduction in use of areas around well pads that were being drilled, which is the phase of energy development associated with the greatest amount of human presence, vehicle traffic, noise, and artificial light. Despite divergent habitat selection patterns, we found no effects of development on individual condition or reproduction and found no differences in any of the physiological or vital rate parameters measured at the population level. However, deer density and annual increases in density were higher in the low-development area. Thus, the recorded behavioral alterations did not appear to be associated with demographic or physiological costs measured at the individual level, possibly because populations are below winter range carrying capacity. Differences in population density between the 2 areas may be a result of a population decline prior to our study (when development was initiated) or area-specific differences in habitat quality, juvenile dispersal, or neonatal or juvenile survival; however, we lack the required data to contrast evidence for these mechanisms.\nGiven our results, it appears that deer can adjust to relatively high densities of well pads in the production phase (the period with markedly lower human activity on the landscape), provided there is sufficient vegetative and topographic cover afforded to them and populations are below carrying capacity. The strong reaction to wells in the drilling phase of development suggests mitigation efforts should focus on this activity and stage of development. Many of the wells in this area were directionally drilled from multiple-well pads, leading to a reduced footprint of disturbance, but were still related to strong behavioral responses. Our results also indicate the likely value of mitigation efforts focusing on reducing human activity (i.e., vehicle traffic, light, and noise). In combination, these findings indicate that attention should be paid to the spatial configuration of the final development footprint to ensure adequate cover. In our study system, minimizing the road network through landscape-level development planning would be valuable (i.e., exploring a maximum road density criteria). Lastly, our study highlights the importance of concomitant assessments of behavior and demography to provide a comprehensive understanding of how wildlife respond to habitat modification."
  },
  {
    "objectID": "publications/articles/HarringtonGerber.html",
    "href": "publications/articles/HarringtonGerber.html",
    "title": "The Mysterious case of the disappering Javan Rhino: Uing clues from Rhinos everyday habits and hobbies to figure out how to help them recover",
    "section": "",
    "text": "Harrington, E. R., & Gerber, B. D. (2020). THE MYSTERIOUS CASE OF THE DISAPPEARING JAVAN RHINO: USING CLUES FROM RHINOS’EVERYDAY HABITS AND HOBBIES TO FIGURE OUT HOW TO HELP THEM RECOVER. People and Wildlife, 47."
  },
  {
    "objectID": "publications/articles/HarringtonGerber.html#citation",
    "href": "publications/articles/HarringtonGerber.html#citation",
    "title": "The Mysterious case of the disappering Javan Rhino: Uing clues from Rhinos everyday habits and hobbies to figure out how to help them recover",
    "section": "",
    "text": "Harrington, E. R., & Gerber, B. D. (2020). THE MYSTERIOUS CASE OF THE DISAPPEARING JAVAN RHINO: USING CLUES FROM RHINOS’EVERYDAY HABITS AND HOBBIES TO FIGURE OUT HOW TO HELP THEM RECOVER. People and Wildlife, 47."
  },
  {
    "objectID": "publications/articles/Ross2020.html",
    "href": "publications/articles/Ross2020.html",
    "title": "Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar",
    "section": "",
    "text": "Ross PH, Patel E, Ferguson B, Ravelijaona RN and others (2020) Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar. Endang Species Res 43:89-98. https://doi.org/10.3354/esr01055"
  },
  {
    "objectID": "publications/articles/Ross2020.html#citation",
    "href": "publications/articles/Ross2020.html#citation",
    "title": "Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar",
    "section": "",
    "text": "Ross PH, Patel E, Ferguson B, Ravelijaona RN and others (2020) Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar. Endang Species Res 43:89-98. https://doi.org/10.3354/esr01055"
  },
  {
    "objectID": "publications/articles/Ross2020.html#abstract",
    "href": "publications/articles/Ross2020.html#abstract",
    "title": "Assessment of the threatened carnivore community in the recently expanded rainforest protected area Anjanaharibe-Sud Special Reserve, Madagascar",
    "section": "Abstract",
    "text": "Abstract\nMadagascar is an island nation renowned for its biodiversity and species endemism, yet it is still largely understudied despite intense anthropogenic threats including forest loss and edge effects. Anjanaharibe-Sud Special Reserve is a recently expanded rainforest protected area that is lacking detailed surveys and assessments of the native carnivore community of the endemic family Eupleridae. To identify which terrestrial carnivores occupy the reserve and what anthropogenic disturbances and factors best explain their occurrence patterns, we deployed 35 motion-activated cameras to detect native and introduced carnivores. From November 2018 to February 2019, we collected 2918 unique capture events (all species) and confirmed the presence of 5 euplerids: Galidia elegans, Galidictis fasciata, Eupleres goudotii, Fossa fossana, and Cryptoprocta ferox. These results extend the known range of E. goudotii and G. fasciata. In the reserve, F. fossana and G. elegans were the most common and widespread native carnivores, while E. goudotii was the rarest. We highlight the negative impact of edge effects on G. fasciata and F. fossana and the threat posed by the free-ranging non-native carnivore C. familiaris. This study represents the first detailed survey and occurrence estimates of the carnivore community of this protected area, allowing comparison with other protected areas in Madagascar. Our empirical findings show that anthropogenic disturbance negatively impacts carnivore existence within the Anjanaharibe-Sud Special Reserve and provide important management recommendations for protecting the carnivore community and the co-occurring wildlife living within this area."
  },
  {
    "objectID": "publications/articles/Betts2020.html",
    "href": "publications/articles/Betts2020.html",
    "title": "Squeezed by a habitat split: Warm ocean conditions and old‐forest loss interact to reduce long‐term occupancy of a threatened seabird",
    "section": "",
    "text": "Betts MG, Northrup JM, Guerrero JAB, et al. Squeezed by a habitat split: Warm ocean conditions and old-forest loss interact to reduce long-term occupancy of a threatened seabird. Conservation Letters. 2020; 13:e12745. https://doi.org/10.1111/conl.12745"
  },
  {
    "objectID": "publications/articles/Betts2020.html#citation",
    "href": "publications/articles/Betts2020.html#citation",
    "title": "Squeezed by a habitat split: Warm ocean conditions and old‐forest loss interact to reduce long‐term occupancy of a threatened seabird",
    "section": "",
    "text": "Betts MG, Northrup JM, Guerrero JAB, et al. Squeezed by a habitat split: Warm ocean conditions and old-forest loss interact to reduce long-term occupancy of a threatened seabird. Conservation Letters. 2020; 13:e12745. https://doi.org/10.1111/conl.12745"
  },
  {
    "objectID": "publications/articles/Betts2020.html#abstract",
    "href": "publications/articles/Betts2020.html#abstract",
    "title": "Squeezed by a habitat split: Warm ocean conditions and old‐forest loss interact to reduce long‐term occupancy of a threatened seabird",
    "section": "Abstract",
    "text": "Abstract\nTheory predicts that species requiring multiple habitat types simultaneously should have heightened sensitivity to anthropogenic pressures, yet tests of this prediction are especially rare. We tested whether breeding site occupancy of the threatened marbled murrelet (Brachyramphus marmoratus) was driven by the synergistic effects of nesting habitat loss in forests, and changing ocean conditions. We paired 70,700 murrelet surveys at 19,837 sites across 20 years from the Oregon Coast Range with annual data on the extent of old forest and biophysical ocean conditions. Dynamic occupancy models indicated that local murrelet colonization rates were strongly reduced during warm ocean conditions with low prey availability. Landscapes that contained more old forest and were closer to the ocean showed reduced rates of local extinction. Given predictions of accelerated ocean warming and increased global timber demand, our results suggest murrelets may continue to be imperiled by deterioration of the two habitats upon which they depend."
  },
  {
    "objectID": "publications/articles/Cordes2020.html",
    "href": "publications/articles/Cordes2020.html",
    "title": "Contrasting effects of climate change on seasonal survival of a hibernating mammal",
    "section": "",
    "text": "Cordes, L. S., Blumstein, D. T., Armitage, K. B., CaraDonna, P. J., Childs, D. Z., Gerber, B. D., … & Ozgul, A. (2020). Contrasting effects of climate change on seasonal survival of a hibernating mammal. Proceedings of the National Academy of Sciences, 117(30), 18119-18126."
  },
  {
    "objectID": "publications/articles/Cordes2020.html#citation",
    "href": "publications/articles/Cordes2020.html#citation",
    "title": "Contrasting effects of climate change on seasonal survival of a hibernating mammal",
    "section": "",
    "text": "Cordes, L. S., Blumstein, D. T., Armitage, K. B., CaraDonna, P. J., Childs, D. Z., Gerber, B. D., … & Ozgul, A. (2020). Contrasting effects of climate change on seasonal survival of a hibernating mammal. Proceedings of the National Academy of Sciences, 117(30), 18119-18126."
  },
  {
    "objectID": "publications/articles/Cordes2020.html#abstract",
    "href": "publications/articles/Cordes2020.html#abstract",
    "title": "Contrasting effects of climate change on seasonal survival of a hibernating mammal",
    "section": "Abstract",
    "text": "Abstract\nClimate change is altering the seasonal environmental conditions to which animals have adapted, but the outcome may differ between seasons for a particular species. Demographic responses therefore need disentangling on a seasonal basis to make accurate forecasts. Our study shows that climate change is causing seasonally divergent demographic responses in a hibernating mammal. Continued climate change will likely have a positive effect on summer survival but a negative effect on winter survival. This potentially has wide-ranging consequences across other species occupying temperate to more extreme arctic and alpine habitats, which are also where the most rapid changes in climate are observed."
  },
  {
    "objectID": "publications/articles/Dwyer2020.html",
    "href": "publications/articles/Dwyer2020.html",
    "title": "Power pole density and avian electrocution risk in the western United States",
    "section": "",
    "text": "James F. Dwyer, Brian D. Gerber, Paul Petersen, William E. Armstrong, Richard E. Harness; Power Pole Density and Avian Electrocution Risk in the Western United States. Journal of Raptor Research 2020; 54 (2): 93–109. doi: https://doi.org/10.3356/0892-1016-54.2.93"
  },
  {
    "objectID": "publications/articles/Dwyer2020.html#citation",
    "href": "publications/articles/Dwyer2020.html#citation",
    "title": "Power pole density and avian electrocution risk in the western United States",
    "section": "",
    "text": "James F. Dwyer, Brian D. Gerber, Paul Petersen, William E. Armstrong, Richard E. Harness; Power Pole Density and Avian Electrocution Risk in the Western United States. Journal of Raptor Research 2020; 54 (2): 93–109. doi: https://doi.org/10.3356/0892-1016-54.2.93"
  },
  {
    "objectID": "publications/articles/Dwyer2020.html#abstract",
    "href": "publications/articles/Dwyer2020.html#abstract",
    "title": "Power pole density and avian electrocution risk in the western United States",
    "section": "Abstract",
    "text": "Abstract\nAvian electrocutions on power poles affect raptor populations globally. Mitigation strategies in the USA are typically bottom-up, combining risk assessments for individual poles into a utility-specific avian protection plan. This approach is usually reactive, relying on incidental documentation of electrocutions for initiation, and can allow uncoordinated mitigation strategies among adjacent utilities. A top-down strategy may help solve both problems if maps identifying where distribution power poles occur were available for comparison to range maps for species at risk of electrocution. Range maps exist but pole location data are rarely publicly available in the USA. Pole-density models were previously created for Colorado and Wyoming, the Great Basin, and the Columbia Plateau because pole density can serve as a surrogate for electrocution risk. We used each of these models to predict pole densities throughout four additional areas: the Northwestern Plains, Southwestern Plains, Southwestern Plateaus, and parts of New Mexico not included in other modeled areas. We also applied the Colorado and Wyoming model to portions of the Uinta Basin and Wyoming Basin projecting from Colorado and Wyoming into Idaho and Utah. The Colorado and Wyoming model fit all areas better than other models, except parts of New Mexico not included in other modeled areas, where the Great Basin model fit best. Our model predictions facilitate assessment of pole density across much (2,573,746 km2) of the western USA. To assess whether the models are useful in predicting electrocutions, we compared predicted pole densities throughout White Sands Missile Range to locations of 59 avian electrocutions. Electrocutions occurred at low rates in cells with low predicted pole densities, and at higher rates in cells with moderate and high predicted pole densities. Because the models do not include species-specific information, they have the potential to be applicable to the conservation of a wide variety of species."
  },
  {
    "objectID": "publications/articles/Farris2020.html",
    "href": "publications/articles/Farris2020.html",
    "title": "Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation",
    "section": "",
    "text": "Farris, Z.J., Gerber, B.D., Karpanty, S. et al. Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation. Biol Invasions 22, 2033–2047 (2020). https://doi.org/10.1007/s10530-020-02237-1"
  },
  {
    "objectID": "publications/articles/Farris2020.html#citation",
    "href": "publications/articles/Farris2020.html#citation",
    "title": "Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation",
    "section": "",
    "text": "Farris, Z.J., Gerber, B.D., Karpanty, S. et al. Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation. Biol Invasions 22, 2033–2047 (2020). https://doi.org/10.1007/s10530-020-02237-1"
  },
  {
    "objectID": "publications/articles/Farris2020.html#abstract",
    "href": "publications/articles/Farris2020.html#abstract",
    "title": "Exploring and interpreting spatiotemporal interactions between native and invasive carnivores across a gradient of rainforest degradation",
    "section": "Abstract",
    "text": "Abstract\nStudies of elusive carnivores often rely on passive sampling when investigating either spatial or temporal interactions. However, inference on behavioral mechanisms are usually lacking. We present an analysis that combines previously published spatial co-occurrence estimates and temporal kernel density estimates to explore spatiotemporal interspecific interactions. We do so by deriving a spatiotemporal value (STV) that is a relative measure of potential interaction in both niche dimensions, across a gradient of degradation, for rainforest carnivore pairs in Madagascar. We also use a conceptual framework to provide insight into the potential behavioral mechanisms of habitat selection. Of the six native and three invasive carnivores, we estimate the spatiotemporal interactions for twelve pairings, which range from no spatial/temporal relationship (n = 5) to spatiotemporal aggregation or segregation (n = 7). We visualized these spatiotemporal interactions along a fragmentation gradient and demonstrate that these interactions are not static, as STV overlap increases with increasing anthropogenic disturbance. Of the three invasive carnivores (free-ranging dogs Canis familiaris, cats Felis species, and small Indian civets Viverricula indica) the latter had the highest number of spatial occurrence (n = 4) and spatiotemporal overlap (n = 4) relationships with native carnivores. Our results highlight the potential for increasing direct and indirect interactions between native and invasive species as forest degradation and invasive predators increase. Our approach allows us to better understand adaptive behaviors, plasticity in temporal activity, community assemblage, and to develop targeted conservation strategies to manage ecological communities in rapidly changing ecosystems."
  },
  {
    "objectID": "publications/articles/GerberWilliams2020.html",
    "href": "publications/articles/GerberWilliams2020.html",
    "title": "Decision-Making and Monitoring Strategies in Natural Resource Management and Conservation",
    "section": "",
    "text": "Gerber, B. D., & Williams, P. J. (2020). Decision-Making and Monitoring Strategies in Natural Resource Management and Conservation. In Terrestrial Ecosystems and Biodiversity (pp. 81-86). CRC Press."
  },
  {
    "objectID": "publications/articles/GerberWilliams2020.html#citation",
    "href": "publications/articles/GerberWilliams2020.html#citation",
    "title": "Decision-Making and Monitoring Strategies in Natural Resource Management and Conservation",
    "section": "",
    "text": "Gerber, B. D., & Williams, P. J. (2020). Decision-Making and Monitoring Strategies in Natural Resource Management and Conservation. In Terrestrial Ecosystems and Biodiversity (pp. 81-86). CRC Press."
  },
  {
    "objectID": "publications/articles/GerberNorthrup2020.html",
    "href": "publications/articles/GerberNorthrup2020.html",
    "title": "Improving spatial predictions of animal resource selection to guide conservation decision making",
    "section": "",
    "text": "Gerber, B. D., and J. M. Northrup. 2020. Improving spatial predictions of animal resource selection to guide conservation decision making. Ecology 101(3):e02953. 10.1002/ecy.2953"
  },
  {
    "objectID": "publications/articles/GerberNorthrup2020.html#citation",
    "href": "publications/articles/GerberNorthrup2020.html#citation",
    "title": "Improving spatial predictions of animal resource selection to guide conservation decision making",
    "section": "",
    "text": "Gerber, B. D., and J. M. Northrup. 2020. Improving spatial predictions of animal resource selection to guide conservation decision making. Ecology 101(3):e02953. 10.1002/ecy.2953"
  },
  {
    "objectID": "publications/articles/GerberNorthrup2020.html#abstract",
    "href": "publications/articles/GerberNorthrup2020.html#abstract",
    "title": "Improving spatial predictions of animal resource selection to guide conservation decision making",
    "section": "Abstract",
    "text": "Abstract\nResource selection is often studied by ecologists interested in the environmental drivers of animal space use and movement. These studies commonly produce spatial predictions, which are of considerable utility to resource managers making habitat and population management decisions. It is thus paramount that predictions from resource selection studies are accurate. We evaluated model building and fitting strategies for optimizing resource selection function predictions in a use-availability framework. We did so by simulating low- and high-intensity spatial sampling data that respectively predicted study area and movement-based resource selection. We compared one of the most commonly used forms of statistical regularization, Akaike’s Information Criterion (AIC), with the lesser used least absolute shrinkage and selection operator (LASSO). LASSO predictions were less variable and more accurate than AIC and were often best when considering additive and interacting variables. We explicitly demonstrate the predictive equivalence using the logistic and Poisson likelihoods and how it is lost when the available sample is too small. Regardless of modeling approach, interpreting the sign of coefficients as a measure of selection can be misleading when optimizing for prediction."
  },
  {
    "objectID": "publications/articles/Baden2020.html",
    "href": "publications/articles/Baden2020.html",
    "title": "Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar",
    "section": "",
    "text": "Baden, A. L., Oliveras, J., & Gerber, B. D. (2020). Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar. Folia Primatologica, 92(1), 12-34."
  },
  {
    "objectID": "publications/articles/Baden2020.html#citation",
    "href": "publications/articles/Baden2020.html#citation",
    "title": "Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar",
    "section": "",
    "text": "Baden, A. L., Oliveras, J., & Gerber, B. D. (2020). Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar. Folia Primatologica, 92(1), 12-34."
  },
  {
    "objectID": "publications/articles/Baden2020.html#abstract",
    "href": "publications/articles/Baden2020.html#abstract",
    "title": "Sex-segregated range use by black-and-white ruffed lemurs (Varecia variegata) in Ranomafana National Park, Madagascar",
    "section": "Abstract",
    "text": "Abstract\nRanging behavior is one important strategy by which nonhuman primates obtain access to resources critical to their biological maintenance and reproductive success. As most primates live in permanent social groups, their members must balance the benefits of group living with the costs of intragroup competition for resources. However, some taxa live in more spatiotemporally flexible social groups, whose members modify patterns of association and range use as a method to mitigate these costs. Here, we describe the range use of one such taxon, the black-and-white ruffed lemur (Varecia variegata), at an undisturbed primary rain forest site in Ranomafana National Park, Madagascar, and characterize sex differences in annual home range area, overlap, and daily distances traveled. Moreover, we characterize seasonal variability in range use and ask whether ranging behaviors can be explained by either climatic or reproductive seasonality. We found that females used significantly larger home ranges than males, though sexes shared equal and moderate levels of home range overlap. Overall, range use did not vary across seasons, although within sexes, male range use varied significantly with climate. Moreover, daily path length was best predicted by day length, female reproductive state, and sex, but was unrelated to climate variables. While the patterns of range use and spatial association presented here share some similarities with “bisexually bonded” community models described for chimpanzees, we argue that ruffed lemurs best conform to a “nuclear neighborhood” community model wherein nuclear (core) groups share the highest levels of home range overlap, and where these groups cluster spatially into adjacent “neighborhoods” within the larger, communally defended territory."
  },
  {
    "objectID": "publications/articles/Gerber2019.html",
    "href": "publications/articles/Gerber2019.html",
    "title": "Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment",
    "section": "",
    "text": "Gerber BD, Hooten MB, Peck CP, et al. Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment. Funct Ecol. 2019; 33: 1695–1707. https://doi.org/10.1111/1365-2435.13390"
  },
  {
    "objectID": "publications/articles/Gerber2019.html#citation",
    "href": "publications/articles/Gerber2019.html#citation",
    "title": "Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment",
    "section": "",
    "text": "Gerber BD, Hooten MB, Peck CP, et al. Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment. Funct Ecol. 2019; 33: 1695–1707. https://doi.org/10.1111/1365-2435.13390"
  },
  {
    "objectID": "publications/articles/Gerber2019.html#abstract",
    "href": "publications/articles/Gerber2019.html#abstract",
    "title": "Extreme site fidelity as an optimal strategy in an unpredictable and homogeneous environment",
    "section": "Abstract",
    "text": "Abstract\nAnimal site fidelity structures space use, population demography and ultimately gene flow. Understanding the adaptive selection for site fidelity patterns provides a mechanistic understanding to both spatial and population processes. This can be achieved by linking space use with environmental variability (spatial and temporal) and demographic parameters. However, rarely is the environmental context that drives the selection for site fidelity behaviour fully considered.\nWe use ecological theory to understand whether the spatial and temporal variability in breeding site quality can explain the site fidelity behaviour and demographic patterns of Gunnison sage-grouse (Centrocercus minimus). We examined female site fidelity patterns across multiple spatial scales: proximity of consecutive year nest locations, space-use overlap within and across the breeding and brooding seasons, and fidelity to a breeding patch. We also examined the spatial and temporal variability in nest, chick, juvenile and adult survival.\nWe found Gunnison sage-grouse to be site faithful to their breeding patch, area of use within the patch and generally where they nest, suggesting an “Always Stay” site fidelity strategy. This is an optimal evolutionary strategy when site quality is unpredictable. Further, we found limited spatial variability in survival within age groups, suggesting little demographic benefit to moving among patches. We suggest Gunnison sage-grouse site fidelity is driven by the unpredictability of predation in a relatively homogeneous environment, the lack of benefits and likely costs to moving across landscape patches and leaving known lek and breeding/brooding areas.\nSpace use and demography are commonly studied separately. More so, site fidelity patterns are rarely framed in the context of ecological theory, beyond questions related to the win-stay:lose-switch rule. To move beyond describing patterns and understand the adaptive selection driving species movements and their demographic consequences require integrating movement, demography and environmental variability in a synthetic framework. Site fidelity theory provides a coherent framework to simultaneously investigate the spatial and population ecology of animal populations. Using it to frame ecological questions will lead to a more mechanistic understanding of animal movement, spatial population structuring and meta-population dynamics."
  },
  {
    "objectID": "publications/articles/Murphy2019.html",
    "href": "publications/articles/Murphy2019.html",
    "title": "Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little‐studied Malagasy carnivore",
    "section": "",
    "text": "Murphy, A., Gerber, B.D., Farris, Z.J., Karpanty, S., Ratelolahy, F. and Kelly, M.J. (2018), Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little-studied Malagasy carnivore. Anim Conserv, 21: 496-504. https://doi.org/10.1111/acv.12420"
  },
  {
    "objectID": "publications/articles/Murphy2019.html#citation",
    "href": "publications/articles/Murphy2019.html#citation",
    "title": "Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little‐studied Malagasy carnivore",
    "section": "",
    "text": "Murphy, A., Gerber, B.D., Farris, Z.J., Karpanty, S., Ratelolahy, F. and Kelly, M.J. (2018), Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little-studied Malagasy carnivore. Anim Conserv, 21: 496-504. https://doi.org/10.1111/acv.12420"
  },
  {
    "objectID": "publications/articles/Murphy2019.html#abstract",
    "href": "publications/articles/Murphy2019.html#abstract",
    "title": "Making the most of sparse data to estimate density of a rare and threatened species: a case study with the fosa, a little‐studied Malagasy carnivore",
    "section": "Abstract",
    "text": "Abstract\nSparse detections in camera trap surveys commonly hinder density estimation for threatened species. By combining detections across multiple surveys, or using informative priors in Bayesian model fitting, researchers can improve parameter estimation from sparse capture–recapture data. Using a spatial mark–resight model that incorporates site-level heterogeneity in the spatial scale parameter via a hierarchical process and prior information, we estimated the density of a threatened carnivore (fosa, Cryptoprocta ferox) from multiple sparse datasets collected during extensive camera trapping surveys in northeastern Madagascar (2008–2015). Our objectives were to estimate density for six sites, examine the response of fosa density and movement to habitat degradation, monitor annual density trends across 7 years at two sites, and estimate fosa abundance in the Makira–Masoala protected area complex. We obtained a mean of 16.1 (se = 0.52; range = 2–49) fosa detections and three observers identified a mean of 3.62 (se = 0.09; range = 1–8) marked individuals per survey. Fosa daily baseline encounter rate was very low (λ0 = 0.004; 0.003–0.006) and density/movement estimates were similar across forest types. Density estimates at resurveyed sites suggested annual variability in density, with estimates trending lower during the final surveys [e.g. D = 0.39 (0.14–1.11) versus 0.08 (0.05–0.31) individuals per km2]. We estimated fosa abundance across the Makira–Masoala region to be 1061 (95% HPDI: 596–1780) adult individuals. On the basis of our estimate and the size of the region, we believe Makira–Masoala harbors a significant portion of the global fosa population. The conservation and management of rare species is commonly limited due to lack of population estimates. By combining detections across surveys, we overcame estimation issues and obtained valuable information on a threatened carnivore, allowing us to better assess its status and prioritize conservation actions. We advocate for practical use of sparse datasets for such data-deficient species."
  },
  {
    "objectID": "publications/articles/Gerber2018.html",
    "href": "publications/articles/Gerber2018.html",
    "title": "Accounting for location uncertainty in azimuthal telemetry data improves ecological inference",
    "section": "",
    "text": "Gerber, B.D., Hooten, M.B., Peck, C.P. et al. Accounting for location uncertainty in azimuthal telemetry data improves ecological inference. Mov Ecol 6, 14 (2018). https://doi.org/10.1186/s40462-018-0129-1"
  },
  {
    "objectID": "publications/articles/Gerber2018.html#citation",
    "href": "publications/articles/Gerber2018.html#citation",
    "title": "Accounting for location uncertainty in azimuthal telemetry data improves ecological inference",
    "section": "",
    "text": "Gerber, B.D., Hooten, M.B., Peck, C.P. et al. Accounting for location uncertainty in azimuthal telemetry data improves ecological inference. Mov Ecol 6, 14 (2018). https://doi.org/10.1186/s40462-018-0129-1"
  },
  {
    "objectID": "publications/articles/Gerber2018.html#abstract",
    "href": "publications/articles/Gerber2018.html#abstract",
    "title": "Accounting for location uncertainty in azimuthal telemetry data improves ecological inference",
    "section": "Abstract",
    "text": "Abstract\nCharacterizing animal space use is critical for understanding ecological relationships. Animal telemetry technology has revolutionized the fields of ecology and conservation biology by providing high quality spatial data on animal movement. Radio-telemetry with very high frequency (VHF) radio signals continues to be a useful technology because of its low cost, miniaturization, and low battery requirements. Despite a number of statistical developments synthetically integrating animal location estimation and uncertainty with spatial process models using satellite telemetry data, we are unaware of similar developments for azimuthal telemetry data. As such, there are few statistical options to handle these unique data and no synthetic framework for modeling animal location uncertainty and accounting for it in ecological models.\nWe developed a hierarchical modeling framework to provide robust animal location estimates from one or more intersecting or non-intersecting azimuths. We used our azimuthal telemetry model (ATM) to account for azimuthal uncertainty with covariates and propagate location uncertainty into spatial ecological models. We evaluate the ATM with commonly used estimators (Lenth (1981) maximum likelihood and M-Estimators) using simulation. We also provide illustrative empirical examples, demonstrating the impact of ignoring location uncertainty within home range and resource selection analyses. We further use simulation to better understand the relationship among location uncertainty, spatial covariate autocorrelation, and resource selection inference."
  },
  {
    "objectID": "publications/articles/Wampole2023.html",
    "href": "publications/articles/Wampole2023.html",
    "title": "Forest carnivores living on the edge with invasive predators",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J., Razafy, P. and Gerber, B.D. (2023), Forest carnivores living on the edge with invasive predators. Anim. Conserv. https://doi.org/10.1111/acv.12926"
  },
  {
    "objectID": "publications/articles/Wampole2023.html#citation",
    "href": "publications/articles/Wampole2023.html#citation",
    "title": "Forest carnivores living on the edge with invasive predators",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J., Razafy, P. and Gerber, B.D. (2023), Forest carnivores living on the edge with invasive predators. Anim. Conserv. https://doi.org/10.1111/acv.12926"
  },
  {
    "objectID": "publications/articles/Wampole2023.html#abstract",
    "href": "publications/articles/Wampole2023.html#abstract",
    "title": "Forest carnivores living on the edge with invasive predators",
    "section": "Abstract",
    "text": "Abstract\nThe proliferation of forest edges and invasive predators have been identified as two primary threats to carnivore populations globally. These threats often occur in unison, facilitated by anthropogenic activities (e.g., fragmentation), and together may pose a greater influence than when they occur separately. Targeted conservation actions for forest carnivores, including Madagascar carnivores, have been hindered by a failure to understand the relative contributions of these factors in driving species declines. To fill this gap, we conducted an extensive camera survey along the edge of intact, continuous protected rainforests in eastern Madagascar to evaluate the extent invasive predators and forest edge separately and in combination affect native carnivore space use. We hypothesized that structural vegetation changes at the forest edge interact with invasive predator trap success and occurrence to reduce native carnivore space use near the forest edge and separately have less influence than when combined. In contrast to findings in fragmented and degraded forests of Madagascar, we found hard forest edge and invasive predators alone do not indiscriminately reduce native carnivore space use in continuous intact forest. Instead, we found free-roaming dogs and cats interact with their surrounding environment (i.e., forest edge) in unique ways that shape species response differently than within interior forest. At the forest edge, vegetational changes of increasing shrub cover and the occurrence of dogs reduce space use of three of four native carnivores. However, we found greater effects of proximity to villages, especially with high invasive predator activity (free-roaming cats). Ultimately, native carnivores showed variable sensitivities to pressures we examined, providing support for species-specific management actions to maximize conservation outcomes. We encourage future studies to consider evaluating the magnitude of separate and combined threats to carnivores. In doing so, conservationists can better identify when threats can be managed in isolation and when they require simultaneous mitigation."
  },
  {
    "objectID": "publications/articles/Chanchani2018.html",
    "href": "publications/articles/Chanchani2018.html",
    "title": "Elevated potential for intraspecific competition in territorial carnivores occupying fragmented landscapes",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J., Razafy, P. and Gerber, B.D. (2023), Forest carnivores living on the edge with invasive predators. Anim. Conserv. https://doi.org/10.1111/acv.12926"
  },
  {
    "objectID": "publications/articles/Chanchani2018.html#citation",
    "href": "publications/articles/Chanchani2018.html#citation",
    "title": "Elevated potential for intraspecific competition in territorial carnivores occupying fragmented landscapes",
    "section": "",
    "text": "Wampole, E.M., Farris, Z.J., Razafy, P. and Gerber, B.D. (2023), Forest carnivores living on the edge with invasive predators. Anim. Conserv. https://doi.org/10.1111/acv.12926"
  },
  {
    "objectID": "publications/articles/Chanchani2018.html#abstract",
    "href": "publications/articles/Chanchani2018.html#abstract",
    "title": "Elevated potential for intraspecific competition in territorial carnivores occupying fragmented landscapes",
    "section": "Abstract",
    "text": "Abstract\nThe distribution of mammals is determined by a suite of endogenous and exogenous factors. In territorial, polygynous species like tigers (Panthera tigris), males often center their space-use around female territories, repelling competitors from these areas. Competition among males for females leads to increased mortality of both sexes and infanticide of unrelated cubs, which can lead to population declines. We hypothesized that increased territorial overlap among adult male tigers and elevated levels of inter and intra-sex competition would be manifest in populations with male-biased adult sex ratios (ASR). We also assessed whether inter-sex variation in adult survival or degree of habitat connectivity resulted in skewed ASR. We evaluated these hypotheses using camera trap data from three tiger populations occupying habitat patches with varying levels of connectivity and ASRs. Data were analyzed using multi-state occupancy models, where states were defined as habitat use by one or more male tigers in sites with and without female use. As predicted, in populations with male-biased or even ASR we found evidence for increased spatial overlap between male tigers, particularly pronounced in areas adjacent to female territories. Given parity in adult survival, habitat fragmentation likely caused male-biased ASR. Our results suggest that the persistence of small tiger populations in habitat patches with male-biased ASR may be significantly compromised by behavior-mediated endogenous demographic processes that are often overlooked. In habitat fragments with pronounced male biased ASR, population recovery of territorial carnivores may require timely supplementation of individuals to compensate for population losses from intraspecific competition."
  },
  {
    "objectID": "publications/articles/Vitkalova2018.html",
    "href": "publications/articles/Vitkalova2018.html",
    "title": "Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards",
    "section": "",
    "text": "Vitkalova AV, Feng L, Rybin AN, et al. Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards. Conservation Letters. 2018; 11: e12574. https://doi.org/10.1111/conl.12574"
  },
  {
    "objectID": "publications/articles/Vitkalova2018.html#citation",
    "href": "publications/articles/Vitkalova2018.html#citation",
    "title": "Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards",
    "section": "",
    "text": "Vitkalova AV, Feng L, Rybin AN, et al. Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards. Conservation Letters. 2018; 11: e12574. https://doi.org/10.1111/conl.12574"
  },
  {
    "objectID": "publications/articles/Vitkalova2018.html#abstract",
    "href": "publications/articles/Vitkalova2018.html#abstract",
    "title": "Transboundary cooperation improves endangered species monitoring and conservation actions: A case study of the global population of Amur leopards",
    "section": "Abstract",
    "text": "Abstract\nPolitical borders and natural boundaries of wildlife populations seldom coincide, often to the detriment of conservation objectives. Transnational monitoring of endangered carnivores is rare, but is necessary for accurate population monitoring and coordinated conservation policies. We investigate the benefits of collaboratively monitoring the abundance and survival of the critically endangered Amur leopard, which occurs as a single transboundary population across China and Russia. Country-specific results overestimated abundance and were generally less precise compared to integrated monitoring estimates; the global population was similar in both years: 84 (70–108, 95% confidence interval). Uncertainty in country-specific annual survival estimates were approximately twice the integrated estimates of 0.82 (0.69–0.91, 95% confidence limits). This collaborative effort provided a better understanding of Amur leopard population dynamics, represented a first step in building trust, and lead to cooperative agreements to coordinate conservation policies."
  },
  {
    "objectID": "publications/articles/GerberKendall2018.html",
    "href": "publications/articles/GerberKendall2018.html",
    "title": "Adaptive management of animal populations with significant unknowns and uncertainties: a case study",
    "section": "",
    "text": "Gerber, B.D. and Kendall, W.L. (2018), Adaptive management of animal populations with significant unknowns and uncertainties: a case study. Ecol Appl, 28: 1325-1341. https://doi.org/10.1002/eap.1734"
  },
  {
    "objectID": "publications/articles/GerberKendall2018.html#citation",
    "href": "publications/articles/GerberKendall2018.html#citation",
    "title": "Adaptive management of animal populations with significant unknowns and uncertainties: a case study",
    "section": "",
    "text": "Gerber, B.D. and Kendall, W.L. (2018), Adaptive management of animal populations with significant unknowns and uncertainties: a case study. Ecol Appl, 28: 1325-1341. https://doi.org/10.1002/eap.1734"
  },
  {
    "objectID": "publications/articles/GerberKendall2018.html#abstract",
    "href": "publications/articles/GerberKendall2018.html#abstract",
    "title": "Adaptive management of animal populations with significant unknowns and uncertainties: a case study",
    "section": "Abstract",
    "text": "Abstract\nConservation and management decision making in natural resources is challenging due to numerous uncertainties and unknowns, especially relating to understanding system dynamics. Adaptive resource management (ARM) is a formal process to making logical and transparent recurrent decisions when there are uncertainties about system dynamics. Despite wide recognition and calls for implementing adaptive natural resource management, applications remain limited. More common is a reactive approach to decision making, which ignores future system dynamics. This contrasts with ARM, which anticipates future dynamics of ecological process and management actions using a model-based framework. Practitioners may be reluctant to adopt ARM because of the dearth of comparative evaluations between ARM and more common approaches to making decisions. We compared the probability of meeting management objectives when managing a population under both types of decision frameworks, specifically in relation to typical uncertainties and unknowns. We use a population of Sandhill Cranes as our case study. We evaluate each decision process under varying levels of monitoring and ecological uncertainty, where the true underlying population dynamics followed a stochastic age-structured population model with environmentally driven vital rate density dependence. We found that the ARM framework outperformed the currently employed reactive decision framework to manage Sandhill Cranes in meeting the population objective across an array of scenarios. This was even the case when the candidate set of population models contained only naïve representations of the true population process. Under the reactive decision framework, we found little improvement in meeting the population objective even if monitoring uncertainty was eliminated. In contrast, if the population was monitored without error within the ARM framework, the population objective was always maintained, regardless of the population models considered. Contrary to expectation, we found that age-specific optimal harvest decisions are not always necessary to meet a population objective when population dynamics are age structured. Population managers can decrease risks and gain transparency and flexibility in management by adopting an ARM framework. If population monitoring data has high sampling variation and/or limited empirical knowledge is available for constructing mechanistic population models, ARM model sets should consider a range of mechanistic, descriptive, and predictive model types."
  },
  {
    "objectID": "publications/articles/GerberConsLetter2018.html",
    "href": "publications/articles/GerberConsLetter2018.html",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "",
    "text": "Gerber, B.D., Converse, S.J., Muths, E., Crockett, H.J., Mosher, B.A. and Bailey, L.L. (2018), Identifying Species Conservation Strategies to Reduce Disease-Associated Declines. Conservation Letters, 11: e12393. https://doi.org/10.1111/conl.12393"
  },
  {
    "objectID": "publications/articles/GerberConsLetter2018.html#citation",
    "href": "publications/articles/GerberConsLetter2018.html#citation",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "",
    "text": "Gerber, B.D., Converse, S.J., Muths, E., Crockett, H.J., Mosher, B.A. and Bailey, L.L. (2018), Identifying Species Conservation Strategies to Reduce Disease-Associated Declines. Conservation Letters, 11: e12393. https://doi.org/10.1111/conl.12393"
  },
  {
    "objectID": "publications/articles/GerberConsLetter2018.html#abstract",
    "href": "publications/articles/GerberConsLetter2018.html#abstract",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "Abstract",
    "text": "Abstract\nEmerging infectious diseases (EIDs) are a salient threat to many animal taxa, causing local and global extinctions, altering communities and ecosystem function. The EID chytridiomycosis is a prominent driver of amphibian declines, which is caused by the fungal pathogen Batrachochytrium dendrobatidis (Bd). To guide conservation policy, we developed a predictive decision-analytic model that combines empirical knowledge of host-pathogen metapopulation dynamics with expert judgment regarding effects of management actions, to select from potential conservation strategies. We apply our approach to a boreal toad (Anaxyrus boreas boreas) and Bd system, identifying optimal strategies that balance tradeoffs in maximizing toad population persistence and landscape-level distribution, while considering costs. The most robust strategy is expected to reduce the decline of toad breeding sites from 53% to 21% over 50 years. Our findings are incorporated into management policy to guide conservation planning. Our online modeling application provides a template for managers of other systems challenged by EIDs."
  },
  {
    "objectID": "publications/articles/NorthrupGerber2018.html",
    "href": "publications/articles/NorthrupGerber2018.html",
    "title": "A comment on priors for Bayesian occupancy models",
    "section": "",
    "text": "Northrup, JM, Gerber, BD. (2018). A comment on priors for Bayesian occupancy models. PLoSOne. 13(2):e0192819. https://doi.org/10.1371/journal.pone.0192819"
  },
  {
    "objectID": "publications/articles/NorthrupGerber2018.html#citation",
    "href": "publications/articles/NorthrupGerber2018.html#citation",
    "title": "A comment on priors for Bayesian occupancy models",
    "section": "",
    "text": "Northrup, JM, Gerber, BD. (2018). A comment on priors for Bayesian occupancy models. PLoSOne. 13(2):e0192819. https://doi.org/10.1371/journal.pone.0192819"
  },
  {
    "objectID": "publications/articles/NorthrupGerber2018.html#abstract",
    "href": "publications/articles/NorthrupGerber2018.html#abstract",
    "title": "A comment on priors for Bayesian occupancy models",
    "section": "Abstract",
    "text": "Abstract\nUnderstanding patterns of species occurrence and the processes underlying these patterns is fundamental to the study of ecology. One of the more commonly used approaches to investigate species occurrence patterns is occupancy modeling, which can account for imperfect detection of a species during surveys. In recent years, there has been a proliferation of Bayesian modeling in ecology, which includes fitting Bayesian occupancy models. The Bayesian framework is appealing to ecologists for many reasons, including the ability to incorporate prior information through the specification of prior distributions on parameters. While ecologists almost exclusively intend to choose priors so that they are “uninformative” or “vague”, such priors can easily be unintentionally highly informative. Here we report on how the specification of a “vague” normally distributed (i.e., Gaussian) prior on coefficients in Bayesian occupancy models can unintentionally influence parameter estimation. Using both simulated data and empirical examples, we illustrate how this issue likely compromises inference about species-habitat relationships. While the extent to which these informative priors influence inference depends on the data set, researchers fitting Bayesian occupancy models should conduct sensitivity analyses to ensure intended inference, or employ less commonly used priors that are less informative (e.g., logistic or t prior distributions). We provide suggestions for addressing this issue in occupancy studies, and an online tool for exploring this issue under different contexts."
  },
  {
    "objectID": "publications/articles/Setiawan2018.html",
    "href": "publications/articles/Setiawan2018.html",
    "title": "Preventing global extinction of the Javan rhino: tsunami risk and future conservation direction",
    "section": "",
    "text": "Setiawan, R., Gerber, B.D., Rahmat, U.M., Daryan, D., Firdaus, A.Y., Haryono, M., Khairani, K.O., Kurniawan, Y., Long, B., Lyet, A., Muhiban, M., Mahmud, R., Muhtarom, A., Purastuti, E., Ramono, W.S., Subrata, D. and Sunarto, S. (2018), Preventing Global Extinction of the Javan Rhino: Tsunami Risk and Future Conservation Direction. Conservation Letters, 11: e12366. https://doi.org/10.1111/conl.12366"
  },
  {
    "objectID": "publications/articles/Setiawan2018.html#citation",
    "href": "publications/articles/Setiawan2018.html#citation",
    "title": "Preventing global extinction of the Javan rhino: tsunami risk and future conservation direction",
    "section": "",
    "text": "Setiawan, R., Gerber, B.D., Rahmat, U.M., Daryan, D., Firdaus, A.Y., Haryono, M., Khairani, K.O., Kurniawan, Y., Long, B., Lyet, A., Muhiban, M., Mahmud, R., Muhtarom, A., Purastuti, E., Ramono, W.S., Subrata, D. and Sunarto, S. (2018), Preventing Global Extinction of the Javan Rhino: Tsunami Risk and Future Conservation Direction. Conservation Letters, 11: e12366. https://doi.org/10.1111/conl.12366"
  },
  {
    "objectID": "publications/articles/Setiawan2018.html#abstract",
    "href": "publications/articles/Setiawan2018.html#abstract",
    "title": "Preventing global extinction of the Javan rhino: tsunami risk and future conservation direction",
    "section": "Abstract",
    "text": "Abstract\nThe Javan rhino (Rhinoceros sondaicus) is one of the most threatened mammals on Earth. The only remaining individuals live as part of a small population isolated in a single protected area, Ujung Kulon National Park, Java, Indonesia. Despite almost a century of studies, little is known about the factors that affect Javan rhino demography and distribution. National park officials require such information to identify conservation strategies and track the success and failures of these efforts; translocating selected individuals to establish a second population has been considered, but the risks must be weighed. We show that the 2013 global population of Javan rhinos was 62 individuals, which is likely near the site’s carrying capacity. Our analysis of rhino distribution indicates that tsunamis are a significant risk to the species in Ujung Kulon, justifying the risks of establishing additional populations. Continued individual-based monitoring is needed to guide future translocation decisions."
  },
  {
    "objectID": "publications/articles/Setash2017.html",
    "href": "publications/articles/Setash2017.html",
    "title": "A biogeographical perspective on the variation in mouse lemur density throughout Madagascar",
    "section": "",
    "text": "Setash, C.M., Zohdy, S., Gerber, B.D. and Karanewsky, C.J. (2017), A biogeographical perspective on the variation in mouse lemur density throughout Madagascar. Mam Rev, 47: 212-229. https://doi.org/10.1111/mam.12093"
  },
  {
    "objectID": "publications/articles/Setash2017.html#citation",
    "href": "publications/articles/Setash2017.html#citation",
    "title": "A biogeographical perspective on the variation in mouse lemur density throughout Madagascar",
    "section": "",
    "text": "Setash, C.M., Zohdy, S., Gerber, B.D. and Karanewsky, C.J. (2017), A biogeographical perspective on the variation in mouse lemur density throughout Madagascar. Mam Rev, 47: 212-229. https://doi.org/10.1111/mam.12093"
  },
  {
    "objectID": "publications/articles/Setash2017.html#abstract",
    "href": "publications/articles/Setash2017.html#abstract",
    "title": "A biogeographical perspective on the variation in mouse lemur density throughout Madagascar",
    "section": "Abstract",
    "text": "Abstract\nMadagascar is home to the smallest primates in the world, the mouse lemurs (Microcebus species). Twenty-four species of mouse lemur are currently recognised and are found in variable ecosystems, from dry forests and spiny deserts to humid forests. Due to their widespread distribution and the large number of sympatric species, mouse lemurs can be used as a model to understand the linkages among species richness, population density, and habitat. As all lemurs are threatened by habitat loss and fragmentation, this information can also be used to inform conservation management. We hypothesise that on an island-wide scale, we will find higher population densities in western dry forests than in eastern humid forests because the western dry forests exhibit lower species richness, more sympatric habitat use, and lower resource stability than the eastern humid forests. We conducted a literature review of population density estimates of known mouse lemur species, and used those data to conduct a meta-analysis and estimate overall average population density by geographic region.\nOur findings suggest that mouse lemur species living in western dry forest generally exhibit higher densities than those in eastern humid forests. This may be partly explained by higher habitat fragmentation in western dry forests, where species co-occur, but is likely to be a function of the magnitude and variability in seasonally available resources in each forest type. Higher seasonality results in less constant food availability and lower levels of environmental predictability, fostering species capable of coping with environmental change and maintaining high densities throughout periods of resource paucity.\nOur study highlights the importance of conducting Microcebus population density research that adheres to standardised methodological approaches. We point to the need for population density estimates for several species for which data are lacking. Such knowledge is important to assess the conservation status of these species, but also to enhance our ability to identify the macro-biogeographical and local ecological drivers of interspecific and intraspecific variability in population density."
  },
  {
    "objectID": "publications/articles/Seymour2017.html",
    "href": "publications/articles/Seymour2017.html",
    "title": "Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Seymour2017.html#citation",
    "href": "publications/articles/Seymour2017.html#citation",
    "title": "Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Seymour2017.html#abstract",
    "href": "publications/articles/Seymour2017.html#abstract",
    "title": "Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line",
    "section": "Abstract",
    "text": "Abstract\nThe effect of climate on the population dynamics of rainforest vertebrates is known only for a limited subset of species and study locations. To extend this knowledge, we carried out an 8-year population study of a Viverrid (Malay civet Viverra tangalunga) in the Wallacea biogeographical region (Buton Island, Sulawesi). Civets were trapped annually from 2003 to 2010, during which there were four weak to moderate El Niño events and one moderate La Niña event. In Indonesia, El Niño events are associated with drier than normal conditions, while La Niña is associated with wetter conditions. The number of individuals captured was strongly correlated with the 12-month summed Southern Oscillation Index (SOI) prior to trapping, with significantly fewer individuals caught in years with lower summed SOI (i.e. stronger El Niño conditions). Adult civet body mass was significantly higher in El Niño years; mean adult male and female body masses were 10.6% and 4.0% greater in El Niño years. There was support for a 1-year time lagged effect of El Niño on the apparent survival (1 – probability of disappearing from the study site due to death or emigration) of male (but not female) civets, which was approximately 50% higher in the year following El Niño events. Using spatially explicit capture–mark–recapture models, we were unable to detect any significant change in civet density between years, which was estimated as 1.36 ± 0.14 (se) individuals km−2. We suggest that increased apparent survival of males observed in the year after El Niño events was brought about by reduced dispersal (possibly associated with a change in mating tactic) rather than reduced mortality."
  },
  {
    "objectID": "publications/articles/Farris2017.html",
    "href": "publications/articles/Farris2017.html",
    "title": "Threats to a rainforest carnivore community: A multi-year assessment of occupancy and co-occurrence in Madagascar",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Farris2017.html#citation",
    "href": "publications/articles/Farris2017.html#citation",
    "title": "Threats to a rainforest carnivore community: A multi-year assessment of occupancy and co-occurrence in Madagascar",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Farris2017.html#abstract",
    "href": "publications/articles/Farris2017.html#abstract",
    "title": "Threats to a rainforest carnivore community: A multi-year assessment of occupancy and co-occurrence in Madagascar",
    "section": "Abstract",
    "text": "Abstract\nProtected areas (PA) aim to eliminate many of the threats that species face on the greater landscape. In the last three decades, PA’s have expanded considerably; however, quantitative assessments of how well they have mitigated threats to habitat and biodiversity are very limited. Habitat bordering PA’s and the wildlife that use it are threatened by a wide-range of anthropogenic pressures (e.g., edge effects, fragmentation, and introduced predators) and this situation is particularly acute for low-density, poorly studied carnivore communities. From 2010 to 2015, we photographically sampled within (contiguous forest) and bordering (degraded, fragmented forest) a UNESCO World Heritage rainforest PA in Madagascar - Ranomafana National Park (RNP). We investigated the effects of invasive predators, local people presence, and habitat quality on the endemic rainforest carnivore community using static, dynamic, and co-occurrence models. We found native carnivores to be absent or have a low probability of occurrence in degraded forest bordering the PA, while local people and dogs (Canis familiaris) had high occurrence. Madagascar’s largest endemic carnivore, the fosa (Cryptoprocta ferox) and the much smaller ring-tailed vontsira (Galidia elegans), occurrence in RNP declined rapidly over six years; their strong co-occurrence with dogs suggests interspecific competition, direct aggression/mortality, or disease as the cause. We highlight the dangers posed to biodiversity, particularly carnivores, from anthropogenic pressures bordering PA’s and present recommendations to address increased human and dog activity, including programs to control dogs and their impact on biodiversity."
  },
  {
    "objectID": "publications/articles/Gerber2017.html",
    "href": "publications/articles/Gerber2017.html",
    "title": "Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes",
    "section": "",
    "text": "Gerber, B.D. and Kendall, W.L. Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes, The Condor, Volume 119, Issue 2,2017, 191–206, https://doi.org/10.1650/CONDOR-16-137.1"
  },
  {
    "objectID": "publications/articles/Gerber2017.html#citation",
    "href": "publications/articles/Gerber2017.html#citation",
    "title": "Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes",
    "section": "",
    "text": "Gerber, B.D. and Kendall, W.L. Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes, The Condor, Volume 119, Issue 2,2017, 191–206, https://doi.org/10.1650/CONDOR-16-137.1"
  },
  {
    "objectID": "publications/articles/Gerber2017.html#abstract",
    "href": "publications/articles/Gerber2017.html#abstract",
    "title": "Evaluating and improving count-based population inference: A case study from 31 years of monitoring Sandhill Cranes",
    "section": "Abstract",
    "text": "Abstract\nMonitoring animal populations can be difficult. Limited resources often force monitoring programs to rely on unadjusted or smoothed counts as an index of abundance. Smoothing counts is commonly done using a moving-average estimator to dampen sampling variation. These indices are commonly used to inform management decisions, although their reliability is often unknown. We outline a process to evaluate the biological plausibility of annual changes in population counts and indices from a typical monitoring scenario and compare results with a hierarchical Bayesian time series (HBTS) model. We evaluated spring and fall counts, fall indices, and model-based predictions for the Rocky Mountain population (RMP) of Sandhill Cranes (Antigone canadensis) by integrating juvenile recruitment, harvest, and survival into a stochastic stage-based population model. We used simulation to evaluate population indices from the HBTS model and the commonly used 3-yr moving average estimator. We found counts of the RMP to exhibit biologically unrealistic annual change, while the fall population index was largely biologically realistic. HBTS model predictions suggested that the RMP changed little over 31 yr of monitoring, but the pattern depended on assumptions about the observational process. The HBTS model fall population predictions were biologically plausible if observed crane harvest mortality was compensatory up to natural mortality, as empirical evidence suggests. Simulations indicated that the predicted mean of the HBTS model was generally a more reliable estimate of the true population than population indices derived using a moving 3-yr average estimator. Practitioners could gain considerable advantages from modeling population counts using a hierarchical Bayesian autoregressive approach. Advantages would include: (1) obtaining measures of uncertainty; (2) incorporating direct knowledge of the observational and population processes; (3) accommodating missing years of data; and (4) forecasting population size."
  },
  {
    "objectID": "publications/articles/Converse2017.html",
    "href": "publications/articles/Converse2017.html",
    "title": "A model to inform management actions as a response to chytridiomycosis-associated decline",
    "section": "",
    "text": "Converse, S. J., Bailey, L. L., Mosher, B. A., Funk, W. C., Gerber, B. D., & Muths, E. (2017). A model to inform management actions as a response to chytridiomycosis-associated decline. EcoHealth, 14, 144-155. https://doi.org/10.1007/s10393-016-1117-9"
  },
  {
    "objectID": "publications/articles/Converse2017.html#citation",
    "href": "publications/articles/Converse2017.html#citation",
    "title": "A model to inform management actions as a response to chytridiomycosis-associated decline",
    "section": "",
    "text": "Converse, S. J., Bailey, L. L., Mosher, B. A., Funk, W. C., Gerber, B. D., & Muths, E. (2017). A model to inform management actions as a response to chytridiomycosis-associated decline. EcoHealth, 14, 144-155. https://doi.org/10.1007/s10393-016-1117-9"
  },
  {
    "objectID": "publications/articles/Converse2017.html#abstract",
    "href": "publications/articles/Converse2017.html#abstract",
    "title": "A model to inform management actions as a response to chytridiomycosis-associated decline",
    "section": "Abstract",
    "text": "Abstract\nDecision-analytic models provide forecasts of how systems of interest will respond to management. These models can be parameterized using empirical data, but sometimes require information elicited from experts. When evaluating the effects of disease in species translocation programs, expert judgment is likely to play a role because complete empirical information will rarely be available. We illustrate development of a decision-analytic model built to inform decision-making regarding translocations and other management actions for the boreal toad (Anaxyrus boreas boreas), a species with declines linked to chytridiomycosis caused by Batrachochytrium dendrobatidis (Bd). Using the model, we explored the management implications of major uncertainties in this system, including whether there is a genetic basis for resistance to pathogenic infection by Bd, how translocation can best be implemented, and the effectiveness of efforts to reduce the spread of Bd. Our modeling exercise suggested that while selection for resistance to pathogenic infection by Bd could increase numbers of sites occupied by toads, and translocations could increase the rate of toad recovery, efforts to reduce the spread of Bd may have little effect. We emphasize the need to continue developing and parameterizing models necessary to assess management actions for combating chytridiomycosis-associated declines."
  },
  {
    "objectID": "publications/articles/Brown2016.html",
    "href": "publications/articles/Brown2016.html",
    "title": "Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion",
    "section": "",
    "text": "Brown, K.A., Farris, Z.J., Yesuf, G. et al. Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion. Biodivers Conserv 25, 2723–2741 (2016). https://doi.org/10.1007/s10531-016-1198-3"
  },
  {
    "objectID": "publications/articles/Brown2016.html#citation",
    "href": "publications/articles/Brown2016.html#citation",
    "title": "Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion",
    "section": "",
    "text": "Brown, K.A., Farris, Z.J., Yesuf, G. et al. Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion. Biodivers Conserv 25, 2723–2741 (2016). https://doi.org/10.1007/s10531-016-1198-3"
  },
  {
    "objectID": "publications/articles/Brown2016.html#abstract",
    "href": "publications/articles/Brown2016.html#abstract",
    "title": "Modeling co-occurrence between toxic prey and naïve predators in an incipient invasion",
    "section": "Abstract",
    "text": "Abstract\nBiological invasions can represent important threats to endemic species, including those within the invaders’ food webs. The Asian common toad (Duttaphrynus melanostictus) was introduced to Madagascar in 2011. This introduction presents a potentially dangerous prey item to a relatively naïve, highly diverse endemic carnivore fauna. Using a multivariate niche modeling approach (background test), we assessed the predicted niche overlap between D. melanostictus and six endemic carnivores in eastern Madagascar. The overlap between this potential prey and predators was assessed on four environmental niche axes: temperature, precipitation, vegetation cover and elevation. Our results showed a mixture of niche overlap and divergence between D. melanostictus and the six carnivores for environmental axes tested. There was significant overlap with five of the carnivores on temperature and NDVI axes. On the precipitation axis, there was significant overlap between D. melanostictus with two species. Our results suggested that wide-ranging, locally rare carnivores may overlap extensively with D. melanostictus. The six carnivores that inhabit the eastern rainforest of Madagascar will likely share multiple, niche axes with this novel potential prey item. Species that eat the non-native common toad and are susceptible to its toxins are at conservation risk because their populations may not be robust enough to adapt quickly to this threat. We advocate closely monitoring these emerging interactions and suggest a preemptive conservation strategy for carnivores potentially at risk."
  },
  {
    "objectID": "publications/articles/GerberKendall2016.html",
    "href": "publications/articles/GerberKendall2016.html",
    "title": "Considering transient population dynamics in the conservation of slow life-history species: An application to the sandhill crane",
    "section": "",
    "text": "Gerber, B. D., & Kendall, W. L. (2016). Considering transient population dynamics in the conservation of slow life-history species: an application to the sandhill crane. Biological Conservation, 200, 228-239. https://doi.org/10.1016/j.biocon.2016.06.014"
  },
  {
    "objectID": "publications/articles/GerberKendall2016.html#citation",
    "href": "publications/articles/GerberKendall2016.html#citation",
    "title": "Considering transient population dynamics in the conservation of slow life-history species: An application to the sandhill crane",
    "section": "",
    "text": "Gerber, B. D., & Kendall, W. L. (2016). Considering transient population dynamics in the conservation of slow life-history species: an application to the sandhill crane. Biological Conservation, 200, 228-239. https://doi.org/10.1016/j.biocon.2016.06.014"
  },
  {
    "objectID": "publications/articles/GerberKendall2016.html#abstract",
    "href": "publications/articles/GerberKendall2016.html#abstract",
    "title": "Considering transient population dynamics in the conservation of slow life-history species: An application to the sandhill crane",
    "section": "Abstract",
    "text": "Abstract\nThe importance of transient dynamics of structured populations is increasingly recognized in ecology, yet these implications are not largely considered in conservation practices. We investigate transient and long-term population dynamics to demonstrate the process and utility of incorporating transient dynamics into conservation research and to better understand the population management of slow life-history species; these species can be theoretically highly sensitive to short- and long-term transient effects. We are specifically interested in the effects of anthropogenic removal of individuals from populations, such as caused by harvest, poaching, translocation, or incidental take. We use the sandhill crane (Grus canadensis) as an exemplar species; it is long-lived, has low reproduction, late maturity, and multiple populations are subject to sport harvest. We found sandhill cranes to have extremely high potential, but low likelihood for transient dynamics, even when the population is being harvested. The typically low population growth rate of slow life-history species appears to buffer against many perturbations causing large transient effects. Transient dynamics will dominate population trajectories of these species when stage structures are highly biased towards the younger and non-reproducing individuals, a situation that may be rare in established populations of long-lived animals. However, short-term transient population growth can be highly sensitive to vital rates that are relatively insensitive under equilibrium, suggesting that stage structure should be known if perturbation analysis is used to identify effective conservation strategies. For populations of slow life-history species that are not prone to large perturbations to their most productive individuals, population growth may be approximated by equilibrium dynamics."
  },
  {
    "objectID": "publications/articles/Dwyer2016.html",
    "href": "publications/articles/Dwyer2016.html",
    "title": "Power Pole Density Informs Spatial Prioritization for Mitigating Avian Electrocution",
    "section": "",
    "text": "Dwyer, J.F., Harness, R.E., Gerber, B.D., Landon, M.A., Petersen, P., Austin, D.D., Woodbridge, B., Williams, G.E. and Eccleston, D. (2016), Power pole density informs spatial prioritization for mitigating avian electrocution. Jour. Wild. Mgmt., 80: 634-642. https://doi.org/10.1002/jwmg.1048"
  },
  {
    "objectID": "publications/articles/Dwyer2016.html#citation",
    "href": "publications/articles/Dwyer2016.html#citation",
    "title": "Power Pole Density Informs Spatial Prioritization for Mitigating Avian Electrocution",
    "section": "",
    "text": "Dwyer, J.F., Harness, R.E., Gerber, B.D., Landon, M.A., Petersen, P., Austin, D.D., Woodbridge, B., Williams, G.E. and Eccleston, D. (2016), Power pole density informs spatial prioritization for mitigating avian electrocution. Jour. Wild. Mgmt., 80: 634-642. https://doi.org/10.1002/jwmg.1048"
  },
  {
    "objectID": "publications/articles/Dwyer2016.html#abstract",
    "href": "publications/articles/Dwyer2016.html#abstract",
    "title": "Power Pole Density Informs Spatial Prioritization for Mitigating Avian Electrocution",
    "section": "Abstract",
    "text": "Abstract\nRaptor and corvid electrocutions cause continental conservation concerns for breeding, migrating, and wintering birds. Although concerns are widespread, mitigation is implemented primarily at local scales of individual electric utilities. By not considering landscape-scale patterns, conservation strategies may fail to focus mitigation where efforts are needed most. To enable resource managers to consider electrocution risk at larger scales, we developed a regional model of distribution power pole (pole) density in a grid of 1-km2 cells throughout Colorado and Wyoming. To do so, we obtained data on pole locations from a sample of electric utilities covering 31% of Colorado and Wyoming, and developed a predictive model of poles throughout the remainder of the 2 states. Pole density was influenced by road lengths, number of oil and gas wells, slope, development, and land cover. Poles were densest in areas with high road lengths, high numbers of wells, and relatively flat terrain, and in areas developed for agriculture or human residences. When model predictions are viewed together with species-specific habitat maps, locations where high pole densities overlap habitat suggest areas where mitigating electrocution risk could be prioritized. Communication between resource managers and local utilities could then clarify the poles that caused the highest risk to raptors from electrocution. Thus, the model provides a framework for systematic spatial prioritization in support of regional conservation planning to minimize electrocution of raptors and corvids. © 2016 The Wildlife Society."
  },
  {
    "objectID": "publications/articles/Gerber2015.html",
    "href": "publications/articles/Gerber2015.html",
    "title": "Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations",
    "section": "",
    "text": "Gerber, B.D., Kendall, W.L., Hooten, M.B., Dubovsky, J.A. and Drewien, R.C. (2015), Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations. J Anim Ecol, 84: 1299-1310. https://doi.org/10.1111/1365-2656.12370"
  },
  {
    "objectID": "publications/articles/Gerber2015.html#citation",
    "href": "publications/articles/Gerber2015.html#citation",
    "title": "Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations",
    "section": "",
    "text": "Gerber, B.D., Kendall, W.L., Hooten, M.B., Dubovsky, J.A. and Drewien, R.C. (2015), Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations. J Anim Ecol, 84: 1299-1310. https://doi.org/10.1111/1365-2656.12370"
  },
  {
    "objectID": "publications/articles/Gerber2015.html#abstract",
    "href": "publications/articles/Gerber2015.html#abstract",
    "title": "Optimal population prediction of sandhill crane recruitment based on climate-mediated habitat limitations",
    "section": "Abstract",
    "text": "Abstract\nPrediction is fundamental to scientific enquiry and application; however, ecologists tend to favour explanatory modelling. We discuss a predictive modelling framework to evaluate ecological hypotheses and to explore novel/unobserved environmental scenarios to assist conservation and management decision-makers. We apply this framework to develop an optimal predictive model for juvenile (&lt;1 year old) sandhill crane Grus canadensis recruitment of the Rocky Mountain Population (RMP). We consider spatial climate predictors motivated by hypotheses of how drought across multiple time-scales and spring/summer weather affects recruitment.\nOur predictive modelling framework focuses on developing a single model that includes all relevant predictor variables, regardless of collinearity. This model is then optimized for prediction by controlling model complexity using a data-driven approach that marginalizes or removes irrelevant predictors from the model. Specifically, we highlight two approaches of statistical regularization, Bayesian least absolute shrinkage and selection operator (LASSO) and ridge regression.\nOur optimal predictive Bayesian LASSO and ridge regression models were similar and on average 37% superior in predictive accuracy to an explanatory modelling approach. Our predictive models confirmed a priori hypotheses that drought and cold summers negatively affect juvenile recruitment in the RMP. The effects of long-term drought can be alleviated by short-term wet spring–summer months; however, the alleviation of long-term drought has a much greater positive effect on juvenile recruitment. The number of freezing days and snowpack during the summer months can also negatively affect recruitment, while spring snowpack has a positive effect.\nBreeding habitat, mediated through climate, is a limiting factor on population growth of sandhill cranes in the RMP, which could become more limiting with a changing climate (i.e. increased drought). These effects are likely not unique to cranes. The alteration of hydrological patterns and water levels by drought may impact many migratory, wetland nesting birds in the Rocky Mountains and beyond. Generalizable predictive models (trained by out-of-sample fit and based on ecological hypotheses) are needed by conservation and management decision-makers. Statistical regularization improves predictions and provides a general framework for fitting models with a large number of predictors, even those with collinearity, to simultaneously identify an optimal predictive model while conducting rigorous Bayesian model selection. Our framework is important for understanding population dynamics under a changing climate and has direct applications for making harvest and habitat management decisions."
  },
  {
    "objectID": "publications/articles/Kotschwar2015.html",
    "href": "publications/articles/Kotschwar2015.html",
    "title": "Assessing carnivore distribution from local knowledge across a human‐dominated landscape in central‐southeastern M adagascar",
    "section": "",
    "text": "Kotschwar Logan, M., Gerber, B.D., Karpanty, S.M., Justin, S. and Rabenahy, F.N. (2015), Local ecological knowledge of Madagascar’s carnivores. Anim Conserv, 18: 82-91. https://doi.org/10.1111/acv.12137"
  },
  {
    "objectID": "publications/articles/Kotschwar2015.html#citation",
    "href": "publications/articles/Kotschwar2015.html#citation",
    "title": "Assessing carnivore distribution from local knowledge across a human‐dominated landscape in central‐southeastern M adagascar",
    "section": "",
    "text": "Kotschwar Logan, M., Gerber, B.D., Karpanty, S.M., Justin, S. and Rabenahy, F.N. (2015), Local ecological knowledge of Madagascar’s carnivores. Anim Conserv, 18: 82-91. https://doi.org/10.1111/acv.12137"
  },
  {
    "objectID": "publications/articles/Kotschwar2015.html#abstract",
    "href": "publications/articles/Kotschwar2015.html#abstract",
    "title": "Assessing carnivore distribution from local knowledge across a human‐dominated landscape in central‐southeastern M adagascar",
    "section": "Abstract",
    "text": "Abstract\nCarnivores are often sensitive to habitat loss and fragmentation, both of which are widespread in Madagascar. Clearing of forests has led to a dramatic increase in highly disturbed, open vegetation communities dominated by humans. In Madagascar’s increasingly disturbed landscape, long-term persistence of native carnivores may be tied to their ability to occupy or traverse these disturbed areas. However, how Malagasy carnivores are distributed in this landscape and how they interact with humans are unknown, as past research has concentrated on populations within continuous and fragmented forests. We investigated local ecological knowledge of carnivores using semi-structured interviews in communities 0 to 20 km from the western edge of continuous rainforest in central-southeastern Madagascar. Responses from 182 interviews in 17 different communities indicated distinct distribution patterns for two native and two exotic carnivore species, suggesting a range of tolerances to the human-dominated landscape. The largest extant native carnivore, the fossa Cryptoprocta ferox, does not persist in much of this landscape; they were only observed in communities &lt; 5 km from the continuous forest within the last five years. In contrast, the ring-tailed mongoose Galidia elegans was observed by most communities (82%), but was observed by a higher proportion of interviewees from communities in close proximity to continuous forest. The exotic small Indian civet Viverricula indica was ubiquitous, while the exotic/feral cat (Felis sp.) was observed by a higher proportion of interviewees in communities farther from continuous forest. Over 20% of interviewees had experienced loss of poultry to wild carnivores in the last year and negative perceptions of carnivores were common. We found the human-dominated landscape to provide little conservation value to native carnivores, emphasizing the need for adequate protected areas and increased engagement of local communities to sustain Madagascar’s carnivore species. This information is critical to multitaxon conservation planning in Madagascar."
  },
  {
    "objectID": "publications/articles/Farris2015.html",
    "href": "publications/articles/Farris2015.html",
    "title": "When carnivores roam: temporal patterns and overlap among Madagascar’s native and exotic carnivores",
    "section": "",
    "text": "Farris, Z.J., Gerber, B.D., Karpanty, S., Murphy, A., Andrianjakarivelo, V., Ratelolahy, F. and Kelly, M.J. (2015), Activity patterns of Madagascar’s carnivore community. J Zool, 296: 45-57. https://doi.org/10.1111/jzo.12216"
  },
  {
    "objectID": "publications/articles/Farris2015.html#citation",
    "href": "publications/articles/Farris2015.html#citation",
    "title": "When carnivores roam: temporal patterns and overlap among Madagascar’s native and exotic carnivores",
    "section": "",
    "text": "Farris, Z.J., Gerber, B.D., Karpanty, S., Murphy, A., Andrianjakarivelo, V., Ratelolahy, F. and Kelly, M.J. (2015), Activity patterns of Madagascar’s carnivore community. J Zool, 296: 45-57. https://doi.org/10.1111/jzo.12216"
  },
  {
    "objectID": "publications/articles/Farris2015.html#abstract",
    "href": "publications/articles/Farris2015.html#abstract",
    "title": "When carnivores roam: temporal patterns and overlap among Madagascar’s native and exotic carnivores",
    "section": "Abstract",
    "text": "Abstract\nMadagascar’s Eupleridae carnivores are perhaps the least studied and most threatened family of Carnivora. Investigating potential direct and indirect competition among these native species and sympatric exotic carnivores is necessary to better direct conservation actions. From 2008 to 2013, we photographically surveyed a diverse rainforest landscape, comparing six native and three exotic carnivores’ activity patterns throughout the diel cycle. We used hierarchical Bayesian Poisson analysis to describe the activity patterns of Madagascar’s carnivore community, assessed effects of season and site on temporal activity patterns, and estimated coefficients of overlap between carnivore pairings to assess effects of body size and ecological niche on temporal overlap among native and exotic carnivores. We observed changes in temporal activity patterns across seasons particularly during the austral summer (hot–dry season) for four native and two exotic carnivores, including evidence of fossa Cryptoprocta ferox altering their temporal activity during their mating season (hot–dry season). We found evidence of high overlap between natives and exotics indicating the potential for increased interactions and competition. The greatest overlap in temporal activity occurred between both ring-tail Galidia elegans and brown-tail vontsira Salanoia concolor and exotic dogs Canis familiaris. Cr. ferox, falanouc Eupleres goudotii and spotted fanaloka Fossa fossana also overlapped in activity with the nocturnal, exotic Indian civet Viverricula indica. Cr. ferox avoided humans and Ca. familiaris across all seasons. Unexpectedly, carnivore body size and ecological niche were not important predictors of temporal overlap. Previous research has shown these native and exotic carnivores overlap spatially and these new findings of temporal overlap among native and exotic carnivores add urgency to the need to manage exotic carnivores across Madagascar."
  },
  {
    "objectID": "publications/articles/Zohdy2014.html",
    "href": "publications/articles/Zohdy2014.html",
    "title": "Teeth, sex, and testosterone: aging in the world’s smallest primate",
    "section": "",
    "text": "Zohdy, S., Gerber, B. D., Tecot, S., Blanco, M. B., Winchester, J. M., Wright, P. C., & Jernvall, J. (2014). Teeth, sex, and testosterone: aging in the world’s smallest primate. PLoS One, 9(10), e109528."
  },
  {
    "objectID": "publications/articles/Zohdy2014.html#citation",
    "href": "publications/articles/Zohdy2014.html#citation",
    "title": "Teeth, sex, and testosterone: aging in the world’s smallest primate",
    "section": "",
    "text": "Zohdy, S., Gerber, B. D., Tecot, S., Blanco, M. B., Winchester, J. M., Wright, P. C., & Jernvall, J. (2014). Teeth, sex, and testosterone: aging in the world’s smallest primate. PLoS One, 9(10), e109528."
  },
  {
    "objectID": "publications/articles/Zohdy2014.html#abstract",
    "href": "publications/articles/Zohdy2014.html#abstract",
    "title": "Teeth, sex, and testosterone: aging in the world’s smallest primate",
    "section": "Abstract",
    "text": "Abstract\nMouse lemurs (Microcebus spp.) are an exciting new primate model for understanding human aging and disease. In captivity, Microcebus murinus develops human-like ailments of old age after five years (e.g., neurodegeneration analogous to Alzheimer’s disease) but can live beyond 12 years. It is believed that wild Microcebus follow a similar pattern of senescence observed in captive animals, but that predation limits their lifespan to four years, thus preventing observance of these diseases in the wild. Testing whether this assumption is true is informative about both Microcebus natural history and environmental influences on senescence, leading to interpretation of findings for models of human aging. Additionally, the study of Microcebus longevity provides an opportunity to better understand mechanisms of sex-biased longevity. Longevity is often shorter in males of species with high male-male competition, such as Microcebus, but mouse lemurs are sexually monomorphic, suggesting similar lifespans. We collected individual-based observations of wild brown mouse lemurs (Microcebus rufus) from 2003–2010 to investigate sex-differences in survival and longevity. Fecal testosterone was measured as a potential mechanism of sex-based differences in survival. We used a combination of high-resolution tooth wear techniques, mark-recapture, and hormone enzyme immunoassays. We found no dental or physical signs of senescence in M. rufus as old as eight years (N = 189, ages 1–8, mean = 2.59±1.63 SE), three years older than captive, senescent congeners (M. murinus). Unlike other polygynandrous vertebrates, we found no sex difference in age-dependent survival, nor sex or age differences in testosterone levels. While elevated male testosterone levels have been implicated in shorter lifespans in several species, this is one of the first studies to show equivalent testosterone levels accompanying equivalent lifespans. Future research on captive aged individuals can determine if senescence is partially a condition of their captive environment, and studies controlling for various environmental factors will further our understanding of senescence."
  },
  {
    "objectID": "publications/articles/Gerber2014.html",
    "href": "publications/articles/Gerber2014.html",
    "title": "Primates and cameras: Noninvasive sampling to make population-level inferences while accounting for imperfect detection",
    "section": "",
    "text": "Gerber, B.D., Williams, P.J. & Bailey, L.L. Primates and Cameras. Int J Primatol 35, 841–858 (2014). https://doi.org/10.1007/s10764-014-9761-9"
  },
  {
    "objectID": "publications/articles/Gerber2014.html#citation",
    "href": "publications/articles/Gerber2014.html#citation",
    "title": "Primates and cameras: Noninvasive sampling to make population-level inferences while accounting for imperfect detection",
    "section": "",
    "text": "Gerber, B.D., Williams, P.J. & Bailey, L.L. Primates and Cameras. Int J Primatol 35, 841–858 (2014). https://doi.org/10.1007/s10764-014-9761-9"
  },
  {
    "objectID": "publications/articles/Gerber2014.html#abstract",
    "href": "publications/articles/Gerber2014.html#abstract",
    "title": "Primates and cameras: Noninvasive sampling to make population-level inferences while accounting for imperfect detection",
    "section": "Abstract",
    "text": "Abstract\nField-based primate studies often make population inferences using count-based indices (e.g., individuals/plot) or distance sampling; the first does not account for the probability of detection and thus can be biased, while the second requires large sample sizes to obtain precise estimates, which is difficult for many primate studies. We discuss photographic sampling and occupancy modeling to correct for imperfect detection when estimating system states and dynamics at the landscape level, specifically in relation to primate ecology. We highlight the flexibility of the occupancy framework and its many applications to studying low-density primate populations or species that are difficult to detect. We discuss relevant sampling and estimation procedures with special attention to data collection via photographic sampling. To provide tangible meaning to terminology and clarify subtleties, we use illustrative examples. Photographic sampling can have many advantages over observer-based sampling, especially when studying rare or elusive species. Combining photographic sampling with an occupancy framework allows inference to larger scales than is common in primate studies, addresses uncertainty due to the observation process, and allows researchers to examine questions of how landscape-level anthropogenic changes affect primate distributions."
  },
  {
    "objectID": "publications/articles/Shannon2014.html",
    "href": "publications/articles/Shannon2014.html",
    "title": "Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data",
    "section": "",
    "text": "Shannon G, Lewis JS, Gerber BD. 2014. Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data. PeerJ 2:e532 https://doi.org/10.7717/peerj.532"
  },
  {
    "objectID": "publications/articles/Shannon2014.html#citation",
    "href": "publications/articles/Shannon2014.html#citation",
    "title": "Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data",
    "section": "",
    "text": "Shannon G, Lewis JS, Gerber BD. 2014. Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data. PeerJ 2:e532 https://doi.org/10.7717/peerj.532"
  },
  {
    "objectID": "publications/articles/Shannon2014.html#abstract",
    "href": "publications/articles/Shannon2014.html#abstract",
    "title": "Recommended survey designs for occupancy modelling using motion-activated cameras: insights from empirical wildlife data",
    "section": "Abstract",
    "text": "Abstract\nMotion-activated cameras are a versatile tool that wildlife biologists can use for sampling wild animal populations to estimate species occurrence. Occupancy modelling provides a flexible framework for the analysis of these data; explicitly recognizing that given a species occupies an area the probability of detecting it is often less than one. Despite the number of studies using camera data in an occupancy framework, there is only limited guidance from the scientific literature about survey design trade-offs when using motion-activated cameras. A fuller understanding of these trade-offs will allow researchers to maximise available resources and determine whether the objectives of a monitoring program or research study are achievable. We use an empirical dataset collected from 40 cameras deployed across 160 km2 of the Western Slope of Colorado, USA to explore how survey effort (number of cameras deployed and the length of sampling period) affects the accuracy and precision (i.e., error) of the occupancy estimate for ten mammal and three virtual species. We do this using a simulation approach where species occupancy and detection parameters were informed by empirical data from motion-activated cameras. A total of 54 survey designs were considered by varying combinations of sites (10–120 cameras) and occasions (20–120 survey days). Our findings demonstrate that increasing total sampling effort generally decreases error associated with the occupancy estimate, but changing the number of sites or sampling duration can have very different results, depending on whether a species is spatially common or rare (occupancy = ψ) and easy or hard to detect when available (detection probability = p). For rare species with a low probability of detection (i.e., raccoon and spotted skunk) the required survey effort includes maximizing the number of sites and the number of survey days, often to a level that may be logistically unrealistic for many studies. For common species with low detection (i.e., bobcat and coyote) the most efficient sampling approach was to increase the number of occasions (survey days). However, for common species that are moderately detectable (i.e., cottontail rabbit and mule deer), occupancy could reliably be estimated with comparatively low numbers of cameras over a short sampling period. We provide general guidelines for reliably estimating occupancy across a range of terrestrial species (rare to common: ψ = 0.175–0.970, and low to moderate detectability: p = 0.003–0.200) using motion-activated cameras. Wildlife researchers/managers with limited knowledge of the relative abundance and likelihood of detection of a particular species can apply these guidelines regardless of location. We emphasize the importance of prior biological knowledge, defined objectives and detailed planning (e.g., simulating different study-design scenarios) for designing effective monitoring programs and research studies."
  },
  {
    "objectID": "publications/articles/GerberParmenter2014.html",
    "href": "publications/articles/GerberParmenter2014.html",
    "title": "Spatial capture-recapture model performance with known small-mammal densities",
    "section": "",
    "text": "Gerber, B.D. and Parmenter, R.R. (2015), Spatial capture–recapture model performance with known small-mammal densities. Ecological Applications, 25: 695-705. https://doi.org/10.1890/14-0960.1"
  },
  {
    "objectID": "publications/articles/GerberParmenter2014.html#citation",
    "href": "publications/articles/GerberParmenter2014.html#citation",
    "title": "Spatial capture-recapture model performance with known small-mammal densities",
    "section": "",
    "text": "Gerber, B.D. and Parmenter, R.R. (2015), Spatial capture–recapture model performance with known small-mammal densities. Ecological Applications, 25: 695-705. https://doi.org/10.1890/14-0960.1"
  },
  {
    "objectID": "publications/articles/GerberParmenter2014.html#abstract",
    "href": "publications/articles/GerberParmenter2014.html#abstract",
    "title": "Spatial capture-recapture model performance with known small-mammal densities",
    "section": "Abstract",
    "text": "Abstract\nAbundance and density of wild animals are important ecological metrics. However, estimating either is fraught with challenges; spatial capture–recapture (SCR) models are a relatively new class of models that attempt to ameliorate common challenges, providing a statistically coherent framework to estimate abundance and density. SCR models are increasingly being used in ecological and conservation studies of mammals worldwide, but have received little testing with empirical field data. We use data collected via a web and grid sampling design to evaluate the basic SCR model where small-mammal abundance (N) and density (D) are known (via exhaustive sampling). We fit the basic SCR model with and without a behavioral effect to 11 small-mammal populations for each sampling design using a Bayesian and likelihood SCR modeling approach. We compare SCR and ad hoc density estimators using frequentist performance measures. We found Bayesian and likelihood SCR estimates of density (D̂) and abundance (N̂) to be similar. We also found SCR models to have moderately poor frequentist coverage of D and N (45–73%), high deviation from truth (i.e., accuracy; D̂, 17–29%; N̂, 16–29%), and consistent negative bias across inferential paradigms, sampling designs, and models. With the trapping grid data, the basic SCR model generally performed more poorly than the best ad hoc estimator (behavior CR super-population estimate divided by the full mean maximum distance moved estimate of the effective trapping area), whereas with the trapping web data, the best-performing SCR model (null) was comparable to the best distance model. Relatively poor frequentist SCR coverage resulted from higher precision (SCR coefficients of variation [CVs] &lt; ad hoc CVs); however D̂ and D were fairly well correlated (r2 range of 0.77–0.96). SCR’s negative relative bias (i.e., average underestimation of the true density) suggests additional heterogeneity in detection and/or that small mammals maintained asymmetric home ranges. We suggest caution in the use of the basic SCR model when trapping animals in a sampling grid and more generally when small sample sizes necessitate the spatial scale parameter (σ) apply to all individuals. When possible, researchers should consider variation in detection and incorporate individual biological and/or ecological variation at the trap level when modeling σ."
  },
  {
    "objectID": "publications/articles/GerberIvanBurnham2014.html",
    "href": "publications/articles/GerberIvanBurnham2014.html",
    "title": "Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small",
    "section": "",
    "text": "Gerber, B.D., Ivan, J.S. & Burnham, K.P. Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small. Popul Ecol 56, 463–470 (2014). https://doi.org/10.1007/s10144-014-0431-8"
  },
  {
    "objectID": "publications/articles/GerberIvanBurnham2014.html#citation",
    "href": "publications/articles/GerberIvanBurnham2014.html#citation",
    "title": "Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small",
    "section": "",
    "text": "Gerber, B.D., Ivan, J.S. & Burnham, K.P. Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small. Popul Ecol 56, 463–470 (2014). https://doi.org/10.1007/s10144-014-0431-8"
  },
  {
    "objectID": "publications/articles/GerberIvanBurnham2014.html#abstract",
    "href": "publications/articles/GerberIvanBurnham2014.html#abstract",
    "title": "Estimating the abundance of rare and elusive carnivores from photographic-sampling data when the population size is very small",
    "section": "Abstract",
    "text": "Abstract\nConservation and management agencies require accurate and precise estimates of abundance when considering the status of a species and the need for directed actions. Due to the proliferation of remote sampling cameras, there has been an increase in capture–recapture studies that estimate the abundance of rare and/or elusive species using closed capture–recapture estimators (C–R). However, data from these studies often do not meet necessary statistical assumptions. Common attributes of these data are (1) infrequent detections, (2) a small number of individuals detected, (3) long survey durations, and (4) variability in detection among individuals. We believe there is a need for guidance when analyzing this type of sparse data. We highlight statistical limitations of closed C–R estimators when data are sparse and suggest an alternative approach over the conventional use of the Jackknife estimator. Our approach aims to maximize the probability individuals are detected at least once over the entire sampling period, thus making the modeling of variability in the detection process irrelevant, estimating abundance accurately and precisely. We use simulations to demonstrate when using the unconditional-likelihood M0 (constant detection probability) closed C–R estimator with profile-likelihood confidence intervals provides reliable results even when detection varies by individual. If each individual in the population is detected on average of at least 2.5 times, abundance estimates are accurate and precise. When studies sample the same species at multiple areas or at the same area over time, we suggest sharing detection information across datasets to increase precision when estimating abundance. The approach suggested here should be useful for monitoring small populations of species that are difficult to detect."
  },
  {
    "objectID": "publications/articles/Sporer2014.html",
    "href": "publications/articles/Sporer2014.html",
    "title": "Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota",
    "section": "",
    "text": "Sporer, M.K., Dwyer, J.F., Gerber, B.D., Harness, R.E. and Pandey, A.K. (2013), Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota. Wildl. Soc. Bull., 37: 796-804. https://doi.org/10.1002/wsb.329"
  },
  {
    "objectID": "publications/articles/Sporer2014.html#citation",
    "href": "publications/articles/Sporer2014.html#citation",
    "title": "Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota",
    "section": "",
    "text": "Sporer, M.K., Dwyer, J.F., Gerber, B.D., Harness, R.E. and Pandey, A.K. (2013), Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota. Wildl. Soc. Bull., 37: 796-804. https://doi.org/10.1002/wsb.329"
  },
  {
    "objectID": "publications/articles/Sporer2014.html#abstract",
    "href": "publications/articles/Sporer2014.html#abstract",
    "title": "Marking power lines to reduce avian collisions near the Audubon National Wildlife Refuge, North Dakota",
    "section": "Abstract",
    "text": "Abstract\nOverhead power lines can pose collision risks to birds. Risks may be mitigated through marking lines with high-visibility devices, but the effectiveness of line marking remains unclear. Effectiveness is particularly poorly described for lines bisecting open water, where detection of carcasses can be difficult. We marked 3 of 9 spans (lines between adjacent structures) along a causeway crossing open water and 2 adjacent spans over lake shores between Lake Sakakawea and Lake Audubon near Audubon National Wildlife Refuge, North Dakota, USA. Over 3 years, we found 1,186 avian carcasses, including 276 attributed to power-line collision. American coots (Fulica americana; n = 83) and double-crested cormorants (Phalacrocorax auritus; n = 27) were the species most commonly associated with power-line collision, but we also found carcasses of 51 other species, including a piping plover (Charadrius melodus; n = 1). Multi-variable modeling indicated line marking over open water reduced predicted collisions per span per season (mid-April through mid-October, 2006–2008) from 10.3 to 5.8. Birds with high-aspect-ratio wings benefitted most from line marking (e.g., shorebirds and gulls). If the 9 open-water spans we studied were unmarked for 30 years, we predicted 2,775 collisions. We predicted only 1,560 collisions if all of these spans were marked. Our data demonstrate that a wide variety of avian species are at risk of collision with lines bisecting open water, marking lines can reduce collision risk, and because collisions persisted and some line markers fell off power lines, improvements to effectively mark lines are needed. © 2013 The Wildlife Society."
  },
  {
    "objectID": "publications/articles/Tecot2014.html",
    "href": "publications/articles/Tecot2014.html",
    "title": "Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur",
    "section": "",
    "text": "Stacey R. Tecot, Brian D. Gerber, Stephen J. King, Jennifer L. Verdolin, Patricia C. Wright, Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur, Behavioral Ecology, Volume 24, Issue 4, 2013, 987–996, https://doi.org/10.1093/beheco/art008"
  },
  {
    "objectID": "publications/articles/Tecot2014.html#citation",
    "href": "publications/articles/Tecot2014.html#citation",
    "title": "Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur",
    "section": "",
    "text": "Stacey R. Tecot, Brian D. Gerber, Stephen J. King, Jennifer L. Verdolin, Patricia C. Wright, Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur, Behavioral Ecology, Volume 24, Issue 4, 2013, 987–996, https://doi.org/10.1093/beheco/art008"
  },
  {
    "objectID": "publications/articles/Tecot2014.html#abstract",
    "href": "publications/articles/Tecot2014.html#abstract",
    "title": "Risky business: sex differences in mortality and dispersal in a polygynous, monomorphic lemur",
    "section": "Abstract",
    "text": "Abstract\nSexually selected traits and the use of strategies to enhance male reproductive success (e.g., competition and dispersal) can yield sex differences in metabolic requirements, rates and durations of growth and maturation, and the propensity for risky behavior, which are suggested to result in age-specific sex differences in mortality and life span. We investigated age-specific sex ratios, mortality, and dispersal in Propithecus edwardsi in Ranomafana National Park, Madagascar. We predicted that, due to similarities in growth rates and body sizes, male and female juvenile mortality rates would be comparable; because both sexes disperse and have intense intersexual competition and aggression, adult mortality would be similar; given similarities in dispersal frequency and distance, the timing of dispersal would not differ. We used 80 group-years births, deaths, and dispersals (Nfemales = 41, Nmales = 34) collected over 23 years to calculate sex ratios and survival curves. Females lived longer than males (maximum 32 and 19 years, respectively). Sex ratios were male biased from sexual maturity through 17 years and female biased at birth and older ages. Infant survival probabilities were similar. Thus, differential development and maturation are unlikely explanations for longer female life span in this species. Males were more likely to survive from 2 to 18 years. However, male annual survival probability declined quickly around 13–18 years; males continued to disperse until their deaths, whereas females generally stopped dispersing after 11 years. We suggest that sex differences in the timing of dispersal and the unique challenges of risky behavior at older ages may be sufficient to yield differences in male and female life span."
  },
  {
    "objectID": "publications/articles/Gerber2012.html",
    "href": "publications/articles/Gerber2012.html",
    "title": "The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar’s rainforests",
    "section": "",
    "text": "Gerber BD, Karpanty SM, Randrianantenaina J. The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar’s rainforests. Oryx. 2012;46(3):414-422. doi:10.1017/S0030605311001116"
  },
  {
    "objectID": "publications/articles/Gerber2012.html#citation",
    "href": "publications/articles/Gerber2012.html#citation",
    "title": "The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar’s rainforests",
    "section": "",
    "text": "Gerber BD, Karpanty SM, Randrianantenaina J. The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar’s rainforests. Oryx. 2012;46(3):414-422. doi:10.1017/S0030605311001116"
  },
  {
    "objectID": "publications/articles/Gerber2012.html#abstract",
    "href": "publications/articles/Gerber2012.html#abstract",
    "title": "The impact of forest logging and fragmentation on carnivore species composition, density and occupancy in Madagascar’s rainforests",
    "section": "Abstract",
    "text": "Abstract\nForest carnivores are threatened globally by logging and forest fragmentation yet we know relatively little about how such change affects predator populations. This is especially true in Madagascar, where carnivores have not been extensively studied. To understand better the effects of logging and fragmentation on Malagasy carnivores we evaluated species composition, density of fossa Cryptoprocta ferox and Malagasy civet Fossa fossana, and carnivore occupancy in central-eastern Madagascar. We photographically-sampled carnivores in two contiguous (primary and selectively-logged) and two fragmented rainforests (fragments &lt;2.5 and &gt;15 km from intact forest). Species composition varied, with more native carnivores in the contiguous than fragmented rainforests. F. fossana was absent from fragmented rainforests and at a lower density in selectively-logged than in primary rainforest (mean 1.38±SE 0.22 and 3.19±SE 0.55 individuals km−2, respectively). C. ferox was detected in fragments &lt;2.5 km from forest and had similar densities in primary and selectively-logged forests (0.12±SE 0.05 and 0.09±SE 0.04 adults km−2, respectively) but was absent in fragments &gt;15 km from forest. We identified only two protected areas in Madagascar that may maintain &gt;300 adult C. ferox. Occupancy of broad-striped mongoose Galidictis fasciata was positively related to fragment size whereas occupancy of ring-tailed mongoose Galidia elegans elegans was negatively associated with increasing exotic wild cat (Felis spp.) activity at a camera site. Degraded rainforest fragments are difficult environments for Malagasy carnivores to occupy; there is a need to prioritize the reconnection and maintenance of contiguous forest tracts."
  },
  {
    "objectID": "publications/articles/Gerber2012b.html",
    "href": "publications/articles/Gerber2012b.html",
    "title": "Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence",
    "section": "",
    "text": "Brian D. Gerber, Sarah M. Karpanty, Johny Randrianantenaina, Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence, Journal of Mammalogy, Volume 93, Issue 3, 2012, Pages 667–676, https://doi.org/10.1644/11-MAMM-A-265.1"
  },
  {
    "objectID": "publications/articles/Gerber2012b.html#citation",
    "href": "publications/articles/Gerber2012b.html#citation",
    "title": "Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence",
    "section": "",
    "text": "Brian D. Gerber, Sarah M. Karpanty, Johny Randrianantenaina, Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence, Journal of Mammalogy, Volume 93, Issue 3, 2012, Pages 667–676, https://doi.org/10.1644/11-MAMM-A-265.1"
  },
  {
    "objectID": "publications/articles/Gerber2012b.html#abstract",
    "href": "publications/articles/Gerber2012b.html#abstract",
    "title": "Activity patterns of carnivores in the rain forests of Madagascar: implications for species coexistence",
    "section": "Abstract",
    "text": "Abstract\nTemporal partitioning of activity among sympatric species can be an important mechanism for species coexistence. Further, if exotic and native species overlap temporally, there is potential for direct competition and antagonism, which may lead to native species extirpation. We 1st assessed if ecologically similar native carnivores of Madagascar demonstrated activity pattern overlap and then explored whether overlap in activity might lead to negative impacts of exotic carnivores on native carnivores. We used photographic sampling to quantify the temporal activity patterns of carnivores at 4 study sites. The activity of the 2 smaller-bodied native species, Galidia elegans and Galidictis fasciata, overlapped minimally; these 2 carnivores share a similar generalist diet, which may drive their divergent temporal activity. In contrast, the medium-sized native species, Fossa fossana and Eupleres goudotii, were both highly nocturnal; these 2 species appear segregated in their diets. The largest native carnivore, Cryptoprocta ferox, selectively used crepuscular hours, but overall was cathemeral; it was notably absent or basically so at sites where dogs were most abundant and active throughout the diel cycle. We found G. elegans to shift from preferred activity periods in the presence of dogs and the exotic Viverricula indica. Our results suggest that the presence and activity of exotic carnivores can negatively impact native carnivores in fragmented rain forests."
  },
  {
    "objectID": "publications/articles/Gerber2012c.html",
    "href": "publications/articles/Gerber2012c.html",
    "title": "Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?",
    "section": "",
    "text": "Gerber, B.D., Arrigo-Nelson, S., Karpanty, S.M. et al. Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?. Int J Primatol 33, 305–321 (2012). https://doi.org/10.1007/s10764-011-9576-x"
  },
  {
    "objectID": "publications/articles/Gerber2012c.html#citation",
    "href": "publications/articles/Gerber2012c.html#citation",
    "title": "Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?",
    "section": "",
    "text": "Gerber, B.D., Arrigo-Nelson, S., Karpanty, S.M. et al. Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?. Int J Primatol 33, 305–321 (2012). https://doi.org/10.1007/s10764-011-9576-x"
  },
  {
    "objectID": "publications/articles/Gerber2012c.html#abstract",
    "href": "publications/articles/Gerber2012c.html#abstract",
    "title": "Spatial Ecology of the Endangered Milne-Edwards’ Sifaka (Propithecus edwardsi): Do Logging and Season Affect Home Range and Daily Ranging Patterns?",
    "section": "Abstract",
    "text": "Abstract\nPrimates often live in human-altered habitats; Malagasy lemurs are no exception. It is important to understand if habitat alteration affects primates’ space use patterns across multiple spatial and temporal scales, as this drives population density. We quantified the daily, seasonal, and annual space-use of seven groups of Milne-Edwards’ sifaka (Propithecus edwardsi) living in unlogged and logged rain forest in Ranomafana National Park, Madagascar between December 2002 and November 2003. Concurrent data showed that sifakas consumed higher quality foods in the unlogged than in logged forests; thus we explored how space use patterns were related to energy use strategies. Sifaka groups in the logged rain forest traveled 7–13% less per day than groups in the unlogged rain forest, despite their larger home ranges (median: 46.12 and 23.52 ha, in the logged and unlogged forests, respectively). Sifakas may thus use an energy-minimizing strategy at the scale of the individual day but an energy-maximizing strategy at the annual home range scale. Sifakas exhibited fidelity to the home range across seasons, but their core area of use shifted considerably with season. We found no difference in population density between sites. However, given the interannual variability in sifaka foods, a multiyear study is needed to assess if energy strategies observed in this study are consistent across longer time periods. Our findings suggest that lemurs may persist in logged habitats by altering spatial use patterns; future work should attempt to quantify the threshold level of forest regeneration from logging that will allow lemurs to persist at similar densities as in unlogged forest."
  },
  {
    "objectID": "publications/articles/Cohen2011.html",
    "href": "publications/articles/Cohen2011.html",
    "title": "Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA",
    "section": "",
    "text": "Cohen, J. B., Gerber, B. D., Karpanty, S. M., Fraser, J. D., & Truitt, B. R. (2011). Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA. Waterbirds, 34(3), 352-356."
  },
  {
    "objectID": "publications/articles/Cohen2011.html#citation",
    "href": "publications/articles/Cohen2011.html#citation",
    "title": "Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA",
    "section": "",
    "text": "Cohen, J. B., Gerber, B. D., Karpanty, S. M., Fraser, J. D., & Truitt, B. R. (2011). Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA. Waterbirds, 34(3), 352-356."
  },
  {
    "objectID": "publications/articles/Cohen2011.html#abstract",
    "href": "publications/articles/Cohen2011.html#abstract",
    "title": "Day and night foraging of Red Knots (Calidris canutus) during spring stopover in Virginia, USA",
    "section": "Abstract",
    "text": "Abstract\nLong-jump migrant shorebirds have brief windows during spring stopover to acquire the energy needed to complete migration. Red Knots (Calidris canutus) refueling on Horseshoe Crab (Limulus polyphemus) eggs in Delaware Bay can meet their energy needs foraging only by day. In nearby Virginia, thousands of Red Knots stop over, but primarily low-quality, hard-shelled prey are available. One tactic Red Knots may use to meet their energy demands with such prey might be to extend their foraging time by feeding at night. To estimate the length of the foraging day in Virginia, daylight feeding was studied during three spring stopover periods (2008 to 2010), and night feeding was studied in 2010. Red Knots foraged 76 ± 3 SE% of the time in 2008 and 2009 combined, and 59 ± 3% of the time in 2010, during 3-minute observations. In 2010, Red Knots foraged 51 ± 7% of the time during a continuous 7-h daytime observation and 77 ± 5% of the time during a continuous 8-h night time observation on the same island. Given constraints on energy intake, night foraging by Red Knots in Virginia may be necessary for birds to attain sufficient mass to complete migration."
  },
  {
    "objectID": "publications/articles/Gerber2011.html",
    "href": "publications/articles/Gerber2011.html",
    "title": "Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet",
    "section": "",
    "text": "Gerber, B.D., Karpanty, S.M. & Kelly, M.J. Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet. Popul Ecol 54, 43–54 (2012). https://doi.org/10.1007/s10144-011-0276-3"
  },
  {
    "objectID": "publications/articles/Gerber2011.html#citation",
    "href": "publications/articles/Gerber2011.html#citation",
    "title": "Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet",
    "section": "",
    "text": "Gerber, B.D., Karpanty, S.M. & Kelly, M.J. Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet. Popul Ecol 54, 43–54 (2012). https://doi.org/10.1007/s10144-011-0276-3"
  },
  {
    "objectID": "publications/articles/Gerber2011.html#abstract",
    "href": "publications/articles/Gerber2011.html#abstract",
    "title": "Evaluating the potential biases in carnivore capture–recapture studies associated with the use of lure and varying density estimation techniques using photographic-sampling data of the Malagasy civet",
    "section": "Abstract",
    "text": "Abstract\nEstimating density of elusive carnivores with capture–recapture analyses is increasingly common. However, providing unbiased and precise estimates is still a challenge due to uncertainties arising from the use of (1) bait or lure to attract animals to the detection device and (2) ad hoc boundary-strip methods to compensate for edge effects in area estimation. We used photographic-sampling data of the Malagasy civet Fossa fossana collected with and without lure to assess the effects of lure and to compare the use of four density estimators which varied in methods of area estimation. The use of lure did not affect permanent immigration or emigration, abundance and density estimation, maximum movement distances, or temporal activity patterns of Malagasy civets, but did provide more precise population estimates by increasing the number of recaptures. The spatially-explicit capture–recapture (SECR) model density estimates ±SE were the least precise as they incorporate spatial variation, but consistent with each other (Maximum likelihood-SECR = 1.38 ± 0.18, Bayesian-SECR = 1.24 ± 0.17 civets/km2), whereas estimates relying on boundary-strip methods to estimate effective trapping area did not incorporate spatial variation, varied greatly and were generally larger than SECR model estimates. Estimating carnivore density with ad hoc boundary-strip methods can lead to overestimation and/or increased uncertainty as they do not incorporate spatial variation. This may lead to inaction or poor management decisions which may jeopardize at-risk populations. In contrast, SECR models free researchers from making subjective decisions associated with boundary-strip methods and they estimate density directly, providing more comparable and valuable population estimates."
  },
  {
    "objectID": "publications/articles/Gerber2010.html",
    "href": "publications/articles/Gerber2010.html",
    "title": "An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps",
    "section": "",
    "text": "Gerber B, Karpanty SM, Crawford C, Kotschwar M, Randrianantenaina J. An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps. Oryx. 2010;44(2):219-222. doi:10.1017/S0030605309991037"
  },
  {
    "objectID": "publications/articles/Gerber2010.html#citation",
    "href": "publications/articles/Gerber2010.html#citation",
    "title": "An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps",
    "section": "",
    "text": "Gerber B, Karpanty SM, Crawford C, Kotschwar M, Randrianantenaina J. An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps. Oryx. 2010;44(2):219-222. doi:10.1017/S0030605309991037"
  },
  {
    "objectID": "publications/articles/Gerber2010.html#abstract",
    "href": "publications/articles/Gerber2010.html#abstract",
    "title": "An assessment of carnivore relative abundance and density in the eastern rainforests of Madagascar using remotely-triggered camera traps",
    "section": "Abstract",
    "text": "Abstract\nDespite major efforts to understand and conserve Madagascar’s unique biodiversity, relatively little is known about the island’s carnivore populations. We therefore deployed 43 camera-trap stations in Ranomafana National Park, Madagascar during June–August 2007 to evaluate the efficacy of this method for studying Malagasy carnivores and to estimate the relative abundance and density of carnivores in the eastern rainforest. A total of 755 camera-trap nights provided 1,605 photographs of four endemic carnivore species (fossa Cryptoprocta ferox, Malagasy civet Fossa fossana, ring-tailed mongoose Galidia elegans and broad-striped mongoose Galidictus fasciata), the exotic Indian civet Viverricula indica and the domestic dog Canis familiaris. We identified 38 individual F. fossana and 10 individual C. ferox. We estimated density using both capture-recapture analyses, with a buffer of full mean-maximum-distance-moved, and a spatially-explicit maximum-likelihood method (F. fossana: 3.03 and 2.23 km-2, respectively; C. ferox: 0.15 and 0.17 km-2, respectively). Our estimated densities of C. ferox in rainforest are lower than published estimates for conspecifics in the western dry forests. Within Ranomafana National Park species richness of native carnivores did not vary among trail systems located in secondary, selectively-logged and undisturbed forest. These results provide the first assessment of carnivore population parameters using camera-traps in the eastern rainforests of Madagascar."
  },
  {
    "objectID": "publications/articles/GerberMark.html",
    "href": "publications/articles/GerberMark.html",
    "title": "Occupancy models–single-species",
    "section": "",
    "text": "Brian D Gerber, Brittany Mosher, Daniel Martin, Larissa Bailey, Thierry Chambert.Occupancy models–single-species. 2012. Program MARK. A Gentle Introduction"
  },
  {
    "objectID": "publications/articles/GerberMark.html#citation",
    "href": "publications/articles/GerberMark.html#citation",
    "title": "Occupancy models–single-species",
    "section": "",
    "text": "Brian D Gerber, Brittany Mosher, Daniel Martin, Larissa Bailey, Thierry Chambert.Occupancy models–single-species. 2012. Program MARK. A Gentle Introduction"
  },
  {
    "objectID": "publications/articles/Gerber2018b.html",
    "href": "publications/articles/Gerber2018b.html",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "",
    "text": "Gerber, B.D., Converse, S.J., Muths, E., Crockett, H.J., Mosher, B.A. and Bailey, L.L. (2018), Identifying Species Conservation Strategies to Reduce Disease-Associated Declines. Conservation Letters, 11: e12393. https://doi.org/10.1111/conl.12393"
  },
  {
    "objectID": "publications/articles/Gerber2018b.html#citation",
    "href": "publications/articles/Gerber2018b.html#citation",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "",
    "text": "Gerber, B.D., Converse, S.J., Muths, E., Crockett, H.J., Mosher, B.A. and Bailey, L.L. (2018), Identifying Species Conservation Strategies to Reduce Disease-Associated Declines. Conservation Letters, 11: e12393. https://doi.org/10.1111/conl.12393"
  },
  {
    "objectID": "publications/articles/Gerber2018b.html#abstract",
    "href": "publications/articles/Gerber2018b.html#abstract",
    "title": "Identifying species conservation strategies to reduce disease‐associated declines",
    "section": "Abstract",
    "text": "Abstract\nEmerging infectious diseases (EIDs) are a salient threat to many animal taxa, causing local and global extinctions, altering communities and ecosystem function. The EID chytridiomycosis is a prominent driver of amphibian declines, which is caused by the fungal pathogen Batrachochytrium dendrobatidis (Bd). To guide conservation policy, we developed a predictive decision-analytic model that combines empirical knowledge of host-pathogen metapopulation dynamics with expert judgment regarding effects of management actions, to select from potential conservation strategies. We apply our approach to a boreal toad (Anaxyrus boreas boreas) and Bd system, identifying optimal strategies that balance tradeoffs in maximizing toad population persistence and landscape-level distribution, while considering costs. The most robust strategy is expected to reduce the decline of toad breeding sites from 53% to 21% over 50 years. Our findings are incorporated into management policy to guide conservation planning. Our online modeling application provides a template for managers of other systems challenged by EIDs."
  },
  {
    "objectID": "publications/articles/Mayer2023.html",
    "href": "publications/articles/Mayer2023.html",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/Mayer2023.html#citation",
    "href": "publications/articles/Mayer2023.html#citation",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "",
    "text": "Mayer, A. E., Ganoe, L. S., Brown, C., & Gerber, B. D. (2023). Diel activity structures the occurrence of a mammal community in a human-dominated landscape. Ecology and Evolution, 13, e10684. https://doi.org/10.1002/ece3.10684"
  },
  {
    "objectID": "publications/articles/Mayer2023.html#abstract",
    "href": "publications/articles/Mayer2023.html#abstract",
    "title": "Diel activity structures the occurrence of a mammal community in a human‐dominated landscape",
    "section": "Abstract",
    "text": "Abstract\nAnthropogenic developments alter the environment and resources available to wildlife communities. In response to these real or perceived threats from this development, species may adjust their spatial occurrence. Additionally, wildlife species may adjust when in diel time (24-h light–dark cycle) they occupy sites on the landscape to adapt to changing conditions. However, many wildlife studies only focus on where a species does and does not occur, ignoring how species may shift their diel activity at sites to mitigate threats. We used a multi-state diel occupancy modeling framework to investigate how a community of mammals (mesocarnivores, urban-adapted omnivores, and herbivore/small mammals) respond to differing levels of anthropogenic development and forest cover across two climatic seasons. We collected camera trap data at 240 survey locations across the summer and winter of 2021–2022. We modeled multi-state diel occupancy for 14 mammal species with extent of development/forest and season hypothesized to influence diel occupancy and season hypothesized to influence the probability of detection. We found that all species displayed heterogeneity in both diel occupancy and detection either by extent of development/forest and or season. Within the mesocarnivore species group, coyote and red fox were less sensitive to development and had higher occupancy probability at these sites in general but used them more during the night, while more sensitive mesocarnivores including fisher and bobcat occupied the day state only when there was increasing forest cover. Our results highlight the importance of incorporating diel activity in habitat modeling to better understand the relationship between a species and its landscape, particularly in a region that is vulnerable to increased anthropogenic pressure."
  },
  {
    "objectID": "publications/articles/GerberBookChapterFosa.html",
    "href": "publications/articles/GerberBookChapterFosa.html",
    "title": "Cryptoprocta ferox, fosa",
    "section": "",
    "text": "Gerber, BD and Hawkins, CE. 2022. Cryptoprocta ferox, fosa. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/GerberBookChapterFosa.html#citation",
    "href": "publications/articles/GerberBookChapterFosa.html#citation",
    "title": "Cryptoprocta ferox, fosa",
    "section": "",
    "text": "Gerber, BD and Hawkins, CE. 2022. Cryptoprocta ferox, fosa. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/FarrisBookChapterMada.html",
    "href": "publications/articles/FarrisBookChapterMada.html",
    "title": "Camera Trapping Madagascar",
    "section": "",
    "text": "Farris, ZJ, Gerber, BD, Murphy, A, and Wampole, E. 2022. Camera Trapping Madagascar. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/FarrisBookChapterMada.html#citation",
    "href": "publications/articles/FarrisBookChapterMada.html#citation",
    "title": "Camera Trapping Madagascar",
    "section": "",
    "text": "Farris, ZJ, Gerber, BD, Murphy, A, and Wampole, E. 2022. Camera Trapping Madagascar. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/RiveraBookChapterMada.html",
    "href": "publications/articles/RiveraBookChapterMada.html",
    "title": "Camera Trapping Madagascar",
    "section": "",
    "text": "Rivera, K, Gerber, BD, and Farris, ZJ. 2022. Eupleres goudotii, small-toothed civet, falanouc. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/RiveraBookChapterMada.html#citation",
    "href": "publications/articles/RiveraBookChapterMada.html#citation",
    "title": "Camera Trapping Madagascar",
    "section": "",
    "text": "Rivera, K, Gerber, BD, and Farris, ZJ. 2022. Eupleres goudotii, small-toothed civet, falanouc. In The new natural history of Madagascar. ed. S. M. Goodman. Princeton, Princeton University Press."
  },
  {
    "objectID": "publications/articles/GerberDwyerCranes.html",
    "href": "publications/articles/GerberDwyerCranes.html",
    "title": "Sandhill Crane (Antigone canadensis)",
    "section": "",
    "text": "Gerber, BD, Dwyer, JD, Nesbitt, SA, Drewien, RC, Littlefield CD, Tacha, TC, and Vohs, PA. 2014. Sandhill Crane (Antigone canadensis). In Birds of the World Online. A. Poole, Ed. Ithaca: Cornell Lab of Ornithology; Birds of North America Online."
  },
  {
    "objectID": "publications/articles/GerberDwyerCranes.html#citation",
    "href": "publications/articles/GerberDwyerCranes.html#citation",
    "title": "Sandhill Crane (Antigone canadensis)",
    "section": "",
    "text": "Gerber, BD, Dwyer, JD, Nesbitt, SA, Drewien, RC, Littlefield CD, Tacha, TC, and Vohs, PA. 2014. Sandhill Crane (Antigone canadensis). In Birds of the World Online. A. Poole, Ed. Ithaca: Cornell Lab of Ornithology; Birds of North America Online."
  },
  {
    "objectID": "publications/articles/Gerber2024.html",
    "href": "publications/articles/Gerber2024.html",
    "title": "A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package",
    "section": "",
    "text": "Gerber, B. D., Devarajan, K., Farris, Z. J., & Fidino, M. (2024). A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package. Journal of Animal Ecology, 00, 1–15. https://doi.org/10.1111/1365-2656.14035"
  },
  {
    "objectID": "publications/articles/Gerber2024.html#citation",
    "href": "publications/articles/Gerber2024.html#citation",
    "title": "A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package",
    "section": "",
    "text": "Gerber, B. D., Devarajan, K., Farris, Z. J., & Fidino, M. (2024). A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package. Journal of Animal Ecology, 00, 1–15. https://doi.org/10.1111/1365-2656.14035"
  },
  {
    "objectID": "publications/articles/Gerber2024.html#abstract",
    "href": "publications/articles/Gerber2024.html#abstract",
    "title": "A model-based hypothesis framework to define and estimate the diel niche via the ‘Diel.Niche’ R package",
    "section": "Abstract",
    "text": "Abstract\n\nHow animals use the diel period (24-h light–dark cycle) is of fundamental importance to understand their niche. While ecological and evolutionary literature abound with discussion of diel phenotypes (e.g. diurnal, nocturnal, crepuscular, cathemeral), they lack clear and explicit quantitative definitions. As such, inference can be confounded when evaluating hypotheses of animal diel niche switching or plasticity across studies because researchers may be operating under different definitions of diel phenotypes.\nWe propose quantitative definitions of diel phenotypes using four alternative hypothesis sets (maximizing, traditional, general and selection) aimed at achieving different objectives. Each hypothesis set is composed of mutually exclusive hypotheses defined based on the activity probabilities in the three fundamental periods of light availability (twilight, daytime and night-time).\nWe develop a Bayesian modelling framework that compares diel phenotype hypotheses using Bayes factors and estimates model parameters using a multinomial model with linear inequality constraints. Model comparison, parameter estimation and visualizing results can be done in the Diel.Niche R package. A simplified R Shiny web application is also available.\nWe provide extensive simulation results to guide researchers on the power to discriminate among hypotheses for a range of sample sizes (10–1280). We also work through several examples of using data to make inferences on diel activity, and include online vignettes on how to use the Diel.Niche package. We demonstrate how our modelling framework complements other analyses, such as circular kernel density estimators and animal movement modelling.\nOur aim is to encourage standardization of the language of diel activity and bridge conceptual frameworks and hypotheses in diel research with data and models. Lastly, we hope more research focuses on the ecological and conservation importance of understanding how animals use diel time."
  },
  {
    "objectID": "publications/articles/Twining2024.html",
    "href": "publications/articles/Twining2024.html",
    "title": "Using global remote camera data of a solitary species complex to evaluate the drivers of group formation",
    "section": "",
    "text": "Twinning et al. (2024). Using global remote camera data of a solitary species complex to evaluate the drivers of group formation. Proceedings of the National Academy of Sciences, 121(12) e2312252121. ."
  },
  {
    "objectID": "publications/articles/Twining2024.html#citation",
    "href": "publications/articles/Twining2024.html#citation",
    "title": "Using global remote camera data of a solitary species complex to evaluate the drivers of group formation",
    "section": "",
    "text": "Twinning et al. (2024). Using global remote camera data of a solitary species complex to evaluate the drivers of group formation. Proceedings of the National Academy of Sciences, 121(12) e2312252121. ."
  },
  {
    "objectID": "publications/articles/Twining2024.html#abstract",
    "href": "publications/articles/Twining2024.html#abstract",
    "title": "Using global remote camera data of a solitary species complex to evaluate the drivers of group formation",
    "section": "Abstract",
    "text": "Abstract\nThe social system of animals involves a complex interplay between physiology, natural history, and the environment. Long relied upon discrete categorizations of “social” and “solitary” inhibit our capacity to understand species and their interactions with the world around them. Here, we use a globally distributed camera trapping dataset to test the drivers of aggregating into groups in a species complex (martens and relatives, family Mustelidae, Order Carnivora) assumed to be obligately solitary. We use a simple quantification, the probability of being detected in a group, that was applied across our globally derived camera trap dataset. Using a series of binomial generalized mixed-effects models applied to a dataset of 16,483 independent detections across 17 countries on four continents we test explicit hypotheses about potential drivers of group formation. We observe a wide range of probabilities of being detected in groups within the solitary model system, with the probability of aggregating in groups varying by more than an order of magnitude. We demonstrate that a species’ context-dependent proclivity toward aggregating in groups is underpinned by a range of resource-related factors, primarily the distribution of resources, with increasing patchiness of resources facilitating group formation, as well as interactions between environmental conditions (resource constancy/winter severity) and physiology (energy storage capabilities). The wide variation in propensities to aggregate with conspecifics observed here highlights how continued failure to recognize complexities in the social behaviors of apparently solitary species limits our understanding not only of the individual species but also the causes and consequences of group formation."
  },
  {
    "objectID": "R1day/index.html#why-learn-to-code",
    "href": "R1day/index.html#why-learn-to-code",
    "title": "Introduction to R",
    "section": "Why learn to code?",
    "text": "Why learn to code?\n\n\nefficiency\ntransparency\nflexibility in application\nshareable\nautomated processes/report writing\nmarketable skill\nneeded for publications"
  },
  {
    "objectID": "R1day/index.html#why-learn-r",
    "href": "R1day/index.html#why-learn-r",
    "title": "Introduction to R",
    "section": "Why learn R?",
    "text": "Why learn R?\n\n\nopen-source and free\nsmall total user base / large in ecology and statistics\nfind help online, e.g., stackoverflow and unmarked group\ndata management\nstatistics\nplotting / graphics"
  },
  {
    "objectID": "R1day/index.html#why-use-rstudio",
    "href": "R1day/index.html#why-use-rstudio",
    "title": "Introduction to R",
    "section": "Why use RStudio?",
    "text": "Why use RStudio?\n\nMakes using R easier\nProjects (file mgmt)\nR Shiny: Interactive online apps\nR Markdown: Interactive documents\nQuarto: interactive articles, websites, blog, …\nPosit - Certified B corp"
  },
  {
    "objectID": "R1day/index.html#how-to-learn-r",
    "href": "R1day/index.html#how-to-learn-r",
    "title": "Introduction to R ",
    "section": "How to learn R?",
    "text": "How to learn R?\n\nIntro to R for Biologists\nIntroduction to R - tidyverse\nR for Data Science (2e)\nAdvanced R\nIntroduction to the R Language\nIntroduction to R\nAn Introduction to R for Research\nIntroduction to Data Exploration ana Analysis with R\nWorking with Data in R"
  },
  {
    "objectID": "R1day/index.html#objectives",
    "href": "R1day/index.html#objectives",
    "title": "Introduction to R ",
    "section": "Objectives",
    "text": "Objectives\n\nR basics\nRStudio basics\nitem 1\nitem 2\nitem 3\nitem 4"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r",
    "href": "R1day/index.html#the-language-of-r",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\n\nObjects\nA storage place for information; stored in the “Environment”\n\n\n‘Attributes’ describes the structure or information of the object"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-1",
    "href": "R1day/index.html#the-language-of-r-1",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nObjects"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-2",
    "href": "R1day/index.html#the-language-of-r-2",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nObjects\n\n# y is an 'object' that is assigned the value 3\ny = 3\ny\n\n[1] 3\n\n\n\n\n\n# Same operation '=' '&lt;-'\ny &lt;- 3"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-3",
    "href": "R1day/index.html#the-language-of-r-3",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nObjects\n\n# We can create new objects from objects\ny2 = y-2\ny2\n\n[1] 1\n\n\n\n\n\n# We can do math with our objects\n# Mind your parentheses (order of operation)\ny*2 / y*4\n\n[1] 8\n\ny*2 / (y*4)\n\n[1] 0.5"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-4",
    "href": "R1day/index.html#the-language-of-r-4",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nFunctions\n‘does stuff’; creates or manipulates objects\n\n‘Arguments’ are the types of things a function is asking for; the inputs"
  },
  {
    "objectID": "R1day/index.html#wrapping-functions",
    "href": "R1day/index.html#wrapping-functions",
    "title": "Introduction to R",
    "section": "Wrapping functions",
    "text": "Wrapping functions\n\n# Functions can be wrapped around each other\n# Functions commonly have multiple arguments\n\nx &lt;- matrix( \n            data = c(1,2,3,4,5,6),\n            nrow = 2,\n            ncol = 3\n            )\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6"
  },
  {
    "objectID": "R1day/index.html#types-of-objects",
    "href": "R1day/index.html#types-of-objects",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nVector\n\n# An ordered collection indexed 1,2,...n\n# Using the function 'c' to concetanate\nz1 = c(4,5,6)\nz1\n\n[1] 4 5 6\n\n\nThe value 4 is in element/index/position 1 of the vector\nThe value 6 is in element/index/position 3 of the vector\n\n\n\n# the dimension of a vector\nlength(z1)\n\n[1] 3\n\n\n\n\n\n\n# A vector of characters\nz2 = c(\"dog\",\"cat\",\"horse\")\nz2\n\n[1] \"dog\"   \"cat\"   \"horse\"\n\n\n\n\n\n\nz3 = c(\"dog\",\"1\",\"horse\")\nz3\n\n[1] \"dog\"   \"1\"     \"horse\"\n\n\n\n\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-1",
    "href": "R1day/index.html#types-of-objects-1",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nSubsetting a vector\n\n\nz3 = c(\"dog\",\n       \"1\",\n       \"horse\",\n       \"chicken\"\n       )\nz3[2]\n\n[1] \"1\"\n\n\n\n\n\n\n2:4\n\n[1] 2 3 4\n\n\n\n\n\n\nz3[2:4]\n\n[1] \"1\"       \"horse\"   \"chicken\"\n\n\n\n\n\n\nz3[c(2,4)]\n\n[1] \"1\"       \"chicken\"\n\n\n\n\n\n\nz3[-1]\n\n[1] \"1\"       \"horse\"   \"chicken\""
  },
  {
    "objectID": "R1day/index.html#types-of-objects-2",
    "href": "R1day/index.html#types-of-objects-2",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nVector of factors\n\n\nz4 = factor(\n            c(\"dog\", \n              \"dog\", \n              \"cat\",\n              \"horse\"\n              )\n           )\n\n\n\n\n\nz4\n\n[1] dog   dog   cat   horse\nLevels: cat dog horse\n\n\n\n\n\n\nlevels(z4)\n\n[1] \"cat\"   \"dog\"   \"horse\"\n\n\n\n\n\n\nsummary(z4)\n\n  cat   dog horse \n    1     2     1"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-3",
    "href": "R1day/index.html#types-of-objects-3",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nMatrix\n\n\nx = matrix(\n            c(1,2,3,4,5,6),\n            nrow = 2, \n            ncol = 3\n           )\n\n\n\n\n\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6\n\n\n\n\n\n\n#rows and columns\ndim(x)\n\n[1] 2 3"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-4",
    "href": "R1day/index.html#types-of-objects-4",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nSubsetting a matrix\n\n# get element of row 1 and column 2\nx[1,2]\n\n[1] 3\n\n\n\n\n\n# get all elements of row 2\nx[2,]\n\n[1] 2 4 6\n\n\n\n\n\n\n# same as\nx[2,1:3]\n\n[1] 2 4 6"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-5",
    "href": "R1day/index.html#types-of-objects-5",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nArray\n\n# ARRAY - more than two dimensions\nz5 = array(\n            c(\"a\",\"b\",\"c\",\"d\",\"1\",\"2\",\"3\",\"4\"), \n            dim = c(2,2,2)\n           )\n\n\n\n\n\n\n\n\n\n\n\n\nz5\n\n, , 1\n\n     [,1] [,2]\n[1,] \"a\"  \"c\" \n[2,] \"b\"  \"d\" \n\n, , 2\n\n     [,1] [,2]\n[1,] \"1\"  \"3\" \n[2,] \"2\"  \"4\""
  },
  {
    "objectID": "R1day/index.html#types-of-objects-6",
    "href": "R1day/index.html#types-of-objects-6",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nList\n\n\n# LIST - a bucket - will take anything\nmy.list = list(z1, z2, z3, z4, z5)\n\n\n\n\n\n#Subset a list\nmy.list[[1]]\n\n[1] 4 5 6\n\n\n\n\n\n\nmy.list[[4]]\n\n[1] dog   dog   cat   horse\nLevels: cat dog horse"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-7",
    "href": "R1day/index.html#types-of-objects-7",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nData frame\nE.g., a row for each observation and a column for each variable (can be different types).\n\n\nx = data.frame(outcome = c(1,0,1,1),\n               exposure = c(\"yes\", \"yes\", \"no\", \"no\"),\n               age = c(24, 55, 39, 18)\n               )\nx\n\n  outcome exposure age\n1       1      yes  24\n2       0      yes  55\n3       1       no  39\n4       1       no  18"
  },
  {
    "objectID": "R1day/index.html#challenge",
    "href": "R1day/index.html#challenge",
    "title": "Introduction to R",
    "section": "Challenge",
    "text": "Challenge\n\n\nexpand for full code\nc.km = 24901.55/0.621\n\nd = c.km/(pi)\n\nd\n\n\n[1] 12763.94"
  },
  {
    "objectID": "R1day/index.html#challenge-1",
    "href": "R1day/index.html#challenge-1",
    "title": "Introduction to R",
    "section": "Challenge 1",
    "text": "Challenge 1\nCompute the diameter (d) of the Earth (in km) at the equator using this formula for the circumfrance (c)…\n\\[d = \\frac{c}{\\pi}\\]\n\n\nc = 24,901.55 miles\n1 km = 0.621 miles\nHint type in ‘pi’ to see what you get\n\n\n\n\nConvert the circumference from miles to km.\nWrite the formula in R by defining objects and the values given to computer d in km.\n\n\n\n\nClick for Answer\nc.km = 24901.55/0.621\n\nd = c.km/pi"
  },
  {
    "objectID": "R1day/index.html#introductions",
    "href": "R1day/index.html#introductions",
    "title": "Introduction to R",
    "section": "Introductions",
    "text": "Introductions\n\n\n\n\n\nInstructors:\n\nKyle Horton\nGeorgia Titcomb\nBrian Gerber"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-5",
    "href": "R1day/index.html#the-language-of-r-5",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nobject = function(argument = input1, argument = input2)\n\n\nobject = function(input1, input2)\n\n\n\nthis = sign(x = -5)\n\n\n\nsign(-5)\n\n[1] -1\n\nsign(5)\n\n[1] 1"
  },
  {
    "objectID": "publications/articles/Shamon2024.html",
    "href": "publications/articles/Shamon2024.html",
    "title": "SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States",
    "section": "",
    "text": "Shamon et al. (2024). SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States. Ecology, e4318, https://doi.org/10.1002/ecy.4318. ."
  },
  {
    "objectID": "publications/articles/Shamon2024.html#citation",
    "href": "publications/articles/Shamon2024.html#citation",
    "title": "SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States",
    "section": "",
    "text": "Shamon et al. (2024). SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States. Ecology, e4318, https://doi.org/10.1002/ecy.4318. ."
  },
  {
    "objectID": "publications/articles/Shamon2024.html#abstract",
    "href": "publications/articles/Shamon2024.html#abstract",
    "title": "SNAPSHOT USA 2021: A third coordinated national cameratrap survey of the United States",
    "section": "Abstract",
    "text": "Abstract\nSNAPSHOT USA is a multicontributor, long-term camera trap survey designed tosurvey mammals across the United States. Participants are recruited through com-munity networks and directly through a website application (https://www.snapshot-usa.org/). The growing Snapshot dataset is useful, for example, for track-ing wildlife population responses to land use, land cover, and climate changesacross spatial and temporal scales. Here we present the SNAPSHOT USA 2021dataset, the third national camera trap survey across the US. Data were collectedacross 109 camera trap arrays and included 1711 camera sites. The total effortequaled 71,519 camera trap nights and resulted in 172,507 sequences of animalobservations. Sampling effort varied among camera trap arrays, with a minimumof 126 camera trap nights, a maximum of 3355 nights, a median 546 nights, and amean 656 ± 431 nights. This third dataset comprises 51 camera trap arrays thatwere surveyed during 2019, 2020, and 2021, along with 71 camera trap arrays thatwere surveyed in 2020 and 2021. All raw data and accompanying metadata arestored on Wildlife Insights (https://www.wildlifeinsights.org/), and are publicly avail-able upon acceptance of the data papers. SNAPSHOT USA aims to sample multipleecoregions in the United States with adequate representation of each ecoregionaccording to its relative size. Currently, the relative density of camera trap arraysvaries by an order of magnitude for the various ecoregions (0.22–5.9 arrays per100,000 km2), emphasizing the need to increase sampling effort by further recruitingand retaining contributors. There are no copyright restrictions on these data. We2 of 6 SHAMON ET AL .request that authors cite this paper when using these data, or a subset of these data,for publication. Any use of trade, firm, or product names is for descriptive purposesonly and does not imply endorsement by the US Government."
  },
  {
    "objectID": "publications/articles/Burton2024.html",
    "href": "publications/articles/Burton2024.html",
    "title": "Mammal responses to global changes in human activity vary by trophic group and landscape",
    "section": "",
    "text": "Burton et al. (2024). SNAPSHOT USA 2021: Mammal responses to global changes in human activity vary by trophic group and landscape. Nature Ecology and Evolution, 8, 924–935, https://doi.org/10.1038/s41559-024-02363-2. ."
  },
  {
    "objectID": "publications/articles/Burton2024.html#citation",
    "href": "publications/articles/Burton2024.html#citation",
    "title": "Mammal responses to global changes in human activity vary by trophic group and landscape",
    "section": "",
    "text": "Burton et al. (2024). SNAPSHOT USA 2021: Mammal responses to global changes in human activity vary by trophic group and landscape. Nature Ecology and Evolution, 8, 924–935, https://doi.org/10.1038/s41559-024-02363-2. ."
  },
  {
    "objectID": "publications/articles/Burton2024.html#abstract",
    "href": "publications/articles/Burton2024.html#abstract",
    "title": "Mammal responses to global changes in human activity vary by trophic group and landscape",
    "section": "Abstract",
    "text": "Abstract\nWildlife must adapt to human presence to survive in the Anthropocene, so it is critical to understand species responses to humans in different contexts. We used camera trapping as a lens to view mammal responses to changes in human activity during the COVID-19 pandemic. Across 163 species sampled in 102 projects around the world, changes in the amount and timing of animal activity varied widely. Under higher human activity, mammals were less active in undeveloped areas but unexpectedly more active in developed areas while exhibiting greater nocturnality. Carnivores were most sensitive, showing the strongest decreases in activity and greatest increases in nocturnality. Wildlife managers must consider how habituation and uneven sensitivity across species may cause fundamental differences in human–wildlife interactions along gradients of human influence."
  },
  {
    "objectID": "publications/articles/Bellier2024.html",
    "href": "publications/articles/Bellier2024.html",
    "title": "A statistical population reconstruction model for wildlife populations: A case study with white-tailed deer and fisher",
    "section": "",
    "text": "Bellier, Edwige, Dylan C. Ferreira, David M. Kalb, Laken S. Ganoe, Amy E. Mayer, and Brian D. Gerber. 2024. “ A Statistical Population Reconstruction Model for Wildlife Populations: A Case Study with White-Tailed Deer and Fisher.” Ecosphere 15(6): e4878. https://doi.org/10.1002/ecs2.4878"
  },
  {
    "objectID": "publications/articles/Bellier2024.html#citation",
    "href": "publications/articles/Bellier2024.html#citation",
    "title": "A statistical population reconstruction model for wildlife populations: A case study with white-tailed deer and fisher",
    "section": "",
    "text": "Bellier, Edwige, Dylan C. Ferreira, David M. Kalb, Laken S. Ganoe, Amy E. Mayer, and Brian D. Gerber. 2024. “ A Statistical Population Reconstruction Model for Wildlife Populations: A Case Study with White-Tailed Deer and Fisher.” Ecosphere 15(6): e4878. https://doi.org/10.1002/ecs2.4878"
  },
  {
    "objectID": "publications/articles/Bellier2024.html#abstract",
    "href": "publications/articles/Bellier2024.html#abstract",
    "title": "A statistical population reconstruction model for wildlife populations: A case study with white-tailed deer and fisher",
    "section": "Abstract",
    "text": "Abstract\nHarvested wildlife populations should ideally be monitored to inform harvest policies and decision-making to help achieve management objectives. When the age of harvested individuals can be obtained, these data (i.e., age-at-harvest data) can be used to estimate trends of abundances, demographic rates, and harvest probabilities by the statistical reconstruction of the living population. This approach was developed primarily within the frequentist framework and requires the inclusion of auxiliary data (e.g., radiotelemetry data). We developed a novel Bayesian hierarchical approach allowing the population reconstruction from the definition of the species’ life cycle without auxiliary data. The hierarchical model assumes that individuals are harvested from an open population whose fluctuations result from demographic processes, and the definition of a superpopulation composed of pseudo-individuals from which the harvested population is drawn. We evaluated the ability of our model to estimate abundances, survival, recruitment, and harvest probabilities based on simulations guided by the demographic processes of a long-lived mammal population. We considered model performance across scenarios, including varying age and temporal structures, superpopulation size, and prior information. We showed how prior information selected based on life history characteristics affects the accuracy of estimated parameters. We found that the model estimates accurate demographic parameters and abundances when the age-at-harvest matrix comprises more than two age classes. Furthermore, an increase in demographic information (number of age groups and years) increased the precision of the estimated parameters. We apply our model to a population of harvested (2012–2021) white-tailed deer (Odocoileus virginianus) and a mammalian carnivore, the fisher (Pekania pennanti), from Rhode Island, USA. Our model estimated biologically realistic population size and demographic rates for both species. Our approach provides robustness to track the population abundance of harvested species through time and estimate fundamental demographic parameters. Such results can be used to monitor whether population objectives are being met and whether harvest policy changes are required. Furthermore, this information can be critical for evaluating the effect of harvest on population growth and projecting trajectories of age-structured populations under different harvest scenarios. Therefore, our framework can help to guide management decisions and species conservation."
  },
  {
    "objectID": "publications/articles/Kays2024.html",
    "href": "publications/articles/Kays2024.html",
    "title": "Climate, food and humans predict communities of mammals inthe United States",
    "section": "",
    "text": "Kays, R., Snider, M. H., Hess, G., Cove, M. V., Jensen, A., Shamon, H., McShea, W. J., Rooney, B., Allen, M. L., Pekins, C. E., Wilmers, C. C., Pendergast, M. E., Green, A. M., Suraci, J., Leslie, M. S., Nasrallah, S., Farkas, D., Jordan, M., Grigione, M., … Parsons, A. (2024). Climate, food and humans predict communities of mammals in the United States. Diversity and Distributions, 00, e13900. https://doi.org/10.1111/ddi.13900"
  },
  {
    "objectID": "publications/articles/Kays2024.html#citation",
    "href": "publications/articles/Kays2024.html#citation",
    "title": "Climate, food and humans predict communities of mammals inthe United States",
    "section": "",
    "text": "Kays, R., Snider, M. H., Hess, G., Cove, M. V., Jensen, A., Shamon, H., McShea, W. J., Rooney, B., Allen, M. L., Pekins, C. E., Wilmers, C. C., Pendergast, M. E., Green, A. M., Suraci, J., Leslie, M. S., Nasrallah, S., Farkas, D., Jordan, M., Grigione, M., … Parsons, A. (2024). Climate, food and humans predict communities of mammals in the United States. Diversity and Distributions, 00, e13900. https://doi.org/10.1111/ddi.13900"
  },
  {
    "objectID": "publications/articles/Kays2024.html#abstract",
    "href": "publications/articles/Kays2024.html#abstract",
    "title": "Climate, food and humans predict communities of mammals inthe United States",
    "section": "Abstract",
    "text": "Abstract\nAim The assembly of species into communities and ecoregions is the result of interacting factors that affect plant and animal distribution and abundance at biogeographic scales. Here, we empirically derive ecoregions for mammals to test whether human disturbance has become more important than climate and habitat resources in structuring communities.\nLocation Conterminous United States.\nTime Period 2010–2021.\nMajor Taxa Studied Twenty-five species of mammals.\nMethods We analysed data from 25 mammal species recorded by camera traps at 6645 locations across the conterminous United States in a joint modelling framework to estimate relative abundance of each species. We then used a clustering analysis to describe 8 broad and 16 narrow mammal communities.\nResults Climate was the most important predictor of mammal abundance overall, while human population density and agriculture were less important, with mixed effects across species. Seed production by forests also predicted mammal abundance, especially hard-mast tree species. The mammal community maps are similar to those of plants, with an east–west split driven by different dominant species of deer and squirrels. Communities vary along gradients of temperature in the east and precipitation in the west. Most fine-scale mammal community boundaries aligned with established plant ecoregions and were distinguished by the presence of regional specialists or shifts in relative abundance of widespread species. Maps of potential ecosystem services provided by these communities suggest high herbivory in the Rocky Mountains and eastern forests, high invertebrate predation in the subtropical south and greater predation pressure on large vertebrates in the west.\nMain Conclusions Our results highlight the importance of climate to modern mammals and suggest that climate change will have strong impacts on these communities. Our new empirical approach to recognizing ecoregions has potential to be applied to expanded communities of mammals or other taxa."
  },
  {
    "objectID": "R1day/index.html#online-resources-to-learn-r",
    "href": "R1day/index.html#online-resources-to-learn-r",
    "title": "Introduction to R",
    "section": "Online resources to learn R",
    "text": "Online resources to learn R\n\nIntro to R for Biologists\nIntroduction to R - tidyverse\nR for Data Science (2e)\nAdvanced R\nIntroduction to the R Language\nIntroduction to R\nAn Introduction to R for Research\nIntroduction to Data Exploration ana Analysis with R\nWorking with Data in R"
  },
  {
    "objectID": "R1day/index.html#learning-objectives",
    "href": "R1day/index.html#learning-objectives",
    "title": "Introduction to R ",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nGOALS\n‘Become familiar with the language and fundamental operations of R’\n‘To help start you off on learning to use R’\n\n\n900 - 930: Intro to RStudio and R (objects and functions)\n1000 - 1130: Data input and output\n1130- 1200: Finding help\n1200 - 1300: Lunch\n1300 - 1400: Data mgmt\n1400 - 1500: Plotting\n1500 - 1600: Challenge"
  },
  {
    "objectID": "R1day/index.html#instructor-showcases",
    "href": "R1day/index.html#instructor-showcases",
    "title": "Introduction to R",
    "section": "Instructor Showcases",
    "text": "Instructor Showcases\nBrian - R Shiny application that allows users to subset data and visualize 14,586 results\n\nKyle - example here\n\nGeorgia - example here"
  },
  {
    "objectID": "R1day/index.html#goal",
    "href": "R1day/index.html#goal",
    "title": "Introduction to R ",
    "section": "Goal",
    "text": "Goal\n‘To get over the initial hump or shock or fear to start using R for data management, graphics, statistics, etc.’\n\n\n900 - 930: Introductions and setup\n930 - 1000:Intro to RStudio and R (objects and functions)\n1000 - 1130: Data input and output\n1130- 1200: Finding help\n1200 - 1300: Lunch\n1300 - 1400: Data mgmt\n1400 - 1500: Plotting\n1500 - 1600: Challenge"
  },
  {
    "objectID": "R1day/index.html#accomplishments",
    "href": "R1day/index.html#accomplishments",
    "title": "Introduction to R ",
    "section": "Accomplishments",
    "text": "Accomplishments\nGoal\n‘To get over the initial hump or shock or fear to start using R’\nLearning Objectives\n\nWrite and execute code in R via RStudio\nR language vocabulary\nFind help\nRead/write data\nManipulate data efficiently\nPlot data or results\n\nExecution\n\nPresentation or code walk through\nChallenge (independent or in teams of 2-3)"
  },
  {
    "objectID": "R1day/index.html#schedule",
    "href": "R1day/index.html#schedule",
    "title": "Introduction to R",
    "section": "Schedule",
    "text": "Schedule\n\n900 - 930: Introductions and setup\n930 - 1000: RStudio and R (objects and functions)\n1000 - 1130: Data input and output\n1130- 1200: Finding help\n1200 - 1300: Lunch\n1300 - 1400: Data mgmt\n1400 - 1500: Plotting\n1500 - 1600: Final Challenge"
  },
  {
    "objectID": "R1day/index.html#today",
    "href": "R1day/index.html#today",
    "title": "Introduction to R",
    "section": "Today",
    "text": "Today\nGoal\n‘Get familiar with fundamentals of R useful for data’\n\n‘To get beyond the initial shock or fear of programming and start using R’"
  },
  {
    "objectID": "R1day/index.html#today-1",
    "href": "R1day/index.html#today-1",
    "title": "Introduction to R",
    "section": "Today",
    "text": "Today\nLearning Objectives\n\nWrite and execute code in R via RStudio\nR language vocabulary\nRead/write data\nFind help\nManipulate data efficiently\nPlot data/results"
  },
  {
    "objectID": "R1day/index.html#what-is-r",
    "href": "R1day/index.html#what-is-r",
    "title": "Introduction to R",
    "section": "What is R?",
    "text": "What is R?\nR is a “suite of software facilities for data manipulation, calculation and graphical display.”\n\n\nR uses packages that are collections of functions, data, and compiled code in a “well-defined format”.\n\n\n\nPackages are downloaded from The Comprehensive R Archive Network (CRAN), R’s central software repository. Also, on GitHub, GitLab, BitBucket or other code sharing platforms."
  },
  {
    "objectID": "R1day/index.html#software",
    "href": "R1day/index.html#software",
    "title": "Introduction to R",
    "section": "Software",
    "text": "Software"
  },
  {
    "objectID": "R1day/index.html#what-is-rstudio",
    "href": "R1day/index.html#what-is-rstudio",
    "title": "Introduction to R",
    "section": "What is RStudio?",
    "text": "What is RStudio?\nRStudio is an “Integrated Development Environment (IDE)”.\n\nRStudio brings tools/languages together.\n\nWe use R within RStudio."
  },
  {
    "objectID": "R1day/index.html#why-use-r",
    "href": "R1day/index.html#why-use-r",
    "title": "Introduction to R",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nopen-source and free\nsmall total user base / large in ecology and statistics\nfind help online, e.g., stackoverflow\nstatistics\nplotting / graphics\ndata management"
  },
  {
    "objectID": "R1day/index.html#rstudio",
    "href": "R1day/index.html#rstudio",
    "title": "Introduction to R",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "R1day/index.html#rstudio-1",
    "href": "R1day/index.html#rstudio-1",
    "title": "Introduction to R",
    "section": "RStudio",
    "text": "RStudio"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-6",
    "href": "R1day/index.html#the-language-of-r-6",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nFunctions\n\n# function - 'c' - concatenate\ny = c(1,2,3,4,5,6)\n\n\n\n\nis.numeric(y)\n\n[1] TRUE\n\n\n\n\n\n\n# The function 'class' has the argument 'x'\nis.numeric(x = y)\n\n[1] TRUE"
  },
  {
    "objectID": "R1day/index.html#objects-1",
    "href": "R1day/index.html#objects-1",
    "title": "Introduction to R",
    "section": "Objects",
    "text": "Objects"
  },
  {
    "objectID": "R1day/index.html#types",
    "href": "R1day/index.html#types",
    "title": "Introduction to R",
    "section": "Types",
    "text": "Types\n\n\nValues\n\nnumeric\ncharacter\nfactor\n\n\nObjects\n\nvector\nmatrix\narray\nlist\ndataframe"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-7",
    "href": "R1day/index.html#the-language-of-r-7",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nFunctions\n\n# How to find out the arguments of a function?\n?is.numeric"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-8",
    "href": "R1day/index.html#the-language-of-r-8",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\nWrapping functions\n\n# Functions are commonly 1) wrapped, 2) have multiple arguments\nx = matrix( \n            data = c(1,2,3,4,5,6),\n            nrow = 2,\n            ncol = 3\n            )\n\n\n\nx\n\n     [,1] [,2] [,3]\n[1,]    1    3    5\n[2,]    2    4    6"
  },
  {
    "objectID": "R1day/index.html#types-of-values",
    "href": "R1day/index.html#types-of-values",
    "title": "Introduction to R",
    "section": "Types of Values",
    "text": "Types of Values\nNumeric\n\n\ny = 3\nclass(y)\n\n[1] \"numeric\"\n\n\n\n\n\n\nInteger\n\ny = integer(3)\nclass(y)\n\n[1] \"integer\"\n\n\n\n\n\n\nCharacter\n\ny = \"habitat\"\nclass(y)\n\n[1] \"character\"\n\n\n\n\n\n\nFactor\n\ny = factor(\"habitat\")\nclass(y)\n\n[1] \"factor\""
  },
  {
    "objectID": "R1day/index.html#challenge-1-1",
    "href": "R1day/index.html#challenge-1-1",
    "title": "Introduction to R",
    "section": "Challenge 1",
    "text": "Challenge 1\n\n\nExpand for code\nc.km = 24901.55/0.621\n\nd = c.km/(pi)"
  },
  {
    "objectID": "R1day/index.html#software-1",
    "href": "R1day/index.html#software-1",
    "title": "Introduction to R",
    "section": "Software",
    "text": "Software\nWhat is R?\nR is a “suite of software facilities for data manipulation, calculation and graphical display.”\n\n\nR uses packages that are collections of functions, data, and compiled code in a “well-defined format”.\n\n\n\nPackages are downloaded from The Comprehensive R Archive Network (CRAN), R’s central software repository. Also, on GitHub, GitLab, BitBucket or other code sharing platforms."
  },
  {
    "objectID": "R1day/index.html#installing-packages",
    "href": "R1day/index.html#installing-packages",
    "title": "Introduction to R",
    "section": "Installing Packages",
    "text": "Installing Packages"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-9",
    "href": "R1day/index.html#the-language-of-r-9",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\n\n\nValues\n\nnumeric\ninteger\ncharacter\nfactor\n\n\nObjects\n\nvector\nmatrix\narray\nlist\ndataframe\nS3, S4, S5, and beyond"
  },
  {
    "objectID": "R1day/index.html#the-language-of-r-10",
    "href": "R1day/index.html#the-language-of-r-10",
    "title": "Introduction to R",
    "section": "The language of R",
    "text": "The language of R\n\n\nValues\n\nnumeric\ninteger\ncharacter\nfactor\n\n\nObjects\n\nvector\nmatrix\narray\nlist\ndataframe"
  },
  {
    "objectID": "R1day/index.html#challenge-2",
    "href": "R1day/index.html#challenge-2",
    "title": "Introduction to R",
    "section": "Challenge 2",
    "text": "Challenge 2\n\nCreate a vector of numbers that has length 6; call this object ‘vec1’.\nUse the function ‘mean’ to find the mean of the values of vec1.\nSubset vec1 to only elements 4 through 6. Call this new object ‘vec1’, thereby overwriting the original vec1.\nCreate a new vector (length 3) of characters called “hab1”, “hab2”, and “hab3”. Call this object ‘vec2’.\nPut vec1 and vec2 together into a data frame and call this object ‘dat’\n\n\n\nClick for Answer\nvec1 = 1:6\nmean(vec1)\nvec1 = vec1[4:6]\nvec2 = c(\"hab1\",\"hab2\",\"hab3\")\ndat = data.frame(vec1,vec2)\ndat"
  },
  {
    "objectID": "R1day/index.html#software-2",
    "href": "R1day/index.html#software-2",
    "title": "Introduction to R",
    "section": "Software",
    "text": "Software\nWhat is RStudio?\nRStudio is an “Integrated Development Environment (IDE)”. It bring tools/languages together. We use R within RStudio."
  },
  {
    "objectID": "R1day/index.html#r-code-for-presentation",
    "href": "R1day/index.html#r-code-for-presentation",
    "title": "Introduction to R",
    "section": "R Code for Presentation",
    "text": "R Code for Presentation\nR Code Script for the remaining code is here\n\nLeft-Click ‘here’ –&gt; Ctrl A –&gt; Ctrl C. Go to RStudio, left-click on an empty script. Ctrl V\n\nOR\n\nRight-click ‘here’ –&gt; ‘Save link as…’. Save file to location. Go to RStudio. File –&gt; Open File… find your file."
  },
  {
    "objectID": "R1day/index.html#code-for-presentation",
    "href": "R1day/index.html#code-for-presentation",
    "title": "Introduction to R",
    "section": "Code for Presentation",
    "text": "Code for Presentation\n\nLeft-Click ‘HERE’ –&gt; Ctrl A –&gt; Ctrl C. Go to RStudio, left-click on an empty script. Ctrl V\n\nOR\n\nRight-click ‘HERE’ –&gt; ‘Save link as…’. Save file to location. Go to RStudio. File –&gt; Open File… find your file."
  },
  {
    "objectID": "R1day/index.html#subsetting-a-matrix",
    "href": "R1day/index.html#subsetting-a-matrix",
    "title": "Introduction to R",
    "section": "Subsetting a matrix",
    "text": "Subsetting a matrix\n\n# get element of row 1 and column 2\nx[1,2]\n\n[1] 3\n\n\n\n\n\n# get element of row 2 and column 6\nx[2,3]\n\n[1] 6\n\n\n\n\n\n\n# get element all elements of row 2\nx[2,]\n\n[1] 2 4 6\n\n\n\n\n::: fragment\n\n# same as\nx[2,1:3]\n\n[1] 2 4 6"
  },
  {
    "objectID": "R1day/index.html#types-of-objects-8",
    "href": "R1day/index.html#types-of-objects-8",
    "title": "Introduction to R",
    "section": "Types of Objects",
    "text": "Types of Objects\nSubset data.frame\n\n\nx$exposure\n\n[1] \"yes\" \"yes\" \"no\"  \"no\" \n\n\n\n\n\n\nx['exposure']\n\n  exposure\n1      yes\n2      yes\n3       no\n4       no\n\n\n\n\n\n\nx[,2]\n\n[1] \"yes\" \"yes\" \"no\"  \"no\""
  },
  {
    "objectID": "R1day/index.html#today-2",
    "href": "R1day/index.html#today-2",
    "title": "Introduction to R",
    "section": "Today",
    "text": "Today\nExecution\n\nPresentation / code walk through\nChallenges (independent or in teams of 2-3)"
  },
  {
    "objectID": "R1day/index.html#today-3",
    "href": "R1day/index.html#today-3",
    "title": "Introduction to R",
    "section": "Today",
    "text": "Today\nSchedule\n\n900 - 930: Introductions and Setup\n930 - 1015: RStudio and R (objects and functions)\n1015 - 1130: Data Input and Output\n1130- 1200: Finding Help\n1200 - 1300: Lunch\n1300 - 1400: Data Mgmt\n1400 - 1500: Plotting\n1500 - 1600: Final Challenge"
  },
  {
    "objectID": "R1day/index.html#showcases",
    "href": "R1day/index.html#showcases",
    "title": "Introduction to R",
    "section": "Showcases",
    "text": "Showcases\n\nBrian - R Shiny application\n\nKyle - Lights out alerts\n\nGeorgia - The Orion Nebula?"
  },
  {
    "objectID": "R1day/index.html#files",
    "href": "R1day/index.html#files",
    "title": "Introduction to R",
    "section": "Files",
    "text": "Files\nDownload this presentation as pdf\nDownload code displayed in presentation\n\nTo save either file…. Right-click –&gt; ‘Save link as…’. Save file to location. Go to RStudio or Acrobat. File –&gt; Open File… find your file.\n\nTo copy/paste code directly:\nLeft-Click –&gt; Ctrl A –&gt; Ctrl C. Go to RStudio, left-click on an empty script. Ctrl V."
  },
  {
    "objectID": "R1day/index.html#download-files",
    "href": "R1day/index.html#download-files",
    "title": "Introduction to R",
    "section": "Download Files",
    "text": "Download Files\nDownload Files for today\n\nTo save either file…. Right-click –&gt; ‘Save link as…’. Save file to location."
  },
  {
    "objectID": "FW680A4/index.html#fw680a4",
    "href": "FW680A4/index.html#fw680a4",
    "title": "Brian D. Gerber",
    "section": "FW680A4",
    "text": "FW680A4\n\n NRS FW680A4 Course Page\n\n\n\n\nStartLearning RWeek 1Week 2Week 3Week 4Week 5Week 6Week 7Week 8Week 9Week 10Week 11Week 12Week 13Week 14\n\n\n\nSchedule/Syllabus\n\nInstall the most versions of R and RStudio.\nGithub\n\nNotes\n\nTo download lectures. Go to lecture html. Click ‘e’. This should connect all slides into one page. Right Click Mouse on page. Click ’Print”. Choose printer “Adobe PDF”; might need Adobe Acrobat installed.\n\n\n\nPrelude In R\nData Carpentry\nIntro to R\nMany Resources\nOur Coding Club\nSW Carpentry\nJeff Doser Book\n\n\n\nLecture: 1) Introduction,  2) Information\nLecture Code: Information.R\nMarkdown Example: 1) Markdown Example File, 2) Compiled HTML\nAssignment: 1) Markdown File 2) Compiled HTML\nAssigned Reading\n\n\n\nWe will be working in R and Markdown. For class, we will be going through (at least) modules 1 and 2. We will also do a bit on Markdown.\n\nR Lecture Modules: R Class.zip\nR project organization example: Project Structure.zip\nAssigned Reading\n\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"pwr\",\"ggplot2\", \"spsurvey\", \"foreach\",\n                   \"sf\", \"doParallel\", \"grDevices\",\"tictoc\",\"plotly\"))\n\n\nLecture: Study Design\nLecture Code: StudyDesign.R\nDownload: Zip\nAssignment (option 1): 1) Markdown File 1) Compiled HTML\nAssignment (option 2): 1) Markdown File 1) Compiled HTML\nAssignment (option 3): 1) Markdown File 1) Compiled HTML\nAssigned Readings 1) Probability Distributions,  2) Probability First Principles\nSuggested Readings\n\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"visualize\",\"plotly\"))\n\n\nLecture: Probabilty\nLecture Code: Probabilty.R\nDownload:\nAssignment: 1) Markdown File 1) Compiled HTML\nAssigned Reading Betts et al. 2021 and Linear Regression Book Chapter or Online Linear Regression\n\n\n\nNo Class / Holiday\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"sjPlot\",\"ggplot2\", \"ggResidpanel\"))\n\n\nLecture: Regression\nLecture Code: regression.R\nDownload: csv\nAssignment: 1) Markdown File 1) Compiled HTML\nAssigned Readings: Assigned Reading\n\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"equatiomatic\",\"faux\"))\n\n\nLecture: GLM\nLecture Code: linear.model.R\nAssignment: 1) Markdown File 1) Compiled HTML\nAssigned Readings: Assigned Reading\n\n\n\n\nDownload/Install JAGS software here. The version you pick will depend on your version of R.\nInstall R packages:\n\n\ninstall.packages(c(\"rjags\",\"bayesplot\",\"rstanarm\"))\n\n\nLecture: Bayesian\nLecture Code: Bayesian.R\nData Download: Data Set 1, and Data Set 2\nJags Code Example: Script, and Model\nStan Code Example: Script\nExtra Model Files: MCMC Algorithim Example: R Script, and MCMC Algorithim Function\nAssignment: 1) Markdown File 1) Compiled HTML\nRe-read the previously assigned Reading: Assigned Reading\nFind a scientific paper that uses Bayesian modeling/inference in your subject area of interest. Be prepared to talk about what the study was about, how the authors used priors, what they made inference on, and how clear were the elements of modeling inference/modeling/computation.\n\n\n\nNo Class or New Homework\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"rjags\",\"bayesplot\",\"runjags\",\"coda\"))\n\n\nLecture: Random Effect\nLecture Code: random.effect.R\n\n\n\n\nInstall R packages:\n\n\ninstall.packages(c(\"rjags\",\"bayesplot\",\"runjags\",\"coda\"))\n\n\nData Simulation Code (developed previous class): Inclass.data.simulation.r\nJAGS Models: model.JAGS.extra.noise.r and model.JAGS.random.slope.r\nModel Scripts: Model.Script.Extra.Noise.r and Model.Script.Random.Slope.r\nAssignment: 1) Markdown File 1) Compiled HTML\n\n\n\nLecture/Lab by Laken, Maegan, Owen, and John\n\nInstall R packages:\n\n\ninstall.packages(c(\"unmarked\",\"rgeos\", \"sf\", \"raster\"))\n\n\nLecture: Occupancy\nAssigned Readings: Assigned Reading and associated questions.\nCode : NRS520-Occupancy-ClassCode.R\nAssignment: NRS 520-Occupancy Assignment.docx\n\n\n\nLecture/Lab by Caroline, Corey, and Rea\n\ninstall.packages(c(\"Hmisc\",\"foreign\",\"reshape2\"))\n\n\nAssigned Reading: Assigned Reading and Discussion Questions.\nLecture: Ordinal Regression\nLecture Code: UCLA_Code.R\nData Download: Data Set\nAssignment: OLR HW Questions.docx\n\n\n\nLecture/Lab by Tori, Liam, and Rebeca\n\ninstall.packages(\"dplyr\", \"ggplot2\", \"lme4\")\n\n\nAssigned Reading: Assigned Reading and RSF Paper Discussion Questions.docx.\nLecture: Slides\nData Download: Data Download\nCode Download: Code Download\nAssignment:  Markdown and HTML\nAppendix A: AppendixA.html\n\n\n\n\nProject\n\nCreate a group of 3\nThe group should discuss ideas in quantitative ecology that you would all like to develop a class dedicated to. If you need help, schedule a time to talk with me.\nOutline a plan:\n\nIdentify a reading that will be assigned prior to class along with relevant topic questions\nIdentify the scope and depth of the lecture material (bullet points of what will be covered),\nIdentify what the goal is to be accomplished in terms of coding (bullet points)\nDecide on a general idea for a homework assignment.\n\nOnce outlined, email me the plan with all group members names. I will look over the general plan and provide comments.\nFrom here, I expect you to move forward with your plan and reach out when you have questions. Arrange at least one time to walk me through the lesson plan prior to the class, such that there is enough time to implement any feedback."
  },
  {
    "objectID": "FW680A4/index.html#wildlife-ecology-modeling-fw680a4",
    "href": "FW680A4/index.html#wildlife-ecology-modeling-fw680a4",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Course Overview\n\n\nSchedule (Subject to Change)\n\n\nWeeksSoftwareAdditionalCo-lead DiscussionProjectLearning\n\n\n\n\n\nWeek 1 (Aug 20, 23)\n\n\nWeek 2 (Aug 27, 30)\n\n\nWeek 3 (Sep 3, 6)\n\n\nWeek 4 (Sep 10, 12)\n\n\nWeek 5 (Sep 17, 20)\n\n\nWeek 6 (Sep 24, 27)\n\n\nWeek 7 (Oct 1, 4)\n\n\nWeek 8 (Oct 8, 11)\n\n\n\n\nWeek 9 (Oct 15, 18)\n\n\nWeek 10 (Oct 22, 25)\n\n\nWeek 11 (Oct 29, Nov 1)\n\n\nWeek 12 (Nov 5, 8)\n\n\nWeek 13 (Nov 12, 15)\n\n\nWeek 14 (Nov 19, 22)\n\n\nWeek 15 (Nov 26, 29): No Classes\n\n\nWeek 16 (Dec 3, 6)\n\n\n\n\n\nInstall the most recent versions of R and RStudio Desktop.\nInstall the software program JAGS.\n\n\n\n\n\n\n\nTo download lectures: Go to lecture html. Click ‘e’. This should connect all slides into one page. Right Click Mouse on page. Click ’Print”. Choose printer “Adobe PDF”; might need Adobe Acrobat installed.\n\n\n\n\n\nLikelihood and MLE.r\nMatrix Algebra.r\nOccupancy Maximum Likelihood.r\nVariable Combinations\nBayesian models specified in class and more\nBayesian Hierarchical Occupancy Models\nDistribution Cheat Sheet\nHabitat selection Model\n\n\n\n\n\nBrian’s Deer lab: html and Zip.\nBrian’s Prob lab: html and Zip.\nBrian’s Regression lab: html and Zip.\nBrian’s GLM lab: html and Zip.\nBrian’s GLMM lab: html and Zip.\nBrian’s Bayesian lab: html and Zip.\nBrian’s CJS lab: html and Zip.\nBrian’s Occupancy lab: html and Zip.\n\n\n\n\n\nStudents will be grouped and assigned a topic (e.g., mark-recapture).\nEach group should pick an application paper (ideally) or methods paper (if desired) that is published on the assigned topic for the class to read.\nPlease send the paper (pdf) to me via email 2 weeks before the topic is listed on the Schedule; I will then post the paper on the website under the class prior to the discussion date.\nThe group should come prepared to lead the discussion on the paper for (20-25 minutes). Assign questions for us to focus on or come prepared with questions to lead the discussion. Generally focus on things like…\n\nwhat is the statistical model\ndid the authors define it clearly or reference another paper\nthe type of data that is relevant\nhow the sampling was achieved\nthe inference/prediction that was sought\nhow the model was used to answer the fundamental research question\nnuisances of issues of concern in the modeling or sampling\ntry and connect principles/stastistics in the paper to what we have been doing in the class\n\n\n\n\nSpecies Distribution Model (10/8): Libby Mojica, Travis Rainey\nMark Recapture (10/11): Alex Badeaux, Noel Clark, Elke Tukker\nN mixture or Integrated Data Models (10/25): Sarah Gaulke, Sean Ingram\nAnimal Movement (10/29): Jeremy Alder, Becca Windell\nHabitat Selection (11/5): Waverly Davis, Lisa Roerk\nCommunity Modeling (11/12): Cat Adams, Bijoya Paul\n\n\n\n\n\nDecide on whether you will work on a 1) independent research project or 2) develop a short lecture or lab case study on a statistical methodology. Research projects are individual, while a lecture/lab case study can be a team of 2-3 people.\nOnce decided, individually (for a research project) or as a group (case study), email me a one paragraph synopsis of your plan and topic of choice. Please do this by October 25.  I will followup if I have any questions.\n\n\nConduct a quantitative-focused project, such as a statistical analysis of data, or simulation based investigation. If you are unsure of whether your idea fits, come talk with me. If you want to use data from your graduate research, that would be great, but no need to use all of it or for exactly the purpose of your project. Simplifying the data and analysis is good and appropriate.\nObjectives:\n\nWrite a report; this should be turned in December 6 (last day of classes).\nPresent findings in class as an ignite talk; i.e., a 5 minute long presentation with 20 slides and with the slides advancing automatically every 15 seconds. Presentations will be on December 3 and 6.\n\nPrepare a report via R Markdown that generally follows the sections of 1) idea/hypothesis/setup, 2) data explanation, sampling methodology, and modeling, 3) results, and 4) summary/conclusions.\nIn Canvas, please submit the compiled HTML, as well as all other files needed to knit this file.\nThis class is focused on statistical models and model fitting, so make sure to emphasize the specifics of the statistical model that is being used and how it is being fit.\nThis report does not have to be long, but it should be clear and well presented. Part of the grade will be your focus on communicating the data/model/results visually and via clear statistical language.\n\n\n\nObjective:\n\nCreate a lecture, R code lab, or hybrid centered around a quantitative approach relevant to wildlife ecology and conservation.\n\nFor example, 1) develop a lecture on a specific statistical model, 2) a lab walk through implementing the model and important nuances to consider, or 3) some mixture of these.\nAim for the lecture/lab to be around 25-30 minutes. Presentations will be on December 3 and 6. Please submit the final materials on Canvas by December 6 (last day of classes).\nEvaluation will be based on the clarity and organization of the materials presented and the preparedness of the instructors in engaging with the class.\n\n\n\n\n\n\n\n\n\nLanguage of R\nPrelude In R\nData Carpentry\nIntro to R\nMany Resources\nOur Coding Club\nSW Carpentry\nDoser et al. Book\nIntro to R for Biologists\nIntroduction to R - tidyverse\nR for Data Science (2e)\nAdvanced R\nIntroduction to the R Language\nIntroduction to R\nAn Introduction to R for Research\nIntroduction to Data Exploration ana Analysis with R\nWorking with Data in R\n\n\n\n\n\n\n\n\nAn Introduction to Statistical Learning\nThe Elements of Statistical Learning. Download.\nBayesian Data Analysis. Download.\nBayesian Models: A Statistical Primer for Ecologists.\nData Analysis Using Regression and Multilevel/Hierarchical\nStatistics for Spatio-Temporal Data. Download\nSpatio-Temporal Statistics with R. Download\nA First Course in Bayesian Statistical Methods\nBayesian Statistical Methods\n\n\n\n\n\nEcological Models and Data in R\nAnimal Movement: Statistical Models for Telemetry Data\nMixed Effects Models and Extensions in Ecology with R\nApplied hierarchical modeling in Ecology\nHierarchical Modeling in Ecology Books and Code\nPopulation Ecology in Practice. Download\n\n\n\n\n\nComputational Statistics\nParameter Redundancy and Identifiability\nBringing Bayesian Models to Life"
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html",
    "href": "FW680A4/overview/CourseOverview.html",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "",
    "text": "Schedule"
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#instructor",
    "href": "FW680A4/overview/CourseOverview.html#instructor",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Instructor",
    "text": "Instructor\nName: Brian D. Gerber\nPosition/Affiliation Research Scientist and Assistant Unit Leader at U.S. Geological Survey, Colorado Cooperative Research Unit and Associate Professor in the Department of Fish, Wildlife, and Conservation Biology at Colorado State University.\nOffice: 202A Wagar, Colorado Cooperative Research Unit\nEmail: brian.gerber@colostate.edu\nOffice Hours: TU X-X, and by appointment"
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#course-information",
    "href": "FW680A4/overview/CourseOverview.html#course-information",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Course Information",
    "text": "Course Information\nCourse Number: FW 680A4 (Experimental Course)\nCredits: 3\nWebsites: Canvas and XXXX.\nPrerequisites: A basic statistics course is required. Being comfortable coding in the R programming language.\nText and Readings: All lecture and course materials will be provided on Canvas.\nComputing: A laptop will be necessary to work on coding during class periods."
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#course-description",
    "href": "FW680A4/overview/CourseOverview.html#course-description",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Course Description",
    "text": "Course Description\nStudents will gain knowledge and skills focused on 1) modeling data to make inference/predictions on wildlife and their habitat, 2) understanding and communicating results, 3) evaluating modeling frameworks based on data and study goals, and 4) implementing models and report writing through the R programming language. The format will include lectures, discussions, in-class labs, out of class assigned labs, and readings. Students are strongly encouraged to have base-level knowledge of coding in R."
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#course-learning-objectives",
    "href": "FW680A4/overview/CourseOverview.html#course-learning-objectives",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nUpon successful completion of this course students will:\n\ndevelop a foundation of statistical thinking that includes principles of study design and modeling relevant to wildlife ecology and conservation\nbe able to communicate statistical approaches and results through transparent and reproducible reporting\nbe able to read and understand quantitative wildlife ecology literature\nbe able to write code to fit and interpret complex statistical models relevant to wildlife ecology and conservation."
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#assessment",
    "href": "FW680A4/overview/CourseOverview.html#assessment",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Assessment",
    "text": "Assessment\n\n\n\nAssessment Components\nPercentage of Grade\n\n\n\n\nCourse Engagement\n10%\n\n\nLab Assignments\n40%\n\n\nOnline Discussion\n10%\n\n\nQuizzes\n10%\n\n\nGroup Project\n30%\n\n\n\nTable 1: Grade breakdown by graded components\n\n\n\n\n\nLetter Grade\nPercentage Range\n\n\n\n\nA+\n100.00 to 96.67\n\n\nA\n96.67 to 93.33\n\n\nA-\n93.33 to 90.00\n\n\nB+\n90.00 to 86.67\n\n\nB\n86.67 to 83.33\n\n\nB-\n83.33 to 80.00\n\n\nC+\n80.00 to 76.67\n\n\nC\n76.67 to 70.00\n\n\nD\n70.00 to 60.00\n\n\nF\n60.00 to 00.00\n\n\n\nTable 1: Grade scheme from CSU"
  },
  {
    "objectID": "FW680A4/overview/CourseOverview.html#student-experiences-and-pedagogical-techniques",
    "href": "FW680A4/overview/CourseOverview.html#student-experiences-and-pedagogical-techniques",
    "title": "\nCourse Overview  (Fall 2024)\n",
    "section": "Student Experiences and Pedagogical Techniques",
    "text": "Student Experiences and Pedagogical Techniques\nIn-class lectures: Most class periods will include a lecture that will take 1/4 to 1/2 of the course period. Lectures will often incorporate brief instructor-led questions and short discussions.\nIn-class student-led discussions: Small groups (~2 students) will be assigned to co-lead discussions on assigned readings. These discussions will occur prior to any lecture for that class. This will provide students with an opportunity to communicate about the assigned readings content, raise questions for themselves and learn to elicit thoughts and questions from others.\nIn-class labs: Every other class will include a lab. Students will be challenged in class to work individually or in groups to understand, develop and implement code to fit models.\nOut-of-class lab assignments: Students will be encouraged to work together to finish the remainder of the labs that were started in-class.\nOut-of-class reading: Every other class will have an assigned reading.\nOut-of-class discussion board: Students will communicate on an online discussion board posted to Canvas about specific course prompts related to readings and lecture.\nOut-of-class quizzes: Short quizzes on Canvas will be used to gauge student comprehension of assigned reading and provide accountability for out-of-class preparation.\nGroup project: A group project will be used as a final assessment of the student’s integration of knowledge through the application of learned material. A group of 2-3 students will either 1) develop an independent research project (ideally connected to their graduate research topic), or 2) develops a short lecture along with a lab case-study that showcases a statistical application relevant to wildlife ecology and conservation."
  },
  {
    "objectID": "FW680A4/overview/Schedule.html",
    "href": "FW680A4/overview/Schedule.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Schedule\n\n\nSyllabus (PDF)\n\n\nCome prepared to discuss the assigned reading. What was interesting and useful? What did not make sense to you? What did you disagree with? What did you learn? Bring points to highlight and bring questions (make a list)."
  },
  {
    "objectID": "FW680A4/overview/Schedule.html#syllabus",
    "href": "FW680A4/overview/Schedule.html#syllabus",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Schedule\n\n\nSyllabus (PDF)\n\n\nCome prepared to discuss the assigned reading. What was interesting and useful? What did not make sense to you? What did you disagree with? What did you learn? Bring points to highlight and bring questions (make a list)."
  },
  {
    "objectID": "FW680A4/overview/Schedule.html#schedule",
    "href": "FW680A4/overview/Schedule.html#schedule",
    "title": "Brian D. Gerber",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDay\nDate\nLecture Topic\nLab Exercises\nAssigned Reading\nBackground Materials\n\n\n\n\n1\nTu\n20-Aug\nClass Intro.; Why statistical model/coding\n\n\n\n\n\n \nThu\n22-Aug\n\nR fundamentals; Markdown; Github\n\n\n\n\n2\nTu\n27-Aug\n\n\n\n\n\n\n \nThu\n29-Aug\n\n\n\n\n\n\n3\nTu\n3-Sep\n\n\n\n\n\n\n \nThu\n5-Sep\n\n\n\n\n\n\n4\nTu\n10-Sep\n\n\n\n\n\n\n \nThu\n12-Sep\n\n\n\n\n\n\n5\nTu\n17-Sep\n\n\n\n\n\n\n6\nTu\n24-Sep\n\n\n\n\n\n\n \nThu\n26-Sep\n\n\n\n\n\n\n7\nTu\n1-Oct\n\n\n\n\n\n\n \nThu\n3-Oct\n\n\n\n\n\n\n8\nTu\n8-Oct\n\n\n\n\n\n\n \nThu\n10-Oct\n\n\n\n\n\n\n9\nTu\n15-Oct\n\n\n\n\n\n\n \nThu\n17-Oct\n\n\n\n\n\n\n10\nTU\n22-Oct\n\n\n\n\n\n\n \nThu\n24-Oct\n\n\n\n\n\n\n11\nTu\n29-Oct\n\n\n\n\n\n\n \nThu\n31-Oct\n\n\n\n\n\n\n12\nTu\n5-Nov\n\n\n\n\n\n\n \nThu\n7-Nov\n\n\n\n\n\n\n13\nTu\n12-Nov\n\n\n\n\n\n\n \nThu\n14-Nov\n\n\n\n\n\n\n14\nTu\n19-Nov\n\n\n\n\n\n\n \nThu\n21-Nov\n\n\n\n\n\n\n15\nTu\n26-Oct\n\n\n\n\n\n\n \nThu\n28-Oct\n\n\n\n\n\n\n16\nTu\n3-Dec\n\n\n\n\n\n\n \nThu\n5-Dec"
  },
  {
    "objectID": "FW680A4/index.html",
    "href": "FW680A4/index.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Course Overview\n\n\nSchedule (Subject to Change)\n\n\nWeeksSoftwareAdditionalCo-lead DiscussionProjectLearning\n\n\n\n\n\nWeek 1 (Aug 20, 23)\n\n\nWeek 2 (Aug 27, 30)\n\n\nWeek 3 (Sep 3, 6)\n\n\nWeek 4 (Sep 10, 12)\n\n\nWeek 5 (Sep 17, 20)\n\n\nWeek 6 (Sep 24, 27)\n\n\nWeek 7 (Oct 1, 4)\n\n\nWeek 8 (Oct 8, 11)\n\n\n\n\nWeek 9 (Oct 15, 18)\n\n\nWeek 10 (Oct 22, 25)\n\n\nWeek 11 (Oct 29, Nov 1)\n\n\nWeek 12 (Nov 5, 8)\n\n\nWeek 13 (Nov 12, 15)\n\n\nWeek 14 (Nov 19, 22)\n\n\nWeek 15 (Nov 26, 29): No Classes\n\n\nWeek 16 (Dec 3, 6)\n\n\n\n\n\nInstall the most recent versions of R and RStudio Desktop.\nInstall the software program JAGS.\n\n\n\n\n\n\n\nTo download lectures: Go to lecture html. Click ‘e’. This should connect all slides into one page. Right Click Mouse on page. Click ’Print”. Choose printer “Adobe PDF”; might need Adobe Acrobat installed.\n\n\n\n\n\nLikelihood and MLE.r\nMatrix Algebra.r\nOccupancy Maximum Likelihood.r\nVariable Combinations\nBayesian models specified in class and more\nBayesian Hierarchical Occupancy Models\nDistribution Cheat Sheet\nHabitat selection Model\n\n\n\n\n\nBrian’s Deer lab: html and Zip.\nBrian’s Prob lab: html and Zip.\nBrian’s Regression lab: html and Zip.\nBrian’s GLM lab: html and Zip.\nBrian’s GLMM lab: html and Zip.\nBrian’s Bayesian lab: html and Zip.\nBrian’s CJS lab: html and Zip.\nBrian’s Occupancy lab: html and Zip.\n\n\n\n\n\nStudents will be grouped and assigned a topic (e.g., mark-recapture).\nEach group should pick an application paper (ideally) or methods paper (if desired) that is published on the assigned topic for the class to read.\nPlease send the paper (pdf) to me via email 2 weeks before the topic is listed on the Schedule; I will then post the paper on the website under the class prior to the discussion date.\nThe group should come prepared to lead the discussion on the paper for (20-25 minutes). Assign questions for us to focus on or come prepared with questions to lead the discussion. Generally focus on things like…\n\nwhat is the statistical model\ndid the authors define it clearly or reference another paper\nthe type of data that is relevant\nhow the sampling was achieved\nthe inference/prediction that was sought\nhow the model was used to answer the fundamental research question\nnuisances of issues of concern in the modeling or sampling\ntry and connect principles/stastistics in the paper to what we have been doing in the class\n\n\n\n\nSpecies Distribution Model (10/8): Libby Mojica, Travis Rainey\nMark Recapture (10/11): Alex Badeaux, Noel Clark, Elke Tukker\nN mixture or Integrated Data Models (10/25): Sarah Gaulke, Sean Ingram\nAnimal Movement (10/29): Jeremy Alder, Becca Windell\nHabitat Selection (11/5): Waverly Davis, Lisa Roerk\nCommunity Modeling (11/12): Cat Adams, Bijoya Paul\n\n\n\n\n\nDecide on whether you will work on a 1) independent research project or 2) develop a short lecture or lab case study on a statistical methodology. Research projects are individual, while a lecture/lab case study can be a team of 2-3 people.\nOnce decided, individually (for a research project) or as a group (case study), email me a one paragraph synopsis of your plan and topic of choice. Please do this by October 25.  I will followup if I have any questions.\n\n\nConduct a quantitative-focused project, such as a statistical analysis of data, or simulation based investigation. If you are unsure of whether your idea fits, come talk with me. If you want to use data from your graduate research, that would be great, but no need to use all of it or for exactly the purpose of your project. Simplifying the data and analysis is good and appropriate.\nObjectives:\n\nWrite a report; this should be turned in December 6 (last day of classes).\nPresent findings in class as an ignite talk; i.e., a 5 minute long presentation with 20 slides and with the slides advancing automatically every 15 seconds. Presentations will be on December 3 and 6.\n\nPrepare a report via R Markdown that generally follows the sections of 1) idea/hypothesis/setup, 2) data explanation, sampling methodology, and modeling, 3) results, and 4) summary/conclusions.\nIn Canvas, please submit the compiled HTML, as well as all other files needed to knit this file.\nThis class is focused on statistical models and model fitting, so make sure to emphasize the specifics of the statistical model that is being used and how it is being fit.\nThis report does not have to be long, but it should be clear and well presented. Part of the grade will be your focus on communicating the data/model/results visually and via clear statistical language.\n\n\n\nObjective:\n\nCreate a lecture, R code lab, or hybrid centered around a quantitative approach relevant to wildlife ecology and conservation.\n\nFor example, 1) develop a lecture on a specific statistical model, 2) a lab walk through implementing the model and important nuances to consider, or 3) some mixture of these.\nAim for the lecture/lab to be around 25-30 minutes. Presentations will be on December 3 and 6. Please submit the final materials on Canvas by December 6 (last day of classes).\nEvaluation will be based on the clarity and organization of the materials presented and the preparedness of the instructors in engaging with the class.\n\n\n\n\n\n\n\n\n\nLanguage of R\nPrelude In R\nData Carpentry\nIntro to R\nMany Resources\nOur Coding Club\nSW Carpentry\nDoser et al. Book\nIntro to R for Biologists\nIntroduction to R - tidyverse\nR for Data Science (2e)\nAdvanced R\nIntroduction to the R Language\nIntroduction to R\nAn Introduction to R for Research\nIntroduction to Data Exploration ana Analysis with R\nWorking with Data in R\n\n\n\n\n\n\n\n\nAn Introduction to Statistical Learning\nThe Elements of Statistical Learning. Download.\nBayesian Data Analysis. Download.\nBayesian Models: A Statistical Primer for Ecologists.\nData Analysis Using Regression and Multilevel/Hierarchical\nStatistics for Spatio-Temporal Data. Download\nSpatio-Temporal Statistics with R. Download\nA First Course in Bayesian Statistical Methods\nBayesian Statistical Methods\n\n\n\n\n\nEcological Models and Data in R\nAnimal Movement: Statistical Models for Telemetry Data\nMixed Effects Models and Extensions in Ecology with R\nApplied hierarchical modeling in Ecology\nHierarchical Modeling in Ecology Books and Code\nPopulation Ecology in Practice. Download\n\n\n\n\n\nComputational Statistics\nParameter Redundancy and Identifiability\nBringing Bayesian Models to Life"
  },
  {
    "objectID": "FW680A4/CourseOverview.html",
    "href": "FW680A4/CourseOverview.html",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Name: Brian D. Gerber\nPosition/Affiliation Research Scientist and Assistant Unit Leader at U.S. Geological Survey, Colorado Cooperative Research Unit and Associate Professor in the Department of Fish, Wildlife, and Conservation Biology at Colorado State University.\nOffice: 202A Wagar, Colorado Cooperative Research Unit\nEmail: brian.gerber@colostate.edu\nOffice Hours: TU 1:30pm - 2:30pm and by appointment\n\n\n\nCourse Number: FW 680A4 (Experimental Course)\nFall 2024: Tu 11am - 12:15 and Fr 10am - 1pm\nCredits: 3\nWebsites: bgerber123.github.io/FW680A4/ (lecture and lab materials) and Canvas (Quizzes, Discussion, Lab Submissions, and Grading).\nSchedule: Subject to Change\nPrerequisites: A basic statistics course is required. Being comfortable coding in the R programming language. See here for the type of R knowledge I am expecting. For learning R, see R resources under ‘Learning R’ tab).\nText and Readings: All lecture and course materials will be provided.\nComputing: A laptop will be necessary to work on coding during class periods.\n\n\n\nStudents will gain knowledge and skills focused on 1) modeling data to make inference/predictions on wildlife and their habitat, 2) understanding and communicating results, 3) evaluating modeling frameworks based on data and study goals, and 4) implementing models and report writing through the R programming language. The format will include lectures, discussions, in-class labs, out of class assigned labs, and readings. Students are strongly encouraged to have base-level knowledge of coding in R.\n\n\n\nUpon successful completion of this course students will:\n\ndevelop a foundation of statistical thinking that includes principles of study design and modeling relevant to wildlife ecology and conservation\nbe able to communicate statistical approaches and results through transparent and reproducible reporting\nbe able to read and understand quantitative wildlife ecology literature\nbe able to write code to fit and interpret complex statistical models relevant to wildlife ecology and conservation.\n\n\n\n\n\n\n\nAssessment Components\nPercentage of Grade\n\n\n\n\nCourse Engagement\n10%\n\n\nLab Assignments\n40%\n\n\nDiscussions\n10%\n\n\nQuizzes\n10%\n\n\nGroup Project\n30%\n\n\n\nTable 1: Grade breakdown by graded components\n\n\n\n\n\nLetter Grade\nPercentage Range\n\n\n\n\nA+\n100.00 to 96.67\n\n\nA\n96.67 to 93.33\n\n\nA-\n93.33 to 90.00\n\n\nB+\n90.00 to 86.67\n\n\nB\n86.67 to 83.33\n\n\nB-\n83.33 to 80.00\n\n\nC+\n80.00 to 76.67\n\n\nC\n76.67 to 70.00\n\n\nD\n70.00 to 60.00\n\n\nF\n60.00 to 00.00\n\n\n\nTable 1: Grade scheme from CSU\n\n\n\nIn-class lectures: Most class periods will include a lecture that will take 1/4 to 1/2 of the course period. Lectures will often incorporate brief instructor-led questions and short discussions.\nIn-class student-led discussions: Small groups (~2 students) will be assigned to co-lead discussions on assigned readings. These discussions will occur prior to any lecture for that class. This will provide students with an opportunity to communicate about the assigned readings content, raise questions for themselves and learn to elicit thoughts and questions from others.\nIn-class labs: Every other class will include a lab. Students will be challenged in class to work individually or in groups to understand, develop and implement code to fit models.\nOut-of-class lab assignments: Students will be encouraged to work together to finish the remainder of the labs that were started in-class.\nOut-of-class reading: Every other class will have an assigned reading.\nOut-of-class discussion board: Students will communicate on an online discussion board posted to Canvas about specific course prompts related to readings and lecture.\nOut-of-class quizzes: Short quizzes on Canvas will be used to gauge student comprehension of assigned reading and provide accountability for out-of-class preparation.\nGroup project: A group project will be used as a final assessment of the student’s integration of knowledge through the application of learned material. A group of 2-3 students will either 1) develop an independent research project (ideally connected to their graduate research topic), or 2) develops a short lecture along with a lab case-study that showcases a statistical application relevant to wildlife ecology and conservation."
  },
  {
    "objectID": "FW680A4/CourseOverview.html#instructor",
    "href": "FW680A4/CourseOverview.html#instructor",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Name: Brian D. Gerber\nPosition/Affiliation Research Scientist and Assistant Unit Leader at U.S. Geological Survey, Colorado Cooperative Research Unit and Associate Professor in the Department of Fish, Wildlife, and Conservation Biology at Colorado State University.\nOffice: 202A Wagar, Colorado Cooperative Research Unit\nEmail: brian.gerber@colostate.edu\nOffice Hours: TU 1:30pm - 2:30pm and by appointment"
  },
  {
    "objectID": "FW680A4/CourseOverview.html#course-information",
    "href": "FW680A4/CourseOverview.html#course-information",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Course Number: FW 680A4 (Experimental Course)\nFall 2024: Tu 11am - 12:15 and Fr 10am - 1pm\nCredits: 3\nWebsites: bgerber123.github.io/FW680A4/ (lecture and lab materials) and Canvas (Quizzes, Discussion, Lab Submissions, and Grading).\nSchedule: Subject to Change\nPrerequisites: A basic statistics course is required. Being comfortable coding in the R programming language. See here for the type of R knowledge I am expecting. For learning R, see R resources under ‘Learning R’ tab).\nText and Readings: All lecture and course materials will be provided.\nComputing: A laptop will be necessary to work on coding during class periods."
  },
  {
    "objectID": "FW680A4/CourseOverview.html#course-description",
    "href": "FW680A4/CourseOverview.html#course-description",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Students will gain knowledge and skills focused on 1) modeling data to make inference/predictions on wildlife and their habitat, 2) understanding and communicating results, 3) evaluating modeling frameworks based on data and study goals, and 4) implementing models and report writing through the R programming language. The format will include lectures, discussions, in-class labs, out of class assigned labs, and readings. Students are strongly encouraged to have base-level knowledge of coding in R."
  },
  {
    "objectID": "FW680A4/CourseOverview.html#course-learning-objectives",
    "href": "FW680A4/CourseOverview.html#course-learning-objectives",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Upon successful completion of this course students will:\n\ndevelop a foundation of statistical thinking that includes principles of study design and modeling relevant to wildlife ecology and conservation\nbe able to communicate statistical approaches and results through transparent and reproducible reporting\nbe able to read and understand quantitative wildlife ecology literature\nbe able to write code to fit and interpret complex statistical models relevant to wildlife ecology and conservation."
  },
  {
    "objectID": "FW680A4/CourseOverview.html#assessment",
    "href": "FW680A4/CourseOverview.html#assessment",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Assessment Components\nPercentage of Grade\n\n\n\n\nCourse Engagement\n10%\n\n\nLab Assignments\n40%\n\n\nDiscussions\n10%\n\n\nQuizzes\n10%\n\n\nGroup Project\n30%\n\n\n\nTable 1: Grade breakdown by graded components\n\n\n\n\n\nLetter Grade\nPercentage Range\n\n\n\n\nA+\n100.00 to 96.67\n\n\nA\n96.67 to 93.33\n\n\nA-\n93.33 to 90.00\n\n\nB+\n90.00 to 86.67\n\n\nB\n86.67 to 83.33\n\n\nB-\n83.33 to 80.00\n\n\nC+\n80.00 to 76.67\n\n\nC\n76.67 to 70.00\n\n\nD\n70.00 to 60.00\n\n\nF\n60.00 to 00.00\n\n\n\nTable 1: Grade scheme from CSU"
  },
  {
    "objectID": "FW680A4/CourseOverview.html#student-experiences-and-pedagogical-techniques",
    "href": "FW680A4/CourseOverview.html#student-experiences-and-pedagogical-techniques",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "In-class lectures: Most class periods will include a lecture that will take 1/4 to 1/2 of the course period. Lectures will often incorporate brief instructor-led questions and short discussions.\nIn-class student-led discussions: Small groups (~2 students) will be assigned to co-lead discussions on assigned readings. These discussions will occur prior to any lecture for that class. This will provide students with an opportunity to communicate about the assigned readings content, raise questions for themselves and learn to elicit thoughts and questions from others.\nIn-class labs: Every other class will include a lab. Students will be challenged in class to work individually or in groups to understand, develop and implement code to fit models.\nOut-of-class lab assignments: Students will be encouraged to work together to finish the remainder of the labs that were started in-class.\nOut-of-class reading: Every other class will have an assigned reading.\nOut-of-class discussion board: Students will communicate on an online discussion board posted to Canvas about specific course prompts related to readings and lecture.\nOut-of-class quizzes: Short quizzes on Canvas will be used to gauge student comprehension of assigned reading and provide accountability for out-of-class preparation.\nGroup project: A group project will be used as a final assessment of the student’s integration of knowledge through the application of learned material. A group of 2-3 students will either 1) develop an independent research project (ideally connected to their graduate research topic), or 2) develops a short lecture along with a lab case-study that showcases a statistical application relevant to wildlife ecology and conservation."
  },
  {
    "objectID": "FW680A4/week1.html",
    "href": "FW680A4/week1.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Introduction\n\n\n\nDiscussion Post on Canvas\n\nReadings for next class:\n\nZitomer et al. 2022 PLOS Computation Biology\n\nWolcott et al. 2019 Book Chapter.\n\n\n\n\n\nLecture: Big Picture\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n  install.packages(c(\"sf\",\"ggplot2\", \"spsurvey\", \"remotes\"))\n\n# Github package install\n  remotes::install_github(\"Pakillo/grateful\")\n\n# OR, download the zip file here and manually install:\n# https://cran.r-project.org/web/packages/grateful/index.html\n\n\n\nRule #2 - Can you describe differences in the type of learning we achieve from 1) manipulative experiments, 2) observational studies, and 3) descriptive/ natural history studies?\nRule #4 - Do you agree?\nRule #7 - What determines a p-value? What does it mean?\nRule #10 - How to do this?\nWhat was a good takeaway from this paper? What was confusing or you disagreed with?\n\n\nWhat is the connection between general linear models and t-test/ANOVA?\nWhat is a fixed and random effect?\nCan you describe elements of a Bayesian or frequentist framework?\nWhat is model selection?\nWhat was a good takeaway from this? What was confusing or you disagreed with?\n\n\nAssigned Readings:\n\nBetts et al. 2022\n\nDumelle et al 2021. Only sections 1 to 1.1.2.\n\nWilliams and Brown 2019. Only sections 1 and 2.\n\n\nBackground Reading (not required):\n\n\nShmueli 2010.\n\nArif and MacNeil 2022."
  },
  {
    "objectID": "FW680A4/week1.html#week-1",
    "href": "FW680A4/week1.html#week-1",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Introduction\n\n\n\nDiscussion Post on Canvas\n\nReadings for next class:\n\nZitomer et al. 2022 PLOS Computation Biology\n\nWolcott et al. 2019 Book Chapter.\n\n\n\n\n\nLecture: Big Picture\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n  install.packages(c(\"sf\",\"ggplot2\", \"spsurvey\", \"remotes\"))\n\n# Github package install\n  remotes::install_github(\"Pakillo/grateful\")\n\n# OR, download the zip file here and manually install:\n# https://cran.r-project.org/web/packages/grateful/index.html\n\n\n\nRule #2 - Can you describe differences in the type of learning we achieve from 1) manipulative experiments, 2) observational studies, and 3) descriptive/ natural history studies?\nRule #4 - Do you agree?\nRule #7 - What determines a p-value? What does it mean?\nRule #10 - How to do this?\nWhat was a good takeaway from this paper? What was confusing or you disagreed with?\n\n\nWhat is the connection between general linear models and t-test/ANOVA?\nWhat is a fixed and random effect?\nCan you describe elements of a Bayesian or frequentist framework?\nWhat is model selection?\nWhat was a good takeaway from this? What was confusing or you disagreed with?\n\n\nAssigned Readings:\n\nBetts et al. 2022\n\nDumelle et al 2021. Only sections 1 to 1.1.2.\n\nWilliams and Brown 2019. Only sections 1 and 2.\n\n\nBackground Reading (not required):\n\n\nShmueli 2010.\n\nArif and MacNeil 2022."
  },
  {
    "objectID": "FW680A4/Introduction.html#class-stuff",
    "href": "FW680A4/Introduction.html#class-stuff",
    "title": "Wildlife Ecology Modeling",
    "section": "Class Stuff",
    "text": "Class Stuff\n\n\nInstructor: Brian Gerber\nClassroom: NR 243\n\nLecture/Lab/Discussion\n\nWhen: Tu 11am - 12:15pm and Fr 10am - 1pm\n\n\n\nMy Office: 202A Wagar, Colorado Cooperative Research Unit\n\nOffice hours: TU 1:30pm - 2:30pm and by appointment\nbrian.gerber@colostate.edu\n\n\n\n\n\nComputers: Bring laptop to class\n\nSoftware/R Packages should be installed prior to lab (posted on website)\n\nRegistration:\n\n680A4 001 (CRN 77149) and 680A4 L01 (CRN 77150)"
  },
  {
    "objectID": "FW680A4/Introduction.html#what-is-this-course",
    "href": "FW680A4/Introduction.html#what-is-this-course",
    "title": "Wildlife Ecology Modeling",
    "section": "What is this course?",
    "text": "What is this course?\nA mix of…\n\nstatistics\nmodeling\ncoding\nmath / notation\nscience philosophy\nwildlife ecology and conservation"
  },
  {
    "objectID": "FW680A4/Introduction.html#our-goals",
    "href": "FW680A4/Introduction.html#our-goals",
    "title": "Wildlife Ecology Modeling",
    "section": "Our Goals",
    "text": "Our Goals"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-is-this-class-useful",
    "href": "FW680A4/Introduction.html#why-is-this-class-useful",
    "title": "Wildlife Ecology Modeling",
    "section": "Why is this class useful?",
    "text": "Why is this class useful?\n\nAble to read modern ecological literature\nUnderstand what you are doing when using data and models; coding/statistics/modeling are related but not the same\nStatistical modeling and coding skills are highly marketable\nTaking control of your analyses\nCollaborate with colleagues/statisticians"
  },
  {
    "objectID": "FW680A4/Introduction.html#who-am-i",
    "href": "FW680A4/Introduction.html#who-am-i",
    "title": "Wildlife Ecology Modeling",
    "section": "Who am I?",
    "text": "Who am I?"
  },
  {
    "objectID": "FW680A4/Introduction.html#and-you",
    "href": "FW680A4/Introduction.html#and-you",
    "title": "Wildlife Ecology Modeling",
    "section": "And you…",
    "text": "And you…\n\n\n\nWhat is your name?\n\n\nWhat is your program/project/field of study?\n\n\nWhy do you want to learn more about ‘quantitative techniques’?\n\n\nWhat is your first emotion when you hear statistics, math, or coding?"
  },
  {
    "objectID": "FW680A4/Introduction.html#science-philosophy",
    "href": "FW680A4/Introduction.html#science-philosophy",
    "title": "Wildlife Ecology Modeling",
    "section": "Science Philosophy",
    "text": "Science Philosophy\n\nI am a pragmatist\n\n\n\nThere are many ways to do great science\n\n\n\n\nThere are more ways to do meh science\n\n\n\n\nDisciplines have conventions\n\n\n\n\nThere are foundations of scientific and statistical learning\n\n\n\n\nKnow the why of your decisions\n\n\n\n\nAsk lots of questions to everybody all the time"
  },
  {
    "objectID": "FW680A4/Introduction.html#teaching-philosophy",
    "href": "FW680A4/Introduction.html#teaching-philosophy",
    "title": "Wildlife Ecology Modeling",
    "section": "Teaching Philosophy",
    "text": "Teaching Philosophy\n\n\nLearning is a choice (in every movement)\nAn inclusive environment is paramount for learning\nCommunication is key\nEveryone has something to teach and something to learn\nStruggle is good. Solving problems leads to learning\nBUT…."
  },
  {
    "objectID": "FW680A4/Introduction.html#tentative-schedule",
    "href": "FW680A4/Introduction.html#tentative-schedule",
    "title": "Wildlife Ecology Modeling",
    "section": "Tentative Schedule",
    "text": "Tentative Schedule\nhttps://bgerber123.github.io/FW680A4/schedule.html"
  },
  {
    "objectID": "FW680A4/Introduction.html#grades",
    "href": "FW680A4/Introduction.html#grades",
    "title": "Wildlife Ecology Modeling",
    "section": "Grades",
    "text": "Grades\n\nAttendance and Participation (10%)\n\nlet me know prior to class if you can not make it\n\nWeekly Assignments (60%)\n\nDue the following class\n\nProject (30%)"
  },
  {
    "objectID": "FW680A4/Introduction.html#project",
    "href": "FW680A4/Introduction.html#project",
    "title": "Wildlife Ecology Modeling",
    "section": "Project",
    "text": "Project\n\nindependent or group research project - highlighting a modeling application, data/code transparency, and communication of results\ngroup development of a lecture and lab case-study that showcases a statistical application relevant to wildlife ecology and conservation"
  },
  {
    "objectID": "FW680A4/Introduction.html#r-code-language",
    "href": "FW680A4/Introduction.html#r-code-language",
    "title": "Wildlife Ecology Modeling",
    "section": "R Code Language",
    "text": "R Code Language\n\nWrite down, what is the name of the\n\nobject?\nfunction?\nargument(s)?\n\n\na = seq(0,1,by=0.1)\n\n\n\nNote: code can be copied to your clipboard (top-right).\n\nCode scripts will also be on the website."
  },
  {
    "objectID": "FW680A4/Introduction.html#rstudio",
    "href": "FW680A4/Introduction.html#rstudio",
    "title": "Wildlife Ecology Modeling",
    "section": "RStudio",
    "text": "RStudio\nWhat does each panel do?"
  },
  {
    "objectID": "FW680A4/Introduction.html#getting-help-with-code",
    "href": "FW680A4/Introduction.html#getting-help-with-code",
    "title": "Wildlife Ecology Modeling",
    "section": "Getting help with Code",
    "text": "Getting help with Code\n\n\nShare via RStudio Server (ideally)\nIf emailing, include a script file and RData file (workspace)\nHierarchical code organization\n\ncode structure using indenting\ntop –&gt; bottom execution\nremove all extraneous code (minimal working example)\nthe code you send is likely different than what you are working on\n\n\n\n\nHelp! My code doesn’t work…\n\n                cor.sp.route.cor=vector(\"list\",n.species)\ncor.sp=rep(NA,n.species)\n            for(s in 1:n.species){\nroute=new.cov.species.long.scaled[[s]]$routeID\ncor.sp[s]=cor(patch.size20.species.scaled.mat.center.route[s,],patch.count20.species.scaled.mat.center.route[s,])\n    for(i in 1:nroutes){\ntemp1=patch.size20.species.scaled.mat.center.route[s,which(route==route.id[i])]\n  temp2=patch.count20.species.scaled.mat.center.route[,][s,which(route==route.id[i])]\n  if(length(temp1)&gt;5){\n  cor.sp.route.cor[[s]]=abs(c(cor.sp.route.cor[[s]],cor(temp1,temp2)))\n  }}}\n\n\n\nMinimal/Annotated working example"
  },
  {
    "objectID": "FW680A4/Introduction.html#code",
    "href": "FW680A4/Introduction.html#code",
    "title": "Wildlife Ecology Modeling",
    "section": "Code",
    "text": "Code"
  },
  {
    "objectID": "FW680A4/Introduction.html#course-learning-objectives",
    "href": "FW680A4/Introduction.html#course-learning-objectives",
    "title": "Wildlife Ecology Modeling",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\nUpon successful completion of this course students will be able to:\n\n\nthink ‘statistically’\nread quantitative ecology literature\nwrite code to fit and interpret complex statistical models relevant to wildlife ecology and conservation\ncommunicate statistical approaches and results"
  },
  {
    "objectID": "FW680A4/Introduction.html#learning",
    "href": "FW680A4/Introduction.html#learning",
    "title": "Wildlife Ecology Modeling",
    "section": "Learning",
    "text": "Learning\n\n\nI do not know where you are starting"
  },
  {
    "objectID": "FW680A4/Introduction.html#statistics-and-coding",
    "href": "FW680A4/Introduction.html#statistics-and-coding",
    "title": "Wildlife Ecology Modeling",
    "section": "Statistics and Coding",
    "text": "Statistics and Coding\nStatistics:\n“The theory and practice of computer-age statistics are, for the most part, a case of new wine in old bottles: The fundamental tenets of good statistical thinking have not changed, but their implementation has.” Cox and Efron, Sci. Adv. 2017;3: e1700768\nSoftware changes all the time. Code will become obsolete."
  },
  {
    "objectID": "FW680A4/Introduction.html#statistics-in-modern-age",
    "href": "FW680A4/Introduction.html#statistics-in-modern-age",
    "title": "Wildlife Ecology Modeling",
    "section": "Statistics in Modern Age",
    "text": "Statistics in Modern Age\n“The theory and practice of computer-age statistics are, for the most part, a case of new wine in old bottles: The fundamental tenets of good statistical thinking have not changed, but their implementation has.” - Cox and Efron, Sci. Adv. 2017;3: e1700768"
  },
  {
    "objectID": "FW680A4/Introduction.html#coding-in-the-modern-age",
    "href": "FW680A4/Introduction.html#coding-in-the-modern-age",
    "title": "Wildlife Ecology Modeling",
    "section": "Coding in the Modern Age",
    "text": "Coding in the Modern Age\n\nSoftware changes all the time\nCode will become obsolete\nBase R functions change slower than packages\nDocument/Annotate code and publish it online\nFile management is important; use sub-folders"
  },
  {
    "objectID": "FW680A4/Introduction.html#statisical-modeling",
    "href": "FW680A4/Introduction.html#statisical-modeling",
    "title": "Wildlife Ecology Modeling",
    "section": "Statisical Modeling",
    "text": "Statisical Modeling\n\nparametric\nprobabilistic\ngenerative\ninferential\npredictive"
  },
  {
    "objectID": "FW680A4/Introduction.html#my-background",
    "href": "FW680A4/Introduction.html#my-background",
    "title": "Wildlife Ecology Modeling",
    "section": "My Background",
    "text": "My Background"
  },
  {
    "objectID": "FW680A4/Introduction.html#my-background-1",
    "href": "FW680A4/Introduction.html#my-background-1",
    "title": "Wildlife Ecology Modeling",
    "section": "My Background",
    "text": "My Background"
  },
  {
    "objectID": "FW680A4/Introduction.html#my-background-2",
    "href": "FW680A4/Introduction.html#my-background-2",
    "title": "Wildlife Ecology Modeling",
    "section": "My Background",
    "text": "My Background"
  },
  {
    "objectID": "FW680A4/Introduction.html#my-background-3",
    "href": "FW680A4/Introduction.html#my-background-3",
    "title": "Wildlife Ecology Modeling",
    "section": "My Background",
    "text": "My Background"
  },
  {
    "objectID": "FW680A4/Introduction.html#learning-1",
    "href": "FW680A4/Introduction.html#learning-1",
    "title": "Wildlife Ecology Modeling",
    "section": "Learning",
    "text": "Learning"
  },
  {
    "objectID": "FW680A4/Introduction.html#a-graduate-students-dilemna",
    "href": "FW680A4/Introduction.html#a-graduate-students-dilemna",
    "title": "Wildlife Ecology Modeling",
    "section": "A Graduate Students Dilemna",
    "text": "A Graduate Students Dilemna\nYou need to know….\n\n\n\nfield techniques\nlogistics\npeople/advisor management\ninstitutional bureaucracy\necological theory\nwildlife mgmt principles\nconservation biology principles\nstudy design\ndata management\n\n\n\npublic speaking\nindependent and team work\ngraphic/visual arts\n‘the literature’\nthe job market\nhow to write a manuscript/thesis\nwriting/sharing coding\nstatistical modeling\n…"
  },
  {
    "objectID": "FW680A4/Introduction.html#our-aim",
    "href": "FW680A4/Introduction.html#our-aim",
    "title": "Wildlife Ecology Modeling",
    "section": "Our Aim",
    "text": "Our Aim\nWhat model did you fit? Why? How?"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-is-statistics-so-difficult",
    "href": "FW680A4/Introduction.html#why-is-statistics-so-difficult",
    "title": "Wildlife Ecology Modeling",
    "section": "Why is statistics so difficult?",
    "text": "Why is statistics so difficult?\n\n\nTheory / Calculus / Optimization &lt;—–&gt; Plug-N-Chug"
  },
  {
    "objectID": "FW680A4/Introduction.html#the-language-of-r",
    "href": "FW680A4/Introduction.html#the-language-of-r",
    "title": "Wildlife Ecology Modeling",
    "section": "The language of R",
    "text": "The language of R\n\nObjects\nA storage place for information; stored in the “Environment”\n\n\n‘Attributes’ describes the structure or information of the object"
  },
  {
    "objectID": "FW680A4/Introduction.html#the-language-of-r-1",
    "href": "FW680A4/Introduction.html#the-language-of-r-1",
    "title": "Wildlife Ecology Modeling",
    "section": "The language of R",
    "text": "The language of R\nObjects\n\n# y is an 'object' that is assigned the value 3\ny = 3\ny\n\n[1] 3"
  },
  {
    "objectID": "FW680A4/Introduction.html#the-language-of-r-2",
    "href": "FW680A4/Introduction.html#the-language-of-r-2",
    "title": "Wildlife Ecology Modeling",
    "section": "The language of R",
    "text": "The language of R\n\n\nValues\n\nnumeric\ninteger\ncharacter\nfactor\n\n\nObjects\n\nvector\nmatrix\narray\nlist\ndataframe\nS3, S4, S5, and beyond"
  },
  {
    "objectID": "FW680A4/Introduction.html#the-language-of-r-3",
    "href": "FW680A4/Introduction.html#the-language-of-r-3",
    "title": "Wildlife Ecology Modeling",
    "section": "The language of R",
    "text": "The language of R\nFunctions\n‘does stuff’; creates or manipulates objects\n\n‘Arguments’ are the types of things a function is asking for; the inputs"
  },
  {
    "objectID": "FW680A4/Introduction.html#some-useful-functions",
    "href": "FW680A4/Introduction.html#some-useful-functions",
    "title": "Wildlife Ecology Modeling",
    "section": "Some useful functions",
    "text": "Some useful functions\nfor loops\n\nsave.this=c()\nfor(i in 1:10){\n  save.this[i] =  1-i\n}"
  },
  {
    "objectID": "FW680A4/Introduction.html#some-useful-functions-1",
    "href": "FW680A4/Introduction.html#some-useful-functions-1",
    "title": "Wildlife Ecology Modeling",
    "section": "Some useful functions",
    "text": "Some useful functions\nCreate your own function\n\nmy.mean.func = function(x){\n                           sum(x)/length(x)\n                          }\n\nmy.mean.func(\n             c(5,4,7,2,7,1)\n             )\n\n[1] 4.333333"
  },
  {
    "objectID": "FW680A4/Introduction.html#some-useful-functions-2",
    "href": "FW680A4/Introduction.html#some-useful-functions-2",
    "title": "Wildlife Ecology Modeling",
    "section": "Some useful functions",
    "text": "Some useful functions\napply/sapply/lapply/vapply\n\nmat= matrix(rnorm(100),nrow=10, ncol=10)\n\napply(mat, 2, FUN=median)\n\n [1] -0.22895129 -0.23543173  0.25250440 -0.05512031 -0.19921642 -0.06873026\n [7] -0.15605470  0.57359061  0.32028873  0.22507929\n\n\n\n\napply(mat, 2, FUN=function(x){\n  \n  length(which(x&gt;1))/length(x)\n  \n})\n\n [1] 0.1 0.2 0.1 0.2 0.1 0.0 0.0 0.4 0.3 0.3"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-is-statistics-and-modeling-so-difficult",
    "href": "FW680A4/Introduction.html#why-is-statistics-and-modeling-so-difficult",
    "title": "Wildlife Ecology Modeling",
    "section": "Why is statistics and modeling so difficult?",
    "text": "Why is statistics and modeling so difficult?\n\n\nStatistical Theory / Calculus / Optimization / Ecological Complexity\n…\nPlug-N-Chug"
  },
  {
    "objectID": "FW680A4/Introduction.html#think-statistically",
    "href": "FW680A4/Introduction.html#think-statistically",
    "title": "Wildlife Ecology Modeling",
    "section": "Think Statistically",
    "text": "Think Statistically\nKnow…\n\n\nyour objective in fitting a model\nthe model and its properties (not just the name)\nhow to interpret ALL the parameters\nhow the parameters are being optimized\nand have justification for modeling decisions\n\nrequires reading literature\nrequires evaluating assumptions yourself"
  },
  {
    "objectID": "FW680A4/Introduction.html#type-of-modeling",
    "href": "FW680A4/Introduction.html#type-of-modeling",
    "title": "Wildlife Ecology Modeling",
    "section": "Type of Modeling",
    "text": "Type of Modeling\n\nparametric\nprobabilistic\ngenerative\ninferential and/or predictive"
  },
  {
    "objectID": "FW680A4/Introduction.html#a-graduate-students-dilemma",
    "href": "FW680A4/Introduction.html#a-graduate-students-dilemma",
    "title": "Wildlife Ecology Modeling",
    "section": "A Graduate Student’s Dilemma",
    "text": "A Graduate Student’s Dilemma\nYou need to know….\n\n\n\nfield techniques\nlogistics / planning\npeople/advisor management\ninstitutional bureaucracy\necological theory\nwildlife mgmt principles\nconservation biology principles\nstudy design\ndata management\n\n\n\npublic speaking\nindependent and team work\ngraphic/visual arts\n‘the literature’\nthe job market\nhow to write a manuscript/thesis\nwriting/sharing coding\nstatistical modeling\n…"
  },
  {
    "objectID": "FW680A4/Introduction.html#assessment",
    "href": "FW680A4/Introduction.html#assessment",
    "title": "Wildlife Ecology Modeling",
    "section": "Assessment",
    "text": "Assessment\n\n\n\nAssessment Components\nPercentage of Grade\n\n\n\n\nCourse Engagement\n10%\n\n\nLab Assignments\n40%\n\n\nDiscussions\n10%\n\n\nQuizzes\n10%\n\n\nProject\n30%"
  },
  {
    "objectID": "FW680A4/Introduction.html#project-1",
    "href": "FW680A4/Introduction.html#project-1",
    "title": "Wildlife Ecology Modeling",
    "section": "Project",
    "text": "Project\n\n\nGroups (2-3) will design a\n\nreading/discussion - lecture - lab - HW\n\naround a statistical / methodology topic relevant to ecology and resource mgmt.\n\nwork with me\nthe topic needs to be general(ish)\nlead one class period"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-is-statistics-and-ecological-modeling-so-difficult",
    "href": "FW680A4/Introduction.html#why-is-statistics-and-ecological-modeling-so-difficult",
    "title": "Wildlife Ecology Modeling",
    "section": "Why is statistics and ecological modeling so difficult?",
    "text": "Why is statistics and ecological modeling so difficult?"
  },
  {
    "objectID": "FW680A4/Introduction.html#statistics-in-the-modern-age",
    "href": "FW680A4/Introduction.html#statistics-in-the-modern-age",
    "title": "Wildlife Ecology Modeling",
    "section": "Statistics in the Modern Age",
    "text": "Statistics in the Modern Age\n\n\n\"The theory and practice of computer-age statistics are, for the most part, a case of new wine in old bottles: The fundamental tenets of good\nstatistical thinking have not changed, but their implementation has.\" - Cox and Efron, Sci. Adv. 2017;3: e1700768."
  },
  {
    "objectID": "FW680A4/Introduction.html#software",
    "href": "FW680A4/Introduction.html#software",
    "title": "Wildlife Ecology Modeling",
    "section": "Software",
    "text": "Software"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-learn-to-code",
    "href": "FW680A4/Introduction.html#why-learn-to-code",
    "title": "Wildlife Ecology Modeling",
    "section": "Why learn to code?",
    "text": "Why learn to code?\n\n\nefficiency\ntransparency\nflexibility in application\nshareable\nmarketable skill\nneeded for publications"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-use-r",
    "href": "FW680A4/Introduction.html#why-use-r",
    "title": "Wildlife Ecology Modeling",
    "section": "Why use R?",
    "text": "Why use R?\n\n\nopen-source and free\nsmall total user base / large in ecology and statistics\nfind help online, e.g., stackoverflow\ndata management\nstatistics\nplotting / graphics"
  },
  {
    "objectID": "FW680A4/Introduction.html#why-use-rstudio",
    "href": "FW680A4/Introduction.html#why-use-rstudio",
    "title": "Wildlife Ecology Modeling",
    "section": "Why use RStudio?",
    "text": "Why use RStudio?\n\nMakes using R easier\nProjects (file mgmt)\nR Shiny: Interactive online apps\nR Markdown: Interactive documents\nQuarto: interactive articles, websites, blog, …\nPosit - Certified B corp"
  },
  {
    "objectID": "FW680A4/Introduction.html#our-aim-1",
    "href": "FW680A4/Introduction.html#our-aim-1",
    "title": "Wildlife Ecology Modeling",
    "section": "Our Aim",
    "text": "Our Aim\nWhat model did you fit? Why? How?"
  },
  {
    "objectID": "FW680A4/Introduction.html#the-language-of-r-4",
    "href": "FW680A4/Introduction.html#the-language-of-r-4",
    "title": "Wildlife Ecology Modeling",
    "section": "The language of R",
    "text": "The language of R\nobject = function(argument1 = input1, argument1 = input2)\n\n\nobject = function(input1, input2)\n\n\n\nthis = sign(x = -5)\n\n\n\nsign(-5)\n\n[1] -1\n\nsign(5)\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/week2.html",
    "href": "FW680A4/week2.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Probability\nLecture Code: Probability.R\n\n\n\n\nIs the use of hypotheses in the literature changing?\nWhen are hypotheses useful?\nWhen are hypotheses not useful?\n\n\n\n\n\nWhat are the attributes and foundations of design-based sampling/inference?\nWhat are the attributes and foundations of model-based sampling/inference?\nHow do you use these two ideas?\nAny concerns of using or not using these ideas?\n\n\n\n\n\n\nProbabiltiy Quiz on Canvas\nReadings for next class:\n\nKery and Kellner Chapter 2 (sections 2.0-2.4)\n\nBackground Reading (not required):\n\n Hobbs & Hooten Ch. 3. Section 3.4.\n Bolker 2007 Ch. 4.\n\n\n\n\n\n\n\n\n\nLecture: Continue with Probability\nDownloads: Files\n\n\n\n\n\nReadings for next class:\n\nKery and Kellner Chapter 2 (sections 2.5-2.6)\n\nBackground Reading (not required):\n\nBolker Ch. 6\nFieberg Ch. 10"
  },
  {
    "objectID": "FW680A4/week2.html#week-2",
    "href": "FW680A4/week2.html#week-2",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Probability\nLecture Code: Probability.R\n\n\n\n\nIs the use of hypotheses in the literature changing?\nWhen are hypotheses useful?\nWhen are hypotheses not useful?\n\n\n\n\n\nWhat are the attributes and foundations of design-based sampling/inference?\nWhat are the attributes and foundations of model-based sampling/inference?\nHow do you use these two ideas?\nAny concerns of using or not using these ideas?\n\n\n\n\n\n\nProbabiltiy Quiz on Canvas\nReadings for next class:\n\nKery and Kellner Chapter 2 (sections 2.0-2.4)\n\nBackground Reading (not required):\n\n Hobbs & Hooten Ch. 3. Section 3.4.\n Bolker 2007 Ch. 4.\n\n\n\n\n\n\n\n\n\nLecture: Continue with Probability\nDownloads: Files\n\n\n\n\n\nReadings for next class:\n\nKery and Kellner Chapter 2 (sections 2.5-2.6)\n\nBackground Reading (not required):\n\nBolker Ch. 6\nFieberg Ch. 10"
  },
  {
    "objectID": "FW680A4/BigPicture.html#do-we-need-study-designs-anymore-to-do-research",
    "href": "FW680A4/BigPicture.html#do-we-need-study-designs-anymore-to-do-research",
    "title": "Big Picture  and Probability",
    "section": "Do we need study designs anymore to do research?",
    "text": "Do we need study designs anymore to do research?\n\n\nData is everywhere; it is the era of  BIG DATA"
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-problems",
    "href": "FW680A4/BigPicture.html#big-data-problems",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data Problems",
    "text": "Big Data Problems\n“The hidden Biases of Big Data” by Kate Crawford in Harvard Business Review (2013)\n“with enough data, the numbers speak for themselves”- Wired Magazine Editor"
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-problems-1",
    "href": "FW680A4/BigPicture.html#big-data-problems-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data Problems",
    "text": "Big Data Problems\n“The hidden Biases of Big Data” by Kate Crawford in Harvard Business Review (2013)\n\"Data and data sets are not objective;\"\n\n\"they are creations of human design.\""
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-problems-2",
    "href": "FW680A4/BigPicture.html#big-data-problems-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data Problems",
    "text": "Big Data Problems\nThe Annals of Applied Statistics (2018); Xiao Li Meng,\nThe Big Data Paradox: \n\n\n\"the bigger the data, the surer we fool ourselves” ... when we fail to account for our sampling process. \n\n\n\n\nSampling Processes == Human Design"
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-problems-3",
    "href": "FW680A4/BigPicture.html#big-data-problems-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data Problems",
    "text": "Big Data Problems\n\n\nBradley et al. 2021 (Nature)\"...data quality matters more than data quantity, and that compensating the former with the latter is a mathematically provable losing proposition.\""
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-problems-4",
    "href": "FW680A4/BigPicture.html#big-data-problems-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data Problems",
    "text": "Big Data Problems\nUsing eBird data w/o accounting for sampling biases.\n\n\n\n\n\n\nLink1. Link2."
  },
  {
    "objectID": "FW680A4/BigPicture.html#the-questioning-scientist",
    "href": "FW680A4/BigPicture.html#the-questioning-scientist",
    "title": "Big Picture  Science and Modeling",
    "section": "The Questioning Scientist",
    "text": "The Questioning Scientist\n\nIn regard to data and statistical models, 21st century scientists should be pragmatic, excited, and questioning.\n\n\nHow and why did these data come to be?\n\nunderstand how the data came to be\nask this even when you design the study, after data collection\n\n\n\n\n\nWhat do these data look like?\n\nvisualize the data in many dimensions\nkeep in mind - not all outcomes are visible in data – example?\n\n\n\n\n\nHow does this statistical model work?\n\nstatistical notation, explicit and implicit assumptions, optimization\n\n\n\n\n\nHow does this statistical model fail in theory and in practice?\n\nstatistical robustness and identifiability"
  },
  {
    "objectID": "FW680A4/BigPicture.html#data-vs.-information",
    "href": "FW680A4/BigPicture.html#data-vs.-information",
    "title": "Big Picture  Science and Modeling",
    "section": "Data vs. Information",
    "text": "Data vs. Information\nData = Numbers/Groupings\nData ≠ Information"
  },
  {
    "objectID": "FW680A4/BigPicture.html#information",
    "href": "FW680A4/BigPicture.html#information",
    "title": "Big Picture  Science and Modeling",
    "section": "Information",
    "text": "Information\nData contains information, depending on ...\n\nthe question being asked of the data\nhow the data came to be\nthe goal of the question"
  },
  {
    "objectID": "FW680A4/BigPicture.html#the-question-and-the-data",
    "href": "FW680A4/BigPicture.html#the-question-and-the-data",
    "title": "Big Picture  Science and Modeling",
    "section": "The question and the data",
    "text": "The question and the data\n\nEcological surveillance monitoring will often have low quality information regarding post-hoc hypotheses.\n\n\nExample?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#the-goal-of-the-question",
    "href": "FW680A4/BigPicture.html#the-goal-of-the-question",
    "title": "Big Picture  Science and Modeling",
    "section": "The goal of the question",
    "text": "The goal of the question\n\n\nlearn about the data (data summary)\napply learning outside of the data (inference)\nlearn about conditions relevant to but not observed in the data (prediction)\n\n\n\n\n\n\ninference and prediction are different goals, optimally requiring different data, statistical modeling proecdures. \n\n\n\n\n\n\nBUT, are also not mutually exclusive."
  },
  {
    "objectID": "FW680A4/BigPicture.html#inference-and-prediction",
    "href": "FW680A4/BigPicture.html#inference-and-prediction",
    "title": "Big Picture  Science and Modeling",
    "section": "Inference and Prediction",
    "text": "Inference and Prediction\n\n\nFrom \"The strategy of model building in population biology\" by Richard Levins (American Scientists, 1966) :\n\n\n\"It is of course desirable to work with manageable models which maximize generality, realism, and precision toward the overlapping but not identical goals of understanding, predicting, and modifying nature. But this cannot be done.\""
  },
  {
    "objectID": "FW680A4/BigPicture.html#infernence-and-prediction",
    "href": "FW680A4/BigPicture.html#infernence-and-prediction",
    "title": "Big Picture  Science and Modeling",
    "section": "Infernence and Prediction",
    "text": "Infernence and Prediction\nThis leads to a strange result: \n\nthe \"wrong\"  statistical model can predict better than the correct one.\n\n\nBUT …\nExplanatory models will likely perform better when predicting outside of the sample space and the model has the core underlying processes"
  },
  {
    "objectID": "FW680A4/BigPicture.html#infernence-and-prediction-1",
    "href": "FW680A4/BigPicture.html#infernence-and-prediction-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Infernence and Prediction",
    "text": "Infernence and Prediction\nTrade-Off Between Prediction Accuracy and Model Interpretability\n\nJames et al. 2013. An Introduction to Statistical Learning"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information",
    "href": "FW680A4/BigPicture.html#statistical-information",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information",
    "text": "Statistical Information\nLet’s turn to the field of statistics to understand Information\n\n\nLikelihood principle\nGiven a statistical model, all the evidence/information in a sample (\\(\\textbf{y}\\), i.e., data) relevant to model parameters (\\(\\theta\\)) is contained in the likelihood function.\n\n\nFisher Information\nThe information an observable random variable (\\(\\textbf{y}\\)) has about an unknown parameter \\(\\theta\\) upon which the probability of \\(\\textbf{y}\\) \\((f(\\textbf{y};\\theta)\\) depends.\n\n\n\nInformation is conditional \n\n\nTo learn about \\(\\theta\\) from \\(\\textbf{y}\\), we need to link them together via a special function, \\(f(\\textbf{y};\\theta)\\)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-1",
    "href": "FW680A4/BigPicture.html#statistical-information-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information",
    "text": "Statistical Information\n The pieces:\n\n\nThe sample data, \\(\\textbf{y}\\)\nA probability function for \\(\\textbf{y}\\):\n\n\\(f(\\textbf{y};\\theta)\\)\n\\([\\textbf{y}|\\theta]\\)\n\nThe unknown parameter: \\(\\theta\\)\n\nspecified in the probability function"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\nWe want to know the proportion of a wetlands that contain a rare plant species. We can not sample the whole area."
  },
  {
    "objectID": "FW680A4/BigPicture.html#rare-plant-data",
    "href": "FW680A4/BigPicture.html#rare-plant-data",
    "title": "Big Picture  Science and Modeling",
    "section": "Rare Plant Data",
    "text": "Rare Plant Data\nWe randomly select plots and look for our plant.\nOur data are\n\ny &lt;- c(0,1,1,1,1,0,1,0,0,0)\nn &lt;- length(y)\nn\n\n[1] 10\n\n\n\n\n\\(\\textbf{y}\\) is a random variable as it depends on random events.\n\n\n\nIn this case, when we induced a random selection of sites."
  },
  {
    "objectID": "FW680A4/BigPicture.html#probabilitylikelihood-function",
    "href": "FW680A4/BigPicture.html#probabilitylikelihood-function",
    "title": "Big Picture  Science and Modeling",
    "section": "Probability/Likelihood Function",
    "text": "Probability/Likelihood Function\n\\(f(\\textbf{y};\\theta)\\) describes the probability for each \\(i^{th}\\) data, \\(y_i\\).\nBut, not just for the data we observed, for all possible data that could be observed.\n\nRules about our data:  \\(y \\in \\{0,1\\}\\),\n\n\n\nwhere the curly brackets imply discrete values in our \"set\".\n\n\nNot this: \\(y \\in [0,1]\\),\n\nwhere the square brackets indicate all real numbers from 0 to 1, including 0 and 1.\n\n\nNot this: \\(y \\in (0,1)\\),\n\nwhere the parantheses indicate all real numbers from 0 to 1, not including 0 and 1."
  },
  {
    "objectID": "FW680A4/BigPicture.html#probability-function",
    "href": "FW680A4/BigPicture.html#probability-function",
    "title": "Big Picture  Science and Modeling",
    "section": "Probability Function",
    "text": "Probability Function\nTwo outcomes, 0 or 1, so we need two probabilities to describe our random variable.\n\n\\[\n  f(y;\\theta) = [y|\\theta]=\n  \\begin{cases}\n    \\theta     & \\text{if $y = 1$}, \\\\\n    1 - \\theta & \\text{if $y = 0$}.\n  \\end{cases}\n\\]\n\n\nAlso,\n\\[\nf(y;\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\n\n\nAlso,\n\\[\n  \\begin{align}\n        P(Y=1) &= \\theta \\\\\n        P(Y=0) &= 1-\\theta  \n  \\end{align}\n\\]\n\nThis probability function is called ________?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#probability-function-1",
    "href": "FW680A4/BigPicture.html#probability-function-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Probability Function",
    "text": "Probability Function\nProbabilities, such as our parameter, have rules:\n\n\n\\(0 \\leq \\theta \\leq 1\\)\n\\(0 \\leq (1 - \\theta) \\leq 1\\)\n\\(\\theta + (1-\\theta) = 1\\)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#probability-function-2",
    "href": "FW680A4/BigPicture.html#probability-function-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Probability Function",
    "text": "Probability Function\nHow do we find \\(\\theta\\) for our data?\n\nWe can use our probability function to calculate the likelihood of a parameter, given our data.\n\n\n\\[\n\\mathcal{L}(\\theta|y) = \\prod_{i=1}^{n} p(y_{i};\\theta)\n\\]\n\n\n\n#Bernoulli probability function\n  prob.function=function(theta){prod(theta^y*(1-theta)^y)}\n\n#possible probabilities\n  theta.guess=matrix(seq(0.01,0.99,by=0.01))\n\n#implement function\n  likelihood=apply(theta.guess,1,prob.function)\n  \n#Find maximum likelood\n  max.index=which.max(likelihood)\n\n#Theta that maximizes our probability function\n  theta.est=theta.guess[max.index]\n\n#Define other probability\n  q.est &lt;- 1-theta.est\n\n#Alternative estimation\n  theta.est2 &lt;- sum(y)/n"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example-1",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\nLet’s combine 1 observation of our random variable, our probability function, and \\(\\theta\\) to quantify the Fisher information (Link ):\n\n\\[\\begin{align}\nI(\\theta) &= -E\\left[\\frac{\\partial^2}{\\partial\\theta^2}\\text{log}(\\theta^y(1-\\theta)^{1-y}) \\right]\\\\\n\\end{align}\\]\n\n\nFor all samples (n), this is reduced to\n\\[\\begin{align}\nI(\\theta) &= \\frac{n}{\\theta(1-\\theta)}\\\\\n\\end{align}\\]"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example-2",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\nTherefore, for our sample\n\nI = n/(theta.est*q.est)\nI\n\n[1] 40\n\n\n\nConsider how information varies by \\(\\theta\\) for a given sample size…."
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example-3",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\n\nthetas=seq(0.05,0.95,0.1)\n\nInformation &lt;- n/(thetas*(1-thetas))\n\npar(cex.lab=2.5,cex.axis=2.5,mar=c(5,5,2,2))\nplot(thetas,Information,type=\"b\",lwd=8)\n\nabline(v=theta.est,col=2,lwd=8)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example-4",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\nFunny enough, Fisher Information is the reciprocal of the variance of our estimate of \\(\\theta\\),\\[Var[\\hat{\\theta}] = \\frac{\\hat{\\theta}  (1-\\hat{\\theta})}{n}\\]"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-information-an-example-5",
    "href": "FW680A4/BigPicture.html#statistical-information-an-example-5",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Information (an example)",
    "text": "Statistical Information (an example)\n\nthetas=seq(0.05,0.95,0.1)\n\nVar.theta &lt;- (thetas*(1-thetas))/n\npar(cex.main=2.5,cex.axis=2.5,cex.lab=2.5,mar=c(5,5,2,2))\nplot(thetas,Var.theta,type=\"b\",lwd=8)\nabline(v=theta.est,col=2,lwd=8)\n\n\n\nHow does this knowledge about this probability function inform the design of a study?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistics",
    "href": "FW680A4/BigPicture.html#statistics",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistics",
    "text": "Statistics\nA field dedicated to observing the real world to gain informational data.\n\nBUT\nOften statistics classes only focus on Power Analysis.\n\n\nTo obtain informational data , we need to think about\n\n\nhow our data will be created\nour question of the data\na probability function to use and its parameters\nthe goal of the question"
  },
  {
    "objectID": "FW680A4/BigPicture.html#reading",
    "href": "FW680A4/BigPicture.html#reading",
    "title": "Big Picture  Science and Modeling",
    "section": "Reading",
    "text": "Reading\n\n\nLink"
  },
  {
    "objectID": "FW680A4/BigPicture.html#sections",
    "href": "FW680A4/BigPicture.html#sections",
    "title": "Big Picture  and Probability",
    "section": "Sections",
    "text": "Sections\n\nHypotheses and Predictions\nBig Data and Sampling\nInference and Prediction\nProbability and Markdown"
  },
  {
    "objectID": "FW680A4/BigPicture.html#hypothesespredictions",
    "href": "FW680A4/BigPicture.html#hypothesespredictions",
    "title": "Big Picture  Science and Modeling",
    "section": "Hypotheses/Predictions",
    "text": "Hypotheses/Predictions\nStudy Objective\nHypothesis\nPrediction"
  },
  {
    "objectID": "FW680A4/schedule.html",
    "href": "FW680A4/schedule.html",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Schedule\n\n\nCourse Overview\nReadings: Come prepared to discuss the assigned reading on the next class after the readings were assigned.\n\nWhat was interesting and useful? What did not make sense? What did you disagree with? What did you learn? Bring points to highlight and bring questions (make a list). Check each week’s link to see if there are listed reading questions.\n\nLabs: are started in class on the day they are listed under and any relevant lab assignment is due one week later, unless otherwise stated."
  },
  {
    "objectID": "FW680A4/schedule.html#course-stuff",
    "href": "FW680A4/schedule.html#course-stuff",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "",
    "text": "Schedule\n\n\nCourse Overview\nReadings: Come prepared to discuss the assigned reading on the next class after the readings were assigned.\n\nWhat was interesting and useful? What did not make sense? What did you disagree with? What did you learn? Bring points to highlight and bring questions (make a list). Check each week’s link to see if there are listed reading questions.\n\nLabs: are started in class on the day they are listed under and any relevant lab assignment is due one week later, unless otherwise stated."
  },
  {
    "objectID": "FW680A4/schedule.html#schedule",
    "href": "FW680A4/schedule.html#schedule",
    "title": "\nFW 680A4  Wildlife Ecology Modeling  (Fall 2024)\n",
    "section": "Schedule",
    "text": "Schedule\n\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDay\nDate\nLecture Topic\nAssignments\nReadings\nBackground Materials\n\n\n\n\n1\nTu\n20-Aug\nClass Intro\nDiscussion Post\nZitomer et al. 2022; Wolcott et al. 2019\n\n\n\n \nFr\n23-Aug\nBig Picture\nLab 1: Sampling\nBetts et al. 2022; Dumelle et al. 2021; Williams and Brown 2019\nShmueli 2010; Arif and MacNeil 2022\n\n\n2\nTu\n27-Aug\nProbability Functions\nProbability Quiz\nKery and Kellner Ch. 2.0-2.4\nHobbs and Hooten Ch.3; Bolker Ch. 4\n\n\n \nFr\n30-Aug\nProbability Functions\nLab 2: Simulation & Prob. Functions\nKery and Kellner Ch. 2.5-2.6\nFieberg Ch. 10; Bolker Ch. 6\n\n\n3\nTu\n3-Sep\nLikelihood / Optimization\n\nDushoff et al. 2019; Fieberg, Ch. 1.10\nFieberg Ch. 1; Bolker Ch. 7; Zurr et al. Ch. 2\n\n\n \nFr\n6-Sep\nRegression\nLab 3: Regression\n\n\n\n\n4\nTu\n10-Sep\nGLM I\n\nZurr and Iano, 2016\n\n\n\n \nFr\n13-Sep\nGLM II\nLab 4: GLM\nFieberg, Ch. 8; Tredennick et al. 2021\n\n\n\n5\nTu\n17-Sep\nModeling Strategies\n\n\nGelman and Hill Ch. 11 and 12\n\n\n \nFr\n20-Sep\nHierarchical Models / GLMM\nLab 5: GLMM\nKery and Kellner Ch. 2.7-2.10\n\n\n\n6\nTu\n24-Sep\nBayesian Inference\n\nEllison 2004\nHobbs and Hooten Ch.5.;Fieberg Ch. 11 & 12\n\n\n \nFr\n27-Sep\nBayesian Inference and Computation\nLab 6: Bayes; Bayes Quiz\n\nKurz, 2023\n\n\n7\nTu\n1-Oct\nHierarchical Bayesian\n\n\n\n\n\n \nFr\n4-Oct\nHierarchical Bayesian\nLab 7; Nothing to submit\nWidmer et al 2021; Guillera-Arroita et al. 2015\nSoley-Guardia et al. 2024; Valavi et al. 2021\n\n\n8\nTu\n8-Oct\nSpecies Distribution Modeling\n\nKery and Schaub Ch 7\n\n\n\n \nFr\n11-Oct\nMark Recapture\nLab 8: CJS\nRoyle et al. 2018\n\n\n\n9\nTu\n15-Oct\nSpatial Capture Recapture\n\nKery and Schaub Ch 13\n\n\n\n \nFr\n18-Oct\nHierarchical Bayesian Occupancy\nLab 9:HB Occu.\nZipkin and Saunders 2018; Zipkin et al. 2021; Powell and Gale Ch 18\n\n\n\n10\nTU\n22-Oct\nN-Mixture and Integrated Data Models\n\nMcCaffery et al. 2016; Kery and Kellner Ch20\n\n\n\n \nFr\n25-Oct\nIntegrated Data Models\nLab 10: ISDM\nWittemyer et al. 2019; Huggler et al. 2022\n\n\n\n11\nTu\n29-Oct\nAnimal Movement\n\n\nNathan et al 2008 and 2022; Signer et al 2018; and more\n\n\n \nFr\n1-Nov\nAnimal Movement\nLab 11: AMT; Nothing to submit\nSmith et al. 2022; Northrup et al. 2022\n\n\n\n12\nTu\n5-Nov\nHabitat Selection\n\nDraft guidance paper\n\n\n\n \nFr\n8-Nov\nHabitat Selection\nLab 12: HabSel\nWright et al 2020\n\n\n\n13\nTu\n12-Nov\nCommunity Modeling\n\n\n\n\n\n \nFr\n15-Nov\nNo Class\nLab 13: Community\n\n\n\n\n14\nTu\n19-Nov\nGroup Project work\n\n\n\n\n\n \nFr\n22-Nov\nGroup Project work\n\n\n\n\n\n15\nTu\n26-Nov\nNo Class\n\n\n\n\n\n \nFr\n29-Nov\nNo Class\n\n\n\n\n\n16\nTu\n3-Dec\nPresent Group Project\n\n\n\n\n\n \nFr\n6-Dec\nPresent Group Project"
  },
  {
    "objectID": "FW680A4/Markdown and R Stuff.html",
    "href": "FW680A4/Markdown and R Stuff.html",
    "title": "Markdown, Equations, and the Normal Distribution",
    "section": "",
    "text": "RStudio can help you use Markdown to create HTML/PDF/Word documents that can embed R code, HTML, CSS, latex (type setting language), and more. This is a good website to checkout for markdown coding.\nWe will use markdown as a way accomplish homework. This way you can provide code and document it simultaneously. I would suggest to not try and get too fancy at first. Keep it simple. Write-text in RStudio as you would in any word processor. Write R code in R chunks. Use “echo=FALSE” and “echo=TRUE” for a code chink to either not print the code or to print the code.\n\n\nThis probability function is the most widely used and heard of. It has amazing utility. Let’s get to know it a bit more intimately.\nLet’s create an R chunk and plot some data by simulating from a random variable y. Let’s define this variable such that it can take on values of any real number from \\(-\\infty\\) to \\(\\infty\\). So, \\(y \\in (-\\infty, \\infty)\\) or \\(y \\in \\mathbb{R}\\).\nMore specifically, let’s define y as having a probability density function of a Normal/Gaussian distribution,\n\\[y \\sim \\text{Normal}(\\mu, \\sigma).\\]\nAnd stated more generally as,\n\\[f(y;\\mu, \\sigma) = [y|\\mu, \\theta].\\]\n\n# Simulate data from a standard normal distribution (mu = 0, sd = 1)\n  set.seed(54235)\n  y=rnorm(100,0,1)\n\n# Create a histogram\n  hist(y)\n\n\n\n\n\n\n\n\nLet’s create a new plot and not output the code. This time we will see the true probability distribution, not simulated values.\n\n\n\n\n\n\n\n\n\nHTML code can be embedded, such as turning text a different color.\nSimple text formatting can be done directly, such as italics or bolding."
  },
  {
    "objectID": "FW680A4/Markdown and R Stuff.html#approximating-an-integral",
    "href": "FW680A4/Markdown and R Stuff.html#approximating-an-integral",
    "title": "Markdown, Equations, and the Normal Distribution",
    "section": "Approximating an Integral",
    "text": "Approximating an Integral\nLet’s understand this math a bit more. What we are doing is for every value of y possible (\\(-\\infty\\) to \\(\\infty\\)), we multiple it by its probability density. Then we take all these values and add them (i.e., the integral).\nIt’s a bit easier to understand what the math is doing by making an approximation.\nWe can approximate the integral by breaking it into pieces to calculate y times the \\(f(y; \\mu, \\sigma)\\) and then sum all these values.\n\n# Create a histogram and save the values\n  set.seed(14341)\n  y.hist=hist(rnorm(1000,0,1),breaks=8, freq=FALSE,ylim=c(0,0.4),\n              main=\"Random Normal Samples\")\n  \n# Plot the true probabiltiy denisty.\n  curve(dnorm(x,0,1),add=TRUE,lwd=3,col=2)\n  legend(\"topright\",lwd=3,col=c(2),legend=\"True Distribution\")\n\n\n\n\n\n\n\n# Get the x-axis mid-points of each bin\n  mid.point.x=y.hist$mids\n  mid.point.x\n\n[1] -3.5 -2.5 -1.5 -0.5  0.5  1.5  2.5  3.5\n\n# Get the y-axis values (probability density) for each value of the . \n  prob.y=y.hist$density\n  prob.y\n\n[1] 0.003 0.021 0.134 0.348 0.343 0.133 0.017 0.001\n\n#multiple these value and sum them\n  sum(prob.y*mid.point.x)\n\n[1] -0.021\n\n\nDoes this answer make sense?\nWhat if you did the same approximation with more simulated values and bins?"
  },
  {
    "objectID": "FW680A4/Introduction.html",
    "href": "FW680A4/Introduction.html",
    "title": "Wildlife Ecology Modeling",
    "section": "",
    "text": "Me: Brian Gerber\nClassroom: here, TuThu???\n\nLecture/Lab/Discussion\n\n\n. . .\n\nMy Office: 202A Wagar, Colorado Cooperative Research Unit\n\nOffice hours: XXXXX\nbrian.gerber@colostate.edu\n\n\n. . .\n\nComputers: Bring laptop to class\n\nSoftware/R Packages should be installed prior to lab (posted on website)"
  },
  {
    "objectID": "FW680A4/schedule.html#course-stuff-fw680a4",
    "href": "FW680A4/schedule.html#course-stuff-fw680a4",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Schedule\n\n\nCourse Overview\nReadings: Come prepared to discuss the assigned reading on the next class. What was interesting and useful? What did not make sense? What did you disagree with? What did you learn? Bring points to highlight and bring questions (make a list). Check each week’s link to see if there are listed reading questions."
  },
  {
    "objectID": "FW680A4/BigPicture.html",
    "href": "FW680A4/BigPicture.html",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "a process of learning through empirical observations\n\n. . .\n\ntogether, science philosophy and statistical modeling is the backbone to empirical learning"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#fw-680a4",
    "href": "FW680A4/Rknowledge.html#fw-680a4",
    "title": "Brian D. Gerber",
    "section": "FW 680A4",
    "text": "FW 680A4\nIn FW 680A4 (Wildlife Ecology Modeling), we will regularly use the R programming language to manipulate data and objects and use functions.\n\nI expect students know the fundamentals of base R."
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge",
    "href": "FW680A4/Rknowledge.html#r-knowledge",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nSome things I expect students to know\n\nwhat an object  is\nhow to subset and manipulate different types of objects\n\nvectors, lists, matrices, dataframes, etc.\n\n\n\nE.g…..\n\n\n# A vector of integers stored as an object...\n\nvec = seq(1,10)\n\nvec\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# A Matrix...\n\nmat = matrix(vec,nrow=2,ncol=5)\n\nmat[2,]\n\n[1]  2  4  6  8 10\n\n# A list\n\nmy.list = list(vec, mat)\n\nmy.list[[2]]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#fw-680a4-wildlife-ecology-modeling",
    "href": "FW680A4/Rknowledge.html#fw-680a4-wildlife-ecology-modeling",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "We will regularly use the R programming language to manipulate data and objects, create figures, and use functions.\n\nI expect students to know some fundamentals of base R.\n\nI am not expecting advanced knowledge of highly specialized and efficient programming.\n\nMore so, I don’t want learning base R to be an impediment of understanding what we are trying to accomplish."
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-1",
    "href": "FW680A4/Rknowledge.html#r-knowledge-1",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nAccessing a dataframe\n\nE.g…..\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-2",
    "href": "FW680A4/Rknowledge.html#r-knowledge-2",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nAccessing a dataframe\n\nE.g…..\n\nmtcars$mpg\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars[,1]\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars['mpg']\n\n                     mpg\nMazda RX4           21.0\nMazda RX4 Wag       21.0\nDatsun 710          22.8\nHornet 4 Drive      21.4\nHornet Sportabout   18.7\nValiant             18.1\nDuster 360          14.3\nMerc 240D           24.4\nMerc 230            22.8\nMerc 280            19.2\nMerc 280C           17.8\nMerc 450SE          16.4\nMerc 450SL          17.3\nMerc 450SLC         15.2\nCadillac Fleetwood  10.4\nLincoln Continental 10.4\nChrysler Imperial   14.7\nFiat 128            32.4\nHonda Civic         30.4\nToyota Corolla      33.9\nToyota Corona       21.5\nDodge Challenger    15.5\nAMC Javelin         15.2\nCamaro Z28          13.3\nPontiac Firebird    19.2\nFiat X1-9           27.3\nPorsche 914-2       26.0\nLotus Europa        30.4\nFord Pantera L      15.8\nFerrari Dino        19.7\nMaserati Bora       15.0\nVolvo 142E          21.4"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-3",
    "href": "FW680A4/Rknowledge.html#r-knowledge-3",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nAccessing a dataframe\n\nE.g…..\n\n# find the location of certain values\n\nwhich(mtcars$mpg&gt;20)\n\n [1]  1  2  3  4  8  9 18 19 20 21 26 27 28 32\n\n# manipulating those elements\n\nmtcars$mpg[which(mtcars$mpg&gt;20)] = NA\nmtcars$mpg\n\n [1]   NA   NA   NA   NA 18.7 18.1 14.3   NA   NA 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7   NA   NA   NA   NA 15.5 15.2 13.3 19.2   NA   NA   NA 15.8 19.7\n[31] 15.0   NA"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-4",
    "href": "FW680A4/Rknowledge.html#r-knowledge-4",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nWhat a function  is\n\nhow to specify attributes of a function\nhow to wrap functions\n\n\nE.g…..\n\n\n# Specifying attributes of a function\n\nmean(mtcars$mpg,\n     na.rm=TRUE\n     )\n\n[1] 15.9"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-5",
    "href": "FW680A4/Rknowledge.html#r-knowledge-5",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nWhat a function  is\n\nhow to specify attributes of a function\nhow to wrap functions\n\n\nE.g…..\n\n# Wrapping functions\n\nsim = rnorm(10, \n            mean = mean(mtcars$mpg,na.rm=TRUE),\n            sd = sd(mtcars$mpg,na.rm=TRUE)\n)\n \nsim\n\n [1] 15.854654 19.592340 17.488673 20.313817 16.970638  8.290658 17.431033\n [8] 14.562005 17.601229 17.778415"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#r-knowledge-6",
    "href": "FW680A4/Rknowledge.html#r-knowledge-6",
    "title": "Brian D. Gerber",
    "section": "R Knowledge",
    "text": "R Knowledge\nEveryone codes differently.\n\nYou may use tidy over base R. That is fine.\n\nIf you are concerned about coding, talk to Brian (202A Wagar)\n\nIf you need resources for learning R, please go here and click on the tab Learning R."
  },
  {
    "objectID": "FW680A4/Rknowledge.html",
    "href": "FW680A4/Rknowledge.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "We will regularly use the R programming language to manipulate data and objects, create figures, and use functions.\n\nI expect students to know some fundamentals of base R.\n\nI am not expecting advanced knowledge of highly specialized and efficient programming.\n\nMore so, I don’t want learning base R to be an impediment of understanding what we are trying to accomplish."
  },
  {
    "objectID": "FW680A4/Rknowledge.html#objects",
    "href": "FW680A4/Rknowledge.html#objects",
    "title": "Brian D. Gerber",
    "section": "Objects",
    "text": "Objects\nSome things I expect students to know\n\nwhat an object  is\nhow to subset and manipulate different types of objects\n\nvectors, lists, matrices, dataframes, etc.\n\n\n\nE.g…..\n\n\n# A vector of integers stored as an object...\n\nvec = seq(1,10)\n\nvec\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n# A Matrix...\n\nmat = matrix(vec,nrow=2,ncol=5)\n\nmat[2,]\n\n[1]  2  4  6  8 10\n\n# A list\n\nmy.list = list(vec, mat)\n\nmy.list[[2]]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    1    3    5    7    9\n[2,]    2    4    6    8   10"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#access",
    "href": "FW680A4/Rknowledge.html#access",
    "title": "Brian D. Gerber",
    "section": "Access",
    "text": "Access\nAccessing a dataframe\n\nE.g…..\n\nhead(mtcars)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#access-1",
    "href": "FW680A4/Rknowledge.html#access-1",
    "title": "Brian D. Gerber",
    "section": "Access",
    "text": "Access\nAccessing a dataframe\n\nE.g…..\n\nmtcars$mpg\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars[,1]\n\n [1] 21.0 21.0 22.8 21.4 18.7 18.1 14.3 24.4 22.8 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7 32.4 30.4 33.9 21.5 15.5 15.2 13.3 19.2 27.3 26.0 30.4 15.8 19.7\n[31] 15.0 21.4\n\nmtcars['mpg']\n\n                     mpg\nMazda RX4           21.0\nMazda RX4 Wag       21.0\nDatsun 710          22.8\nHornet 4 Drive      21.4\nHornet Sportabout   18.7\nValiant             18.1\nDuster 360          14.3\nMerc 240D           24.4\nMerc 230            22.8\nMerc 280            19.2\nMerc 280C           17.8\nMerc 450SE          16.4\nMerc 450SL          17.3\nMerc 450SLC         15.2\nCadillac Fleetwood  10.4\nLincoln Continental 10.4\nChrysler Imperial   14.7\nFiat 128            32.4\nHonda Civic         30.4\nToyota Corolla      33.9\nToyota Corona       21.5\nDodge Challenger    15.5\nAMC Javelin         15.2\nCamaro Z28          13.3\nPontiac Firebird    19.2\nFiat X1-9           27.3\nPorsche 914-2       26.0\nLotus Europa        30.4\nFord Pantera L      15.8\nFerrari Dino        19.7\nMaserati Bora       15.0\nVolvo 142E          21.4"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#access-2",
    "href": "FW680A4/Rknowledge.html#access-2",
    "title": "Brian D. Gerber",
    "section": "Access",
    "text": "Access\nAccessing a dataframe\n\nE.g…..\n\n# find the location of certain values\n\nwhich(mtcars$mpg&gt;20)\n\n [1]  1  2  3  4  8  9 18 19 20 21 26 27 28 32\n\n# manipulating those elements\n\nmtcars$mpg[which(mtcars$mpg&gt;20)] = NA\nmtcars$mpg\n\n [1]   NA   NA   NA   NA 18.7 18.1 14.3   NA   NA 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7   NA   NA   NA   NA 15.5 15.2 13.3 19.2   NA   NA   NA 15.8 19.7\n[31] 15.0   NA"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#function",
    "href": "FW680A4/Rknowledge.html#function",
    "title": "Brian D. Gerber",
    "section": "function",
    "text": "function\nWhat a function  is\n\nhow to specify attributes of a function\nhow to wrap functions\n\n\nE.g…..\n\n\n# Specifying attributes of a function\n\nmean(mtcars$mpg,\n     na.rm=TRUE\n     )\n\n[1] 15.9"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#function-1",
    "href": "FW680A4/Rknowledge.html#function-1",
    "title": "Brian D. Gerber",
    "section": "function",
    "text": "function\n\nE.g…..\n\n# Wrapping functions\n\nsim = rnorm(10, \n            mean = mean(mtcars$mpg,na.rm=TRUE),\n            sd = sd(mtcars$mpg,na.rm=TRUE)\n)\n \nsim\n\n [1] 17.72882 14.86549 19.22804 14.58197 14.99671 15.32980 21.51015 18.36904\n [9] 16.48433 17.26201"
  },
  {
    "objectID": "FW680A4/Rknowledge.html#last",
    "href": "FW680A4/Rknowledge.html#last",
    "title": "Brian D. Gerber",
    "section": "Last",
    "text": "Last\nEveryone codes differently.\n\nYou may use tidy over base R. That is fine.\n\nIf you are concerned about coding, talk to Brian (202A Wagar)\n\nIf you need resources for learning R, please go here and click on the tab Learning R."
  },
  {
    "objectID": "FW680A4/Rknowledge.html#indexing",
    "href": "FW680A4/Rknowledge.html#indexing",
    "title": "Brian D. Gerber",
    "section": "Indexing",
    "text": "Indexing\nIndexing a dataframe\n\nE.g…..\n\n# find the location of certain values\n\nwhich(mtcars$mpg&gt;20)\n\n [1]  1  2  3  4  8  9 18 19 20 21 26 27 28 32\n\n# manipulating those elements\n\nmtcars$mpg[which(mtcars$mpg&gt;20)] = NA\nmtcars$mpg\n\n [1]   NA   NA   NA   NA 18.7 18.1 14.3   NA   NA 19.2 17.8 16.4 17.3 15.2 10.4\n[16] 10.4 14.7   NA   NA   NA   NA 15.5 15.2 13.3 19.2   NA   NA   NA 15.8 19.7\n[31] 15.0   NA"
  },
  {
    "objectID": "R1day/index.html#packages-for-workshop",
    "href": "R1day/index.html#packages-for-workshop",
    "title": "Introduction to R",
    "section": "Packages for Workshop",
    "text": "Packages for Workshop\nPlease install from CRAN\n\ntidyverse\nreadxl\nggridges\ngridExtra\n\n\n  install.packages(c(\"tidyverse\",\n                     \"readxl\", \n                     \"ggridges\", \n                     \"gridExtra\")\n                   )"
  },
  {
    "objectID": "publications/articles/Ganoe2024.html",
    "href": "publications/articles/Ganoe2024.html",
    "title": "Mesocarnivore sensitivity to natural and anthropogenic disturbance leads to declines in occurrence and concern for species persistence",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Ganoe2024.html#citation",
    "href": "publications/articles/Ganoe2024.html#citation",
    "title": "Mesocarnivore sensitivity to natural and anthropogenic disturbance leads to declines in occurrence and concern for species persistence",
    "section": "",
    "text": "Seymour, A.S., Tarrant, M.R., Gerber, B.D., Sharp, A., Woollam, J. and Cox, R. (2017), Effects of El Niño on the population dynamics of the Malay civet east of the Wallace line. J Zool, 303: 120-128. https://doi.org/10.1111/jzo.12469"
  },
  {
    "objectID": "publications/articles/Ganoe2024.html#abstract",
    "href": "publications/articles/Ganoe2024.html#abstract",
    "title": "Mesocarnivore sensitivity to natural and anthropogenic disturbance leads to declines in occurrence and concern for species persistence",
    "section": "Abstract",
    "text": "Abstract\nProtected areas (PA) aim to eliminate many of the threats that species face on the greater landscape. In the last three decades, PA’s have expanded considerably; however, quantitative assessments of how well they have mitigated threats to habitat and biodiversity are very limited. Habitat bordering PA’s and the wildlife that use it are threatened by a wide-range of anthropogenic pressures (e.g., edge effects, fragmentation, and introduced predators) and this situation is particularly acute for low-density, poorly studied carnivore communities. From 2010 to 2015, we photographically sampled within (contiguous forest) and bordering (degraded, fragmented forest) a UNESCO World Heritage rainforest PA in Madagascar - Ranomafana National Park (RNP). We investigated the effects of invasive predators, local people presence, and habitat quality on the endemic rainforest carnivore community using static, dynamic, and co-occurrence models. We found native carnivores to be absent or have a low probability of occurrence in degraded forest bordering the PA, while local people and dogs (Canis familiaris) had high occurrence. Madagascar’s largest endemic carnivore, the fosa (Cryptoprocta ferox) and the much smaller ring-tailed vontsira (Galidia elegans), occurrence in RNP declined rapidly over six years; their strong co-occurrence with dogs suggests interspecific competition, direct aggression/mortality, or disease as the cause. We highlight the dangers posed to biodiversity, particularly carnivores, from anthropogenic pressures bordering PA’s and present recommendations to address increased human and dog activity, including programs to control dogs and their impact on biodiversity."
  },
  {
    "objectID": "FW680A4/Introduction.html#file-managements",
    "href": "FW680A4/Introduction.html#file-managements",
    "title": "Wildlife Ecology Modeling",
    "section": "File managements",
    "text": "File managements\nProject Folder\nSubfolders:\n\ndata\noutputs\nplots\nR"
  },
  {
    "objectID": "FW680A4/Introduction.html#file-management",
    "href": "FW680A4/Introduction.html#file-management",
    "title": "Wildlife Ecology Modeling",
    "section": "File management",
    "text": "File management\nProject Folder\nSubfolders:\n\ndata\noutputs\nplots\nR"
  },
  {
    "objectID": "FW680A4/Introduction.html#science-practice",
    "href": "FW680A4/Introduction.html#science-practice",
    "title": "Wildlife Ecology Modeling",
    "section": "Science Practice",
    "text": "Science Practice\n\nI am a pragmatist\n\n\n\nThere are many ways to do great science\n\n\n\n\nThere are more ways to do meh science\n\n\n\n\nDisciplines have conventions\n\n\n\n\nThere are foundations of scientific and statistical learning\n\n\n\n\nKnow the why of your decisions\n\n\n\n\nAsk lots of questions to everybody all the time"
  },
  {
    "objectID": "FW680A4/Introduction.html#section",
    "href": "FW680A4/Introduction.html#section",
    "title": "Wildlife Ecology Modeling",
    "section": "",
    "text": "Class Questions"
  },
  {
    "objectID": "FW680A4/Introduction.html#some-useful-functions-3",
    "href": "FW680A4/Introduction.html#some-useful-functions-3",
    "title": "Wildlife Ecology Modeling",
    "section": "Some useful functions",
    "text": "Some useful functions\nCreate your own function - Better\n\nmy.mean.func = function(x){\n                           sum(x)/length(x)\n                          }"
  },
  {
    "objectID": "FW680A4/Introduction.html#code-organization",
    "href": "FW680A4/Introduction.html#code-organization",
    "title": "Wildlife Ecology Modeling",
    "section": "Code Organization",
    "text": "Code Organization\n\n\nHierarchical code organization\n\ncode structure using indenting\ntop –&gt; bottom execution\n\n\n\n\nHelp! My code doesn’t work…\n\n                cor.sp.route.cor=vector(\"list\",n.species)\ncor.sp=rep(NA,n.species)\n            for(s in 1:n.species){\nroute=new.cov.species.long.scaled[[s]]$routeID\ncor.sp[s]=cor(patch.size20.species.scaled.mat.center.route[s,],patch.count20.species.scaled.mat.center.route[s,])\n    for(i in 1:nroutes){\ntemp1=patch.size20.species.scaled.mat.center.route[s,which(route==route.id[i])]\n  temp2=patch.count20.species.scaled.mat.center.route[,][s,which(route==route.id[i])]\n  if(length(temp1)&gt;5){\n  cor.sp.route.cor[[s]]=abs(c(cor.sp.route.cor[[s]],cor(temp1,temp2)))\n  }}}"
  },
  {
    "objectID": "FW680A4/Introduction.html#better",
    "href": "FW680A4/Introduction.html#better",
    "title": "Wildlife Ecology Modeling",
    "section": "Better…",
    "text": "Better…\n\n# Create Storage objects\n  cor.sp.route.cor=vector(\"list\",n.species)\n  cor.sp=rep(NA,n.species)\n\n#loop over species    \n  for(s in 1:n.species)\n    {\n      route=new.cov.species.long.scaled[[s]]$routeID\n                        \n      cor.sp[s] = cor(patch.size20.species.scaled.mat.center.route[s,],\n                      patch.count20.species.scaled.mat.center.route[s,]\n                      )\n        # loop over species and routes                    \n        for(i in 1:nroutes)\n          {\n            temp1 = patch.size20.species.scaled.mat.center.route[s,which(route==route.id[i])]\n            temp2 = patch.count20.species.scaled.mat.center.route[,][s,which(route==route.id[i])]\n            if(length(temp1)&gt;5){\n                                cor.sp.route.cor[[s]]=abs(c(cor.sp.route.cor[[s]],cor(temp1,temp2)))\n                                } #End if statement\n          } #End routes loop\n                       \n    } #End species loop"
  },
  {
    "objectID": "FW680A4/BigPicture.html#placeholder",
    "href": "FW680A4/BigPicture.html#placeholder",
    "title": "Big Picture  Science and Modeling",
    "section": "Placeholder",
    "text": "Placeholder\n\n\nData is everywhere; it is the era of  BIG DATA"
  },
  {
    "objectID": "R1day/index.html",
    "href": "R1day/index.html",
    "title": "Introduction to R",
    "section": "",
    "text": "Download this presentation as pdf\nDownload Files for today\n\nTo save either file…. Right-click –&gt; ‘Save link as…’. Save file to location. Go to RStudio or Acrobat. File –&gt; Open File… find your file."
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-picture",
    "href": "FW680A4/BigPicture.html#big-picture",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Picture",
    "text": "Big Picture\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling\n3. Model-Based vs Design-Based Inference\n4. Inference and Prediction\n\n\n\nLab: Simulation and Markdown"
  },
  {
    "objectID": "FW680A4/BigPicture.html#hypotheses-and-predictions",
    "href": "FW680A4/BigPicture.html#hypotheses-and-predictions",
    "title": "Big Picture  Science and Modeling",
    "section": "Hypotheses and Predictions",
    "text": "Hypotheses and Predictions\nStudy Objective\n\nDefinition\nWhat you want to accomplish. Can have multiple related in a single manuscript.\n\n\nDefinition\nEx: to understand space-use of coyotes in urban areas."
  },
  {
    "objectID": "FW680A4/BigPicture.html#hypotheses-and-predictions-1",
    "href": "FW680A4/BigPicture.html#hypotheses-and-predictions-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Hypotheses and Predictions",
    "text": "Hypotheses and Predictions\nHypothesis\n\nDefinition\n\nA story that explains how the world works\nAn explanation for an observed phenomenon\n\n\n\nExample\nTHIS"
  },
  {
    "objectID": "FW680A4/BigPicture.html#hypotheses-and-predictions-2",
    "href": "FW680A4/BigPicture.html#hypotheses-and-predictions-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Hypotheses and Predictions",
    "text": "Hypotheses and Predictions\nResearch Hypothesis\n\nResearch Hypothesis\nA statement about a phenomenon that also includes the potential mechanism or cause of that phenomenon. (Betts et al. 2021)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#study-objective",
    "href": "FW680A4/BigPicture.html#study-objective",
    "title": "Big Picture  Science and Modeling",
    "section": "Study Objective",
    "text": "Study Objective\n\nDefinition\nWhat you want to accomplish; can have multiple related objectives in a single manuscript.\n\n\nExample\nTo understand the space-use of coyotes.\n\n\nFraming the importance of the objective(s) provides the justification and depends on the audience."
  },
  {
    "objectID": "FW680A4/BigPicture.html#hypothesis",
    "href": "FW680A4/BigPicture.html#hypothesis",
    "title": "Big Picture  Science and Modeling",
    "section": "Hypothesis",
    "text": "Hypothesis\n\nDefinition\n\nA story that explains how the world works\nAn explanation for an observed phenomenon\n\n\n\nExample (weak)\nCoyotes have small home ranges in urban areas"
  },
  {
    "objectID": "FW680A4/BigPicture.html#research-hypothesis",
    "href": "FW680A4/BigPicture.html#research-hypothesis",
    "title": "Big Picture  Science and Modeling",
    "section": "Research Hypothesis",
    "text": "Research Hypothesis\n\nDefinition\n“A statement about a phenomenon that also includes the potential mechanism or cause of that phenomenon”. (Betts et al. 2021)\n\n\nExample\nCoyotes have small home ranges in urban area because food resource density is high\n\n\nNon-Research hypothesis: We hypothesize variation in coyote home range size."
  },
  {
    "objectID": "FW680A4/BigPicture.html#prediction",
    "href": "FW680A4/BigPicture.html#prediction",
    "title": "Big Picture  Science and Modeling",
    "section": "Prediction",
    "text": "Prediction\n\nDefinition\nThe expected outcome from a hypothesis. If agrees with data, it would support the hypothesis or at least not reject it.\n\n\nExample 1\n\nOkay: Coyote home ranges are smaller in urban areas compared to non-urban areas\n\n\n\nExample 2\n\nBetter: Coyote home ranges in urban areas with high available food resources is smaller than coyote home ranges in urban areas with less available food resources and smaller than coyotes living in non-urban areas"
  },
  {
    "objectID": "FW680A4/BigPicture.html#researchscientific-hypothesis",
    "href": "FW680A4/BigPicture.html#researchscientific-hypothesis",
    "title": "Big Picture  Science and Modeling",
    "section": "Research/Scientific Hypothesis",
    "text": "Research/Scientific Hypothesis\n\nDefinition\n“A statement about a phenomenon that also includes the potential mechanism or cause of that phenomenon”. (Betts et al. 2021)\n\n\nExample\nCoyotes have small home ranges in urban areas because food resource density is high\n\n\nNon-hypothesis hypothesis:  We hypothesize variation in coyote home range size."
  },
  {
    "objectID": "FW680A4/BigPicture.html#types-of-studies",
    "href": "FW680A4/BigPicture.html#types-of-studies",
    "title": "Big Picture  Science and Modeling",
    "section": "Types of Studies",
    "text": "Types of Studies\n\nDescriptive/Naturalist (not hypothetico-deductive)\nHypothetico-Deductive Observational\nHypothetico-Deductive Experimental"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-modelshypothesis",
    "href": "FW680A4/BigPicture.html#statistical-modelshypothesis",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Models/Hypothesis",
    "text": "Statistical Models/Hypothesis\n\nDefinition\n\nAn explicit quantitative representation of the observational & mechanistic process of how your empirical observations came to be that recognizes uncertainty."
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-modelshypothesis-1",
    "href": "FW680A4/BigPicture.html#statistical-modelshypothesis-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Models/Hypothesis",
    "text": "Statistical Models/Hypothesis\nE.g.,\n\\[\\textbf{y} = \\beta_0 + \\beta_1 \\times \\textbf{Cov} + \\mathbf{\\epsilon}\\]\n\nwhere…\n\\(\\textbf{y}\\) = home range sizes of coyotes  \\(\\beta_0\\) = intercept  \\(\\beta_1\\) = slope  \\(\\mathbf{\\epsilon} \\sim \\text{Normal}(0, \\sigma^2\\))  \\(\\sigma^2\\) = uncertainty / unknown variability"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-modelhypothesis",
    "href": "FW680A4/BigPicture.html#statistical-modelhypothesis",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Model/Hypothesis",
    "text": "Statistical Model/Hypothesis\n\nDefinition\n\nAn explicit mathematical and stochastic representation of the observational & mechanistic process of the empirical observations."
  },
  {
    "objectID": "FW680A4/BigPicture.html#manuscript",
    "href": "FW680A4/BigPicture.html#manuscript",
    "title": "Big Picture  Science and Modeling",
    "section": "Manuscript",
    "text": "Manuscript\nWhere do you put these?\n\nobjective\njustification of objective\nhypothesis\nprediction"
  },
  {
    "objectID": "FW680A4/BigPicture.html#manuscript-writing",
    "href": "FW680A4/BigPicture.html#manuscript-writing",
    "title": "Big Picture  Science and Modeling",
    "section": "Manuscript Writing",
    "text": "Manuscript Writing\nWhere do you put these?\n\nobjectives\njustification of objectives\nhypotheses\npredictions"
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data",
    "href": "FW680A4/BigPicture.html#big-data",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data",
    "text": "Big Data\n\n\nData is everywhere; it is the era of  BIG DATA"
  },
  {
    "objectID": "FW680A4/BigPicture.html#big-data-background-image-imgbigdata.png",
    "href": "FW680A4/BigPicture.html#big-data-background-image-imgbigdata.png",
    "title": "Big Picture  Science and Modeling",
    "section": "Big Data {background-image = “/img/BigData.png”}",
    "text": "Big Data {background-image = “/img/BigData.png”}\n\n\nData is everywhere; it is the era of  BIG DATA"
  },
  {
    "objectID": "FW680A4/BigPicture.html#section",
    "href": "FW680A4/BigPicture.html#section",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "Data is everywhere  It is the era of  BIG DATA"
  },
  {
    "objectID": "FW680A4/BigPicture.html#section-1",
    "href": "FW680A4/BigPicture.html#section-1",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "Data is everywhere  It is the era of  BIG DATA!"
  },
  {
    "objectID": "FW680A4/BigPicture.html#infernence-and-prediction-2",
    "href": "FW680A4/BigPicture.html#infernence-and-prediction-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Infernence and Prediction",
    "text": "Infernence and Prediction\nWhen does an explantory model likely predict better than a predictive model?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#inference-and-prediction-1",
    "href": "FW680A4/BigPicture.html#inference-and-prediction-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Inference and Prediction",
    "text": "Inference and Prediction\n\n\nFrom \"To Explain or to Predict\" by Galit Shmueli (Statistical Science, 2010):\n\nExplanatory modeling focuses on minimizing (statistical) bias to obtain the most accurate representation of the underlying theory.\n\n\nPredictive modeling focuses on minimizing both bias and estimation variance; this may sacrifice theoretical accuracy for improved empirical precision."
  },
  {
    "objectID": "FW680A4/BigPicture.html#inference-and-prediction-2",
    "href": "FW680A4/BigPicture.html#inference-and-prediction-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Inference and Prediction",
    "text": "Inference and Prediction\nThis leads to a strange result: \n\nthe \"wrong\"  statistical model can predict better than the correct one.\n\n\nBUT …\nExplanatory models will likely perform better when predicting outside of the sample space and the model has the core underlying processes"
  },
  {
    "objectID": "FW680A4/BigPicture.html#inference-and-prediction-3",
    "href": "FW680A4/BigPicture.html#inference-and-prediction-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Inference and Prediction",
    "text": "Inference and Prediction\n\nTrade-Off between prediction accuracy and model interpretability; from James et al. 2013. An Introduction to Statistical Learning"
  },
  {
    "objectID": "FW680A4/BigPicture.html#section-2",
    "href": "FW680A4/BigPicture.html#section-2",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "Inference and Prediction"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-modelhypothesis-1",
    "href": "FW680A4/BigPicture.html#statistical-modelhypothesis-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Model/Hypothesis",
    "text": "Statistical Model/Hypothesis\nExample:\n\\[\\textbf{y} = \\beta_0 + \\beta_1 \\times \\textbf{x} + \\mathbf{\\epsilon}\\] \\[\\mathbf{\\epsilon} \\sim \\text{Normal}(0, \\sigma^2)\\]\n\nwhere…\n\\(\\textbf{y}\\) = vector of home range sizes of coyotes  \\(\\beta_0\\) = intercept  \\(\\beta_1\\) = effect diff. of HR size for urban coyotes  \\(\\textbf{x}\\) = indicator of HR in urban (1) or not in urban (0)  \\(\\sigma^2\\) = uncertainty / unknown variability"
  },
  {
    "objectID": "FW680A4/BigPicture.html#sampling",
    "href": "FW680A4/BigPicture.html#sampling",
    "title": "Big Picture  Science and Modeling",
    "section": "Sampling",
    "text": "Sampling\nWhen do we need statistics?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based",
    "href": "FW680A4/BigPicture.html#design-based",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\n\n\n\n\nThompson, 2012. Sampling.\nThe sample and population are what??"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-vs.-model",
    "href": "FW680A4/BigPicture.html#design-vs.-model",
    "title": "Big Picture  Science and Modeling",
    "section": "Design vs. Model",
    "text": "Design vs. Model\nrandomness comes in fundamentally different ways."
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-1",
    "href": "FW680A4/BigPicture.html#design-based-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\n\n\n\n\n\ninference relies on randomly assigning some units to be in the sample (e.g., random sampling)."
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-2",
    "href": "FW680A4/BigPicture.html#design-based-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\n\n\n\n\n\nthe values themselves are held to be fixed, whereas the sampling process is random."
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based",
    "href": "FW680A4/BigPicture.html#model-based",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based",
    "text": "Model-Based\nInference relies on …\n “a statistical model describing how observations on population units are thought to have been generated from a super‐population with potentially infinitely many observations for each unit;” Williams and Brown, 2019\n\n\n“The analysis need not account for sampling randomization, because the sample is considered fixed. However, the unit values are considered random.” Williams and Brown, 2019"
  },
  {
    "objectID": "FW680A4/BigPicture.html#section-3",
    "href": "FW680A4/BigPicture.html#section-3",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "Design- and Model-Based Sampling/Inference"
  },
  {
    "objectID": "FW680A4/BigPicture.html#inference-and-prediction-4",
    "href": "FW680A4/BigPicture.html#inference-and-prediction-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Inference and Prediction",
    "text": "Inference and Prediction\n\nTrade-Off between prediction accuracy and model interpretability; from James et al. 2013. An Introduction to Statistical Learning"
  },
  {
    "objectID": "FW680A4/BigPicture.html#section-4",
    "href": "FW680A4/BigPicture.html#section-4",
    "title": "Big Picture  Science and Modeling",
    "section": "",
    "text": "When do we need statistics?"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code",
    "href": "FW680A4/BigPicture.html#design-based-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nTRUTH\n\n#random discrete uniform sampler\nrdu&lt;-function(n,lower,upper){sample(lower:upper,n,replace=T)}\n\nmat = matrix(rdu(25, \n                 lower = 0, \n                 upper = 400\n                 ),\n             nrow=5, ncol=5\n             )\nmat\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]   51   33  294  191  366\n[2,]  184   71  312  302  290\n[3,]   99  285   98  336  128\n[4,]    0  298  105   15  294\n[5,]  216  224   88  341   30"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-1",
    "href": "FW680A4/BigPicture.html#design-based-code-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nRandom Sampling\n\n  n = 10\n  y = sample(\n             c(mat),\n             10, \n             replace = TRUE\n             )\n  y\n\n [1] 216 285 216  30 312 341 216  71  30 294\n\n\n\n\n\nEstimator for the population mean\n\n  mean(y)\n\n[1] 201.1"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-2",
    "href": "FW680A4/BigPicture.html#design-based-code-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nSampling Distribution\n\n# How many ways can we uniquely sample 10 things from 25\ncombs = function(n, x) {\n  factorial(n) / factorial(n-x) / factorial(x)\n}\n\ncombs(25, 10)\n\n[1] 3268760"
  },
  {
    "objectID": "FW680A4/BigPicture.html#random-variable",
    "href": "FW680A4/BigPicture.html#random-variable",
    "title": "Big Picture  Science and Modeling",
    "section": "Random Variable",
    "text": "Random Variable\nWikipedia: A random variable (also called ‘random quantity’ or ‘stochastic variable’) is a mathematical formalization of a quantity or object which depends on random events.\n\n\nWe observe samples from the domain or population or sampling frame.\n\n\n\nSamples are observed with some probability."
  },
  {
    "objectID": "FW680A4/BigPicture.html#whats-the-point-of-statistics",
    "href": "FW680A4/BigPicture.html#whats-the-point-of-statistics",
    "title": "Big Picture  Science and Modeling",
    "section": "What’s the point of statistics?",
    "text": "What’s the point of statistics?\n\n\n\na process of learning through empirical observations\n\n\n\ntogether, science philosophy and statistical modeling is the backbone to empirical learning"
  },
  {
    "objectID": "FW680A4/BigPicture.html#today",
    "href": "FW680A4/BigPicture.html#today",
    "title": "Big Picture  Science and Modeling",
    "section": "Today",
    "text": "Today\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling\n3. Inference and Prediction\n4. Model-Based vs Design-Based Sampling/Inference\n\n\n\nLab: Simulation and Markdown"
  },
  {
    "objectID": "FW680A4/BigPicture.html#markdown-lab",
    "href": "FW680A4/BigPicture.html#markdown-lab",
    "title": "Big Picture  Science and Modeling",
    "section": "Markdown Lab",
    "text": "Markdown Lab\n\nDesign-based: explore the sampling distribution by exploring all possible - knowing truth (all values)\nModel-based: we assume parameters are known to investigate the sampling distribution."
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-1",
    "href": "FW680A4/BigPicture.html#model-based-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based",
    "text": "Model-Based\nBUT….\nwhen linking ‘unit values’ in a model, we need to account for their dependence.\n\n\nRandomization allows us to make conditional independence claims among data in our sample, thus the model is simpler.\n\n\n\n\\(P(y_{2}|y_{1}) = P(y_{2})\\)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-2",
    "href": "FW680A4/BigPicture.html#model-based-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based",
    "text": "Model-Based\n\nKey Strengths: Very flexible. Modeling is magic.\n\n\n\nKey Weaknesses: 1) Can be difficult to assess assumptions and 2) sampling frame is not always clear and thus the population you are infering to is not entirely clear"
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-code",
    "href": "FW680A4/BigPicture.html#model-based-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based Code",
    "text": "Model-Based Code\n\n#Create a function, to be replicated\n  lambda=200\n  n.sim=500\n  mat.fn = function(lambda){matrix(rpois(25, lambda=lambda),\n                               nrow=5, ncol=5\n                               )\n  }"
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-code-1",
    "href": "FW680A4/BigPicture.html#model-based-code-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based Code",
    "text": "Model-Based Code\n\n# repeat the function n.sim times\n  list.mat = replicate(n.sim, \n                       mat.fn(lambda), \n                       simplify=FALSE\n                       )\n  length(list.mat)\n\n[1] 500\n\n\n\n\n#One realization\n  list.mat[[1]]\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]  213  221  202  204  173\n[2,]  195  182  193  190  215\n[3,]  221  216  187  182  179\n[4,]  176  196  218  210  211\n[5,]  218  182  193  229  188\n\n# Sample mean for the first realization\n  mean(list.mat[[1]])\n\n[1] 199.76"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-3",
    "href": "FW680A4/BigPicture.html#design-based-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\nKey Strengths: the population of interest is often defined (e.g., grid area); does not relying on stochastic models representing the structure of the data for reliable inference\n\n\n\nKey Weaknesses: limited in application; still requires models to accommodate observational processes, such as detection probability"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-4",
    "href": "FW680A4/BigPicture.html#design-based-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\n\\(\\textbf{Y}\\) = [\\(y_1\\),…,\\(y_N\\)]\n\n\nThis means something different:\n\n\\(\\textbf{Y}\\) = (\\(y_1\\),…,\\(y_N\\))\n\n\n\n\n(stuff) is exclusive of end points\n[stuff] is inclusive of end points"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-5",
    "href": "FW680A4/BigPicture.html#design-based-5",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based",
    "text": "Design-Based\n\n\\(\\textbf{Y}\\) = [\\(y_1\\),…,\\(y_N\\)]\nThe mean is \\(\\bar{Y} = \\sum_{i=1}^N Y_i / N\\) and the sample mean is \\(\\hat{\\bar{y}} = \\sum_{i=1}^n y_i / n\\)\n\n\n\nThe population mean describes ….?\n\n\n\n\n\\(\\textbf{y}\\) is a random vector that has \\(n\\) random variables. One sample of 4 cells.\n\n\n\n\\(\\boldsymbol{y} = \\begin{matrix} [y_{1} & y_{2} & y_{3} & y_{4 }]\\end{matrix}\\)\n\n\n\\(\\boldsymbol{y}' = \\boldsymbol{y}^{T}  = \\begin{bmatrix} y_{1} & \\\\y_{2} &\\\\  y_{3}  & \\\\y_{4 }\\end{bmatrix}\\)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistic",
    "href": "FW680A4/BigPicture.html#statistic",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistic",
    "text": "Statistic\n\n\\(\\hat{\\bar{y}}\\) is a ‘statistic’ (# computed from a sample) and is also a random variable\n\n\n\nstatistics have a sampling distribution, describing the probability associated to observing different values of the statistic"
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-3",
    "href": "FW680A4/BigPicture.html#model-based-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based",
    "text": "Model-Based\n\n\\(\\textbf{y} \\sim\\) Poisson(\\(\\lambda\\)) Wikipedia link\n\\(y_{i} \\sim\\) Poisson(\\(\\lambda\\))\n\n\n\n\\(\\lambda\\) is the population mean and variance\n\n\n\n\nSample mean Estimator \\(\\hat{\\lambda} = \\sum_{i=1}^n y_{i}/n\\)\n\n\n\n\nMaximum-Likelihood Estimate (MLE)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#take-aways",
    "href": "FW680A4/BigPicture.html#take-aways",
    "title": "Big Picture  Science and Modeling",
    "section": "Take-Aways?",
    "text": "Take-Aways?\n1. Study Objectives, Hypotheses, and Predictions"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab",
    "href": "FW680A4/BigPicture.html#lab",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab",
    "text": "Lab\nObjectives\n\nIntroduce R Markdown\nUse simulation and design-based sampling to investigate bias and precision"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-bias-and-precision",
    "href": "FW680A4/BigPicture.html#statistical-bias-and-precision",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Bias and Precision",
    "text": "Statistical Bias and Precision\n\n\\(\\textbf{y} \\sim \\text{Poisson}(\\lambda)\\)\n\n\n\n\\(\\text{Bias}(\\lambda) = E_{y|\\lambda}[\\hat{\\lambda}] - \\lambda\\)\n\n\n\n\n\\(E_{y|\\lambda}[\\hat{\\lambda}]\\) is the expected over the distribution P(y|\\(\\lambda\\)) (i.e., averaging over all possible observations y). Wikipedia\n\n\n\n\nAn estimator is said to be unbiased if its bias is equal to zero for all values of the parameter, or equivalently, if the expected value of the estimator matches that of the parameter. Wikipedia"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-bias",
    "href": "FW680A4/BigPicture.html#statistical-bias",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Bias",
    "text": "Statistical Bias\nthe difference b/w the true value and the mean of the sampling distribution of all possible values; applies to design- and model-based sampling"
  },
  {
    "objectID": "FW680A4/BigPicture.html#precision",
    "href": "FW680A4/BigPicture.html#precision",
    "title": "Big Picture  Science and Modeling",
    "section": "Precision",
    "text": "Precision\nFor a given sample size, what is the probability that we will observe a mean within 5% of the truth?\nWe can do this doing Monte Carlo integration\n\n\n\n[1] 5\n\n\n[1] 0.914"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-bias-code",
    "href": "FW680A4/BigPicture.html#statistical-bias-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Bias (Code)",
    "text": "Statistical Bias (Code)\n\n# Bias\n  mean(lambda.hat) - lambda\n\n[1] 0.00544\n\n# relative bias\n  (mean(lambda.hat) - lambda)/lambda\n\n[1] 2.72e-05"
  },
  {
    "objectID": "FW680A4/BigPicture.html#statistical-modelhypothesis-2",
    "href": "FW680A4/BigPicture.html#statistical-modelhypothesis-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Statistical Model/Hypothesis",
    "text": "Statistical Model/Hypothesis\nExample:\n\\[\\textbf{y} = \\beta_0 + \\beta_1 \\times \\textbf{x} + \\mathbf{\\epsilon}\\] \\[\\mathbf{\\epsilon} \\sim \\text{Normal}(0, \\sigma^2)\\]\nEvidence of hypothesis support\n\\(\\beta_1\\) is negative and statistically clearly different1 than zero"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup",
    "href": "FW680A4/BigPicture.html#lab-setup",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nLet’s add some more reality in our work while using design-based sampling in R.\n\n\nObjective: Evaluate sample size trade-offs for estimating white-tailed deer abundance throughout Rhode Island.\n\n\nMethodology: Count deer in 1 sq. mile cells using FLIR technology attached to a helicopter."
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup-1",
    "href": "FW680A4/BigPicture.html#lab-setup-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nSteps to consider\n\n\n\nSampling Frame\n\nall of RI or some subset"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup-2",
    "href": "FW680A4/BigPicture.html#lab-setup-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nSteps to consider\n\n\n\n“Truth”\n\nhow many deer per cell; how variable"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup-3",
    "href": "FW680A4/BigPicture.html#lab-setup-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nSteps to consider\n\n\n\nSampling Process\n\nhow to pick each cell"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup-4",
    "href": "FW680A4/BigPicture.html#lab-setup-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nSteps to consider\n\n\n\nEstimation Process\n\nestimate total deer population from the sample\n\nCriteria to Evaluate\n\nuse sampling distribution of deer abundance estimate or some other statistic"
  },
  {
    "objectID": "FW680A4/BigPicture.html#go-to-code",
    "href": "FW680A4/BigPicture.html#go-to-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Go to code",
    "text": "Go to code"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup---bias-code",
    "href": "FW680A4/BigPicture.html#lab-setup---bias-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup - Bias (Code)",
    "text": "Lab Setup - Bias (Code)\n\n  # Bias\n  bias.lambda = mean(lambda.hat) - lambda\n  bias.lambda\n\n[1] 0.0304\n\n  # relative bias\n  (mean(lambda.hat) - lambda)/lambda\n\n[1] 0.000152"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup---precision-code",
    "href": "FW680A4/BigPicture.html#lab-setup---precision-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup - Precision (Code)",
    "text": "Lab Setup - Precision (Code)\nFor a given sample size, what is the probability that we will observe a mean within 5% of the truth?\nWe can do this doing Monte Carlo integration\n\n\n  diff = 0.025*lambda\n  diff\n\n[1] 5\n\n  lower = lambda-diff\n  upper = lambda+diff\n\nindex = which(lambda.hat&gt;=lower & lambda.hat &lt;= upper)\n\n#Probability of getting a mean within 5% of the truth\nlength(index)/n.sim\n\n[1] 0.93"
  },
  {
    "objectID": "FW680A4/BigPicture.html#lab-setup-5",
    "href": "FW680A4/BigPicture.html#lab-setup-5",
    "title": "Big Picture  Science and Modeling",
    "section": "Lab Setup",
    "text": "Lab Setup\nSteps to consider\n\n\n\nEstimation Process\n\nestimate total deer population from the sample\n\nCriteria to Evaluate\n\nuse sampling distribution of deer abundance estimate or some other statistic"
  },
  {
    "objectID": "publications/articles/Rivera2024.html",
    "href": "publications/articles/Rivera2024.html",
    "title": "Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes",
    "section": "",
    "text": "Rivera, K., Garcia-Quijano, C., Sonnet, V., & Gerber, B. D. (2024). Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes. Conservation Science and Practice, e13177. https://doi.org/10.1111/csp2.13177"
  },
  {
    "objectID": "publications/articles/Rivera2024.html#citation",
    "href": "publications/articles/Rivera2024.html#citation",
    "title": "Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes",
    "section": "",
    "text": "Rivera, K., Garcia-Quijano, C., Sonnet, V., & Gerber, B. D. (2024). Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes. Conservation Science and Practice, e13177. https://doi.org/10.1111/csp2.13177"
  },
  {
    "objectID": "publications/articles/Rivera2024.html#abstract",
    "href": "publications/articles/Rivera2024.html#abstract",
    "title": "Applying a hierarchical Bayesian framework to reveal how fear and animal ownership drive human’s valuation of and interactions with coyotes",
    "section": "Abstract",
    "text": "Abstract\nHuman dimensions research is valuable to managing human-wildlife interactions, especially in urban environments where such interactions are common. Survey data, which commonly contain Likert scales and questions, are useful in this field; however, these data can be difficult to analyze with formal modeling approaches. We demonstrate one approach, based on hierarchical Bayesian ordinal regression, to evaluate human-coyote relationships in Rhode Island, USA. We implemented a survey to collect demographic and sociocultural characteristics of Rhode Island residents and information related to their knowledge of and experiences with coyotes. Our objectives were to assess how these characteristics affected respondents’ valuation of and interactions (sightings and incidents) with coyotes. We analyzed 980 surveys from October to December 2020. We found that respondents who had fear of coyotes or experienced an incident between an owned animal and coyote, had the lowest valuation of coyotes. The same demographic of respondents also reported the highest sightings of and incidents with coyote. These results indicate that fearful residents, in addition to pet and livestock owners, are priority targets for disseminating information or programming about coyotes. Our analyses and findings demonstrate how Bayesian ordinal regression can provide clear and appropriate inference from survey data on how groups of people vary in their relationship with wildlife. These results are important in effectively and efficiently allocating resources towards mitigation, education, and management of human-wildlife interactions."
  },
  {
    "objectID": "publications/articles/GerberMarkBook.html",
    "href": "publications/articles/GerberMarkBook.html",
    "title": "Occupancy models – single-species",
    "section": "",
    "text": "Gerber, BD, Martin, D, Bailey, L, Chambert, T, and Mosher, B. 2022. Occupancy models – single-species, Chapter 21 in Program MARK – a ’gentle introduction."
  },
  {
    "objectID": "publications/articles/GerberMarkBook.html#citation",
    "href": "publications/articles/GerberMarkBook.html#citation",
    "title": "Occupancy models – single-species",
    "section": "",
    "text": "Gerber, BD, Martin, D, Bailey, L, Chambert, T, and Mosher, B. 2022. Occupancy models – single-species, Chapter 21 in Program MARK – a ’gentle introduction."
  },
  {
    "objectID": "FW680A4/BigPicture.html#whis-is-worse",
    "href": "FW680A4/BigPicture.html#whis-is-worse",
    "title": "Big Picture  Science and Modeling",
    "section": "Whis is worse?",
    "text": "Whis is worse?\n\nunbiased imprecise result\nprecise biased result"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-3",
    "href": "FW680A4/BigPicture.html#design-based-code-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nGet Every combination and then calcualte the mean for each sample of 10\n\n  set.seed(5435)\n  all.combs = utils::combn(c(mat), 10)\n  dim(all.combs)\n\n[1]      10 3268760\n\n  mean.all.combs = apply(all.combs,2,mean)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-4",
    "href": "FW680A4/BigPicture.html#design-based-code-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nOR, we can sample enough times to approximate it\n\n  set.seed(5435)\n  sim.sampling.dist=replicate(2000,\n                              sample(c(mat),10)\n                              )\n  dim(sim.sampling.dist)\n\n[1]   10 2000\n\n  mean.samples = apply(sim.sampling.dist,2,mean)"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-5",
    "href": "FW680A4/BigPicture.html#design-based-code-5",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code"
  },
  {
    "objectID": "FW680A4/BigPicture.html#design-based-code-6",
    "href": "FW680A4/BigPicture.html#design-based-code-6",
    "title": "Big Picture  Science and Modeling",
    "section": "Design-Based Code",
    "text": "Design-Based Code\nSampling Distribution of the Mean"
  },
  {
    "objectID": "FW680A4/BigPicture.html#model-based-code-2",
    "href": "FW680A4/BigPicture.html#model-based-code-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Model-Based Code",
    "text": "Model-Based Code\nSampling Distribution\n\nlambda.hat = unlist(lapply(list.mat,FUN=mean))"
  },
  {
    "objectID": "FW680A4/BigPicture.html#precision-of-the-mean-code",
    "href": "FW680A4/BigPicture.html#precision-of-the-mean-code",
    "title": "Big Picture  Science and Modeling",
    "section": "Precision of the mean (Code)",
    "text": "Precision of the mean (Code)\nWhat is the probability that we will observe a mean within 5% of the truth?\n\nWe can calculate this using Monte Carlo integration\n\n\n\n  diff = 0.025*lambda\n  diff\n\n[1] 5\n\n  lower = lambda-diff\n  upper = lambda+diff\n\n  index = which(lambda.hat&gt;=lower & lambda.hat &lt;= upper)\n\n#Probability of getting a mean within 5% of the truth\n  length(index)/n.sim\n\n[1] 0.934"
  },
  {
    "objectID": "FW680A4/BigPicture.html#take-aways-1",
    "href": "FW680A4/BigPicture.html#take-aways-1",
    "title": "Big Picture  Science and Modeling",
    "section": "Take-Aways",
    "text": "Take-Aways\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling"
  },
  {
    "objectID": "FW680A4/BigPicture.html#take-aways-2",
    "href": "FW680A4/BigPicture.html#take-aways-2",
    "title": "Big Picture  Science and Modeling",
    "section": "Take-Aways",
    "text": "Take-Aways\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling\n3. Inference and Prediction"
  },
  {
    "objectID": "FW680A4/BigPicture.html#take-aways-3",
    "href": "FW680A4/BigPicture.html#take-aways-3",
    "title": "Big Picture  Science and Modeling",
    "section": "Take-Aways",
    "text": "Take-Aways\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling\n3. Inference and Prediction\n4. Model-Based vs Design-Based Inference"
  },
  {
    "objectID": "FW680A4/BigPicture.html#take-aways-4",
    "href": "FW680A4/BigPicture.html#take-aways-4",
    "title": "Big Picture  Science and Modeling",
    "section": "Take-Aways",
    "text": "Take-Aways\n1. Study Objectives, Hypotheses, and Predictions\n2. Big Data and Sampling\n3. Inference and Prediction\n4. Model-Based vs Design-Based Inference"
  },
  {
    "objectID": "FW680A4/Introduction.html#website",
    "href": "FW680A4/Introduction.html#website",
    "title": "Wildlife Ecology Modeling",
    "section": "Website",
    "text": "Website\nhttps://bgerber123.github.io/FW680A4/index.html"
  },
  {
    "objectID": "FW680A4/temp.html",
    "href": "FW680A4/temp.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "## Statistical Information {.scrollable}\nLet’s turn to the field of statistics to understand Information\n\n. . .\nLikelihood principle\nGiven a statistical model, all the evidence/information in a sample (\\(\\textbf{y}\\), i.e., data) relevant to model parameters (\\(\\theta\\)) is contained in the likelihood function.\n. . .\nFisher Information\nThe information an observable random variable (\\(\\textbf{y}\\)) has about an unknown parameter \\(\\theta\\) upon which the probability of \\(\\textbf{y}\\) \\((f(\\textbf{y};\\theta)\\) depends.\n\n. . .\nInformation is conditional. . .\nTo learn about \\(\\theta\\) from \\(\\textbf{y}\\), we need to link them together via a special function, \\(f(\\textbf{y};\\theta)\\)\n## Statistical Information\n The pieces:\n::: incremental - The sample data, \\(\\textbf{y}\\)\n\n\nA probability function for \\(\\textbf{y}\\):\n\n\\(f(\\textbf{y};\\theta)\\)\n\\([\\textbf{y}|\\theta]\\)\n\n\n\nThe unknown parameter: \\(\\theta\\)\n\nspecified in the probability function\n\n\n\n:::\n## Statistical Information (an example)\nWe want to know the proportion of a wetlands that contain a rare plant species. We can not sample the whole area.\n\n\n\n\n## Rare Plant Data\nWe randomly select plots and look for our plant.\nOur data are\n::: {.cell}\ny &lt;- c(0,1,1,1,1,0,1,0,0,0)\nn &lt;- length(y)\nn\n::: {.cell-output .cell-output-stdout}\n[1] 10\n::: :::\n. . .\n\n\\(\\textbf{y}\\) is a random variable as it depends on random events.\n\n. . .\nIn this case, when we induced a random selection of sites.\n## Probability/Likelihood Function\n\\(f(\\textbf{y};\\theta)\\) describes the probability for each \\(i^{th}\\) data, \\(y_i\\).\nBut, not just for the data we observed, for all possible data that could be observed.\n. . .\nRules about our data: \\(y \\in \\{0,1\\}\\),\n. . .\n\nwhere the curly brackets imply discrete values in our \"set\".\n\n. . .\nNot this: \\(y \\in [0,1]\\),\n\nwhere the square brackets indicate all real numbers from 0 to 1, including 0 and 1.\n\n. . .\nNot this: \\(y \\in (0,1)\\),\n\nwhere the parantheses indicate all real numbers from 0 to 1, not including 0 and 1.\n\n## Probability Function {.scrollable}\nTwo outcomes, 0 or 1, so we need two probabilities to describe our random variable.\n. . .\n\\[\n    f(y;\\theta) = [y|\\theta]=\n    \\begin{cases}\n      \\theta     & \\text{if $y = 1$}, \\\\\n      1 - \\theta & \\text{if $y = 0$}.\n    \\end{cases}\n  \\]\n. . .\nAlso,\n\\[\n  f(y;\\theta) = [y|\\theta]=\n    \\begin{align}\n          \\theta^{y}\\times(1-\\theta)^{1-y}\n    \\end{align}\n  \\]\n. . .\nAlso,\n\\[\n    \\begin{align}\n          P(Y=1) &= \\theta \\\\\n          P(Y=0) &= 1-\\theta  \n    \\end{align}\n  \\]\n\nThis probability function is called ________?\n\n## Probability Function\nProbabilities, such as our parameter, have rules:\n::: incremental - \\(0 \\leq \\theta \\leq 1\\)\n\n\\(0 \\leq (1 - \\theta) \\leq 1\\)\n\\(\\theta + (1-\\theta) = 1\\)\n\n:::\n## Probability Function {.scrollable}\nHow do we find \\(\\theta\\) for our data?\n. . .\nWe can use our probability function to calculate the likelihood of a parameter, given our data.\n. . .\n\\[\n  \\mathcal{L}(\\theta|y) = \\prod_{i=1}^{n} p(y_{i};\\theta)\n  \\]\n. . .\n::: {.cell}\n#Bernoulli probability function\n  prob.function=function(theta){prod(theta^y*(1-theta)^y)}\n\n#possible probabilities\n  theta.guess=matrix(seq(0.01,0.99,by=0.01))\n\n#implement function\n  likelihood=apply(theta.guess,1,prob.function)\n  \n#Find maximum likelood\n  max.index=which.max(likelihood)\n\n#Theta that maximizes our probability function\n  theta.est=theta.guess[max.index]\n\n#Define other probability\n  q.est &lt;- 1-theta.est\n\n#Alternative estimation\n  theta.est2 &lt;- sum(y)/n\n:::\n. . .\n::: {.cell} ::: {.cell-output-display}  ::: :::\n## Statistical Information (an example)\nLet’s combine 1 observation of our random variable, our probability function, and \\(\\theta\\) to quantify the Fisher information (Link ):\n. . .\n\\[\\begin{align}\nI(\\theta) &= -E\\left[\\frac{\\partial^2}{\\partial\\theta^2}\\text{log}(\\theta^y(1-\\theta)^{1-y}) \\right]\\\\\n\\end{align}\\]\n. . .\nFor all samples (n), this is reduced to\n\\[\\begin{align}\nI(\\theta) &= \\frac{n}{\\theta(1-\\theta)}\\\\\n\\end{align}\\]\n## Statistical Information (an example)\nTherefore, for our sample\n::: {.cell}\nI = n/(theta.est*q.est)\nI\n::: {.cell-output .cell-output-stdout}\n[1] 40\n::: :::\n. . .\nConsider how information varies by \\(\\theta\\) for a given sample size….\n## Statistical Information (an example) {.scrollable}\n::: {.cell layout-align=“center”}\nthetas=seq(0.05,0.95,0.1)\n\nInformation &lt;- n/(thetas*(1-thetas))\n\npar(cex.lab=2.5,cex.axis=2.5,mar=c(5,5,2,2))\nplot(thetas,Information,type=\"b\",lwd=8)\n\nabline(v=theta.est,col=2,lwd=8)\n::: {.cell-output-display}  ::: :::\n## Statistical Information (an example) {.scrollable}\nFunny enough, Fisher Information is the reciprocal of the variance of our estimate of \\(\\theta\\),\\[Var[\\hat{\\theta}] = \\frac{\\hat{\\theta}  (1-\\hat{\\theta})}{n}\\]\n## Statistical Information (an example)\n::: {.cell layout-align=“center”}\nthetas=seq(0.05,0.95,0.1)\n\nVar.theta &lt;- (thetas*(1-thetas))/n\npar(cex.main=2.5,cex.axis=2.5,cex.lab=2.5,mar=c(5,5,2,2))\nplot(thetas,Var.theta,type=\"b\",lwd=8)\nabline(v=theta.est,col=2,lwd=8)\n::: {.cell-output-display}  ::: :::\n. . .\nHow does this knowledge about this probability function inform the design of a study?\n## Statistics\nA field dedicated to observing the real world to gain informational data.\n. . .\nBUT\nOften statistics classes only focus on Power Analysis.\n. . .\nTo obtain informational data , we need to think about\n::: incremental - how our data will be created - our question of the data - a probability function to use and its parameters - the goal of the question :::\n## Reading\n\n\n\n\n\nLink"
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html",
    "title": "My title",
    "section": "",
    "text": "Main Take-Away:\n\nIn this report, I evaluate sampling design trade-offs in estimating total white-tailed deer abundance in the state of Rhode Island, USA. I consider two extremes of deer density - 1 deer/mi\\(^2\\) and 20 deer/mi\\(^2\\). For each deer density, I use a random sampling process to choose blocks of 1 mi\\(^2\\) to conduct a forward-looking infrared-red (FLIR) count of deer. The count is presumed to be done by helicopter with a FLIR camera attachment. Flights are assumed to occur in the winter and at night to increase the heat signature of deer. As such, detection probability within a block is assumed to be one (this however should be evaluated). I evaluate three sample sizes of 10, 20, and 40 blocks. The objective is to find the sample size that minimizes costs while being highly certain (0.90 probability) that the total population estimate is within 10% of the true value. This study design evaluation is done by using design-based sampling and inference.\n\n\n\n\nI considered the sampling frame to include all one square mile blocks of contiguous lands in Rhode Island that have less than 80% ‘development’.\n\n# find values of high development  \n  index=which(RI$Devel_area&gt;0.8)\n\n# drop values of high development and make a new spatial object\n  RI=RI[-index,]\n\n  # Update the id column\n  RI$Id=1:nrow(RI)\n\n# plot updated map\n  plot(RI[\"Devel_area\"])\n\n\n\n\n\n\n\nThere are no current studies to suggest the true mean deer density or the spatial structure of the Rhode Island deer population. As such, I will simulate two scenarios that consider a low (1 deer/mi\\(^2\\)) and high mean deer density (20 deer/mi\\(^2\\)).\n\n# Mean deer per square mile (1 cell)\n  deer.dens=c(1,20)\n\n# Total expected deer populations\n  deer.dens*nrow(RI)\n\n[1]   944 18880\n\n# Simulate deer densities\n  set.seed(434343)\n  deer1=rpois(nrow(RI),deer.dens[1])\n  deer2=rpois(nrow(RI),deer.dens[2])\n  \n  par(mfrow=c(1,2))\n  hist(deer1,freq=FALSE, main=\"True distribution - mean 1 mi^2\")\n  hist(deer2,freq=FALSE, main=\"True distribution - mean 20 mi^2\")\n\n\n\n\n\n\n\nThe assumed true total population size for both scenarios are 905 and 18800, respectively. These populations include random spatial variation. Considering additional spatial structure, such as variation in deer density by the percentage of development (Devel_area) could be a useful exercise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI will consider sampling both populations with three different samples sizes (10, 20, and 40). For each sample size, I will simulate random samples 1000 times. This will not evaluate all possible combinations of samples for each size, but it will be enough to approximate the sampling distribution. This can be evaluated by looking at the symmetry of the sampling distribution. Highly skewed and non-symmetric sampling distributions will require a higher number of simulations.\n\n  sample.sizes = c(10, 20, 40)\n  n.sim = 1000\n\n\n\n\nThe below code is shown to make it clear how exactly the sampling and estimation is done There are two for loops. One (index z) that loops through the number of sample sizes and the other (index i) that loops through the the number of simulation iterations within each sample sample.\nThe important code is the use of the function grts that selects a spatially balanced sample from the areal sampling frame and the estimation of the mean deer size for each cell using the function mean. There is no model used to estimate and predict the total deer abundanec. Rather, I am using the mean as the estimator.\n\n# Here, I am demonstrating random sampling one time and for one sample size and then using that random sample to estimate the total deer population for low and high scenarios.\n  sample.size=10\n  eqprob &lt;- grts(RI, n_base = sample.size)\n  y1=eqprob$sites_base$Deer1\n  y2=eqprob$sites_base$Deer2\n  est1=mean(y1)\n  est2=mean(y2)\n  deer.total.abundance1=est1*nrow(RI)\n  deer.total.abundance2=est2*nrow(RI)\n\n\nFirst, examining the absolute bias of the estimator, we see . . .\nLooking at the sampling distributions for low and high deer density, we see ….\nThe range (min-max) of possible total deer population estimates at low and high deer density for sample sizes (10, 20, and 40) are:\nTo specifically address the objective of this study, I used Monte Carlo integration to estimate the probability a single total deer density would be within 10% of truth. I found….\n\nConsidering low and high deer densities, I found that the objective to be highly certain (0.90 probability) that a single estimate of the total population estimate is within 10% of the true value…."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#context",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#context",
    "title": "My title",
    "section": "",
    "text": "In this report, I evaluate sampling design trade-offs in estimating total white-tailed deer abundance in the state of Rhode Island, USA. I consider two extremes of deer density - 1 deer/mi\\(^2\\) and 20 deer/mi\\(^2\\). For each deer density, I use a random sampling process to choose blocks of 1 mi\\(^2\\) to conduct a forward-looking infrared-red (FLIR) count of deer. The count is presumed to be done by helicopter with a FLIR camera attachment. Flights are assumed to occur in the winter and at night to increase the heat signature of deer. As such, detection probability within a block is assumed to be one (this however should be evaluated). I evaluate three sample sizes of 10, 20, and 40 blocks. The objective is to find the sample size that minimizes costs while being highly certain (0.90 probability) that the total population estimate is within 10% of the true value. This study design evaluation is done by using design-based sampling and inference."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#setup",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#setup",
    "title": "My title",
    "section": "",
    "text": "I considered the sampling frame to include all one square mile blocks of contiguous lands in Rhode Island that have less than 80% ‘development’.\n\n# find values of high development  \n  index=which(RI$Devel_area&gt;0.8)\n\n# drop values of high development and make a new spatial object\n  RI=RI[-index,]\n\n  # Update the id column\n  RI$Id=1:nrow(RI)\n\n# plot updated map\n  plot(RI[\"Devel_area\"])\n\n\n\n\n\n\n\nThere are no current studies to suggest the true mean deer density or the spatial structure of the Rhode Island deer population. As such, I will simulate two scenarios that consider a low (1 deer/mi\\(^2\\)) and high mean deer density (20 deer/mi\\(^2\\)).\n\n# Mean deer per square mile (1 cell)\n  deer.dens=c(1,20)\n\n# Total expected deer populations\n  deer.dens*nrow(RI)\n\n[1]   944 18880\n\n# Simulate deer densities\n  set.seed(434343)\n  deer1=rpois(nrow(RI),deer.dens[1])\n  deer2=rpois(nrow(RI),deer.dens[2])\n  \n  par(mfrow=c(1,2))\n  hist(deer1,freq=FALSE, main=\"True distribution - mean 1 mi^2\")\n  hist(deer2,freq=FALSE, main=\"True distribution - mean 20 mi^2\")\n\n\n\n\n\n\n\nThe assumed true total population size for both scenarios are 905 and 18800, respectively. These populations include random spatial variation. Considering additional spatial structure, such as variation in deer density by the percentage of development (Devel_area) could be a useful exercise."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#simulation",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#simulation",
    "title": "My title",
    "section": "",
    "text": "I will consider sampling both populations with three different samples sizes (10, 20, and 40). For each sample size, I will simulate random samples 1000 times. This will not evaluate all possible combinations of samples for each size, but it will be enough to approximate the sampling distribution. This can be evaluated by looking at the symmetry of the sampling distribution. Highly skewed and non-symmetric sampling distributions will require a higher number of simulations.\n\n  sample.sizes = c(10, 20, 40)\n  n.sim = 1000\n\n\n\n\nThe below code is shown to make it clear how exactly the sampling and estimation is done There are two for loops. One (index z) that loops through the number of sample sizes and the other (index i) that loops through the the number of simulation iterations within each sample sample.\nThe important code is the use of the function grts that selects a spatially balanced sample from the areal sampling frame and the estimation of the mean deer size for each cell using the function mean. There is no model used to estimate and predict the total deer abundanec. Rather, I am using the mean as the estimator.\n\n# Here, I am demonstrating random sampling one time and for one sample size and then using that random sample to estimate the total deer population for low and high scenarios.\n  sample.size=10\n  eqprob &lt;- grts(RI, n_base = sample.size)\n  y1=eqprob$sites_base$Deer1\n  y2=eqprob$sites_base$Deer2\n  est1=mean(y1)\n  est2=mean(y2)\n  deer.total.abundance1=est1*nrow(RI)\n  deer.total.abundance2=est2*nrow(RI)"
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#results",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#results",
    "title": "My title",
    "section": "",
    "text": "First, examining the absolute bias of the estimator, we see . . .\nLooking at the sampling distributions for low and high deer density, we see ….\nThe range (min-max) of possible total deer population estimates at low and high deer density for sample sizes (10, 20, and 40) are:\nTo specifically address the objective of this study, I used Monte Carlo integration to estimate the probability a single total deer density would be within 10% of truth. I found…."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#conclusion",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#conclusion",
    "title": "My title",
    "section": "",
    "text": "Considering low and high deer densities, I found that the objective to be highly certain (0.90 probability) that a single estimate of the total population estimate is within 10% of the true value…."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling Template.html#software",
    "href": "classfiles/deerlab/RI Deer Sampling Template.html#software",
    "title": "My title",
    "section": "Software",
    "text": "Software\nThis report was generated from the R Statistical Software (v4.2.2; R Core Team 2021) using the Markdown language and RStudio. The R packages used are acknowledged below.\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nbase\n4.4.1\n@base\n\n\ndoParallel\n1.0.17\n@doParallel\n\n\nforeach\n1.5.2\n@foreach\n\n\nknitr\n1.47\n\n@knitr2014; @knitr2015; @knitr2024\n\n\n\nrmarkdown\n2.27\n\n@rmarkdown2018; @rmarkdown2020; @rmarkdown2024\n\n\n\nsf\n1.0.16\n\n@sf2018; @sf2023\n\n\n\nspsurvey\n5.5.1\n@spsurvey\n\n\ntictoc\n1.2.1\n@tictoc\n\n\ntidyverse\n2.0.0\n@tidyverse"
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "Main Take-Away: the objective can not be met at the sample sizes investigated.\n\nI evaluate sampling design trade-offs in estimating total white-tailed deer abundance in the state of Rhode Island, USA. I consider two extremes of deer density - 1 deer/mi\\(^2\\) and 20 deer/mi\\(^2\\). For each deer density, I use a random sampling process to choose blocks of 1 mi\\(^2\\) to conduct a forward-looking infrared-red (FLIR) count of deer. The count is presumed to be done by helicopter with a FLIR camera attachment. Flights are assumed to occur in the winter and at night to increase the heat signature of deer. As such, detection probability within a block is assumed to be one (this however should be evaluated). I evaluate three sample sizes of 10, 20, and 40 blocks. The objective is to find the sample size that minimizes costs while being highly certain (0.90 probability) that the total population estimate is within 10% of the true value. This study design evaluation is done by using design-based sampling and inference.\n\n\n\n\nI considered the sampling frame to include all one square mile blocks of contiguous lands in Rhode Island that have less than 80% ‘development’.\n\n# find values of high development  \n  index=which(RI$Devel_area&gt;0.8)\n\n# drop values of high development and make a new spatial object\n  RI=RI[-index,]\n\n# Update the id column\n  RI$Id=1:nrow(RI)\n\n# plot updated map\n  plot(RI[\"Devel_area\"])\n\n\n\n\n\n\n\nThere are no current studies to suggest the true mean deer density or the spatial structure of the Rhode Island deer population. As such, I will simulate two scenarios that consider a low (1 deer/mi\\(^2\\)) and high mean deer density (20 deer/mi\\(^2\\)).\n\n# Mean deer per square mile (1 cell)\n  deer.dens=c(1,20)\n\n# Total expected deer populations\n  deer.dens*nrow(RI)\n\n[1]   944 18880\n\n# Simulate deer densities\n  set.seed(434343)\n  deer1=rpois(nrow(RI),deer.dens[1])\n  deer2=rpois(nrow(RI),deer.dens[2])\n  \n  par(mfrow=c(1,2))\n  hist(deer1,freq=FALSE, main=\"True distribution - mean 1 mi^2\")\n  hist(deer2,freq=FALSE, main=\"True distribution - mean 20 mi^2\")\n\n\n\n\n\n\n\nThe assumed true total population size for both scenarios are 905 and 18800, respectively. These populations include random spatial variation. Considering additional spatial structure, such as variation in deer density by the percentage of development (Devel_area) could be a useful exercise.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI will consider sampling both populations with three different samples sizes (10, 20, and 40). For each sample size, I will simulate random samples 1000 times. This will not evaluate all possible combinations of samples for each size, but it will be enough to approximate the sampling distribution. This can be evaluated by looking at the symmetry of the sampling distribution. Highly skewed and non-symmetric sampling distributions will require a higher number of simulations.\n\n  sample.sizes = c(10, 20, 40)\n  n.sim = 1000\n\n\n\n\nThe below code is shown to make it clear how exactly the sampling and estimation is done There are two for loops. One (index z) that loops through the number of sample sizes and the other (index i) that loops through the the number of simulation iterations within each sample sample.\nThe important code is the use of the function grts that selects a spatially balanced sample from the areal sampling frame and the estimation of the mean deer size for each cell using the function mean. There is no model used to estimate and predict the total deer abundanec. Rather, I am using the mean as the estimator.\n\n# Start code timer and Loop over sample size choices\n  tic(\"simulation\")\n  for(z in 1:length(sample.sizes)){\n  \n  # For each sample size, repeat the \n  # sampling/estimation criteria n.sim times\n    for(i in 1:n.sim){  \n        set.seed(434343+i) #defined random number generation\n        eqprob &lt;- grts(RI, n_base = sample.sizes[z])\n        y1=eqprob$sites_base$Deer1\n        y2=eqprob$sites_base$Deer2\n        est1=mean(y1)\n        est2=mean(y2)\n        deer.total.abundance1[z,i]=est1*nrow(RI)\n        deer.total.abundance2[z,i]=est2*nrow(RI)\n    \n      #monitor loops\n      if(i%%10==0) cat(\"\\nz =\",z, \", i =\", i)\n    } #End i loop\n  };toc() #End z loop and End codetimer\n\n\n\n\n\n\nFirst, examining the absolute bias of the estimator, we see that for the low deer density there to be low bias across sample sizes (10, 20, 40): 12.85, -1.17, -2.06, respectively. The relative bias puts these results in proportion to the size of the true population size: 0.01, 0, 0, making it more clear how little bias there is. Some of this is likely Markov error, such that increasing the number of simulations would drive these values even lower. The results are similar for the high deer density scenario, where the absolute bias is -51.88, 22.6, -21.5, and the relative bias is 0, 0, 0.\nLooking at the sampling distributions for low and deer density, we see the range of possible deer population sizes shrink towards the true value as the sample size increases.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe range (min-max) of possible total deer population estimates at the low deer density for sample sizes (10, 20, and 40) are:\n\n\n      10   20   40\nmin  189  236  519\nmax 1794 1510 1345\n\n\nThe same results for the high deer density are:\n\n\n       10    20    40\nmin 14726 16048 16756\nmax 23128 21901 21476\n\n\n\nTo specifically address the objective of this study, I found that the probability (given the assumed true low deer density and random sampling) of obtaining a single sample at the three different sample sizes (10, 20, and 40) to be substantially lower than the desired probability of 0.90.\n\n#Probability of means being within 10% of truth - low deer density\napply(deer.total.abundance1,1,FUN=function(x){\n  low=true.total1-true.total1*0.05\n  upp=true.total1+true.total1*0.05\n  length(which(x&gt;low & x&lt;upp))/length(x)\n})\n\n[1] 0.129 0.176 0.274\n\n\nHigher probabilities were found under the high deer density, but still do not meet the goal of 90%:\n\n\n[1] 0.496 0.703 0.865\n\n\n\nConsidering low and high deer densities, I found that the objective to be highly certain (0.90 probability) that a single estimate of the total population estimate is within 10% of the true value can not be met at sample sizes of 10, 20, and 40. A sample size of 50 may reach the goal at the high deer density, but a much larger sample size will be need if deer densities are low. However, there is very little bias in the estimator at either low or high deer densities."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#context",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#context",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "I evaluate sampling design trade-offs in estimating total white-tailed deer abundance in the state of Rhode Island, USA. I consider two extremes of deer density - 1 deer/mi\\(^2\\) and 20 deer/mi\\(^2\\). For each deer density, I use a random sampling process to choose blocks of 1 mi\\(^2\\) to conduct a forward-looking infrared-red (FLIR) count of deer. The count is presumed to be done by helicopter with a FLIR camera attachment. Flights are assumed to occur in the winter and at night to increase the heat signature of deer. As such, detection probability within a block is assumed to be one (this however should be evaluated). I evaluate three sample sizes of 10, 20, and 40 blocks. The objective is to find the sample size that minimizes costs while being highly certain (0.90 probability) that the total population estimate is within 10% of the true value. This study design evaluation is done by using design-based sampling and inference."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#setup",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#setup",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "I considered the sampling frame to include all one square mile blocks of contiguous lands in Rhode Island that have less than 80% ‘development’.\n\n# find values of high development  \n  index=which(RI$Devel_area&gt;0.8)\n\n# drop values of high development and make a new spatial object\n  RI=RI[-index,]\n\n# Update the id column\n  RI$Id=1:nrow(RI)\n\n# plot updated map\n  plot(RI[\"Devel_area\"])\n\n\n\n\n\n\n\nThere are no current studies to suggest the true mean deer density or the spatial structure of the Rhode Island deer population. As such, I will simulate two scenarios that consider a low (1 deer/mi\\(^2\\)) and high mean deer density (20 deer/mi\\(^2\\)).\n\n# Mean deer per square mile (1 cell)\n  deer.dens=c(1,20)\n\n# Total expected deer populations\n  deer.dens*nrow(RI)\n\n[1]   944 18880\n\n# Simulate deer densities\n  set.seed(434343)\n  deer1=rpois(nrow(RI),deer.dens[1])\n  deer2=rpois(nrow(RI),deer.dens[2])\n  \n  par(mfrow=c(1,2))\n  hist(deer1,freq=FALSE, main=\"True distribution - mean 1 mi^2\")\n  hist(deer2,freq=FALSE, main=\"True distribution - mean 20 mi^2\")\n\n\n\n\n\n\n\nThe assumed true total population size for both scenarios are 905 and 18800, respectively. These populations include random spatial variation. Considering additional spatial structure, such as variation in deer density by the percentage of development (Devel_area) could be a useful exercise."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#simulation",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#simulation",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "I will consider sampling both populations with three different samples sizes (10, 20, and 40). For each sample size, I will simulate random samples 1000 times. This will not evaluate all possible combinations of samples for each size, but it will be enough to approximate the sampling distribution. This can be evaluated by looking at the symmetry of the sampling distribution. Highly skewed and non-symmetric sampling distributions will require a higher number of simulations.\n\n  sample.sizes = c(10, 20, 40)\n  n.sim = 1000\n\n\n\n\nThe below code is shown to make it clear how exactly the sampling and estimation is done There are two for loops. One (index z) that loops through the number of sample sizes and the other (index i) that loops through the the number of simulation iterations within each sample sample.\nThe important code is the use of the function grts that selects a spatially balanced sample from the areal sampling frame and the estimation of the mean deer size for each cell using the function mean. There is no model used to estimate and predict the total deer abundanec. Rather, I am using the mean as the estimator.\n\n# Start code timer and Loop over sample size choices\n  tic(\"simulation\")\n  for(z in 1:length(sample.sizes)){\n  \n  # For each sample size, repeat the \n  # sampling/estimation criteria n.sim times\n    for(i in 1:n.sim){  \n        set.seed(434343+i) #defined random number generation\n        eqprob &lt;- grts(RI, n_base = sample.sizes[z])\n        y1=eqprob$sites_base$Deer1\n        y2=eqprob$sites_base$Deer2\n        est1=mean(y1)\n        est2=mean(y2)\n        deer.total.abundance1[z,i]=est1*nrow(RI)\n        deer.total.abundance2[z,i]=est2*nrow(RI)\n    \n      #monitor loops\n      if(i%%10==0) cat(\"\\nz =\",z, \", i =\", i)\n    } #End i loop\n  };toc() #End z loop and End codetimer"
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#results",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#results",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "First, examining the absolute bias of the estimator, we see that for the low deer density there to be low bias across sample sizes (10, 20, 40): 12.85, -1.17, -2.06, respectively. The relative bias puts these results in proportion to the size of the true population size: 0.01, 0, 0, making it more clear how little bias there is. Some of this is likely Markov error, such that increasing the number of simulations would drive these values even lower. The results are similar for the high deer density scenario, where the absolute bias is -51.88, 22.6, -21.5, and the relative bias is 0, 0, 0.\nLooking at the sampling distributions for low and deer density, we see the range of possible deer population sizes shrink towards the true value as the sample size increases.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe range (min-max) of possible total deer population estimates at the low deer density for sample sizes (10, 20, and 40) are:\n\n\n      10   20   40\nmin  189  236  519\nmax 1794 1510 1345\n\n\nThe same results for the high deer density are:\n\n\n       10    20    40\nmin 14726 16048 16756\nmax 23128 21901 21476\n\n\n\nTo specifically address the objective of this study, I found that the probability (given the assumed true low deer density and random sampling) of obtaining a single sample at the three different sample sizes (10, 20, and 40) to be substantially lower than the desired probability of 0.90.\n\n#Probability of means being within 10% of truth - low deer density\napply(deer.total.abundance1,1,FUN=function(x){\n  low=true.total1-true.total1*0.05\n  upp=true.total1+true.total1*0.05\n  length(which(x&gt;low & x&lt;upp))/length(x)\n})\n\n[1] 0.129 0.176 0.274\n\n\nHigher probabilities were found under the high deer density, but still do not meet the goal of 90%:\n\n\n[1] 0.496 0.703 0.865"
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#conclusion",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#conclusion",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "",
    "text": "Considering low and high deer densities, I found that the objective to be highly certain (0.90 probability) that a single estimate of the total population estimate is within 10% of the true value can not be met at sample sizes of 10, 20, and 40. A sample size of 50 may reach the goal at the high deer density, but a much larger sample size will be need if deer densities are low. However, there is very little bias in the estimator at either low or high deer densities."
  },
  {
    "objectID": "classfiles/deerlab/RI Deer Sampling_BDG.html#software",
    "href": "classfiles/deerlab/RI Deer Sampling_BDG.html#software",
    "title": "Study Design Evaluation of Estimating White-tailed Deer Abundance in Rhode Island, USA",
    "section": "Software",
    "text": "Software\nThis report was generated from the R Statistical Software (v4.2.2; R Core Team 2021) using the Markdown language and RStudio. The R packages used are acknowledged below.\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nbase\n4.4.1\n@base\n\n\ndoParallel\n1.0.17\n@doParallel\n\n\nforeach\n1.5.2\n@foreach\n\n\nknitr\n1.47\n\n@knitr2014; @knitr2015; @knitr2024\n\n\n\nrmarkdown\n2.27\n\n@rmarkdown2018; @rmarkdown2020; @rmarkdown2024\n\n\n\nsf\n1.0.16\n\n@sf2018; @sf2023\n\n\n\nspsurvey\n5.5.1\n@spsurvey\n\n\ntictoc\n1.2.1\n@tictoc\n\n\ntidyverse\n2.0.0\n@tidyverse"
  },
  {
    "objectID": "FW680A4/Probability.html#probabilitystatistics",
    "href": "FW680A4/Probability.html#probabilitystatistics",
    "title": "Probability",
    "section": "Probability/Statistics",
    "text": "Probability/Statistics\n\n\nProbability and statistics are the opposite sides of the same coin.\n\n\nTo understand statistics, we need to understand probability and probability functions.\n\n\n\nThe two key things to understand this connection is the random variable (RV) and parameters (e.g., \\(\\theta\\), \\(\\sigma\\), \\(\\epsilon\\), \\(\\mu\\))."
  },
  {
    "objectID": "FW680A4/Probability.html#motivation",
    "href": "FW680A4/Probability.html#motivation",
    "title": "Probability",
    "section": "Motivation",
    "text": "Motivation\n\nWhy learn about RVs and probability math?\n\n\nFoundations of:\n\nlinear regression\ngeneralized linear models\nmixed models\n\n\n\nOur Goal:\n\nconceptual framework to think about data, probabilities, and parameters\nmathematical connections and notation"
  },
  {
    "objectID": "FW680A4/Probability.html#not-random-variables",
    "href": "FW680A4/Probability.html#not-random-variables",
    "title": "Probability",
    "section": "Not Random Variables",
    "text": "Not Random Variables\n\\[\n\\begin{align*}\na =& 10 \\\\\nb =& \\text{log}(a) \\times 12 \\\\\nc =& \\frac{a}{b} \\\\\ny =& \\beta_0 + \\beta_1*c\n\\end{align*}\n\\]\n\nAll variables here are scalars. They are what they are and that is it. \\(\\beta\\) variables and \\(y\\) are currently unknown, but still scalars.\n\n\n\nScalars are quantities that are fully described by a magnitude (or numerical value) alone."
  },
  {
    "objectID": "FW680A4/Probability.html#random-variables",
    "href": "FW680A4/Probability.html#random-variables",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\\[\ny \\sim f(y)\n\\]\n\\(y\\) is a random variable which may change values each observation; it changes based on a probability function, \\(f(y)\\).\n\n\nThe tilde (\\(\\sim\\)) denotes “has the probability distribution of”.\n\n\n\nWhich value (y) is observed is predictable. Need to know parameters (\\(\\theta\\)) of the probability function \\(f(y)\\).\n\n\n\nSpecifically, \\(f(y|\\theta)\\), where ‘|’ is read as ‘given’.\n\n\n\nToss of a coin  Roll of a die  Weight of a captured elk  Count of plants in a sampled plot \n\n\n\n\n\nThe values observed can be understand based on the frequency within the population or presumed super-population. These frequencies can be described by probabilities."
  },
  {
    "objectID": "FW680A4/Probability.html#frequency-probabilitities",
    "href": "FW680A4/Probability.html#frequency-probabilitities",
    "title": "Probability",
    "section": "Frequency / Probabilitities",
    "text": "Frequency / Probabilitities\n\npar(mfrow=c(1,2))\nhist(y, breaks=20,xlim=c(0,25),main=main)\nhist(y, breaks=20,xlim=c(0,25),freq = FALSE,main=main)\n\n\n\n\n\n\n\n\n\nWe often only get to see ONE sample from this distribution."
  },
  {
    "objectID": "FW680A4/Probability.html#random-variables-1",
    "href": "FW680A4/Probability.html#random-variables-1",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\nWe are often interested in the characteristics of the whole population of frequencies,\n\ncentral tendency (mean, mode, median)\nvariability (var, sd)\nproportion of the population that meets some condition P(\\(8 \\leq y \\leq\\) 12) =0.68\n\n\nWe infer what these are based on our sample (i.e., statistical inference)."
  },
  {
    "objectID": "FW680A4/Probability.html#philosophy",
    "href": "FW680A4/Probability.html#philosophy",
    "title": "Probability",
    "section": "Philosophy",
    "text": "Philosophy\nFrequentist Paradigm:\nData (e.g., \\(y\\)) are random variables that can be described by probability distributions with unknown parameters that (e.g., \\(\\theta\\)) are fixed (scalars).\n\n\nBayesian Paradigm:\nData (e.g., \\(y\\)) are random variables that can be described by probability functions where the unknown parameters (e.g., \\(\\theta\\)) are also random variables that have probability functions that describe them."
  },
  {
    "objectID": "FW680A4/Probability.html#frequentist-random-variables",
    "href": "FW680A4/Probability.html#frequentist-random-variables",
    "title": "Probability",
    "section": "Frequentist Random Variables",
    "text": "Frequentist Random Variables\n\\[\n\\begin{align*}\ny =& \\text{ event/outcome} \\\\\nf(y|\\boldsymbol{\\theta}) =& [y|\\boldsymbol{\\theta}]=  \\text{ process governing the value of } y \\\\\n\\boldsymbol{\\theta} =& \\text{ parameters} \\\\\n\\end{align*}\n\\]\n\n\\(f()\\) or [ ] is conveying a function (math).\n\n\nIt is called a PDF when \\(y\\) is continuous and a PMF when \\(y\\) is discrete.\n\nPDF: probability density function\nPMF: probability mass function"
  },
  {
    "objectID": "FW680A4/Probability.html#functions",
    "href": "FW680A4/Probability.html#functions",
    "title": "Probability",
    "section": "Functions",
    "text": "Functions\nWe commonly use deterministic functions (indicated by non-italic letter); e.g., log(), exp(). Output is always the same with the same input. \\[\n\\hspace{-12pt}\\text{g} \\\\\nx \\Longrightarrow\\fbox{DO STUFF\n} \\Longrightarrow \\text{g}(x)\n\\]\n\n\\[\n\\hspace{-14pt}\\text{g} \\\\\nx \\Longrightarrow\\fbox{+7\n} \\Longrightarrow \\text{g}(x)\n\\]\n\n\n\\[\n\\text{g}(x) = x + 7\n\\]"
  },
  {
    "objectID": "FW680A4/Probability.html#random-variables-2",
    "href": "FW680A4/Probability.html#random-variables-2",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\\[\n\\begin{align*}\ny =& \\text{ event/outcome} \\\\\nf(y|\\boldsymbol{\\theta}) =& [y|\\boldsymbol{\\theta}]=  \\text{ process governing the value of } y \\\\\n\\boldsymbol{\\theta} =& \\text{ parameters} \\\\\n\\end{align*}\n\\]\n\n\\(f()\\) or [ ] is conveying a function (math).\n\n\nIt is called a PDF when \\(y\\) is continuous and a PMF when \\(y\\) is discrete.\n\nPDF: probability density function\nPMF: probability mass function"
  },
  {
    "objectID": "FW680A4/Probability.html#probability-functions",
    "href": "FW680A4/Probability.html#probability-functions",
    "title": "Probability",
    "section": "Probability Functions",
    "text": "Probability Functions\nSpecial functions with rules to guarantee our logic of probabilities are maintained.\n\nDiscrete RVs\n\\(y\\) can only be a certain set of values.\n\n\n\\(y \\in  \\{0,1\\}\\)\n\n0 = dead, 1 = alive\n\n\\(y \\in  \\{0,1, 2\\}\\)\n\n0 = site unoccupied, 1 = site occupied w/o young, 2 = site occupied with young\n\n\\(y \\in  \\{0, 1, 2, ..., 15\\}\\)\n\ncount of pups in a litter; max could by physiological constraint\n\n\n\n\nThese sets are called the sample space (\\(\\Omega\\)) or the support of the RV."
  },
  {
    "objectID": "FW680A4/Probability.html#pmf",
    "href": "FW680A4/Probability.html#pmf",
    "title": "Probability",
    "section": "PMF",
    "text": "PMF\n\\[\nf(y) = P(Y=y)\n\\]\n\nData has two outcomes (0 = dead, 1 = alive)\n\\(y \\in  \\{0,1\\}\\)\n\n\nThere are two probabilities\n\n\\(f(0) = P(Y=0)\\)\n\\(f(1) = P(Y=1)\\)\n\n\n\nAxiom 1: The probability of an event is greater than or equal to zero and less than or equal to 1.\n\\[\n0 \\leq f(y) \\leq 1\n\\] Example,\n\n\\(f(0) = 0.1\\)\n\\(f(1) = 0.9\\)\n\n\n\nAxiom 2: The sum of the probabilities of all possible values (sample space) is one.\n\n\n\\[\n\\sum_{i} f(y_i) = f(y_1) + f(y_2) + ... = P(\\Omega) =1\n\\] Example,\n\n\\(f(0) + f(1) = 0.1 + 0.9 = 1\\)"
  },
  {
    "objectID": "FW680A4/Probability.html#pmf-example-1",
    "href": "FW680A4/Probability.html#pmf-example-1",
    "title": "Probability",
    "section": "PMF Example 1",
    "text": "PMF Example 1\nStill need to define \\(f()\\), our PMF for \\(y \\in  \\{0,1\\}\\)\n\nThe Bernoulli distribution\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\n\n\\(\\theta\\) = P(Y = 1) = 0.2\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2^{1}\\times(1-0.2)^{0-0}\n  \\end{align}\n\\]\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2 \\times (0.8)^{0} = 0.2\n  \\end{align}\n\\]"
  },
  {
    "objectID": "FW680A4/Probability.html#binomial",
    "href": "FW680A4/Probability.html#binomial",
    "title": "Probability",
    "section": "Binomial",
    "text": "Binomial\nThe Bernoulli is a special case of the Binomial Distribution.\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        {N\\choose y} \\theta^{y}\\times(1-\\theta)^{N-y}\n  \\end{align}\n\\]\n\n\\(N\\) = total trials / tagged and released animals\n\n\n\n\\(y\\) = number of successes / number of alive animals at the of the study.\n\n\n\n# 1 duck tagged/released and one simulation\n  theta=0.2;  N=1 \n  rbinom(n=1,size=N,theta)\n\n[1] 1\n\n\n\n\n\n# 1000 ducks tagged/released and one simulation\n  theta=0.2;  N=1000 \n  rbinom(n=1,size=N,theta)\n\n[1] 198\n\n\n\n\n\n# 1000 ducks tagged/released and 10 simulation\n  theta=0.2;  N=1000 \n  rbinom(n=10,size=N,theta)\n\n [1] 180 190 198 192 169 192 192 217 206 216\n\n\n\n\n\n# 1 duck tagged for each of 1000 simulations\n  theta=0.2;  N=1\n  y = rbinom(n=1000,size=N,theta)\n  y\n\n   [1] 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n  [38] 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n  [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [112] 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n [149] 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n [186] 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [223] 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0\n [260] 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n [297] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n [334] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n [371] 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n [408] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n [445] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n [482] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n [519] 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0\n [556] 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n [593] 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n [630] 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1\n [667] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n [704] 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n [741] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n [778] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n [815] 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n [852] 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [889] 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0\n [926] 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n [963] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n[1000] 0\n\n\n\n\n\nsum(y)\n\n[1] 186"
  },
  {
    "objectID": "FW680A4/Probability.html#support",
    "href": "FW680A4/Probability.html#support",
    "title": "Probability",
    "section": "Support",
    "text": "Support\nUse a probability function that makes sense for your data/RV. In Bayesian infernece, we also pick prob. functions that make sense for parameters.\n\nThe sample space and parameter support can be found on Wikipedia for many probability functions."
  },
  {
    "objectID": "FW680A4/Probability.html#normal-distribution",
    "href": "FW680A4/Probability.html#normal-distribution",
    "title": "Probability",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nWe collect data on adult alligator lengths (in).\n\n\n [1]  90.30  83.02 103.67  85.17  99.20 106.74  90.76 105.28  99.41 101.72\n\n\n\n\n Should we use the Normal Distribution to estimate the mean?  \n\n\n\nDoes the support of our data match the support of the PDF?\n\n\n\n\nWhat PDF does?\n\n\n\n\n\n\n\n\n\n\n\n\n\nAre they exactly the same?\n\n\n\n\nThe issue is when the data are near 0, we might estimate non-sensical values (e.g. negative)."
  },
  {
    "objectID": "FW680A4/Probability.html#pdf",
    "href": "FW680A4/Probability.html#pdf",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nContinuous RVs\n\\(y\\) are an uncountable set of values.\n\n\nProvide ecological data examples that match the support?\n\n\n\nGamma: \\(y \\in  (0,\\infty)\\)\nBeta: \\(y \\in  (0,1)\\)\nContinuous Uniform: \\(y \\in  [a,b]\\)"
  },
  {
    "objectID": "FW680A4/Probability.html#pdf-1",
    "href": "FW680A4/Probability.html#pdf-1",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nPDFs of continious RVs follow the same rules as PMFs.\nConfusing Differences\n\nAxiom 1:\n\n\\(f(y) \\geq 0\\)\n\nPDFs output probability densities, not probabilities.\n\n\n\nAxiom 2:\n\nProbs are the area b/w a lower and upper value of \\(y\\); i.e, area under the curve\n\n\n\n\\[\ny \\sim \\text{Normal}(\\mu, \\sigma) \\\\\nf(y|\\mu,\\sigma ) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{1}{2}(\\frac{y-\\mu}{\\sigma})^{2}} \\\\\n\\]\n\n\n\nvisualize.it(dist = 'norm', stat = c(100),\n             list(mu = 100 , sd = 10), section = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe math,\n\\[\n\\int_{120}^{\\infty} f(y| \\mu, \\sigma)dy = P(120&lt;Y&lt;\\infty)\n\\]\n\n\nRead this as “the integral of the probability density function between 120 and infinity (on the left-hand side) is equal to the probability that the outcome of the random variable is between 120 and infinity (on the right-hand side)”.\n\n\n\nThe code\n\npnorm(120,mean=100,sd=10,lower.tail = FALSE)\n\n[1] 0.02275013\n\n\n\n\n\nOr, we could reverse the question.\n\nqnorm(0.02275,100,10,lower.tail = FALSE)\n\n[1] 120"
  },
  {
    "objectID": "FW680A4/Probability.html#pdf-2",
    "href": "FW680A4/Probability.html#pdf-2",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nAxiom 3:\n\n\\(\\int_{\\text{lower support}}^{\\text{upper suppport}}f(y)dy = 1\\)\n\nThe sum of the probability densities of all possible outcomes is equal to 1."
  },
  {
    "objectID": "FW680A4/Probability.html#one-side-of-the-coin",
    "href": "FW680A4/Probability.html#one-side-of-the-coin",
    "title": "Probability",
    "section": "One side of the coin",
    "text": "One side of the coin\nProbability: Interested in the variation of y, \\[\n\\begin{align*}\ny \\leftarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\boldsymbol{\\theta}  =& \\begin{matrix} [\\kappa & \\theta] \\end{matrix} \\\\\nf(y|\\boldsymbol{\\theta}) &= \\text{Gamma(}\\kappa, \\theta) \\\\\n\\end{align*}\n\\]\n\n\n\\[\n\\begin{align*}\nf(y|\\boldsymbol{\\theta}) &= \\frac{1}{\\Gamma(\\kappa)\\theta^{\\kappa}}y^{y^{\\kappa-1} e^{-y/\\theta}} \\\\\n\\end{align*}\n\\]\n\n\nSample/parameter Support:\n\n\\(y \\in (0,\\infty)\\)\n\\(\\kappa \\in (0,\\infty)\\)\n\\(\\theta \\in (0,\\infty)\\)\n\n\n\nWhat is the probability we would sample a value &gt;40?  In this population, how common is a value &gt;40?\n\n\n\\[\n\\begin{align*}\np(y&gt;40) = \\int_{40}^{\\infty} f(y|\\boldsymbol{\\theta}) \\,dy\n\\end{align*}\n\\]\n\npgamma(q=40, shape=10, scale=2,lower.tail=FALSE)\n\n[1] 0.004995412\n\n\n\n\n\nWhat is the probability of observing \\(y\\) &lt; 50\n\npgamma(q=20,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 0.5420703\n\n\n\n\n\nReverse the question: What values of \\(y\\) and lower have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 9.590777\n\n\n\n\n\nWhat values of \\(y\\) and higher have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=FALSE)\n\n[1] 34.16961\n\n\n\n\n\ncurve(dgamma(x,shape=10, scale=2),xlim=c(0,50),lwd=3,\n      xlab=\"y\", ylab=\"dgamma(x,shape=10, scale=2)\")\nabline(v=c(9.590777,34.16961),lwd=3,col=2)\n\n\n\n\n\n\n\n\n\n\nWe can consider samples from this population,\n\nset.seed(154434)\ny &lt;- rgamma(100, shape=10, scale=2)"
  },
  {
    "objectID": "FW680A4/Probability.html#the-others-side-of-the-coin",
    "href": "FW680A4/Probability.html#the-others-side-of-the-coin",
    "title": "Probability",
    "section": "The others side of the coin",
    "text": "The others side of the coin\nStatistics: Interested in estimating population-level characteristics; i.e., the parameters\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n\n\n REMEMBER \n\n\\(f(y|\\boldsymbol{\\theta})\\) is a probability statement about \\(y\\),  NOT  \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "FW680A4/Probability.html#the-likelihood-function",
    "href": "FW680A4/Probability.html#the-likelihood-function",
    "title": "Probability",
    "section": "The Likelihood Function",
    "text": "The Likelihood Function\nWhat we can say about our parameters using this function?\n\\[\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}|y) = P(y|\\boldsymbol{\\theta})  = f(y|\\boldsymbol{\\theta})\n\\end{align*}\n\\]\n\nThe likelihood (\\(\\mathcal{L}\\)) of the unknown parameters, given our data, can be calculated using our probability function.\n\n\nCODE:\n\n# A data point\n  y=c(10)\n\n#the likelihood the mean is 8, given our data\n  dnorm(y,mean=8)\n\n[1] 0.05399097\n\n\n\n\n\nIf we knew the mean is truly 8, it would also be the probability density of the observation y = 10."
  },
  {
    "objectID": "FW680A4/Probability.html#many-parameter-guesses",
    "href": "FW680A4/Probability.html#many-parameter-guesses",
    "title": "Probability",
    "section": "Many Parameter Guesses",
    "text": "Many Parameter Guesses\n\n# Let's take many guesses of the mean\n  means=seq(0,20,by=0.1)\n\n# Use dnorm to get likelihood of each guess of the mean\n# Assumes sd = 1\n  likelihood=dnorm(y, mean=means)"
  },
  {
    "objectID": "FW680A4/Probability.html#statistics-and-pdf-example",
    "href": "FW680A4/Probability.html#statistics-and-pdf-example",
    "title": "Probability",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWhat is the mean height of King Penguins?"
  },
  {
    "objectID": "FW680A4/Probability.html#statistics-and-pdf-example-1",
    "href": "FW680A4/Probability.html#statistics-and-pdf-example-1",
    "title": "Probability",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWe go and collect data,\n\\(\\boldsymbol{y} = \\begin{matrix} [4.34 & 3.53 & 3.75] \\end{matrix}\\)\n\n\nLet’s decide to use the Normal Distribution as our PDF.\n\n\n\\[\n\\begin{align*}\nf(y_1 = 4.34|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{1}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nAND\n\\[\n\\begin{align*}\nf(y_2 = 3.53|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{2}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\] . . .\nAND\n\\[\n\\begin{align*}\nf(y_3 = 3.75|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{3}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nOr simply,\n\\[\n\\textbf{y} \\stackrel{iid}{\\sim} \\text{Normal}(\\mu, \\sigma)\n\\] . . .\n\\(iid\\) = independent and identically distributed"
  },
  {
    "objectID": "FW680A4/Probability.html#continued",
    "href": "FW680A4/Probability.html#continued",
    "title": "Probability",
    "section": "Continued",
    "text": "Continued\nThe joint probability of our data with shared parameters \\(\\mu\\) and \\(\\sigma\\),\n\\[\n\\begin{align*}\n& P(Y_{1} = y_1,Y_{2} = y_2, Y_{3} = y_3 | \\mu, \\sigma) \\\\\n&= \\mathcal{L}(\\mu, \\sigma|\\textbf{y})\n\\end{align*}\n\\]\n\nIF each \\(y_{i}\\) is independent, the joint probability of our data are simply the multiplication of all three probability densities,\n\\[\n\\begin{align*}\n=& f(y_{1}|\\mu, \\sigma)\\times f(y_{2}|\\mu, \\sigma)\\times f(y_{3}|\\mu, \\sigma) \\end{align*}\n\\]\nWe can do this because we are assuming knowing one value (\\(y_1\\)) does not tell us any new information about another value \\(y_2\\).\n\n\n\\[\n\\begin{align*}\n=& \\prod_{i=1}^{3} f(y_{i}|\\mu, \\sigma) \\\\\n=& \\mathcal{L}(\\mu, \\sigma|y_{1},y_{2},y_{3})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/Probability.html#code",
    "href": "FW680A4/Probability.html#code",
    "title": "Probability",
    "section": "Code",
    "text": "Code\nTranslate the math to code…\n\n# penguin height data\n  y=c(4.34, 3.53, 3.75)\n\n#Joint likelihood of mu=3, sigma =1, given our data\n  prod(dnorm(y,mean=3,sd=1))\n\n[1] 0.01696987\n\n\n\n\nCalcualte likelihood of many guesses of \\(\\mu\\) and \\(\\sigma\\) simultaneously,\n\n# The Guesses\n  mu=seq(0,6,0.05)\n  sigma=seq(0.01,2,0.05)\n  try=expand.grid(mu,sigma)\n  colnames(try)=c(\"mu\",\"sigma\")\n\n# function\nfun=function(a,b){\n  prod(dnorm(y,mean=a,sd=b))\n  }\n\n# mapply the function with the inputs\n  likelihood=mapply(a=try$mu,b=try$sigma, FUN=fun)\n\n# maximum likelihood of parameters\n  try[which.max(likelihood),]\n\n      mu sigma\n925 3.85  0.36"
  },
  {
    "objectID": "FW680A4/Probability.html#likelihood-plot-3d",
    "href": "FW680A4/Probability.html#likelihood-plot-3d",
    "title": "Probability",
    "section": "Likelihood plot (3D)",
    "text": "Likelihood plot (3D)"
  },
  {
    "objectID": "FW680A4/Probability.html#sample-size",
    "href": "FW680A4/Probability.html#sample-size",
    "title": "Probability",
    "section": "Sample Size",
    "text": "Sample Size\nWhat happens to the likelihood if we increase the sample size to N=100?"
  },
  {
    "objectID": "FW680A4/Probability.html#proper-guessing",
    "href": "FW680A4/Probability.html#proper-guessing",
    "title": "Probability",
    "section": "Proper Guessing",
    "text": "Proper Guessing\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n#Note: optim function uses minimization, not maximization. \n#THUS, need to put negative in our function\n\n#Note: log=TRUE, allows us to add rather than multiply \n#      (sum, instead of prod)\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1))\n\n#Maximum likihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/Probability.html#the-linear-regression-way",
    "href": "FW680A4/Probability.html#the-linear-regression-way",
    "title": "Probability",
    "section": "The Linear Regression way",
    "text": "The Linear Regression way\nKing Penguin Height Data (N=100)\n\nout=lm(y~1)\nsummary(out)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.00136 -0.61581  0.01208  0.67407  2.58369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.9012     0.0932   41.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.932 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/Probability.html#moments",
    "href": "FW680A4/Probability.html#moments",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nProperties of all probability functions.\n\n\n1\\({^{st}}\\) moment is central tendency\n2\\({^{nd}}\\) moment is the dispersion\n…\n\n\n\nNormal Distribution: parameters (\\(\\mu\\) and \\(\\sigma\\)) are 1\\({^{st}}\\) and 2\\({^{nd}}\\) moments"
  },
  {
    "objectID": "FW680A4/Probability.html#moment-matching",
    "href": "FW680A4/Probability.html#moment-matching",
    "title": "Probability",
    "section": "Moment Matching",
    "text": "Moment Matching\nColleague estimated daily rainfall as, \\(\\hat{\\mu} = 10\\) and \\(\\hat{\\sigma} = 9\\).\nNow, we want to consider future daily rainfall probabilities,\n\n\n#Parameters of Normal Distribution\n  mu=10\n  sd=9\n\n#simualte and plot\n  y = rnorm(10000,mean=mu,sd=sd)\n  hist(y, main=\"Daily Rainfall\")\n\n\n\n\n\n\n\n\n\n\nTake our parameters/moments and match them to parameters where the support makes more sense.\n\n\n\nGamma Distribution\nMoments on left, parameters on the right.\n\\[\n\\mu = \\frac{\\alpha}{\\beta} \\\\\n\\sigma^2 = \\frac{\\alpha}{\\beta^2} \\\\\n\\]\n. . .\n\\[\n\\alpha = \\frac{\\mu^2}{\\sigma^2} \\\\\n\\beta = \\frac{\\mu}{\\sigma^2} \\\\\n\\] . . .\n\n#Parameters of Gamma Distribution\n  alpha = mu^2/sd^2 \n  beta = mu/sd^2\n\n#simualte and plot\n  y = rgamma(10000,shape=alpha, rate=beta)\n  hist(y, main=\"Daily Rainfall\")"
  },
  {
    "objectID": "FW680A4/Probability.html#pmf-example-1-1",
    "href": "FW680A4/Probability.html#pmf-example-1-1",
    "title": "Probability",
    "section": "PMF Example 1",
    "text": "PMF Example 1\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\nSample space support (\\(\\Omega\\)):\n\n\\(y \\in  \\{0,1\\}\\)\n\n\nParameter space support (\\(\\Theta\\)):\n\n\\(\\theta \\in  [0,1]\\)\nGeneral: \\(\\theta \\in \\Theta\\)"
  },
  {
    "objectID": "FW680A4/Probability.html#bernoulli-distribution",
    "href": "FW680A4/Probability.html#bernoulli-distribution",
    "title": "Probability",
    "section": "Bernoulli distribution",
    "text": "Bernoulli distribution\nWhat would our data look like for 10 ducks that had a probability of survival (Y=1) of 0.20?\n\n#Define inputs\n  theta=0.2;  N=1 \n\n#Random sample - 1 duck\n  rbinom(n=1,size=N,theta)\n\n[1] 0\n\n#Random sample - 10 ducks\n  rbinom(n=10,size=N,theta)\n\n [1] 1 0 0 0 1 0 1 0 1 0"
  },
  {
    "objectID": "FW680A4/Probability.html#reality-check",
    "href": "FW680A4/Probability.html#reality-check",
    "title": "Probability",
    "section": "Reality Check",
    "text": "Reality Check\nWhy is this useful to us?\nWhat if we wanted to evaluate the sample size of how many ducks we need to tag to estimate \\(\\theta\\)?\n\ny.mat = replicate(1000,rbinom(n=10,size=N,theta))\nhist(apply(y.mat, 2, mean),freq=TRUE,breaks=40, bquote=\"Sampling Distribution of\"~theta)"
  },
  {
    "objectID": "FW680A4/Probability.html#why-is-this-useful-to-us",
    "href": "FW680A4/Probability.html#why-is-this-useful-to-us",
    "title": "Probability",
    "section": "Why is this useful to us?",
    "text": "Why is this useful to us?\nHow about to evaluate the sample size of ducks needed to estimate \\(\\theta\\)?\n\n\ny.mat = replicate(1000,rbinom(n = 10,size=N,theta))\ntheta.hat = apply(y.mat, 2, mean)"
  },
  {
    "objectID": "FW680A4/Probability.html#normal-pdf",
    "href": "FW680A4/Probability.html#normal-pdf",
    "title": "Probability",
    "section": "Normal PDF",
    "text": "Normal PDF\nFor example, the Normal/Gaussian distribution describes the sample space for all values on the real number line.\n\\[y \\sim \\text{Normal}(\\mu, \\sigma) \\\\ y \\in (-\\infty, \\infty) \\\\ y \\in \\mathbb{R}\\]\nWhat is the parameter space for \\(\\mu\\) and \\(\\sigma\\)?"
  },
  {
    "objectID": "FW680A4/Probability.html#objectives",
    "href": "FW680A4/Probability.html#objectives",
    "title": "Probability",
    "section": "Objectives",
    "text": "Objectives\n\n\nConnect random variables, probabilities, and parameters\ndefine prob. functions\n\ndiscrete and continuous random variables\n\nuse/plot prob. functions\nlearn some notation"
  },
  {
    "objectID": "FW680A4/Probability.html#normal-distribution-pdf-code",
    "href": "FW680A4/Probability.html#normal-distribution-pdf-code",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ny = rnorm(1000, mean = 20, sd = 3)\nhist(y,freq=FALSE,ylim=c(0,0.14))\nlines(density(y),lwd=3,col=4)"
  },
  {
    "objectID": "FW680A4/Probability.html#gamma-distribution-pdf-code",
    "href": "FW680A4/Probability.html#gamma-distribution-pdf-code",
    "title": "Probability",
    "section": "Gamma Distribution (PDF Code)",
    "text": "Gamma Distribution (PDF Code)\nGamma Wikipedia\n\nshape =10\nscale = 2\n\nmean1 = shape*scale\nmean1\n\n[1] 20\n\nmode1 = (shape-1)*scale\nmode1\n\n[1] 18\n\nstdev = sqrt(shape*scale^2)\nstdev\n\n[1] 6.324555"
  },
  {
    "objectID": "FW680A4/Probability.html#normal-distribution-pdf-code-1",
    "href": "FW680A4/Probability.html#normal-distribution-pdf-code-1",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ncurve(dnorm(x, mean= 20, sd = 3),\n      xlim=c(0,40),lwd=3,col=2,ylab=\"Probability Density\",xlab=\"y\")\nabline(v=20, lwd=3, col=1, lty=4)"
  },
  {
    "objectID": "FW680A4/Probability.html#normal-distribution-pdf-code-2",
    "href": "FW680A4/Probability.html#normal-distribution-pdf-code-2",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ncurve(dnorm(x, mean = 10, sd = 3),xlim=c(0,40),lwd=4,col=3,add=TRUE)"
  },
  {
    "objectID": "FW680A4/Probability.html#gamma-distribution-pdf-code-1",
    "href": "FW680A4/Probability.html#gamma-distribution-pdf-code-1",
    "title": "Probability",
    "section": "Gamma Distribution (PDF Code)",
    "text": "Gamma Distribution (PDF Code)"
  },
  {
    "objectID": "FW680A4/Probability.html#pmf-1",
    "href": "FW680A4/Probability.html#pmf-1",
    "title": "Probability",
    "section": "PMF",
    "text": "PMF\nStill need to define \\(f()\\), our PMF for \\(y \\in  \\{0,1\\}\\)\n\nThe Bernoulli distribution\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\n\n\\(\\theta\\) = P(Y = 1) = 0.2\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2^{1}\\times(1-0.2)^{0-0}\n  \\end{align}\n\\]\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2 \\times (0.8)^{0} = 0.2\n  \\end{align}\n\\]"
  },
  {
    "objectID": "FW680A4/Probability.html#bernoulli-pmf",
    "href": "FW680A4/Probability.html#bernoulli-pmf",
    "title": "Probability",
    "section": "Bernoulli PMF",
    "text": "Bernoulli PMF\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\nSample space support (\\(\\Omega\\)):\n\n\\(y \\in  \\{0,1\\}\\)\n\n\nParameter space support (\\(\\Theta\\)):\n\n\\(\\theta \\in  [0,1]\\)\nGeneral: \\(\\theta \\in \\Theta\\)"
  },
  {
    "objectID": "FW680A4/Probability.html#bernoulli-pmf-code",
    "href": "FW680A4/Probability.html#bernoulli-pmf-code",
    "title": "Probability",
    "section": "Bernoulli PMF (Code)",
    "text": "Bernoulli PMF (Code)\nWhat would our data look like for 10 ducks that had a probability of survival (Y=1) of 0.20?\n\n#Define inputs\n  theta=0.2;  N=1 \n\n#Random sample - 1 duck\n  rbinom(n=1,size=N,theta)\n\n[1] 0\n\n#Random sample - 10 ducks\n  rbinom(n=10,size=N,theta)\n\n [1] 1 0 0 0 1 0 1 0 1 0"
  },
  {
    "objectID": "FW680A4/Probability.html#binomial-pmf",
    "href": "FW680A4/Probability.html#binomial-pmf",
    "title": "Probability",
    "section": "Binomial PMF",
    "text": "Binomial PMF\nThe Bernoulli is a special case of the Binomial Distribution.\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        {N\\choose y} \\theta^{y}\\times(1-\\theta)^{N-y}\n  \\end{align}\n\\]\n\n\\(N\\) = total trials / tagged and released animals\n\n\n\n\\(y\\) = number of successes / number of alive animals at the of the study."
  },
  {
    "objectID": "FW680A4/Probability.html#binomial-pmf-code",
    "href": "FW680A4/Probability.html#binomial-pmf-code",
    "title": "Probability",
    "section": "Binomial PMF (Code)",
    "text": "Binomial PMF (Code)\n\n# 1 duck tagged/released and one simulation\n  theta=0.2;  N=1 \n  rbinom(n=1,size=N,theta)\n\n[1] 1\n\n\n\n\n# 1000 ducks tagged/released and one simulation\n  theta=0.2;  N=1000 \n  rbinom(n=1,size=N,theta)\n\n[1] 198\n\n\n\n\n\n# 1000 ducks tagged/released and 10 simulation\n  theta=0.2;  N=1000 \n  rbinom(n=10,size=N,theta)\n\n [1] 180 190 198 192 169 192 192 217 206 216\n\n\n\n\n\n# 1 duck tagged for each of 1000 simulations\n  theta=0.2;  N=1\n  y = rbinom(n=1000,size=N,theta)\n  y\n\n   [1] 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n  [38] 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n  [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [112] 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n [149] 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n [186] 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [223] 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0\n [260] 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n [297] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n [334] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n [371] 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n [408] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n [445] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n [482] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n [519] 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0\n [556] 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n [593] 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n [630] 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1\n [667] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n [704] 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n [741] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n [778] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n [815] 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n [852] 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [889] 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0\n [926] 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n [963] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n[1000] 0\n\n\n\n\n\nsum(y)\n\n[1] 186"
  },
  {
    "objectID": "FW680A4/Probability.html#gamma-distribution",
    "href": "FW680A4/Probability.html#gamma-distribution",
    "title": "Probability",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\nProbability: Interested in the variation of y, \\[\n\\begin{align*}\ny \\leftarrow& f(y|\\boldsymbol{\\theta'}) \\\\\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\boldsymbol{\\theta'}  =& \\begin{matrix} [\\kappa & \\theta] \\end{matrix} \\\\\nf(y|\\boldsymbol{\\theta}') &= \\text{Gamma(}\\kappa, \\theta) \\\\\n\\end{align*}\n\\]\n\n\n\\[\n\\begin{align*}\nf(y|\\boldsymbol{\\theta}') &= \\frac{1}{\\Gamma(\\kappa)\\theta^{\\kappa}}y^{\\kappa-1} e^{-y/\\theta} \\\\\n\\end{align*}\n\\]\n\n\nSample/parameter Support:\n\n\\(y \\in (0,\\infty)\\)\n\\(\\kappa \\in (0,\\infty)\\)\n\\(\\theta \\in (0,\\infty)\\)"
  },
  {
    "objectID": "FW680A4/Probability.html#gamma-distribution-1",
    "href": "FW680A4/Probability.html#gamma-distribution-1",
    "title": "Probability",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\nWhat is the probability we would sample a value &gt;40?  In this population, how common is a value &gt;40?\n\n\\[\n\\begin{align*}\np(y&gt;40) = \\int_{40}^{\\infty} f(y|\\boldsymbol{\\theta}) \\,dy\n\\end{align*}\n\\]\n\npgamma(q=40, shape=10, scale=2,lower.tail=FALSE)\n\n[1] 0.004995412\n\n\n\n\n\nWhat is the probability of observing \\(y\\) &lt; 20\n\npgamma(q=20,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 0.5420703\n\n\n\n\n\nWhat is the probability of observing 20 &lt; \\(y\\) &lt; 40\n\npgamma(q=40,shape=10, scale=2,lower.tail=TRUE)-\npgamma(q=20,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 0.4529343\n\n\n\n\n\nReverse the question: What values of \\(y\\) and lower have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 9.590777\n\n\n\n\n\nWhat values of \\(y\\) and higher have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=FALSE)\n\n[1] 34.16961\n\n\n\n\n\ncurve(dgamma(x,shape=10, scale=2),xlim=c(0,50),lwd=3,\n      xlab=\"y\", ylab=\"dgamma(x,shape=10, scale=2)\")\nabline(v=c(9.590777,34.16961),lwd=3,col=2)\n\n\n\n\n\n\n\n\n\n\nWe can consider samples from this population,\n\nset.seed(154434)\ny &lt;- rgamma(100, shape=10, scale=2)"
  },
  {
    "objectID": "FW680A4/temp2.html",
    "href": "FW680A4/temp2.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "What we can say about our parameters using this function?\n\\[\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}|y) = P(y|\\boldsymbol{\\theta})  = f(y|\\boldsymbol{\\theta})\n\\end{align*}\n\\]\n. . .\nThe likelihood (\\(\\mathcal{L}\\)) of the unknown parameters, given our data, can be calculated using our probability function.\n. . .\nCODE:\n\n# A data point\n  y=c(10)\n\n#the likelihood the mean is 8, given our data\n  dnorm(y,mean=8)\n\n[1] 0.05399097\n\n\n\n. . .\nIf we knew the mean is truly 8, it would also be the probability density of the observation y = 10."
  },
  {
    "objectID": "FW680A4/temp2.html#the-likelihood-function",
    "href": "FW680A4/temp2.html#the-likelihood-function",
    "title": "Likelihood / Regression",
    "section": "The Likelihood Function",
    "text": "The Likelihood Function\nWhat we can say about our parameters using this function?\n\\[\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}|y) = P(y|\\boldsymbol{\\theta})  = f(y|\\boldsymbol{\\theta})\n\\end{align*}\n\\]\n\nThe likelihood (\\(\\mathcal{L}\\)) of the unknown parameters, given our data, can be calculated using our probability function.\n\n\nCODE:\n\n# A data point\n  y=c(10)\n\n#the likelihood the mean is 8, given our data\n  dnorm(y,mean=8)\n\n[1] 0.05399097\n\n\n\n\n\nIf we knew the mean is truly 8, it would also be the probability density of the observation y = 10."
  },
  {
    "objectID": "FW680A4/temp2.html#many-parameter-guesses",
    "href": "FW680A4/temp2.html#many-parameter-guesses",
    "title": "Likelihood / Regression",
    "section": "Many Parameter Guesses",
    "text": "Many Parameter Guesses\n\n# Let's take many guesses of the mean\n  means=seq(0,20,by=0.1)\n\n# Use dnorm to get likelihood of each guess of the mean\n# Assumes sd = 1\n  likelihood=dnorm(y, mean=means)"
  },
  {
    "objectID": "FW680A4/temp2.html#statistics-and-pdf-example",
    "href": "FW680A4/temp2.html#statistics-and-pdf-example",
    "title": "Likelihood / Regression",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWhat is the mean height of King Penguins?"
  },
  {
    "objectID": "FW680A4/temp2.html#statistics-and-pdf-example-1",
    "href": "FW680A4/temp2.html#statistics-and-pdf-example-1",
    "title": "Likelihood / Regression",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWe go and collect data,\n\\(\\boldsymbol{y} = \\begin{matrix} [4.34 & 3.53 & 3.75] \\end{matrix}\\)\n\n\nLet’s decide to use the Normal Distribution as our PDF.\n\n\n\\[\n\\begin{align*}\nf(y_1 = 4.34|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{1}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nAND\n\\[\n\\begin{align*}\nf(y_2 = 3.53|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{2}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\] . . .\nAND\n\\[\n\\begin{align*}\nf(y_3 = 3.75|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{3}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nOr simply,\n\\[\n\\textbf{y} \\stackrel{iid}{\\sim} \\text{Normal}(\\mu, \\sigma)\n\\] . . .\n\\(iid\\) = independent and identically distributed"
  },
  {
    "objectID": "FW680A4/temp2.html#continued",
    "href": "FW680A4/temp2.html#continued",
    "title": "Likelihood / Regression",
    "section": "Continued",
    "text": "Continued\nThe joint probability of our data with shared parameters \\(\\mu\\) and \\(\\sigma\\),\n\\[\n\\begin{align*}\n& P(Y_{1} = y_1,Y_{2} = y_2, Y_{3} = y_3 | \\mu, \\sigma) \\\\\n&= \\mathcal{L}(\\mu, \\sigma|\\textbf{y})\n\\end{align*}\n\\]\n\nIF each \\(y_{i}\\) is independent, the joint probability of our data are simply the multiplication of all three probability densities,\n\\[\n\\begin{align*}\n=& f(y_{1}|\\mu, \\sigma)\\times f(y_{2}|\\mu, \\sigma)\\times f(y_{3}|\\mu, \\sigma) \\end{align*}\n\\]\nWe can do this because we are assuming knowing one value (\\(y_1\\)) does not tell us any new information about another value \\(y_2\\).\n\n\n\\[\n\\begin{align*}\n=& \\prod_{i=1}^{3} f(y_{i}|\\mu, \\sigma) \\\\\n=& \\mathcal{L}(\\mu, \\sigma|y_{1},y_{2},y_{3})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/temp2.html#code",
    "href": "FW680A4/temp2.html#code",
    "title": "Likelihood / Regression",
    "section": "Code",
    "text": "Code\nTranslate the math to code…\n\n# penguin height data\n  y=c(4.34, 3.53, 3.75)\n\n#Joint likelihood of mu=3, sigma =1, given our data\n  prod(dnorm(y,mean=3,sd=1))\n\n[1] 0.01696987\n\n\n\n\nCalcualte likelihood of many guesses of \\(\\mu\\) and \\(\\sigma\\) simultaneously,\n\n# The Guesses\n  mu=seq(0,6,0.05)\n  sigma=seq(0.01,2,0.05)\n  try=expand.grid(mu,sigma)\n  colnames(try)=c(\"mu\",\"sigma\")\n\n# function\nfun=function(a,b){\n  prod(dnorm(y,mean=a,sd=b))\n  }\n\n# mapply the function with the inputs\n  likelihood=mapply(a=try$mu,b=try$sigma, FUN=fun)\n\n# maximum likelihood of parameters\n  try[which.max(likelihood),]\n\n      mu sigma\n925 3.85  0.36"
  },
  {
    "objectID": "FW680A4/temp2.html#likelihood-plot-3d",
    "href": "FW680A4/temp2.html#likelihood-plot-3d",
    "title": "Likelihood / Regression",
    "section": "Likelihood plot (3D)",
    "text": "Likelihood plot (3D)"
  },
  {
    "objectID": "FW680A4/temp2.html#sample-size",
    "href": "FW680A4/temp2.html#sample-size",
    "title": "Likelihood / Regression",
    "section": "Sample Size",
    "text": "Sample Size\nWhat happens to the likelihood if we increase the sample size to N=100?"
  },
  {
    "objectID": "FW680A4/Probability.html#random-variables-3",
    "href": "FW680A4/Probability.html#random-variables-3",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\nProbability: Interested in \\(y\\), the data, and the probability function that “generates” the data. \\[\n\\begin{align*}\ny \\leftarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n\nStatistics: Interested in population characteristics of \\(y\\); i.e., the parameters,\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "classfiles/problab/Markdown and Probability Functions.html",
    "href": "classfiles/problab/Markdown and Probability Functions.html",
    "title": "Markdown, Equations, and the Normal Distribution",
    "section": "",
    "text": "RStudio can help you use Markdown to create HTML/PDF/Word documents that can embed R code, HTML, CSS, latex (type setting language), and more. This is a good website to checkout for markdown coding.\nMarkdown is quite useful for developing reports or doing homeework. Anytime you want to combile code, plotting, or analyses with text, markdown can help. We will use markdown as a way accomplish homework. This way you can provide code and document it simultaneously. I would suggest to not try and get too fancy at first. Keep it simple. Write-text in RStudio as you would in any word processor. Write R code in R chunks. Use “echo=FALSE” and “echo=TRUE” for a code chink to either not print the code or to print the code.\n\nThis probability function is the most widely used and heard of. It has amazing utility. Let’s get to know it a bit more intimately.\nLet’s create an R chunk and plot some data by simulating from a random variable y. Let’s define this variable such that it can take on values of any real number from \\(-\\infty\\) to \\(\\infty\\). So, \\(y \\in (-\\infty, \\infty)\\) or \\(y \\in \\mathbb{R}\\).\nMore specifically, let’s define y as having a probability density function of a Normal/Gaussian distribution,\n\\[y \\sim \\text{Normal}(\\mu, \\sigma).\\]\nAnd stated more generally as,\n\\[f(y;\\mu, \\sigma) = [y|\\mu, \\theta].\\]\n\n# Simulate data from a standard normal distribution (mu = 10, sd = 1)\n  set.seed(54235)\n  y=rnorm(100,10,1)\n\n# Create a histogram\n  hist(y,xlim=c(6,14))\n\n\n\n\n\n\n\nLet’s create a new plot and not output the code. This time we will see the true probability distribution, not simulated values.\n\n\n\n\n\n\n\n\nHTML code can be embedded, such as turning text a different color.\nSimple text formatting can be done directly, such as italics or bolding."
  },
  {
    "objectID": "classfiles/problab/Markdown and Probability Functions.html#approximating-an-integral",
    "href": "classfiles/problab/Markdown and Probability Functions.html#approximating-an-integral",
    "title": "Markdown, Equations, and the Normal Distribution",
    "section": "Approximating an Integral",
    "text": "Approximating an Integral\nLet’s understand this math a bit more. What we are doing is for every value of y possible (\\(-\\infty\\) to \\(\\infty\\)), we multiple it by its probability density. Then we take all these values and add them (i.e., the integral).\nIt’s a bit easier to understand what the math is doing by making an approximation.\nWe can approximate the integral by breaking it into pieces to calculate y times the \\(f(y; \\mu, \\sigma)\\) and then sum all these values.\n\n# Create a histogram and save the values\n  set.seed(14341)\n  y.hist=hist(rnorm(1000,10,1),breaks=8, freq=FALSE,ylim=c(0,0.4),\n              main=\"Random Normal Samples\")\n  \n# Plot the true probabiltiy denisty.\n  curve(dnorm(x,10,1),add=TRUE,lwd=3,col=2)\n  legend(\"topright\",lwd=3,col=c(2),legend=\"True Distribution\")\n\n\n\n\n\n\n# Get the x-axis mid-points of each bin\n  mid.point.x=y.hist$mids\n  mid.point.x\n\n[1]  6.5  7.5  8.5  9.5 10.5 11.5 12.5 13.5\n\n# Get the y-axis values (probability density) for each value. \n  prob.y=y.hist$density\n  prob.y\n\n[1] 0.003 0.021 0.134 0.348 0.343 0.133 0.017 0.001\n\n#multiple these value and sum them\n  sum(prob.y*mid.point.x)\n\n[1] 9.979\n\n\nDoes this answer make sense?\nWhat if you did the same approximation with more simulated values and bins? Perhaps our approximation would get closer to the true value (\\(\\mu = 10\\))!"
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html",
    "href": "classfiles/problab/problab_BDG.html",
    "title": "Probability Lab",
    "section": "",
    "text": "Objective 1) Get acquainted with the Bernoulli/Binomial probability mass function (PMF)\nExercise 1a) Evaluate sample size requirements for tagging studies to asses survival\nExercise 1b) Evaluate the robustness of our findings by varying the true value\n\n\nObjective 2) Get acquainted with the Poisson PMF\nExercise 2) Evaluate sample size requirements for assessing a species’ mean relative abundance\n\n\nObjective 3) Get acquainted with a probability function you do not know well and additional markdown features\nExercise 3) Use markdown to create a summary of a chosen probability function"
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html#objectives-exercises",
    "href": "classfiles/problab/problab_BDG.html#objectives-exercises",
    "title": "Probability Lab",
    "section": "",
    "text": "Objective 1) Get acquainted with the Bernoulli/Binomial probability mass function (PMF)\nExercise 1a) Evaluate sample size requirements for tagging studies to asses survival\nExercise 1b) Evaluate the robustness of our findings by varying the true value\n\n\nObjective 2) Get acquainted with the Poisson PMF\nExercise 2) Evaluate sample size requirements for assessing a species’ mean relative abundance\n\n\nObjective 3) Get acquainted with a probability function you do not know well and additional markdown features\nExercise 3) Use markdown to create a summary of a chosen probability function"
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html#objective-1",
    "href": "classfiles/problab/problab_BDG.html#objective-1",
    "title": "Probability Lab",
    "section": "Objective 1",
    "text": "Objective 1\nLets explore the Bernoulli/Binomial probability mass function (PMF). Imagine doing a tagging study to estimate the survival of sandhill cranes in New Mexico over the winter. We want to use the PMF to connect the ideas of generating data via a probability distribution that is defined by parameters.\nIn this situation, we are interested in simulating samples or observations (or more generally, generate synthetic data) of where cranes either lived (\\(y = 1\\)) or died (y = 0) over our period of interest (winter). If we use the Bernoulli PMF our focus is typically on each i\\(^th\\) crane, while if we are interested in the sum of the number of cranes that lived (\\(\\sum_{i}^n y_i\\)) than we would use the Binomial PMF. Either way, we need to define the parameter associeted with both function, which is the probability of observing a 1 (\\(P(Y=1)\\)), which we will define here as \\(\\theta\\). To make this a useful exercise, we want to decide on \\(\\theta\\) could be in real life.\nRemember, estimation is turning the process around and having data to inform the parameter. Before we do estimation, we want to understand probability functions through simulating/generating synthetic data so we have a better idea of what we are assuming about our empirical data when we use probability functions to estimate parameters. Plus, this process can help us guide our design of future studies.\n\n# Define sandhill crane over winter survival probability (P(Y=1))\n theta = 0.8\n\nThe Bernoulli PMF is useful when thinking about a single event, happening once. Remember, this is a limiting case of the Binomial PMF. We will use the same function, but change the inputs.\nLets observe/generate a single data point where a crane dies (y = 0) or lives (y = 1). In a sense, we are flipping a theoretical coin with probability theta (i.e., \\(P(Y = 1) = \\theta\\)) to observe/sample whether this tagged crane dies or lives.\n\nrbinom(n = 1, size = 1,prob = theta)\n\n[1] 1\n\n\nConsider 10 tagged cranes to get a sample of the number of alive cranes (success’ or 1’s) at the end of the study\n\nrbinom(n = 1, size = 10, prob = theta)\n\n[1] 8\n\n\nNow, consider 10 tagged cranes and you want to keep track of each bird and whether they lived or died (not just the sum of the alive ones).\n\n  rbinom(n = 10, size = 1,prob = theta)\n\n [1] 1 1 1 1 1 1 0 1 1 1\n\n\nNotice that changing the arguments ‘size’ and ‘n’ either focuses on the individual event of 0 and 1’s (size = 1) or the sum of the 1’s (size &gt; 1). n controls how many of those outputs you would like to have\nWhat if we wanted to generate synthetic data of mortality, rather than survival? Well, we just change our setup. Still assuming survival probability is 0.80, than the equivalent mortality probability would be \\(\\theta = 1 - 0.80 = 0.20\\), such the we are saying the probability a crane dies is \\(P(Y = 1) = \\theta = 0.2\\) Now, we can generate data of cranes that have died (1) and that have lived (0).\n\ntheta = 0.2\nrbinom(n = 10, size = 1,prob = theta)\n\n [1] 0 0 0 0 0 0 0 1 0 1\n\n\nWhat is rbinom really doing? Well, the code is actually calling a function using the C programming language because it is fast. But, we can understand more simply what the binomial sampling process looks like by using the generic sample function.\nThe code here defines the outcomes of the stochastic process as either a 0 or 1; x is the argument name of the function. We are asking for 10 trials using size. The replace argument is telling the sampler that we are allowing it sample each outcome (0 and 1) more than one time. Lastly, we are defining the \\(P(y = 1)\\) to be 0.80 and the \\(P(y = 0)\\) to be 0.20. This code replicates the same process as the code above: rbinom(n = 10, size = 1,prob = theta).\n\nsample(x = c(1,0),\n       size = 10, \n       replace=TRUE,\n       prob = c(0.8,0.2)\n       )\n\n [1] 1 1 1 0 1 1 1 1 1 0\n\n\nExercise 1a\nUse your knowledge of the Binomial PMF and investigate the study design trade offs of a tagging study to estimate the survival of sandhill cranes. Consider 3 sample sizes of tagged individuals (N): 100, 250, and 500. Define the survival probability as $\\theta$ = 0.80. For each sample, estimate the probability of survival using the estimator \\(\\sum(y)/N\\), where y is the number of alive cranes at the end of the study and N is the number of total tagged cranes. We will justify this decision at a later point, but logically this should be a good estimator. For each sample size, you want to approximate the sampling distribution of the estimator. Once you have each sampling distribution,\n\ndisplay the three sampling distributions on a single plot\nevaluate estimator bias and relative bias. Is the estimator biased?\nestimate the probability a given sample mean will be within 10% of the true values (theta).\ndetermine the most cost efficient number of tags to use such that there is 0.90 probability that a single sample mean is within 10% of the true value\n\nNote: make sure you use enough replicates such that the sampling distribution appears well approximated (i.e., symmetric).\n\n  n.sim = 5000\n  n = c(100,250,500)\n  theta = 0.8\n  theta.hat=matrix(NA, nrow=n.sim, ncol=length(n))\n\n  theta.hat[,1]=rbinom(n.sim, n[1], theta)/n[1]\n  theta.hat[,2]=rbinom(n.sim, n[2], theta)/n[2]\n  theta.hat[,3]=rbinom(n.sim, n[3], theta)/n[3]\n\n  plot.data = data.frame(theta.hat = c(theta.hat), N = c(rep(\"10\",n.sim),rep(\"100\",n.sim),rep(\"1000\",n.sim)))\n\n\n  ggplot(plot.data,aes(theta.hat,fill=N))+\n     scale_fill_manual(values=c(\"red\",\"blue\",\"green\"))+\n     geom_density(alpha=0.5,binwidth=0.05,position=\"identity\") + \n    theme_bw()\n\nWarning in geom_density(alpha = 0.5, binwidth = 0.05, position = \"identity\"):\nIgnoring unknown parameters: `binwidth`\n\n\n\n\n\n\n\n\nThe estimated bias and relative bias show that the estimator is unbiased.\n\nbias = apply(theta.hat,2,mean)-theta\nbias\n\n[1] -0.0006680 -0.0000856 -0.0001304\n\n\n\nr.bias = (apply(theta.hat,2,mean)-theta)/theta\nr.bias\n\n[1] -0.000835 -0.000107 -0.000163\n\n\nA sample size of 250 tags is the best choice to minimize costs and meet the objective of having a 0.90 probability of being within 10% of the true value of \\(\\theta\\).\n\n  limits.truth=c(theta-theta*0.05,\n                 theta+theta*0.05\n                 )\n  my.func = function(x){length(which(x&gt;=limits.truth[1] & \n                                     x&lt;=limits.truth[2]))/length(x)\n                        }\n  prob.truth = apply(theta.hat, 2,FUN = my.func)\n  data.frame(n = n, prob = prob.truth)\n\n    n   prob\n1 100 0.7322\n2 250 0.9046\n3 500 0.9780\n\n\nExercise 1b\nWhat if we are wrong about the assumed probability of survival? Well, we can evaluate this assumption! Rather than considering a single truth (\\(\\theta = 0.80\\)), we can instead consider a range of true values. This way we can evaluate the robustness of our findings. Meaning, if we find that a sample size of 250 meets our objective (0.90 probability of being within 10% of the true \\(\\theta\\)) across a range of assumed survival probabilities, we are can be confident in our recommendation of tagging 250 cranes. Keep in mind there is a lot of real world factors we have not accounted for yet!\nUsing a sample size of 250, evaluate whether there is at least 0.90 probability of being within 10% of the true \\(\\theta\\) where \\(\\theta\\) varies from 0.80 to 1.0 by increments of 0.05. For example, theta = seq(0.7, 1, by = 0.05).\n\nfor each value of \\(\\theta\\), generate the sampling distribution of estimates of \\(\\theta\\) and then calculate the probability of being within 10% of that given values of \\(\\theta\\)\n\nplot these probabilities on a x-y line graph where the x axis is the true value (\\(\\theta\\)) and the y-axis is the estimated probabilities of interest\nusing the plot, decide whether the findings are robust to the choice of \\(\\theta\\)\n\n\n\n  n.sim = 5000\n  n = 250\n  theta = seq(0.8, 1, by=0.05)\n  prob.obj=rep(NA, length(theta))\n\n  for(i in 1:length(theta)){\n    theta.hat=rbinom(n.sim, n, theta[i])/n\n    \n    limits.truth=c(theta[i]-theta[i]*0.05,\n                   theta[i]+theta[i]*0.05\n                   )\n\n    prob.obj[i] = length(which(theta.hat&gt;=limits.truth[1] & \n                 theta.hat&lt;=limits.truth[2]))/length(theta.hat)\n  }  \n\n  plot(theta, prob.obj,type=\"b\",lwd=3,ylim=c(0.5,1),\n       xlab=expression(paste(theta)),\n       ylab=\"Probability of Objective\")\n  abline(h=0.90,lwd=3,col=3)\n\n\n\n\n\n\n\nWe see that our objective (green horizontal line) is met or is higher at all values of \\(\\theta\\) ranging from 0.80 to 1.0."
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html#objective-2",
    "href": "classfiles/problab/problab_BDG.html#objective-2",
    "title": "Probability Lab",
    "section": "Objective 2",
    "text": "Objective 2\nThe Poisson PMF is often the distribution used first when considering count data. For example, counts of plants or animals within a given area. Its always a goog choice when needing to consider rates, such as counts per unit effort. Note that we are not going to think about detection probability at this point. Assuming constant detection probability, we can think of these counts as a measure of relative abundance.\nLet’s say we are interested in counts of American Pika in 10x10 m plots throughout boulder fields in the Rocky Mountains. First, we need to define the mean count, defined as \\(\\lambda\\). Then, we need to decide on how many plots to sample (n).\nSample 10 plots, count pika in each, where the true mean is 100.\n\nrpois(n = 10, lambda = 100)\n\n [1]  90  99  91  96 109  98 100 119 110  99\n\n\nSample 10 plots where the mean is 2\n\nrpois(n = 10, lambda = 2)\n\n [1] 3 3 1 0 2 2 1 3 0 2\n\n\nWhen considering the Poisson distribution, notice how few plots have zero pika. In ecological and wildlife sampling, zero counts are common for a variety of reasons. This is one reason people tend to model counts with two components - a Poisson distribution and a zero-inflated part. More about this later.\nOne of the interesting properties of the Poisson PMF is that it can be fully described with only one parameter (\\(\\lambda\\)), which defines the mean and variance as equivalent. This parameter governs the central tendency of the observations and how much it varies.\nLets look at this property by simulating 10000 counts and estimating the mean and variance.\n\n  set.seed(43243)\n  y = rpois(n = 100000, lambda = 10)\n  mean(y)\n\n[1] 10.00741\n\n  var(y)\n\n[1] 10.0551\n\n\nSo, when using the Poisson distribution, we need to consider that the mean and variance will be assumed equal.\nExercise 2\nEvaluate the sampling distribution of the estimator \\(\\sum(y)/N\\), where y are the counts and N is the number of counts. Assuming \\(\\lambda = 100\\), determine how many sample plots are needed such that the probability a sample is within 5% of the mean is at least 95%. Once this is completed, change to \\(\\lambda  = 25\\). How does your evaluation of the sample size change? Do you need the same, more, or less samples to achieve the same objective?\n\n#Define inputs and outputs\n  lambda = 100\n  n = seq(10,500,by=5)\n  n.sim = 10000\n  mean.mat =matrix(NA, nrow=n.sim, ncol=length(n))\n\n# loop over the different sample sizes - n\nfor(i in 1:length(n)){\n  y.temp = matrix(\n                  replicate(n.sim,\n                            rpois(n[i],lambda=lambda)\n                            ), nrow=n[i],byrow = TRUE\n                  )\n  #Estimate mean of each sample\n  mean.temp = apply(y.temp, 2, mean)\n  mean.mat[,i] = mean.temp\n}\n\ndim(mean.mat)\n\n[1] 10000    99\n\n#Define 5% around truth\n  limits.truth=c(lambda-lambda*0.025,\n                 lambda+lambda*0.025\n                 )\n\n#Estimate probability of being within 5%\n  probs = apply(mean.mat,2,FUN=function(x){length(which(x&gt;=limits.truth[1] &\n                                                        x&lt;= limits.truth[2]\n                                                        )\n                                                  ) / n.sim \n                                         }\n             )\n\n# Plot the probability versus the sample size\n  plot(n,probs,type=\"l\",lwd=3,col=1)\n  abline(h=0.90,lwd=3,col=3)\n\n\n\n\n\n\n\nWe need 45 samples to achieve our objective.\n\n\n\n\n\n\n\n\nChanging to \\(\\lambda = 25\\), we see that a lot more samples are needed to achieve the same objective (&gt;100)."
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html#objective-3",
    "href": "classfiles/problab/problab_BDG.html#objective-3",
    "title": "Probability Lab",
    "section": "Objective 3",
    "text": "Objective 3\nThere are a lot of probability functions that are commonly used in wildlife and ecological modeling. Generally, a lot these functions fall within the exponential family of probability functions. The objective is to become a bit more familiar with a new probability function and to use the nice features of markdown to describe the function and its various properties.\nExercise 3\nCreate a summary of a probability function of your choosing. If you aren’t sure pick from here: Binomial, Poisson, Log-Normal, Beta, or Gamma. If you feel comfortable with these distributions then choose from a long list of options from wikipedia.\nFollow the example below for the Discrete Uniform probability distribution and …\n\nDefine the random variable \\(y\\) that is \\(iid\\) from your distribution\nDefine the sample space and parameter space for each parameter\nInclude the equation of the probability density/mass function\nDefine the expected value (mean) and variance of the distribution (if they exist in closed form)\nVisualize (plot outputs) the pdf/pmf using at least 2 sets of parameters\nDemonstrate using code how to calculate the probability of data over certain ranges (e.g. pnorm).\nDemonstrate how to find the values of data pertaining to a certain probability (e.g. qnorm).\nPlot a small and large sample from the distribution. Comment on whether the samples looks like the PDF.\nProvide an example of what type of data this probability function could be useful for\n\nFor simplicity, use the setup below and swap in code and notation for your chosen probability function."
  },
  {
    "objectID": "classfiles/problab/problab_BDG.html#discrete-uniform",
    "href": "classfiles/problab/problab_BDG.html#discrete-uniform",
    "title": "Probability Lab",
    "section": "Discrete Uniform",
    "text": "Discrete Uniform\nThe discrete uniform distribution defines probabilities for a set of integer values ranging from a lower bound to an upper bound.\n\\[\ny \\sim \\text{Uniform}(a,b)\n\\]\nSupport\nThe support of the random variable \\(y\\) is \\[\ny \\in \\{a, a+1,..., b-1, b\\}\n\\]\nThe support of the parameters \\(a\\) and \\(b\\) are all integers, where \\(b \\geq a\\), and \\(n = b-a+1\\).\nProbability Function\n\\[\nf(y|a,b) = \\frac{1}{n}\n\\]\nMean/Variance\n\\[\nE[y] = \\frac{a+b}{2}\\\\\nVar[Y] = \\frac{n^2-1}{12}\n\\]\nPlotting\nExample 1\n\n#Parameters\n  a=1; b=5\n# Sample Space of RV\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass  \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=3,\n     ylab=\"f(y)\",xlab=c(\"a = 1, b = 5\"))\n     abline(v=(a+b)/2,lwd=3,col=4)\n     legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n\n\n\n\n\n\n\nExample 2\n\n#Parameters\n  a=10; b=100\n#Sample Space\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass    \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=1,\n     ylab=\"f(y)\",xlab=c(\"a = 10, b = 100\"))\n  abline(v=(a+b)/2,lwd=3,col=4)\n  legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n\n\n\n\n\n\n\nProbability\nThe probability of observing samples \\(\\geq\\) 60 when \\(a\\) = 10 and \\(b\\) =100 is,\n\n#Parameters\n  a=10; b=100\n#Sample space\n  x=seq(a,b,by=1)\n  n=length(x)\n#Probability of any one value\n  p=1/n\n  p\n\n[1] 0.01098901\n\n#Add probabilities for all the integers &gt;=60\n  length(which(x&gt;=60))*p\n\n[1] 0.4505495\n\n\nSampling\n\n#Parameters\n  a=10; b=100\n\n#Sample at different sample sizes\n  sample.size=100\n  sample.size2=10000\n  \n  y=round(runif(sample.size,a,b),digits=0)\n  y2=round(runif(sample.size2,a,b),digits=0)\n\n#plotting samples with True probability\n  par(mfrow=c(1,2))\n  \n  hist(y,main=\"N = 100\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n  \n  hist(y2,main=\"N = 10000\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n\n\n\n\n\n\n\nEven at a sample size of 10000, the probabilities are still a bit wonky from the truth, but close. Certainly a lot close to the sample size at 100.\nEcological Data\nThe discrete uniform is not a very useful probability distribution for data. However, it is commonly used as a prior probability distribution when fitting a model using Bayesian inference for parameters that can only be integers within a given range."
  },
  {
    "objectID": "classfiles/problab/problab.html",
    "href": "classfiles/problab/problab.html",
    "title": "Probability Lab",
    "section": "",
    "text": "Objective 1) Get acquainted with the Bernoulli/Binomial probability mass function (PMF)\nExercise 1a) Evaluate sample size requirements for tagging studies to asses survival\nExercise 1b) Evaluate the robustness of our findings by varying the true value\n\n\nObjective 2) Get acquainted with the Poisson PMF\nExercise 2) Evaluate sample size requirements for assessing a species’ mean relative abundance\n\n\nObjective 3) Get acquainted with a probability function you do not know well and additional markdown features\nExercise 3) Use markdown to create a summary of a chosen probability function"
  },
  {
    "objectID": "classfiles/problab/problab.html#objectives-exercises",
    "href": "classfiles/problab/problab.html#objectives-exercises",
    "title": "Probability Lab",
    "section": "",
    "text": "Objective 1) Get acquainted with the Bernoulli/Binomial probability mass function (PMF)\nExercise 1a) Evaluate sample size requirements for tagging studies to asses survival\nExercise 1b) Evaluate the robustness of our findings by varying the true value\n\n\nObjective 2) Get acquainted with the Poisson PMF\nExercise 2) Evaluate sample size requirements for assessing a species’ mean relative abundance\n\n\nObjective 3) Get acquainted with a probability function you do not know well and additional markdown features\nExercise 3) Use markdown to create a summary of a chosen probability function"
  },
  {
    "objectID": "classfiles/problab/problab.html#objective-1",
    "href": "classfiles/problab/problab.html#objective-1",
    "title": "Probability Lab",
    "section": "Objective 1",
    "text": "Objective 1\nLets explore the Bernoulli/Binomial probability mass function (PMF). Imagine doing a tagging study to estimate the survival of sandhill cranes in New Mexico over the winter. We want to use the PMF to connect the ideas of generating data via a probability distribution that is defined by parameters.\nIn this situation, we are interested in simulating samples or observations (or more generally, generate synthetic data) of where cranes either lived (\\(y = 1\\)) or died (y = 0) over our period of interest (winter). If we use the Bernoulli PMF our focus is typically on each i\\(^th\\) crane, while if we are interested in the sum of the number of cranes that lived (\\(\\sum_{i}^n y_i\\)) than we would use the Binomial PMF. Either way, we need to define the parameter associeted with both function, which is the probability of observing a 1 (\\(P(Y=1)\\)), which we will define here as \\(\\theta\\). To make this a useful exercise, we want to decide on \\(\\theta\\) could be in real life.\nRemember, estimation is turning the process around and having data to inform the parameter. Before we do estimation, we want to understand probability functions through simulating/generating synthetic data so we have a better idea of what we are assuming about our empirical data when we use probability functions to estimate parameters. Plus, this process can help us guide our design of future studies.\n\n# Define sandhill crane over winter survival probability (P(Y=1))\n theta = 0.8\n\nThe Bernoulli PMF is useful when thinking about a single event, happening once. Remember, this is a limiting case of the Binomial PMF. We will use the same function, but change the inputs.\nLets observe/generate a single data point where a crane dies (y = 0) or lives (y = 1). In a sense, we are flipping a theoretical coin with probability theta (i.e., \\(P(Y = 1) = \\theta\\)) to observe/sample whether this tagged crane dies or lives.\n\nrbinom(n = 1, size = 1,prob = theta)\n\n[1] 1\n\n\nConsider 10 tagged cranes to get a sample of the number of alive cranes (success’ or 1’s) at the end of the study\n\nrbinom(n = 1, size = 10, prob = theta)\n\n[1] 7\n\n\nNow, consider 10 tagged cranes and you want to keep track of each bird and whether they lived or died (not just the sum of the alive ones).\n\n  rbinom(n = 10, size = 1,prob = theta)\n\n [1] 1 1 0 1 1 0 1 1 1 0\n\n\nNotice that changing the arguments ‘size’ and ‘n’ either focuses on the individual event of 0 and 1’s (size = 1) or the sum of the 1’s (size &gt; 1). n controls how many of those outputs you would like to have\nWhat if we wanted to generate synthetic data of mortality, rather than survival? Well, we just change our setup. Still assuming survival probability is 0.80, than the equivalent mortality probability would be \\(\\theta = 1 - 0.80 = 0.20\\), such the we are saying the probability a crane dies is \\(P(Y = 1) = \\theta = 0.2\\) Now, we can generate data of cranes that have died (1) and that have lived (0).\n\ntheta = 0.2\nrbinom(n = 10, size = 1,prob = theta)\n\n [1] 0 0 0 0 0 0 1 0 1 0\n\n\nWhat is rbinom really doing? Well, the code is actually calling a function using the C programming language because it is fast. But, we can understand more simply what the binomial sampling process looks like by using the generic sample function.\nThe code here defines the outcomes of the stochastic process as either a 0 or 1; x is the argument name of the function. We are asking for 10 trials using size. The replace argument is telling the sampler that we are allowing it sample each outcome (0 and 1) more than one time. Lastly, we are defining the \\(P(y = 1)\\) to be 0.80 and the \\(P(y = 0)\\) to be 0.20. This code replicates the same process as the code above: rbinom(n = 10, size = 1,prob = theta).\n\nsample(x = c(1,0),\n       size = 10, \n       replace=TRUE,\n       prob = c(0.8,0.2)\n       )\n\n [1] 1 1 1 1 0 1 0 0 1 0\n\n\nExercise 1a\nUse your knowledge of the Binomial PMF and investigate the study design trade offs of a tagging study to estimate the survival of sandhill cranes. Consider 3 sample sizes of tagged individuals (N): 100, 250, and 500. Define the survival probability as $\\theta$ = 0.80. For each sample, estimate the probability of survival using the estimator \\(\\sum(y)/N\\), where y is the number of alive cranes at the end of the study and N is the number of total tagged cranes. We will justify this decision at a later point, but logically this should be a good estimator. For each sample size, you want to approximate the sampling distribution of the estimator. Once you have each sampling distribution,\n\ndisplay the three sampling distributions on a single plot\nevaluate estimator bias and relative bias. Is the estimator biased?\nestimate the probability a given sample mean will be within 10% of the true values (theta).\ndetermine the most cost efficient number of tags to use such that there is 0.90 probability that a single sample mean is within 10% of the true value\n\nNote: make sure you use enough replicates such that the sampling distribution appears well approximated (i.e., symmetric).\n\n# Simulate data\n\nThe estimated bias and relative bias show that the estimator is unbiased.\n\n# Calculate Bias\n\n\n# Calculate Relative Bias\n\nA sample size of 250 tags is the best choice to minimize costs and meet the objective of having a 0.90 probability of being within 10% of the true value of \\(\\theta\\).\n\n  # Code to estimat probability here.\n\nExercise 1b\nWhat if we are wrong about the assumed probability of survival? Well, we can evaluate this assumption! Rather than considering a single truth (\\(\\theta = 0.80\\)), we can instead consider a range of true values. This way we can evaluate the robustness of our findings. Meaning, if we find that a sample size of 250 meets our objective (0.90 probability of being within 10% of the true \\(\\theta\\)) across a range of assumed survival probabilities, we are can be confident in our recommendation of tagging 250 cranes. Keep in mind there is a lot of real world factors we have not accounted for yet!\nUsing a sample size of 250, evaluate whether there is at least 0.90 probability of being within 10% of the true \\(\\theta\\) where \\(\\theta\\) varies from 0.80 to 1.0 by increments of 0.05. For example, theta = seq(0.7, 1, by = 0.05).\n\nfor each value of \\(\\theta\\), generate the sampling distribution of estimates of \\(\\theta\\) and then calculate the probability of being within 10% of that given values of \\(\\theta\\)\n\nplot these probabilities on a x-y line graph where the x axis is the true value (\\(\\theta\\)) and the y-axis is the estimated probabilities of interest\nusing the plot, decide whether the findings are robust to the choice of \\(\\theta\\)\n\n\n\n# Simulation and plotting code here\n\nWe see that our objective (green horizontal line) is met or is higher at all values of \\(\\theta\\) ranging from 0.80 to 1.0."
  },
  {
    "objectID": "classfiles/problab/problab.html#objective-2",
    "href": "classfiles/problab/problab.html#objective-2",
    "title": "Probability Lab",
    "section": "Objective 2",
    "text": "Objective 2\nThe Poisson PMF is often the distribution used first when considering count data. For example, counts of plants or animals within a given area. Its always a goog choice when needing to consider rates, such as counts per unit effort. Note that we are not going to think about detection probability at this point. Assuming constant detection probability, we can think of these counts as a measure of relative abundance.\nLet’s say we are interested in counts of American Pika in 10x10 m plots throughout boulder fields in the Rocky Mountains. First, we need to define the mean count, defined as \\(\\lambda\\). Then, we need to decide on how many plots to sample (n).\nSample 10 plots, count pika in each, where the true mean is 100.\n\nrpois(n = 10, lambda = 100)\n\n [1] 127  80  82  89 104  79  98 101 110  83\n\n\nSample 10 plots where the mean is 2\n\nrpois(n = 10, lambda = 2)\n\n [1] 1 3 5 1 2 1 1 2 1 3\n\n\nWhen considering the Poisson distribution, notice how few plots have zero pika. In ecological and wildlife sampling, zero counts are common for a variety of reasons. This is one reason people tend to model counts with two components - a Poisson distribution and a zero-inflated part. More about this later.\nOne of the interesting properties of the Poisson PMF is that it can be fully described with only one parameter (\\(\\lambda\\)), which defines the mean and variance as equivalent. This parameter governs the central tendency of the observations and how much it varies.\nLets look at this property by simulating 10000 counts and estimating the mean and variance.\n\n  set.seed(43243)\n  y = rpois(n = 100000, lambda = 10)\n  mean(y)\n\n[1] 10.00741\n\n  var(y)\n\n[1] 10.0551\n\n\nSo, when using the Poisson distribution, we need to consider that the mean and variance will be assumed equal.\nExercise 2\nEvaluate the sampling distribution of the estimator \\(\\sum(y)/N\\), where y are the counts and N is the number of counts. Assuming \\(\\lambda = 100\\), determine how many sample plots are needed such that the probability a sample is within 5% of the mean is at least 95%. Once this is completed, change to \\(\\lambda  = 25\\). How does your evaluation of the sample size change? Do you need the same, more, or less samples to achieve the same objective?\n\n# Simulation Code\n\n\n# Estimate probability and plot results"
  },
  {
    "objectID": "classfiles/problab/problab.html#objective-3",
    "href": "classfiles/problab/problab.html#objective-3",
    "title": "Probability Lab",
    "section": "Objective 3",
    "text": "Objective 3\nThere are a lot of probability functions that are commonly used in wildlife and ecological modeling. Generally, a lot these functions fall within the exponential family of probability functions. The objective is to become a bit more familiar with a new probability function and to use the nice features of markdown to describe the function and its various properties.\nExercise 3\nCreate a summary of a probability function of your choosing. If you aren’t sure pick from here: Binomial, Poisson, Log-Normal, Beta, or Gamma. If you feel comfortable with these distributions then choose from a long list of options from wikipedia.\nFollow the example below for the Discrete Uniform probability distribution and …\n\nDefine the random variable \\(y\\) that is \\(iid\\) from your distribution\nDefine the sample space and parameter space for each parameter\nInclude the equation of the probability density/mass function\nDefine the expected value (mean) and variance of the distribution (if they exist in closed form)\nVisualize (plot outputs) the pdf/pmf using at least 2 sets of parameters\nDemonstrate using code how to calculate the probability of data over certain ranges (e.g. pnorm).\nDemonstrate how to find the values of data pertaining to a certain probability (e.g. qnorm).\nPlot a small and large sample from the distribution. Comment on whether the samples looks like the PDF.\nProvide an example of what type of data this probability function could be useful for\n\nFor simplicity, you can use the setup below and swap in code and notation for your chosen probability function. Also, see the markdown file shared for the Normal Distribution as another exmaple."
  },
  {
    "objectID": "classfiles/problab/problab.html#discrete-uniform",
    "href": "classfiles/problab/problab.html#discrete-uniform",
    "title": "Probability Lab",
    "section": "Discrete Uniform",
    "text": "Discrete Uniform\nThe discrete uniform distribution defines probabilities for a set of integer values ranging from a lower bound to an upper bound.\n\\[\ny \\sim \\text{Uniform}(a,b)\n\\]\nSupport\nThe support of the random variable \\(y\\) is \\[\ny \\in \\{a, a+1,..., b-1, b\\}\n\\]\nThe support of the parameters \\(a\\) and \\(b\\) are all integers, where \\(b \\geq a\\), and \\(n = b-a+1\\).\nProbability Function\n\\[\nf(y|a,b) = \\frac{1}{n}\n\\]\nMean/Variance\n\\[\nE[y] = \\frac{a+b}{2}\\\\\nVar[Y] = \\frac{n^2-1}{12}\n\\]\nPlotting\nExample 1\n\n#Parameters\n  a=1; b=5\n# Sample Space of RV\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass  \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=3,\n     ylab=\"f(y)\",xlab=c(\"a = 1, b = 5\"))\n     abline(v=(a+b)/2,lwd=3,col=4)\n     legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n\n\n\n\n\n\n\nExample 2\n\n#Parameters\n  a=10; b=100\n#Sample Space\n  x=seq(a,b,by=1)\n  n=length(x)\n#plotting probability mass    \n  plot(x,rep(1/n,length(x)),col=2,pch=18,cex=1,\n     ylab=\"f(y)\",xlab=c(\"a = 10, b = 100\"))\n  abline(v=(a+b)/2,lwd=3,col=4)\n  legend(\"topright\",lwd=3,col=4,legend=c(\"Mean\"))\n\n\n\n\n\n\n\nProbability\nThe probability of observing samples \\(\\geq\\) 60 when \\(a\\) = 10 and \\(b\\) =100 is,\n\n#Parameters\n  a=10; b=100\n#Sample space\n  x=seq(a,b,by=1)\n  n=length(x)\n#Probability of any one value\n  p=1/n\n  p\n\n[1] 0.01098901\n\n#Add probabilities for all the integers &gt;=60\n  length(which(x&gt;=60))*p\n\n[1] 0.4505495\n\n\nSampling\n\n#Parameters\n  a=10; b=100\n\n#Sample at different sample sizes\n  sample.size=100\n  sample.size2=10000\n  \n  y=round(runif(sample.size,a,b),digits=0)\n  y2=round(runif(sample.size2,a,b),digits=0)\n\n#plotting samples with True probability\n  par(mfrow=c(1,2))\n  \n  hist(y,main=\"N = 100\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n  \n  hist(y2,main=\"N = 10000\",freq = FALSE)\n  abline(h=p,col=3,lwd=3)\n\n\n\n\n\n\n\nEven at a sample size of 10000, the probabilities are still a bit wonky from the truth, but close. Certainly a lot close to the sample size at 100.\nEcological Data\nThe discrete uniform is not a very useful probability distribution for data. However, it is commonly used as a prior probability distribution when fitting a model using Bayesian inference for parameters that can only be integers within a given range."
  },
  {
    "objectID": "docs/FW680A4/probability.html",
    "href": "docs/FW680A4/probability.html",
    "title": "Probability",
    "section": "",
    "text": "Connect random variables, probabilities, and parameters\n\ndefine prob. functions\n\ndiscrete and continuous random variables\n\n\nuse/plot prob. functions\nlearn some notation"
  },
  {
    "objectID": "docs/FW680A4/probability.html#objectives",
    "href": "docs/FW680A4/probability.html#objectives",
    "title": "Probability",
    "section": "",
    "text": "Connect random variables, probabilities, and parameters\n\ndefine prob. functions\n\ndiscrete and continuous random variables\n\n\nuse/plot prob. functions\nlearn some notation"
  },
  {
    "objectID": "docs/FW680A4/probability.html#probabilitystatistics",
    "href": "docs/FW680A4/probability.html#probabilitystatistics",
    "title": "Probability",
    "section": "Probability/Statistics",
    "text": "Probability/Statistics\n\n\nProbability and statistics are the opposite sides of the same coin.\n\n. . .\nTo understand statistics, we need to understand probability and probability functions.\n\n. . .\nThe two key things to understand this connection is the random variable (RV) and parameters (e.g., \\(\\theta\\), \\(\\sigma\\), \\(\\epsilon\\), \\(\\mu\\))."
  },
  {
    "objectID": "docs/FW680A4/probability.html#motivation",
    "href": "docs/FW680A4/probability.html#motivation",
    "title": "Probability",
    "section": "Motivation",
    "text": "Motivation\n\nWhy learn about RVs and probability math?\n\n. . .\nFoundations of:\n\nlinear regression\ngeneralized linear models\nmixed models\n\n. . .\nOur Goal:\n\nconceptual framework to think about data, probabilities, and parameters\n\nmathematical connections and notation"
  },
  {
    "objectID": "docs/FW680A4/probability.html#not-random-variables",
    "href": "docs/FW680A4/probability.html#not-random-variables",
    "title": "Probability",
    "section": "Not Random Variables",
    "text": "Not Random Variables\n\\[\n\\begin{align*}\na =& 10 \\\\\nb =& \\text{log}(a) \\times 12 \\\\\nc =& \\frac{a}{b} \\\\\ny =& \\beta_0 + \\beta_1*c\n\\end{align*}\n\\]\n. . .\nAll variables here are scalars. They are what they are and that is it. \\(\\beta\\) variables and \\(y\\) are currently unknown, but still scalars.\n. . .\n\nScalars are quantities that are fully described by a magnitude (or numerical value) alone."
  },
  {
    "objectID": "docs/FW680A4/probability.html#random-variables",
    "href": "docs/FW680A4/probability.html#random-variables",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\\[\ny \\sim f(y)\n\\]\n\\(y\\) is a random variable which may change values each observation; it changes based on a probability function, \\(f(y)\\).\n\n. . .\nThe tilde (\\(\\sim\\)) denotes “has the probability distribution of”.\n\n. . .\nWhich value (y) is observed is predictable. Need to know parameters (\\(\\theta\\)) of the probability function \\(f(y)\\).\n\n. . .\nSpecifically, \\(f(y|\\theta)\\), where ‘|’ is read as ‘given’.\n. . .\n\nToss of a coin Roll of a die Weight of a captured elk Count of plants in a sampled plot \n\n. . .\n\nThe values observed can be understand based on the frequency within the population or presumed super-population. These frequencies can be described by probabilities."
  },
  {
    "objectID": "docs/FW680A4/probability.html#frequency-probabilitities",
    "href": "docs/FW680A4/probability.html#frequency-probabilitities",
    "title": "Probability",
    "section": "Frequency / Probabilitities",
    "text": "Frequency / Probabilitities\n\n\n\n\npar(mfrow=c(1,2))\nhist(y, breaks=20,xlim=c(0,25),main=main)\nhist(y, breaks=20,xlim=c(0,25),freq = FALSE,main=main)\n\n\n\n\n\n\n\n. . .\nWe often only get to see ONE sample from this distribution."
  },
  {
    "objectID": "docs/FW680A4/probability.html#random-variables-1",
    "href": "docs/FW680A4/probability.html#random-variables-1",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\nWe are often interested in the characteristics of the whole population of frequencies,\n\n\ncentral tendency (mean, mode, median)\n\nvariability (var, sd)\n\nproportion of the population that meets some condition P(\\(8 \\leq y \\leq\\) 12) =0.68\n\n. . .\nWe infer what these are based on our sample (i.e., statistical inference)."
  },
  {
    "objectID": "docs/FW680A4/probability.html#philosophy",
    "href": "docs/FW680A4/probability.html#philosophy",
    "title": "Probability",
    "section": "Philosophy",
    "text": "Philosophy\nFrequentist Paradigm:\nData (e.g., \\(y\\)) are random variables that can be described by probability distributions with unknown parameters that (e.g., \\(\\theta\\)) are fixed (scalars).\n\n. . .\nBayesian Paradigm:\nData (e.g., \\(y\\)) are random variables that can be described by probability functions where the unknown parameters (e.g., \\(\\theta\\)) are also random variables that have probability functions that describe them."
  },
  {
    "objectID": "docs/FW680A4/probability.html#random-variables-2",
    "href": "docs/FW680A4/probability.html#random-variables-2",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\n\\[\n\\begin{align*}\ny =& \\text{ event/outcome} \\\\\nf(y|\\boldsymbol{\\theta}) =& [y|\\boldsymbol{\\theta}]=  \\text{ process governing the value of } y \\\\\n\\boldsymbol{\\theta} =& \\text{ parameters} \\\\\n\\end{align*}\n\\]\n. . .\n\\(f()\\) or [ ] is conveying a function (math).\n. . .\nIt is called a PDF when \\(y\\) is continuous and a PMF when \\(y\\) is discrete.\n\nPDF: probability density function\n\nPMF: probability mass function"
  },
  {
    "objectID": "docs/FW680A4/probability.html#functions",
    "href": "docs/FW680A4/probability.html#functions",
    "title": "Probability",
    "section": "Functions",
    "text": "Functions\nWe commonly use deterministic functions (indicated by non-italic letter); e.g., log(), exp(). Output is always the same with the same input. \\[\n\\hspace{-12pt}\\text{g} \\\\\nx \\Longrightarrow\\fbox{DO STUFF\n} \\Longrightarrow \\text{g}(x)\n\\]\n. . .\n\\[\n\\hspace{-14pt}\\text{g} \\\\\nx \\Longrightarrow\\fbox{+7\n} \\Longrightarrow \\text{g}(x)\n\\]\n. . .\n\\[\n\\text{g}(x) = x + 7\n\\]\n. . ."
  },
  {
    "objectID": "docs/FW680A4/probability.html#random-variables-3",
    "href": "docs/FW680A4/probability.html#random-variables-3",
    "title": "Probability",
    "section": "Random Variables",
    "text": "Random Variables\nProbability: Interested in \\(y\\), the data, and the probability function that “generates” the data. \\[\n\\begin{align*}\ny \\leftarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n. . .\nStatistics: Interested in population characteristics of \\(y\\); i.e., the parameters,\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "docs/FW680A4/probability.html#probability-functions",
    "href": "docs/FW680A4/probability.html#probability-functions",
    "title": "Probability",
    "section": "Probability Functions",
    "text": "Probability Functions\nSpecial functions with rules to guarantee our logic of probabilities are maintained.\n. . .\nDiscrete RVs\n\\(y\\) can only be a certain set of values.\n\n\n\n\\(y \\in  \\{0,1\\}\\)\n\n0 = dead, 1 = alive\n\n\n\n\\(y \\in  \\{0,1, 2\\}\\)\n\n0 = site unoccupied, 1 = site occupied w/o young, 2 = site occupied with young\n\n\n\n\\(y \\in  \\{0, 1, 2, ..., 15\\}\\)\n\ncount of pups in a litter; max could by physiological constraint\n\n\n\n\n\nThese sets are called the sample space (\\(\\Omega\\)) or the support of the RV."
  },
  {
    "objectID": "docs/FW680A4/probability.html#pmf",
    "href": "docs/FW680A4/probability.html#pmf",
    "title": "Probability",
    "section": "PMF",
    "text": "PMF\n\\[\nf(y) = P(Y=y)\n\\]\n. . .\nData has two outcomes (0 = dead, 1 = alive)\n\\(y \\in  \\{0,1\\}\\)\n. . .\nThere are two probabilities\n\n\\(f(0) = P(Y=0)\\)\n\\(f(1) = P(Y=1)\\)\n\n. . .\nAxiom 1: The probability of an event is greater than or equal to zero and less than or equal to 1.\n\\[\n0 \\leq f(y) \\leq 1\n\\] Example,\n\n\\(f(0) = 0.1\\)\n\\(f(1) = 0.9\\)\n\n. . .\nAxiom 2: The sum of the probabilities of all possible values (sample space) is one.\n. . .\n\\[\n\\sum_{i} f(y_i) = f(y_1) + f(y_2) + ... = P(\\Omega) =1\n\\] Example,\n\n\\(f(0) + f(1) = 0.1 + 0.9 = 1\\)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#pmf-1",
    "href": "docs/FW680A4/probability.html#pmf-1",
    "title": "Probability",
    "section": "PMF",
    "text": "PMF\nStill need to define \\(f()\\), our PMF for \\(y \\in  \\{0,1\\}\\)\n. . .\nThe Bernoulli distribution\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\n\n\\(\\theta\\) = P(Y = 1) = 0.2\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2^{1}\\times(1-0.2)^{0-0}\n  \\end{align}\n\\]\n\n\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        = 0.2 \\times (0.8)^{0} = 0.2\n  \\end{align}\n\\]"
  },
  {
    "objectID": "docs/FW680A4/probability.html#bernoulli-pmf",
    "href": "docs/FW680A4/probability.html#bernoulli-pmf",
    "title": "Probability",
    "section": "Bernoulli PMF",
    "text": "Bernoulli PMF\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        \\theta^{y}\\times(1-\\theta)^{1-y}\n  \\end{align}\n\\]\nSample space support (\\(\\Omega\\)):\n\n\\(y \\in  \\{0,1\\}\\)\n\n\nParameter space support (\\(\\Theta\\)):\n\n\\(\\theta \\in  [0,1]\\)\nGeneral: \\(\\theta \\in \\Theta\\)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#bernoulli-pmf-code",
    "href": "docs/FW680A4/probability.html#bernoulli-pmf-code",
    "title": "Probability",
    "section": "Bernoulli PMF (Code)",
    "text": "Bernoulli PMF (Code)\nWhat would our data look like for 10 ducks that had a probability of survival (Y=1) of 0.20?\n\n#Define inputs\n  theta=0.2;  N=1 \n\n#Random sample - 1 duck\n  rbinom(n=1,size=N,theta)\n\n[1] 0\n\n#Random sample - 10 ducks\n  rbinom(n=10,size=N,theta)\n\n [1] 1 0 0 0 1 0 1 0 1 0"
  },
  {
    "objectID": "docs/FW680A4/probability.html#why-is-this-useful-to-us",
    "href": "docs/FW680A4/probability.html#why-is-this-useful-to-us",
    "title": "Probability",
    "section": "Why is this useful to us?",
    "text": "Why is this useful to us?\nHow about to evaluate the sample size of ducks needed to estimate \\(\\theta\\)?\n. . .\n\ny.mat = replicate(1000,rbinom(n = 10,size=N,theta))\ntheta.hat = apply(y.mat, 2, mean)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#binomial-pmf",
    "href": "docs/FW680A4/probability.html#binomial-pmf",
    "title": "Probability",
    "section": "Binomial PMF",
    "text": "Binomial PMF\nThe Bernoulli is a special case of the Binomial Distribution.\n\\[\nf(y|\\theta) = [y|\\theta]=\n  \\begin{align}\n        {N\\choose y} \\theta^{y}\\times(1-\\theta)^{N-y}\n  \\end{align}\n\\]\n\n\\(N\\) = total trials / tagged and released animals\n\n\n\n\\(y\\) = number of successes / number of alive animals at the of the study."
  },
  {
    "objectID": "docs/FW680A4/probability.html#binomial-pmf-code",
    "href": "docs/FW680A4/probability.html#binomial-pmf-code",
    "title": "Probability",
    "section": "Binomial PMF (Code)",
    "text": "Binomial PMF (Code)\n\n# 1 duck tagged/released and one simulation\n  theta=0.2;  N=1 \n  rbinom(n=1,size=N,theta)\n\n[1] 1\n\n\n\n\n# 1000 ducks tagged/released and one simulation\n  theta=0.2;  N=1000 \n  rbinom(n=1,size=N,theta)\n\n[1] 198\n\n\n\n\n\n# 1000 ducks tagged/released and 10 simulation\n  theta=0.2;  N=1000 \n  rbinom(n=10,size=N,theta)\n\n [1] 180 190 198 192 169 192 192 217 206 216\n\n\n\n\n\n# 1 duck tagged for each of 1000 simulations\n  theta=0.2;  N=1\n  y = rbinom(n=1000,size=N,theta)\n  y\n\n   [1] 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0\n  [38] 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0\n  [75] 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n [112] 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 0 0\n [149] 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0\n [186] 1 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [223] 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 1 1 0 0 0 1 0 0\n [260] 0 1 1 0 0 1 0 0 0 1 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n [297] 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n [334] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n [371] 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1\n [408] 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n [445] 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0\n [482] 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n [519] 0 0 1 1 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 0 0 1 0 1 0 0\n [556] 1 0 0 0 1 1 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0\n [593] 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0\n [630] 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 0 1\n [667] 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0\n [704] 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n [741] 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n [778] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1\n [815] 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0\n [852] 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0\n [889] 0 0 1 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 0 0 0\n [926] 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n [963] 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n[1000] 0\n\n\n\n\n\nsum(y)\n\n[1] 186"
  },
  {
    "objectID": "docs/FW680A4/probability.html#support",
    "href": "docs/FW680A4/probability.html#support",
    "title": "Probability",
    "section": "Support",
    "text": "Support\nUse a probability function that makes sense for your data/RV. In Bayesian infernece, we also pick prob. functions that make sense for parameters.\n\nThe sample space and parameter support can be found on Wikipedia for many probability functions."
  },
  {
    "objectID": "docs/FW680A4/probability.html#normal-pdf",
    "href": "docs/FW680A4/probability.html#normal-pdf",
    "title": "Probability",
    "section": "Normal PDF",
    "text": "Normal PDF\nFor example, the Normal/Gaussian distribution describes the sample space for all values on the real number line.\n\\[y \\sim \\text{Normal}(\\mu, \\sigma) \\\\ y \\in (-\\infty, \\infty) \\\\ y \\in \\mathbb{R}\\]\nWhat is the parameter space for \\(\\mu\\) and \\(\\sigma\\)?"
  },
  {
    "objectID": "docs/FW680A4/probability.html#normal-distribution",
    "href": "docs/FW680A4/probability.html#normal-distribution",
    "title": "Probability",
    "section": "Normal Distribution",
    "text": "Normal Distribution\nWe collect data on adult alligator lengths (in).\n\n\n [1]  90.30  83.02 103.67  85.17  99.20 106.74  90.76 105.28  99.41 101.72\n\n\n\n\n Should we use the Normal Distribution to estimate the mean? \n\n. . .\n\nDoes the support of our data match the support of the PDF?\n\n. . .\n\nWhat PDF does?\n\n. . .\n\n\n\n\n\n\n\n\n\nAre they exactly the same?\n\n\n. . .\nThe issue is when the data are near 0, we might estimate non-sensical values (e.g. negative)."
  },
  {
    "objectID": "docs/FW680A4/probability.html#pdf",
    "href": "docs/FW680A4/probability.html#pdf",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nContinuous RVs\n\\(y\\) are an uncountable set of values.\n\n\nProvide ecological data examples that match the support?\n\n\n\n\nGamma: \\(y \\in  (0,\\infty)\\)\n\n\nBeta: \\(y \\in  (0,1)\\)\n\n\nContinuous Uniform: \\(y \\in  [a,b]\\)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#pdf-1",
    "href": "docs/FW680A4/probability.html#pdf-1",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nPDFs of continious RVs follow the same rules as PMFs.\nConfusing Differences\n\nAxiom 1:\n\n\\(f(y) \\geq 0\\)\n\nPDFs output probability densities, not probabilities.\n\n\n\nAxiom 2:\n\nProbs are the area b/w a lower and upper value of \\(y\\); i.e, area under the curve\n\n\n\n\\[\ny \\sim \\text{Normal}(\\mu, \\sigma) \\\\\nf(y|\\mu,\\sigma ) = \\frac{1}{\\sigma\\sqrt{2\\pi}}e^{\\frac{1}{2}(\\frac{y-\\mu}{\\sigma})^{2}} \\\\\n\\]\n\n\n\n\n\n\nvisualize.it(dist = 'norm', stat = c(100),\n             list(mu = 100 , sd = 10), section = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe math,\n\\[\n\\int_{120}^{\\infty} f(y| \\mu, \\sigma)dy = P(120&lt;Y&lt;\\infty)\n\\]\n\n\nRead this as “the integral of the probability density function between 100 and infinity (on the left-hand side) is equal to the probability that the outcome of the random variable is between 100 and infinity (on the right-hand side)”.\n\n\n\nThe code\n\npnorm(120,mean=100,sd=10,lower.tail = FALSE)\n\n[1] 0.02275013\n\n\n\n\n\nOr, we could reverse the question.\n\nqnorm(0.02275,100,10,lower.tail = FALSE)\n\n[1] 120"
  },
  {
    "objectID": "docs/FW680A4/probability.html#pdf-2",
    "href": "docs/FW680A4/probability.html#pdf-2",
    "title": "Probability",
    "section": "PDF",
    "text": "PDF\nAxiom 3:\n\n\\(\\int_{\\text{lower support}}^{\\text{upper suppport}}f(y)dy = 1\\)\n\nThe sum of the probability densities of all possible outcomes is equal to 1."
  },
  {
    "objectID": "docs/FW680A4/probability.html#normal-distribution-pdf-code",
    "href": "docs/FW680A4/probability.html#normal-distribution-pdf-code",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ny = rnorm(1000, mean = 20, sd = 3)\nhist(y,freq=FALSE,ylim=c(0,0.14))\nlines(density(y),lwd=3,col=4)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#normal-distribution-pdf-code-1",
    "href": "docs/FW680A4/probability.html#normal-distribution-pdf-code-1",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ncurve(dnorm(x, mean= 20, sd = 3),\n      xlim=c(0,40),lwd=3,col=2,ylab=\"Probability Density\",xlab=\"y\")\nabline(v=20, lwd=3, col=1, lty=4)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#normal-distribution-pdf-code-2",
    "href": "docs/FW680A4/probability.html#normal-distribution-pdf-code-2",
    "title": "Probability",
    "section": "Normal Distribution (PDF Code)",
    "text": "Normal Distribution (PDF Code)\n\ncurve(dnorm(x, mean = 10, sd = 4),xlim=c(0,40),lwd=4,col=3,add=TRUE)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#gamma-distribution",
    "href": "docs/FW680A4/probability.html#gamma-distribution",
    "title": "Probability",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\nProbability: Interested in the variation of y, \\[\n\\begin{align*}\ny \\leftarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n. . .\n\\[\n\\begin{align*}\n\\boldsymbol{\\theta}  =& \\begin{matrix} [\\kappa & \\theta] \\end{matrix} \\\\\nf(y|\\boldsymbol{\\theta}) &= \\text{Gamma(}\\kappa, \\theta) \\\\\n\\end{align*}\n\\]\n. . .\n\\[\n\\begin{align*}\nf(y|\\boldsymbol{\\theta}) &= \\frac{1}{\\Gamma(\\kappa)\\theta^{\\kappa}}y^{y^{\\kappa-1} e^{-y/\\theta}} \\\\\n\\end{align*}\n\\]\n. . .\nSample/parameter Support:\n\n\\(y \\in (0,\\infty)\\)\n\\(\\kappa \\in (0,\\infty)\\)\n\\(\\theta \\in (0,\\infty)\\)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#gamma-distribution-pdf-code",
    "href": "docs/FW680A4/probability.html#gamma-distribution-pdf-code",
    "title": "Probability",
    "section": "Gamma Distribution (PDF Code)",
    "text": "Gamma Distribution (PDF Code)\nGamma Wikipedia\n\nshape =10\nscale = 2\n\nmean1 = shape*scale\nmode1 = (shape-1)*scale\n\nstdev = sqrt(shape*scale^2)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#gamma-distribution-pdf-code-1",
    "href": "docs/FW680A4/probability.html#gamma-distribution-pdf-code-1",
    "title": "Probability",
    "section": "Gamma Distribution (PDF Code)",
    "text": "Gamma Distribution (PDF Code)\n\ncurve(dgamma(x, shape = shape, scale=scale),xlim=c(0,50),lwd=3,col=2,ylab=\"Probability Density\",xlab=\"y\")\nabline(v=mean1, lwd=3, col=1, lty=4); abline(v=mode1, lwd=3, col=3, lty=4)\nlegend(\"topright\",lty=3, col=c(1,2),legend=c(\"Mean\",\"Mode\"),lwd=3)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#gamma-distribution-1",
    "href": "docs/FW680A4/probability.html#gamma-distribution-1",
    "title": "Probability",
    "section": "Gamma Distribution",
    "text": "Gamma Distribution\nWhat is the probability we would sample a value &gt;40?  In this population, how common is a value &gt;40?\n. . .\n\\[\n\\begin{align*}\np(y&gt;40) = \\int_{40}^{\\infty} f(y|\\boldsymbol{\\theta}) \\,dy\n\\end{align*}\n\\]\n\npgamma(q=40, shape=10, scale=2,lower.tail=FALSE)\n\n[1] 0.004995412\n\n\n\n. . .\nWhat is the probability of observing \\(y\\) &lt; 50\n\npgamma(q=20,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 0.5420703\n\n\n\n. . .\nReverse the question: What values of \\(y\\) and lower have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=TRUE)\n\n[1] 9.590777\n\n\n\n. . .\nWhat values of \\(y\\) and higher have a probability of 0.025\n\nqgamma(p=0.025,shape=10, scale=2,lower.tail=FALSE)\n\n[1] 34.16961\n\n\n. . .\n\ncurve(dgamma(x,shape=10, scale=2),xlim=c(0,50),lwd=3,\n      xlab=\"y\", ylab=\"dgamma(x,shape=10, scale=2)\")\nabline(v=c(9.590777,34.16961),lwd=3,col=2)\n\n\n\n\n\n\n\n. . .\nWe can consider samples from this population,\n\nset.seed(154434)\ny &lt;- rgamma(100, shape=10, scale=2)"
  },
  {
    "objectID": "docs/FW680A4/probability.html#the-others-side-of-the-coin",
    "href": "docs/FW680A4/probability.html#the-others-side-of-the-coin",
    "title": "Probability",
    "section": "The others side of the coin",
    "text": "The others side of the coin\nStatistics: Interested in estimating population-level characteristics; i.e., the parameters\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n. . .\n\n REMEMBER \n\n\\(f(y|\\boldsymbol{\\theta})\\) is a probability statement about \\(y\\),  NOT  \\(\\boldsymbol{\\theta}\\)."
  },
  {
    "objectID": "FW680A4/Probability.html",
    "href": "FW680A4/Probability.html",
    "title": "Probability",
    "section": "",
    "text": "Connect random variables, probabilities, and parameters\n\ndefine prob. functions\n\ndiscrete and continuous random variables\n\n\nuse/plot prob. functions\nlearn some notation"
  },
  {
    "objectID": "FW680A4/temp2.html#the-others-side-of-the-coin",
    "href": "FW680A4/temp2.html#the-others-side-of-the-coin",
    "title": "Likelihood / Regression",
    "section": "The others side of the coin",
    "text": "The others side of the coin\nStatistics: Interested in estimating population-level characteristics; i.e., the parameters\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/temp2.html#proper-guessing",
    "href": "FW680A4/temp2.html#proper-guessing",
    "title": "Likelihood / Regression",
    "section": "Proper Guessing",
    "text": "Proper Guessing\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n#Note: optim function uses minimization, not maximization. \n#THUS, need to put negative in our function\n\n#Note: log=TRUE, allows us to add rather than multiply \n#      (sum, instead of prod)\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1))\n\n#Maximum likihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/temp2.html#the-linear-regression-way",
    "href": "FW680A4/temp2.html#the-linear-regression-way",
    "title": "Likelihood / Regression",
    "section": "The Linear Regression way",
    "text": "The Linear Regression way\nKing Penguin Height Data (N=100)\n\nout=lm(y~1)\nsummary(out)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.00136 -0.61581  0.01208  0.67407  2.58369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.9012     0.0932   41.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.932 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/temp2.html#moments",
    "href": "FW680A4/temp2.html#moments",
    "title": "Likelihood / Regression",
    "section": "Moments",
    "text": "Moments\nBook Chapter (Section 3.4.4.)\nProbability Functions have qualities called ‘Moments’\n\nMoment 1: Expected Value (mean)\nMoment 2: Variance\nMoment 3: Skewness\nMoment 4: Kurtosis\nMoment k: …\n\n\nParameters are not always moments."
  },
  {
    "objectID": "FW680A4/likelihood.html#the-others-side-of-the-coin",
    "href": "FW680A4/likelihood.html#the-others-side-of-the-coin",
    "title": "Likelihood / Optimization",
    "section": "The others side of the coin",
    "text": "The others side of the coin\nStatistics: Interested in estimating population-level characteristics; i.e., the parameters\n\\[\n\\begin{align*}\ny \\rightarrow& f(y|\\boldsymbol{\\theta}) \\\\\n\\end{align*}\n\\]\n\n\nEstimation\n\nlikelihood\nBayesian"
  },
  {
    "objectID": "FW680A4/likelihood.html#estimation",
    "href": "FW680A4/likelihood.html#estimation",
    "title": "Likelihood / Optimization",
    "section": "Estimation",
    "text": "Estimation\n\nlikelihood\nBayesian"
  },
  {
    "objectID": "FW680A4/likelihood.html#likelihood",
    "href": "FW680A4/likelihood.html#likelihood",
    "title": "Likelihood / Optimization",
    "section": "Likelihood",
    "text": "Likelihood\nLikelihood principle\nAll the evidence/information in a sample (\\(\\textbf{y}\\), i.e., data) relevant to making inference on model parameters (\\(\\theta\\)) is contained in the likelihood function."
  },
  {
    "objectID": "FW680A4/likelihood.html#the-likelihood-function",
    "href": "FW680A4/likelihood.html#the-likelihood-function",
    "title": "Likelihood / Optimization",
    "section": "The Likelihood Function",
    "text": "The Likelihood Function\n\\[\n\\begin{align*}\n\\mathcal{L}(\\boldsymbol{\\theta}|y) = P(y|\\boldsymbol{\\theta})  = f(y|\\boldsymbol{\\theta})\n\\end{align*}\n\\]\n\nThe likelihood (\\(\\mathcal{L}\\)) of the unknown parameters, given our data, can be calculated using our probability function."
  },
  {
    "objectID": "FW680A4/likelihood.html#many-parameter-guesses",
    "href": "FW680A4/likelihood.html#many-parameter-guesses",
    "title": "Likelihood / Optimization",
    "section": "Many Parameter Guesses",
    "text": "Many Parameter Guesses\n\n# Let's take many guesses of the mean\n# (GRID SEARCH)\n  means = seq(0,20,by=0.1)\n\n# Use dnorm to get likelihood of each guess of the mean\n  likelihood = dnorm(y, mean=means, sd=1)\n  sum(likelihood*0.1)\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/likelihood.html#maximum-likelihoof-properties",
    "href": "FW680A4/likelihood.html#maximum-likelihoof-properties",
    "title": "Likelihood / Optimization",
    "section": "Maximum Likelihoof Properties",
    "text": "Maximum Likelihoof Properties\n\nCentral Tenet: evidence is relative.\nParameters are not RVs. They are not defined by a PDF/PMF.\nMLEs are consistent. As sample size increases, they will converge to the true parameter value.\nMLEs are asymptotically unbiased. The \\(E[\\hat{\\theta}]\\) converges to \\(\\theta\\) as the sample size gets larger.\nNo guarantee that MLE is unbiased as small sample size. Can be tested!\nMLEs will have the minimum variance among all estimators, as the sample size gets larger."
  },
  {
    "objectID": "FW680A4/likelihood.html#statistics-and-pdf-example",
    "href": "FW680A4/likelihood.html#statistics-and-pdf-example",
    "title": "Likelihood / Optimization",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWhat is the mean height of King Penguins?"
  },
  {
    "objectID": "FW680A4/likelihood.html#statistics-and-pdf-example-1",
    "href": "FW680A4/likelihood.html#statistics-and-pdf-example-1",
    "title": "Likelihood / Optimization",
    "section": "Statistics and PDF Example",
    "text": "Statistics and PDF Example\nWe go and collect data,\n\\(\\boldsymbol{y} = \\begin{matrix} [4.34 & 3.53 & 3.75] \\end{matrix}\\)\n\n\nLet’s decide to use the Normal Distribution as our PDF.\n\n\n\\[\n\\begin{align*}\nf(y_1 = 4.34|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{1}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nAND\n\\[\n\\begin{align*}\nf(y_2 = 3.53|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{2}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\] . . .\nAND\n\\[\n\\begin{align*}\nf(y_3 = 3.75|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{3}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nOr simply,\n\\[\n\\textbf{y} \\stackrel{iid}{\\sim} \\text{Normal}(\\mu, \\sigma)\n\\] . . .\n\\(iid\\) = independent and identically distributed"
  },
  {
    "objectID": "FW680A4/likelihood.html#continued",
    "href": "FW680A4/likelihood.html#continued",
    "title": "Likelihood / Optimization",
    "section": "Continued",
    "text": "Continued\nThe joint probability of our data with shared parameters \\(\\mu\\) and \\(\\sigma\\),\n\\[\n\\begin{align*}\n& P(Y_{1} = y_1,Y_{2} = y_2, Y_{3} = y_3 | \\mu, \\sigma) \\\\\n&= \\mathcal{L}(\\mu, \\sigma|\\textbf{y})\n\\end{align*}\n\\]\n\nIF each \\(y_{i}\\) is independent, the joint probability of our data are simply the multiplication of all three probability densities,\n\\[\n\\begin{align*}\n=& f(y_{1}|\\mu, \\sigma)\\times f(y_{2}|\\mu, \\sigma)\\times f(y_{3}|\\mu, \\sigma) \\end{align*}\n\\]\nWe can do this because we are assuming knowing one value (\\(y_1\\)) does not tell us any new information about another value \\(y_2\\).\n\n\n\\[\n\\begin{align*}\n=& \\prod_{i=1}^{3} f(y_{i}|\\mu, \\sigma) \\\\\n=& \\mathcal{L}(\\mu, \\sigma|y_{1},y_{2},y_{3})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/likelihood.html#code",
    "href": "FW680A4/likelihood.html#code",
    "title": "Likelihood / Optimization",
    "section": "Code",
    "text": "Code\nTranslate the math to code…\n\n# penguin height data\n  y = c(4.34, 3.53, 3.75)\n\n# Joint likelihood of mu=3, sigma =1, given our data\n  prod(dnorm(y, mean = 3,sd = 1))\n\n[1] 0.01696987"
  },
  {
    "objectID": "FW680A4/likelihood.html#likelihood-plot-3d",
    "href": "FW680A4/likelihood.html#likelihood-plot-3d",
    "title": "Likelihood / Optimization",
    "section": "Likelihood plot (3D)",
    "text": "Likelihood plot (3D)"
  },
  {
    "objectID": "FW680A4/likelihood.html#sample-size",
    "href": "FW680A4/likelihood.html#sample-size",
    "title": "Likelihood / Optimization",
    "section": "Sample Size",
    "text": "Sample Size\nWhat happens to the likelihood if we increase the sample size to N=100?"
  },
  {
    "objectID": "FW680A4/likelihood.html#proper-guessing",
    "href": "FW680A4/likelihood.html#proper-guessing",
    "title": "Likelihood / Optimization",
    "section": "Proper Guessing",
    "text": "Proper Guessing\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n#Note: optim function uses minimization, not maximization. \n#THUS, need to put negative in our function\n\n#Note: log=TRUE, allows us to add rather than multiply \n#      (sum, instead of prod)\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1))\n\n#Maximum likihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/likelihood.html#the-linear-regression-way",
    "href": "FW680A4/likelihood.html#the-linear-regression-way",
    "title": "Likelihood / Optimization",
    "section": "The Linear Regression way",
    "text": "The Linear Regression way\nKing Penguin Height Data (N=100)\n\nout=lm(y~1)\nsummary(out)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.00136 -0.61581  0.01208  0.67407  2.58369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.9012     0.0932   41.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.932 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/likelihood.html#moments",
    "href": "FW680A4/likelihood.html#moments",
    "title": "Likelihood / Optimization",
    "section": "Moments",
    "text": "Moments\nBook Chapter (Section 3.4.4.)\nProbability Functions have qualities called ‘Moments’\n\nMoment 1: Expected Value (mean)\nMoment 2: Variance\nMoment 3: Skewness\nMoment 4: Kurtosis\nMoment k: …\n\n\nParameters are not always moments."
  },
  {
    "objectID": "publications/articles/Mezbish2024.html",
    "href": "publications/articles/Mezbish2024.html",
    "title": "Habitat selection of non-breeding American black ducks in an urban estuary",
    "section": "",
    "text": "Mezebish Quinn, T., P. W. Paton, B. D. Gerber, J. E. Kilburn, and S. R. McWilliams. 2024. Habitat selection of non-breeding American black ducks in an urban estuary. Journal of Wildlife Management e22649. https://doi.org/10.1002/jwmg.22649"
  },
  {
    "objectID": "publications/articles/Mezbish2024.html#citation",
    "href": "publications/articles/Mezbish2024.html#citation",
    "title": "Habitat selection of non-breeding American black ducks in an urban estuary",
    "section": "",
    "text": "Mezebish Quinn, T., P. W. Paton, B. D. Gerber, J. E. Kilburn, and S. R. McWilliams. 2024. Habitat selection of non-breeding American black ducks in an urban estuary. Journal of Wildlife Management e22649. https://doi.org/10.1002/jwmg.22649"
  },
  {
    "objectID": "publications/articles/Mezbish2024.html#abstract",
    "href": "publications/articles/Mezbish2024.html#abstract",
    "title": "Habitat selection of non-breeding American black ducks in an urban estuary",
    "section": "Abstract",
    "text": "Abstract\nShellfish aquaculture is a globally expanding industry, including in urban estuaries that support non-breeding waterfowl. The effects of shellfish aquaculture on the spatial distribution of non-breeding waterfowl, however, are poorly understood and depend on the ecology of waterfowl and cultivated shellfish species. We investigated how proximity to shellfish aquaculture influenced habitat selection and movement patterns of American black ducks (Anas rubripes) during the non-breeding season (~Oct–May) in 2020–2023 in Rhode Island, USA. The extent to which proximity to aquaculture influenced habitat selection of black ducks depended on factors specific to individuals’ primary non-breeding sites, although proximity to aquaculture did not have biologically meaningful influences on black duck movement rates across all sites. Black ducks across sites consistently selected for areas better suited for aquaculture (i.e., areas of potential future development) relative to areas poorly suited for aquaculture (i.e., areas less likely to be developed). The continued expansion of aquaculture into preferred black duck habitats will increase black duck interactions with aquaculture and therefore should be considered in the decision-making process for siting future aquaculture leases. Future studies should quantify the extent to which continued expansion of aquaculture in those preferred coastal habitats directly influences black ducks."
  },
  {
    "objectID": "FW680A4/Probability.html#moments-1",
    "href": "FW680A4/Probability.html#moments-1",
    "title": "Probability",
    "section": "Moments",
    "text": "Moments\nGamma Distribution: parameters are not moments\nParameters\nShape = \\(\\alpha\\), Rate = \\(\\beta\\)\nOR\nShape = \\(\\kappa\\), Scale = \\(\\theta\\), where \\(\\theta = \\frac{1}{\\beta}\\)\n\nNOTE: probability functions can have Alternative Parameterizations, such they have different parameters.\n\n\nMoments are functions of these parameters:\n\nmean = \\(\\kappa\\theta\\) or \\(\\frac{\\alpha}{\\beta}\\)\nvar = \\(\\kappa\\theta^2\\) or \\(\\frac{\\alpha}{\\beta^2}\\)"
  },
  {
    "objectID": "FW680A4/likelihood.html",
    "href": "FW680A4/likelihood.html",
    "title": "Likelihood / Optimization",
    "section": "",
    "text": "likelihood principle\nlikelihood connection to probability function\noptimization / parameter estimation"
  },
  {
    "objectID": "FW680A4/week3.html",
    "href": "FW680A4/week3.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Likelihood and Optimization\nLecture Code: Likelihood.R\n\n\nReadings for next class:\n\nDushoff et al. 2019\nFieberg, Chapter 1.10\n\n\nBackground Reading (not required):\n\nFieberg, Ch. 1\nBolker Ch. 7\nZurr Ch. 2\n\n\n\n\n\nLecture: Regression\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n  install.packages(c(\"marginaleffects\",\"ggResidpanel\"))\n\n\n\nWhat is biological significance and statistical significance?\nWhat is a p-value and what are the issues with null hypothesis testing?"
  },
  {
    "objectID": "FW680A4/week3.html#week-3",
    "href": "FW680A4/week3.html#week-3",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Likelihood and Optimization\nLecture Code: Likelihood.R\n\n\nReadings for next class:\n\nDushoff et al. 2019\nFieberg, Chapter 1.10\n\n\nBackground Reading (not required):\n\nFieberg, Ch. 1\nBolker Ch. 7\nZurr Ch. 2\n\n\n\n\n\nLecture: Regression\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n  install.packages(c(\"marginaleffects\",\"ggResidpanel\"))\n\n\n\nWhat is biological significance and statistical significance?\nWhat is a p-value and what are the issues with null hypothesis testing?"
  },
  {
    "objectID": "FW680A4/likelihood.html#the-pieces",
    "href": "FW680A4/likelihood.html#the-pieces",
    "title": "Likelihood / Optimization",
    "section": "The pieces",
    "text": "The pieces\n\nThe sample data, \\(\\textbf{y}\\)\nA probability function for \\(\\textbf{y}\\):\n\n\\(f(\\textbf{y};\\theta)\\) or \\([\\textbf{y}|\\theta]\\) or \\(P(\\textbf{y}|\\theta)\\)\nthe unknown parameter(s) (\\(\\theta\\)) of the probability function"
  },
  {
    "objectID": "FW680A4/likelihood.html#the-likelihood-function-1",
    "href": "FW680A4/likelihood.html#the-likelihood-function-1",
    "title": "Likelihood / Optimization",
    "section": "The Likelihood Function",
    "text": "The Likelihood Function\nFor example, for \\(y_{1} \\sim \\text{Normal}(\\mu,\\sigma)\\)\nCODE:\n\n# A data point\n  y = c(10)\n\n#the likelihood the mean is 8, given our data\n  dnorm(y, mean = 8)\n\n[1] 0.05399097\n\n\n\n\nIf we knew the mean is truly 8, it would also be the probability density of the observation y = 10. But, we don’t know what the mean truly is.\n\n\n\nThe key is to understand that the likelihood values are relative, which means we need many guesses.\n\n\n\n\n#the likelihood the mean is 9, given our data\n  dnorm(y, mean = 9)\n\n[1] 0.2419707"
  },
  {
    "objectID": "FW680A4/likelihood.html#maximum-likelihood-properties",
    "href": "FW680A4/likelihood.html#maximum-likelihood-properties",
    "title": "Likelihood / Optimization",
    "section": "Maximum Likelihood Properties",
    "text": "Maximum Likelihood Properties\n\n\nCentral Tenet: evidence is relative.\nParameters are not RVs. They are not defined by a PDF/PMF.\nMLEs are consistent. As sample size increases, they will converge to the true parameter value.\nMLEs are asymptotically unbiased. The \\(E[\\hat{\\theta}]\\) converges to \\(\\theta\\) as the sample size gets larger.\nNo guarantee that MLE is unbiased at small sample size. Can be tested!\nMLEs will have the minimum variance among all estimators, as the sample size gets larger."
  },
  {
    "objectID": "FW680A4/likelihood.html#double-check",
    "href": "FW680A4/likelihood.html#double-check",
    "title": "Likelihood / Optimization",
    "section": "Double Check",
    "text": "Double Check\n\n  means = seq(0,20,by=0.1)\n  likelihood = dnorm(y, mean=means, sd=1)\n  sum(likelihood*0.1)\n\n[1] 1\n\n\n\n\n  means = seq(0,20,by=0.01)\n  likelihood = dnorm(y, mean=means, sd=1)\n  sum(likelihood*0.1)\n\n[1] 10\n\n  sum(likelihood*0.01)\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/likelihood.html#mle-with-n-1",
    "href": "FW680A4/likelihood.html#mle-with-n-1",
    "title": "Likelihood / Optimization",
    "section": "MLE with n > 1",
    "text": "MLE with n &gt; 1\nWhat is the mean height of King Penguins?"
  },
  {
    "objectID": "FW680A4/likelihood.html#mle-with-n-1-1",
    "href": "FW680A4/likelihood.html#mle-with-n-1-1",
    "title": "Likelihood / Optimization",
    "section": "MLE with n > 1",
    "text": "MLE with n &gt; 1\nWe go and collect data,\n\\(\\boldsymbol{y} = \\begin{matrix} [4.34 & 3.53 & 3.75] \\end{matrix}\\)\n\n\nLet’s decide to use the Normal Distribution as our PDF.\n\n\\[\n\\begin{align*}\nf(y_1 = 4.34|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{1}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nAND\n\\[\n\\begin{align*}\nf(y_2 = 3.53|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{2}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]\n\n\nAND\n\\[\n\\begin{align*}\nf(y_3 = 3.75|\\mu,\\sigma)  &= \\frac{1}{\\sigma\\sqrt(2\\pi)}e^{-\\frac{1}{2}(\\frac{y_{3}-\\mu}{\\sigma})^2} \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/likelihood.html#optimization",
    "href": "FW680A4/likelihood.html#optimization",
    "title": "Likelihood / Optimization",
    "section": "Optimization",
    "text": "Optimization\nGrid Search\n\n  means = seq(0, 20,by = 0.1) # many guesses of the mean\n  likelihood = dnorm(y, mean = means, sd = 1) # likelihood of each guess of the mean"
  },
  {
    "objectID": "FW680A4/likelihood.html#need-to-connect-data-together",
    "href": "FW680A4/likelihood.html#need-to-connect-data-together",
    "title": "Likelihood / Optimization",
    "section": "Need to connect data together",
    "text": "Need to connect data together\nOr simply,\n\\[\n\\textbf{y} \\stackrel{iid}{\\sim} \\text{Normal}(\\mu, \\sigma)\n\\]\n\\(iid\\) = independent and identically distributed"
  },
  {
    "objectID": "FW680A4/likelihood.html#optimization-code-grid-search",
    "href": "FW680A4/likelihood.html#optimization-code-grid-search",
    "title": "Likelihood / Optimization",
    "section": "Optimization Code (Grid Search)",
    "text": "Optimization Code (Grid Search)\nCalculate likelihood of many guesses of \\(\\mu\\) and \\(\\sigma\\) simultaneously,\n\n# The Guesses\n  mu = seq(0,6,0.05)\n  sigma = seq(0.01,2,0.05)\n  try = expand.grid(mu,sigma)\n  colnames(try) = c(\"mu\",\"sigma\")\n\n# function\nfun = function(a,b){\n          prod(dnorm(y,mean = a, sd = b))\n      }\n\n# mapply the function with the inputs\n  likelihood = mapply(a = try$mu, b = try$sigma, FUN=fun)"
  },
  {
    "objectID": "FW680A4/likelihood.html#mle-code",
    "href": "FW680A4/likelihood.html#mle-code",
    "title": "Likelihood / Optimization",
    "section": "MLE Code",
    "text": "MLE Code\n\n# maximum likelihood of parameters\n  try[which.max(likelihood),]\n\n      mu sigma\n925 3.85  0.36\n\n\n\n\nLets compare to,\n\nsum(y)/length(y)\n\n[1] 3.873333"
  },
  {
    "objectID": "FW680A4/likelihood.html#objectives",
    "href": "FW680A4/likelihood.html#objectives",
    "title": "Likelihood / Optimization",
    "section": "Objectives",
    "text": "Objectives\n\n\nlikelihood principle\nlikelihood connection to probability function\noptimization / parameter estimation"
  },
  {
    "objectID": "FW680A4/likelihood.html#relativeness",
    "href": "FW680A4/likelihood.html#relativeness",
    "title": "Likelihood / Optimization",
    "section": "Relativeness",
    "text": "Relativeness\nlog-likelihood\n\nfun.log = function(a,b){\n              sum(dnorm(y,mean = a, sd = b, log=TRUE))\n          }\n\nlog.likelihood = mapply(a = try$mu, b = try$sigma, FUN=fun.log)\n  \n# maximum log-likelihood of parameters\n  try[which.max(log.likelihood),]\n\n       mu sigma\n55683 3.9  0.93"
  },
  {
    "objectID": "FW680A4/likelihood.html#optimization-code-minimizationmaximization",
    "href": "FW680A4/likelihood.html#optimization-code-minimizationmaximization",
    "title": "Likelihood / Optimization",
    "section": "Optimization Code (minimization/maximization)",
    "text": "Optimization Code (minimization/maximization)\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n# Note: optim function uses minimization, not maximization. \n# WE want to find the minimum negative log-likelihood\n# THUS, need to put negative in our function\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1)\n             )\n\n#Maximum likelihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/likelihood.html#need-to-connect-data-together-1",
    "href": "FW680A4/likelihood.html#need-to-connect-data-together-1",
    "title": "Likelihood / Optimization",
    "section": "Need to connect data together",
    "text": "Need to connect data together\nThe joint probability of our data with shared parameters \\(\\mu\\) and \\(\\sigma\\),\n\\[\n\\begin{align*}\n& P(Y_{1} = y_1,Y_{2} = y_2, Y_{3} = y_3 | \\mu, \\sigma) \\\\\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n& P(Y_{1} = 4.34,Y_{2} = 3.53, Y_{3} = 3.75 | \\mu, \\sigma) \\\\\n&= \\mathcal{L}(\\mu, \\sigma|\\textbf{y})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/likelihood.html#need-to-connect-data-together-2",
    "href": "FW680A4/likelihood.html#need-to-connect-data-together-2",
    "title": "Likelihood / Optimization",
    "section": "Need to connect data together",
    "text": "Need to connect data together\nIF each \\(y_{i}\\) is independent, the joint probability of our data are simply the multiplication of all three probability densities,\n\\[\n\\begin{align*}\n=& f(4.34|\\mu, \\sigma)\\times f(3.53|\\mu, \\sigma)\\times f(3.75|\\mu, \\sigma) \\end{align*}\n\\] \\[\n\\begin{align*}\n=& \\prod_{i=1}^{3} f(y_{i}|\\mu, \\sigma) \\\\\n=& \\mathcal{L}(\\mu, \\sigma|y_{1},y_{2},y_{3})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/likelihood.html#conditional-independence-assumption",
    "href": "FW680A4/likelihood.html#conditional-independence-assumption",
    "title": "Likelihood / Optimization",
    "section": "Conditional Independence Assumption",
    "text": "Conditional Independence Assumption\nWe can do this because we are assuming knowing one observation does not tell us any new information about another observation. Such that,\n\\(P(y_{2}|y_{1}) = P(y_{2})\\)"
  },
  {
    "objectID": "FW680A4/likelihood.html#optimization-code-minmax",
    "href": "FW680A4/likelihood.html#optimization-code-minmax",
    "title": "Likelihood / Optimization",
    "section": "Optimization Code (min/max)",
    "text": "Optimization Code (min/max)\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n# Note: optim function uses minimization, not maximization. \n# WE want to find the minimum negative log-likelihood\n# THUS, need to put negative in our function\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1)\n             )\n\n#Maximum likelihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/likelihood.html#linear-regression",
    "href": "FW680A4/likelihood.html#linear-regression",
    "title": "Likelihood / Optimization",
    "section": "Linear Regression",
    "text": "Linear Regression\nKing Penguin Height Data (N=100)\n\nout = lm(y~1)\nsummary(out)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3.00136 -0.61581  0.01208  0.67407  2.58369 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   3.9012     0.0932   41.86   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.932 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/likelihood.html#optimization-code-numerical",
    "href": "FW680A4/likelihood.html#optimization-code-numerical",
    "title": "Likelihood / Optimization",
    "section": "Optimization Code (Numerical)",
    "text": "Optimization Code (Numerical)\nLet’s let the computer do some smarter guessing, i.e., optimization.\n\n# Note: optim function uses minimization, not maximization. \n# WE want to find the minimum negative log-likelihood\n# THUS, need to put negative in our function\n\nneg.log.likelihood=function(par){\n  -sum(dnorm(y,mean=par[1],sd=par[2],log=TRUE))\n  }\n\n#find the values that minimizes the function\n#c(1,1) are the initial values for mu and sigma\nfit &lt;- optim(par=c(1,1), fn=neg.log.likelihood,\n             method=\"L-BFGS-B\",\n             lower=c(0,0),upper=c(10,1)\n             )\n\n#Maximum likelihood estimates for mu and sigma\nfit$par\n\n[1] 3.901219 0.927352"
  },
  {
    "objectID": "FW680A4/regression.html#objectives",
    "href": "FW680A4/regression.html#objectives",
    "title": "Linear Regression",
    "section": "Objectives",
    "text": "Objectives\n\n\nfundamentals\nassumptions\nlm / glm functions\nconfidence intervals\ncase study"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-motivation",
    "href": "FW680A4/regression.html#linear-regression-motivation",
    "title": "Linear Regression",
    "section": "Linear Regression (motivation)",
    "text": "Linear Regression (motivation)"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-equation",
    "href": "FW680A4/regression.html#linear-regression-equation",
    "title": "Linear Regression",
    "section": "Linear Regression (Equation)",
    "text": "Linear Regression (Equation)"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-equation-2",
    "href": "FW680A4/regression.html#linear-regression-equation-2",
    "title": "Linear Regression",
    "section": "Linear Regression (Equation 2)",
    "text": "Linear Regression (Equation 2)\n\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma)\\\\\n\\mu_{i} = \\beta_0 + \\beta_1 \\times x_i \\\\\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-line-1",
    "href": "FW680A4/regression.html#linear-regression-line-1",
    "title": "Linear Regression",
    "section": "Linear Regression Line 1",
    "text": "Linear Regression Line 1\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-line-2",
    "href": "FW680A4/regression.html#linear-regression-line-2",
    "title": "Linear Regression",
    "section": "Linear Regression Line 2",
    "text": "Linear Regression Line 2\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#linear-regression-line-3",
    "href": "FW680A4/regression.html#linear-regression-line-3",
    "title": "Linear Regression",
    "section": "Linear Regression Line 3",
    "text": "Linear Regression Line 3\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#visual",
    "href": "FW680A4/regression.html#visual",
    "title": "Linear Regression",
    "section": "Visual",
    "text": "Visual\n\nBlack cicles = observed values / data Red lines = residuals \\(y-\\hat{y}\\) Blue line = \\(\\hat{\\mu}\\)"
  },
  {
    "objectID": "FW680A4/regression.html#assumptions",
    "href": "FW680A4/regression.html#assumptions",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nIndependence of the errors\n\nCorrelation(\\(\\epsilon_{i}\\),\\(\\epsilon_{j}\\)) = 0, \\(\\forall\\) pairs of \\(i\\) and \\(j\\)\n\nThis means that knowing how far observation \\(i\\) will be from the true regression line tells us nothing about how far observation \\(j\\) will be from the regression line."
  },
  {
    "objectID": "FW680A4/regression.html#assumptions-1",
    "href": "FW680A4/regression.html#assumptions-1",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nHomogeniety of the variance\nvar(\\(\\epsilon_{i}\\)) = \\(\\sigma^2\\)\nConstancy in the scatter of observations above and below the line, going left to right."
  },
  {
    "objectID": "FW680A4/regression.html#assumptions-2",
    "href": "FW680A4/regression.html#assumptions-2",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nHeteroskedasticity"
  },
  {
    "objectID": "FW680A4/regression.html#assumptions-3",
    "href": "FW680A4/regression.html#assumptions-3",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nLinearity\n \\[\nE[y_i|x_i] = \\mu_i = \\beta_0 + \\beta_1 \\times x_i \\\\\n\\] \nThe hypothesis about the variables included in the model (e.g., \\(x_i\\)) characterizes the mean well."
  },
  {
    "objectID": "FW680A4/regression.html#assumption-violations",
    "href": "FW680A4/regression.html#assumption-violations",
    "title": "Linear Regression",
    "section": "Assumption Violations",
    "text": "Assumption Violations\nRobustness\n\nLinearity and constant variance are often more important than the assumption of normality (see e.g., Knief & Forstmeier, 2021 and references therein)\n\n\n\nThis is especially true for large sample sizes"
  },
  {
    "objectID": "FW680A4/regression.html#intercept-only-model",
    "href": "FW680A4/regression.html#intercept-only-model",
    "title": "Linear Regression",
    "section": "Intercept-Only Model",
    "text": "Intercept-Only Model\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0\n\\]\n\n\nGenerate Data\n\n#Setup parameters\n  n = 100 # sample size\n  beta0 = 10 # true mean\n  sigma = 2 # true std.dev\n\n# Simulate a data set of observations\n  set.seed(43243)\n  y = rnorm(n, mean = beta0, sd = sigma)"
  },
  {
    "objectID": "FW680A4/regression.html#simulate-intercept-only-model",
    "href": "FW680A4/regression.html#simulate-intercept-only-model",
    "title": "Linear Regression",
    "section": "Simulate Intercept-Only Model",
    "text": "Simulate Intercept-Only Model\n\n#Setup parameters\n  n = 100 # sample size\n  beta0 = 10 # true mean\n  sigma = 2 # true std.dev\n\n# Simulate a data set of observations\n  set.seed(43243)\n  y = rnorm(n, mean = beta0, sd = sigma)"
  },
  {
    "objectID": "FW680A4/regression.html#visualize-intercept-only-model",
    "href": "FW680A4/regression.html#visualize-intercept-only-model",
    "title": "Linear Regression",
    "section": "Visualize Intercept-Only Model",
    "text": "Visualize Intercept-Only Model\n\n  hist(y)"
  },
  {
    "objectID": "FW680A4/regression.html#fit-intercept-only-model",
    "href": "FW680A4/regression.html#fit-intercept-only-model",
    "title": "Linear Regression",
    "section": "Fit Intercept-Only Model",
    "text": "Fit Intercept-Only Model\n\n# Fit model/hypothesis using maximum likelihood\n  model1.0 = lm(y~1)\n\n  model1.1 = glm(y~1)\n\n  model1.2 = glm(y~1, family=gaussian(link = identity))\n\n  \n  \n# Compare Results  \n  data.frame(intercept=c(model1.0$coefficients,model1.1$coefficients, model1.2$coefficients),\n             SE = c(summary(model1.0)$coefficients[, 2], summary(model1.1)$coefficients[, 2],summary(model1.2)$coefficients[, 2])\n            )\n\n  intercept        SE\n1  9.913821 0.1765343\n2  9.913821 0.1765343\n3  9.913821 0.1765343"
  },
  {
    "objectID": "FW680A4/regression.html#fit-intercept-only-model-1",
    "href": "FW680A4/regression.html#fit-intercept-only-model-1",
    "title": "Linear Regression",
    "section": "Fit Intercept-Only Model",
    "text": "Fit Intercept-Only Model\n\n# Summary of model results  \n  summary(model1.0)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7815 -1.2733 -0.0581  1.1558  4.4979 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.9138     0.1765   56.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.765 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/regression.html#fitted-values-intercept-only-model",
    "href": "FW680A4/regression.html#fitted-values-intercept-only-model",
    "title": "Linear Regression",
    "section": "Fitted-values Intercept-Only Model",
    "text": "Fitted-values Intercept-Only Model\n\n#Predict response for all data\n  preds=predict(model1.0, se.fit = TRUE)\n  preds\n\n$fit\n       1        2        3        4        5        6        7        8 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n       9       10       11       12       13       14       15       16 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      17       18       19       20       21       22       23       24 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      25       26       27       28       29       30       31       32 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      33       34       35       36       37       38       39       40 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      41       42       43       44       45       46       47       48 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      49       50       51       52       53       54       55       56 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      57       58       59       60       61       62       63       64 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      65       66       67       68       69       70       71       72 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      73       74       75       76       77       78       79       80 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      81       82       83       84       85       86       87       88 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      89       90       91       92       93       94       95       96 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      97       98       99      100 \n9.913821 9.913821 9.913821 9.913821 \n\n$se.fit\n  [1] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n  [8] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [15] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [22] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [29] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [36] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [43] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [50] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [57] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [64] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [71] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [78] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [85] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [92] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [99] 0.1765343 0.1765343\n\n$df\n[1] 99\n\n$residual.scale\n[1] 1.765343"
  },
  {
    "objectID": "FW680A4/regression.html#confidence-intervals-intercept-only-model",
    "href": "FW680A4/regression.html#confidence-intervals-intercept-only-model",
    "title": "Linear Regression",
    "section": "Confidence Intervals Intercept-Only Model",
    "text": "Confidence Intervals Intercept-Only Model\n\n# Get 90% confidence intervals (Type I error = 0.1)\n  c(\n    (preds$fit+preds$se.fit*qnorm(0.05))[1],\n    (preds$fit+preds$se.fit*qnorm(0.95))[1]\n   )\n\n        1         1 \n 9.623448 10.204195 \n\n  CI.Normal=confint(model1.0, level=0.9)\n  CI.Normal\n\n                 5 %     95 %\n(Intercept) 9.620705 10.20694"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping",
    "href": "FW680A4/regression.html#bootstrapping",
    "title": "Linear Regression",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nInstead of relying on the 95% intervals from an assumed normal distribution, we will create a distribution by resampling our data.\n\nSee, Stats4Ecologists"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-idea",
    "href": "FW680A4/regression.html#bootstrapping-idea",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-idea-1",
    "href": "FW680A4/regression.html#bootstrapping-idea-1",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-idea-2",
    "href": "FW680A4/regression.html#bootstrapping-idea-2",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-code",
    "href": "FW680A4/regression.html#bootstrapping-code",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)\n\n# Setup\n  nboot &lt;- 1000 # number of bootstrap samples\n  nobs &lt;- length(y)\n  bootcoefs &lt;- rep(NA, nboot)\n# Start loop  \nfor(i in 1:nboot){\n  set.seed(43243+i)\n  # Create bootstrap data set by sampling original observations w/ replacement  \n  bootdat &lt;- y[sample(1:nobs, nobs, replace=TRUE)] \n  # Calculate bootstrap statistic\n  glmboot &lt;- glm(bootdat ~ 1)\n  bootcoefs[i] &lt;- coef(glmboot)\n}"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-code-1",
    "href": "FW680A4/regression.html#bootstrapping-code-1",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)"
  },
  {
    "objectID": "FW680A4/regression.html#bootstrapping-code-2",
    "href": "FW680A4/regression.html#bootstrapping-code-2",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)\n\n# Calculate bootstrap standard errors\n  boot.se = sd(bootcoefs)\n\n# boostrap-normal CI\n  boot.normal = c(\n        (preds$fit+boot.se*qnorm(0.05))[1],\n        (preds$fit+boot.se*qnorm(0.95))[1]\n        )\n\n# bootstrap percentile\nconfdat.boot.pct &lt;- quantile(bootcoefs, probs = c(0.05, 0.95))"
  },
  {
    "objectID": "FW680A4/regression.html#comparison",
    "href": "FW680A4/regression.html#comparison",
    "title": "Linear Regression",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "FW680A4/regression.html#categorical-variable-w-2-levels",
    "href": "FW680A4/regression.html#categorical-variable-w-2-levels",
    "title": "Linear Regression",
    "section": "Categorical Variable w/ 2 levels",
    "text": "Categorical Variable w/ 2 levels\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0+\\beta_1\\times x_i\n\\] where \\(x_i\\) is either a zero or one, indicating whether the \\(i^{th}\\) row is from site 1 (0) or site 2 (1).\n\nThis is called Dummy Coding."
  },
  {
    "objectID": "FW680A4/regression.html#categorical-variable-w-2-levels-1",
    "href": "FW680A4/regression.html#categorical-variable-w-2-levels-1",
    "title": "Linear Regression",
    "section": "Categorical Variable w/ 2 levels",
    "text": "Categorical Variable w/ 2 levels\n\n# Setup data\n  x=as.factor(rep(c(\"Site 1\",\"Site 2\"),n/2))\n  levels(x)\n\n[1] \"Site 1\" \"Site 2\"\n\n\n\n\n\n# Turn the factor into 0 and 1's\n  head(model.matrix(~x))\n\n  (Intercept) xSite 2\n1           1       0\n2           1       1\n3           1       0\n4           1       1\n5           1       0\n6           1       1\n\n  x.var=model.matrix(~x)[,2]\n\n\n\n\n\n# Parameters  \n  b0=50\n  b1=-20\n  mu=b0+b1*x.var\n\n# Sample Data\n  set.seed(43243)\n  y=rnorm(n,mean=mu,sd=4)\n\n\n\n\n\n#fit the model \n  model2=glm(y~x)\n  model2.1=glm(y~x.var)\n\n#comparison  \n  rbind(coef(model2), coef(model2.1))\n\n     (Intercept)  xSite 2\n[1,]    50.51109 -21.3669\n[2,]    50.51109 -21.3669"
  },
  {
    "objectID": "FW680A4/regression.html#side-bar-maximum-likelihood-optimization",
    "href": "FW680A4/regression.html#side-bar-maximum-likelihood-optimization",
    "title": "Linear Regression",
    "section": "Side-Bar: Maximum Likelihood Optimization",
    "text": "Side-Bar: Maximum Likelihood Optimization\n\n#Here is our negative log-likelihood function with three\n#parameters - the mean (2) and stdev (1)\nneg.log.like = function(par) {\n  mu=par[1]+par[2]*x.var\n  sum(-dnorm(y,mean = mu,sd = par[3],log = TRUE))\n}\n\n\n\nUse our function in an optimization function\n\n#use optim with initial values and define the lower and upper limits of the possible values\nfit1 &lt;- optim(\n    par = c(0, 0,1),\n    fn = neg.log.like,\n    method = \"L-BFGS-B\",\n    lower = c(-100, -100, 0.01),\n    upper = c(400, 400, 100)\n  )\n\nfit1$par\n\n[1]  50.511067 -21.366842   3.445873"
  },
  {
    "objectID": "FW680A4/regression.html#categorical-variable-w-2-levels-2",
    "href": "FW680A4/regression.html#categorical-variable-w-2-levels-2",
    "title": "Linear Regression",
    "section": "Categorical Variable w/ 2 levels",
    "text": "Categorical Variable w/ 2 levels\n\nsummary(model2)\n\n\nCall:\nglm(formula = y ~ x)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  50.5111     0.4923  102.61   &lt;2e-16 ***\nxSite 2     -21.3669     0.6962  -30.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 12.11631)\n\n    Null deviance: 12601.0  on 99  degrees of freedom\nResidual deviance:  1187.4  on 98  degrees of freedom\nAIC: 537.22\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/regression.html#relevel",
    "href": "FW680A4/regression.html#relevel",
    "title": "Linear Regression",
    "section": "Relevel",
    "text": "Relevel\nWe can manipulate the factor levels of \\(x\\) to indicate that site 1 is denoted by a 1 now and site 2 is denoted by a 0.\n\n\n\n#change intercept meaning\n  x.relev=relevel(x,ref=\"Site 2\")\n  levels(x.relev)\n\n[1] \"Site 2\" \"Site 1\"\n\n\n\n\n\n\n#fit the model again\n  model2.2=glm(y~x.relev)\n\n#Look at coefs  \n  rbind(coef(model2),coef(model2.1),coef(model2.2))\n\n     (Intercept)  xSite 2\n[1,]    50.51109 -21.3669\n[2,]    50.51109 -21.3669\n[3,]    29.14419  21.3669\n\n\n\n\n\n\n#compare predictions  \n  rbind(predict(model2)[1:2],  \n        predict(model2.1)[1:2],\n        predict(model2.2)[1:2]  \n  )\n\n            1        2\n[1,] 50.51109 29.14419\n[2,] 50.51109 29.14419\n[3,] 50.51109 29.14419"
  },
  {
    "objectID": "FW680A4/regression.html#categorical-variable-w-4-levels",
    "href": "FW680A4/regression.html#categorical-variable-w-4-levels",
    "title": "Linear Regression",
    "section": "Categorical Variable w/ 4 levels",
    "text": "Categorical Variable w/ 4 levels\nDummy Coding\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0+(\\beta_1\\times x_{1,i}) + (\\beta_2\\times x_{2,i}) + (\\beta_3\\times x_{3,i})\n\\] \\(x_{1,i} =\\) indicator of site 2 (1) or not (0)\n\\(x_{2,i} =\\) indicator of site 3 (1) or not (0)\n\\(x_{3,i} =\\) indicator of site 4 (1) or not (0)"
  },
  {
    "objectID": "FW680A4/regression.html#categorical-variable-w-4-levels-1",
    "href": "FW680A4/regression.html#categorical-variable-w-4-levels-1",
    "title": "Linear Regression",
    "section": "Categorical Variable w/ 4 levels",
    "text": "Categorical Variable w/ 4 levels\n\n#Setup Data\n  x=as.factor(rep(c(\"Site 1\",\"Site 2\",\"Site 3\", \"Site 4\"),n/4))\n  levels(x)\n\n[1] \"Site 1\" \"Site 2\" \"Site 3\" \"Site 4\"\n\n#Convert factors to 0 and 1's\n  head(model.matrix(~x))\n\n  (Intercept) xSite 2 xSite 3 xSite 4\n1           1       0       0       0\n2           1       1       0       0\n3           1       0       1       0\n4           1       0       0       1\n5           1       0       0       0\n6           1       1       0       0\n\n  x.var=model.matrix(~x)[,2:4]\n\n\n\n\n# Set Parameters  \n  b0=50 #Site 1\n  b1=-20 #Diff of site 2 to site 1\n  b2=-200 #Diff of site 3 to site 1\n  b3=100 #Diff of site 4 to site 1\n  \n# Mean  \n  mu = b0+b1*x.var[,1]+b2*x.var[,2]+b3*x.var[,3]\n\n#True mean group-level values\n  unique(mu)\n\n[1]   50   30 -150  150\n\n#Grand Mean\n  mean(unique(mu))\n\n[1] 20\n\n\n\n\n\n\n# Simulate Data  \n  set.seed(43243)\n  y=rnorm(n,mean=mu,sd=4)\n\n\n\n\n\n# fit the model\n  model3=glm(y~x)\n  model3.1=glm(y~x.var)\n\n# Compare coefs    \n  rbind(coef(model3), coef(model3.1))\n\n     (Intercept)   xSite 2   xSite 3  xSite 4\n[1,]    50.59576 -21.91446 -200.1693 99.01133\n[2,]    50.59576 -21.91446 -200.1693 99.01133"
  },
  {
    "objectID": "FW680A4/regression.html#effect-coding-w-4-levels",
    "href": "FW680A4/regression.html#effect-coding-w-4-levels",
    "title": "Linear Regression",
    "section": "Effect Coding w/ 4 levels",
    "text": "Effect Coding w/ 4 levels\nEffect Coding Link\n\n#Use effect coding to make the intercept the grand mean\n  model3.2=glm(y~x,contrasts = list(x = contr.sum))\n\n\n# Intercept = grand mean of group-means\n# Coef 1 = effect difference of Site 1 from Grand Mean\n# Coef 2 = effect difference of Site 2 from Grand Mean\n# Coef 3 = effect difference of Site 3 from Grand Mean\n\n  coef(model3.2)\n\n(Intercept)          x1          x2          x3 \n  19.827643   30.768114    8.853654 -169.401216 \n\n\n\n\n\n#The coefficient for site-level 4 (difference from the grand mean)\n  sum(coef(model3.2)[-1]*(-1))\n\n[1] 129.7794\n\n\n\n\n\n\n#Predict the values and compare them to the true means for\n#each site\n  rbind(unique(mu),\n  predict(model3.2)[1:4])\n\n            1       2         3        4\n[1,] 50.00000 30.0000 -150.0000 150.0000\n[2,] 50.59576 28.6813 -149.5736 149.6071"
  },
  {
    "objectID": "FW680A4/regression.html#additive-model",
    "href": "FW680A4/regression.html#additive-model",
    "title": "Linear Regression",
    "section": "Additive Model",
    "text": "Additive Model\nCategorical (2 levels) and Continuous Variable\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0+(\\beta_1\\times x_{1,i}) + (\\beta_2\\times x_{2,i})\n\\] \\(x_{1,i} =\\) indicator of site 2 (1) or not (0)\n\\(x_{2,i} =\\) is a continuous numeric value"
  },
  {
    "objectID": "FW680A4/regression.html#additive-model-1",
    "href": "FW680A4/regression.html#additive-model-1",
    "title": "Linear Regression",
    "section": "Additive Model",
    "text": "Additive Model\n\n#A continuous and categorical variable \n  x=as.factor(rep(c(\"Site 1\",\"Site 2\"),n/2))\n  levels(x)\n\n[1] \"Site 1\" \"Site 2\"\n\n  x.var=model.matrix(~x)[,2]\n\n\n\n\n#Simulate x2 variable\n  set.seed(54334)\n  x2=rpois(n,100)\n\n#Parameters\n  b0=50\n  b1=-50\n  b2=4\n\n#Mean  \n  mu=b0+b1*x.var+b2*x2\n\n#Simualte Date  \n  set.seed(43243)\n  y=rnorm(n,mean=mu,sd=50)\n\n# fit the model\n  model4=glm(y~x+x2)\n\n  coef(model4)\n\n(Intercept)     xSite 2          x2 \n  96.615158  -66.748462    3.597896 \n\n\n\n\n\n\n#Confidence intervals of coefs\n  confint(model4)\n\n                 2.5 %     97.5 %\n(Intercept)  14.604365 178.625952\nxSite 2     -83.822719 -49.674206\nx2            2.787034   4.408758\n\n\n\n\n\n\n# Summary  \n  summary(model4)\n\n\nCall:\nglm(formula = y ~ x + x2)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  96.6152    41.8430   2.309   0.0231 *  \nxSite 2     -66.7485     8.7115  -7.662 1.39e-11 ***\nx2            3.5979     0.4137   8.697 8.70e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1894.243)\n\n    Null deviance: 428531  on 99  degrees of freedom\nResidual deviance: 183742  on 97  degrees of freedom\nAIC: 1043.4\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n\n\n\n# Fitted Values\n  newdata=expand.grid(x,x2)\n  head(newdata)\n\n    Var1 Var2\n1 Site 1  112\n2 Site 2  112\n3 Site 1  112\n4 Site 2  112\n5 Site 1  112\n6 Site 2  112\n\n  colnames(newdata)=c(\"x\",\"x2\")\n\n\n  preds=predict(model4,newdata=newdata,type=\"response\",\n              se.fit = TRUE)"
  },
  {
    "objectID": "FW680A4/regression.html#additive-model-plot-1",
    "href": "FW680A4/regression.html#additive-model-plot-1",
    "title": "Linear Regression",
    "section": "Additive Model Plot 1",
    "text": "Additive Model Plot 1\n\nlibrary(sjPlot)\nplot_model(model4, type = \"pred\", terms = c(\"x\"))"
  },
  {
    "objectID": "FW680A4/regression.html#additive-model-plot-2",
    "href": "FW680A4/regression.html#additive-model-plot-2",
    "title": "Linear Regression",
    "section": "Additive Model Plot 2",
    "text": "Additive Model Plot 2\n\nplot_model(model4, type = \"pred\", terms = c(\"x2\",\"x\"))"
  },
  {
    "objectID": "FW680A4/regression.html#interaction-model",
    "href": "FW680A4/regression.html#interaction-model",
    "title": "Linear Regression",
    "section": "Interaction Model",
    "text": "Interaction Model\nCategorical (2 levels) and Continuous Variable\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0+(\\beta_1\\times x_{1,i}) + (\\beta_2\\times x_{2,i}) + (\\beta_3*(x_{1,i}\\times x_{2,i}))\n\\] \\(x_{1,i} =\\) indicator of site 2 (1) or not (0)\n\\(x_{2,i} =\\) is a numeric value\n\\(x_{1,i} \\times x_{2,i}=\\) is zero for site 1 values and the numeric value for site 2 values"
  },
  {
    "objectID": "FW680A4/regression.html#interaction-model-1",
    "href": "FW680A4/regression.html#interaction-model-1",
    "title": "Linear Regression",
    "section": "Interaction Model",
    "text": "Interaction Model\nCategorical (2 levels) and Continuous Variable\n\n# Simulate Variables\n  x=as.factor(rep(c(\"Site 1\",\"Site 2\"),n/2))\n  levels(x)\n\n[1] \"Site 1\" \"Site 2\"\n\n  x.var=model.matrix(~x)[,2]\n\n  set.seed(5453)\n  x2=rpois(n,100)\n\n# Parameters \n  b0=50\n  b1=-50\n  b2=4\n  b3=-20\n\n# Mean  \n  mu = b0+b1*x.var+b2*x2+b3*(x.var*x2)\n\n#Simulate Data\n  set.seed(43243)\n  y=rnorm(n,mean=mu,sd=10)\n\n# fit the model\n  model5=glm(y~x2*x)\n  model5.1=glm(y~x+x2+x:x2)\n\n#comparison  \n  rbind(coef(model5),coef(model5.1))\n\n     (Intercept)         x2    xSite 2 x2:xSite 2\n[1,]    47.51796   4.037598 -60.864156  -19.92472\n[2,]    47.51796 -60.864156   4.037598  -19.92472\n\n\n. . .\n\n\n#Confidence intervals of coefs\n  confint(model5)\n\n                 2.5 %     97.5 %\n(Intercept)  23.600505  71.435410\nx2            3.799657   4.275539\nxSite 2     -95.499112 -26.229199\nx2:xSite 2  -20.270675 -19.578762"
  },
  {
    "objectID": "FW680A4/regression.html#interaction-model-2",
    "href": "FW680A4/regression.html#interaction-model-2",
    "title": "Linear Regression",
    "section": "Interaction Model",
    "text": "Interaction Model\n\n#Summary  \n  summary(model5)\n\n\nCall:\nglm(formula = y ~ x2 * x)\n\nCoefficients:\n            Estimate Std. Error  t value Pr(&gt;|t|)    \n(Intercept)  47.5180    12.2030    3.894 0.000182 ***\nx2            4.0376     0.1214   33.258  &lt; 2e-16 ***\nxSite 2     -60.8642    17.6712   -3.444 0.000850 ***\nx2:xSite 2  -19.9247     0.1765 -112.881  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 76.60874)\n\n    Null deviance: 1.0550e+08  on 99  degrees of freedom\nResidual deviance: 7.3544e+03  on 96  degrees of freedom\nAIC: 723.58\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/regression.html#interaction-model-plot",
    "href": "FW680A4/regression.html#interaction-model-plot",
    "title": "Linear Regression",
    "section": "Interaction Model Plot",
    "text": "Interaction Model Plot\n\ntheme_set(theme_sjplot())\nplot_model(model5, type = \"pred\", terms = c(\"x2\",\"x\"))"
  },
  {
    "objectID": "FW680A4/regression.html#evaluating-assumptions",
    "href": "FW680A4/regression.html#evaluating-assumptions",
    "title": "Linear Regression",
    "section": "Evaluating Assumptions",
    "text": "Evaluating Assumptions\nLargely done based on the residuals\n\\(y_{i} - \\hat{y}_{i}\\)\n\nhist(model$residuals)"
  },
  {
    "objectID": "FW680A4/regression.html#linearity-variance-assumption",
    "href": "FW680A4/regression.html#linearity-variance-assumption",
    "title": "Linear Regression",
    "section": "Linearity & Variance Assumption",
    "text": "Linearity & Variance Assumption"
  },
  {
    "objectID": "FW680A4/regression.html#normality-assumption",
    "href": "FW680A4/regression.html#normality-assumption",
    "title": "Linear Regression",
    "section": "Normality Assumption",
    "text": "Normality Assumption\nTop-left: Normal Q-Q plot. Quantiles of the standardized residuals versus quantiles of a standard normal distribution.\n\npar(mfrow=c(2,2))\nplot(model)"
  },
  {
    "objectID": "FW680A4/regression.html#notes",
    "href": "FW680A4/regression.html#notes",
    "title": "Linear Regression",
    "section": "Notes",
    "text": "Notes\nThe scale-location plot is very similar to residuals vs fitted, but simplifies analysis of the homoskedasticity assumption. It takes the square root of the absolute value of standardized residuals instead of plotting the residuals themselves.\nLeverage refers to the extent to which the coefficients in the regression model would change if a particular observation was removed from the dataset."
  },
  {
    "objectID": "FW680A4/regression.html#exploring-assumptions",
    "href": "FW680A4/regression.html#exploring-assumptions",
    "title": "Linear Regression",
    "section": "Exploring Assumptions",
    "text": "Exploring Assumptions\nNicer looking Plots\n\nlibrary(ggResidpanel)\nresid_panel(model)"
  },
  {
    "objectID": "FW680A4/regression.html#continuous-variable",
    "href": "FW680A4/regression.html#continuous-variable",
    "title": "Linear Regression",
    "section": "Continuous Variable",
    "text": "Continuous Variable\nADD here and mean-centering\n\n#lm(Temperature ~ I(Chirps - mean(Chirps)), data = CricketChirps)"
  },
  {
    "objectID": "FW680A4/regression.html#what-is-a-ci",
    "href": "FW680A4/regression.html#what-is-a-ci",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?\n\n“A confidence interval for a parameter is an interval computed using sample data …\n\n\n“… by a method that will contain the parameter for a specified proportion of all samples.\n\n\nThe success rate (proportion of all samples whose intervals contain the parameter) is known as the confidence level.” R. H. Lock et al. (2020)"
  },
  {
    "objectID": "FW680A4/regression.html#what-is-a-ci-1",
    "href": "FW680A4/regression.html#what-is-a-ci-1",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?\nKey\n\nthe parameter we are trying to estimate is a fixed unknown (i.e., it is not varying across samples)\n\n\n\nthe endpoints of our confidence interval are random and will change every time we collect a new data set (the endpoints themselves actually have a sampling distribution!)\n\n\nMore at Stats4Ecologists"
  },
  {
    "objectID": "FW680A4/regression.html#what-is-a-ci-2",
    "href": "FW680A4/regression.html#what-is-a-ci-2",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?"
  },
  {
    "objectID": "FW680A4/regression.html#assumptions-4",
    "href": "FW680A4/regression.html#assumptions-4",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nNormality\n \\[\n\\epsilon_i \\sim \\text{Normal}(0,\\sigma)\n\\] \nEach \\(i^{th}\\) residual\n\n\ncomes from a Normal distribution with a mean of zero\nis symmetrically disributed around zero\nvaries around zero by \\(\\sigma\\), which is the same for each residual."
  },
  {
    "objectID": "FW680A4/regression.html#fitted-values",
    "href": "FW680A4/regression.html#fitted-values",
    "title": "Linear Regression",
    "section": "Fitted-values",
    "text": "Fitted-values\n\n#Predict response for all data\n  preds = predict(model1.0, se.fit = TRUE)\n  preds\n\n$fit\n       1        2        3        4        5        6        7        8 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n       9       10       11       12       13       14       15       16 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      17       18       19       20       21       22       23       24 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      25       26       27       28       29       30       31       32 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      33       34       35       36       37       38       39       40 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      41       42       43       44       45       46       47       48 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      49       50       51       52       53       54       55       56 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      57       58       59       60       61       62       63       64 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      65       66       67       68       69       70       71       72 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      73       74       75       76       77       78       79       80 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      81       82       83       84       85       86       87       88 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      89       90       91       92       93       94       95       96 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      97       98       99      100 \n9.913821 9.913821 9.913821 9.913821 \n\n$se.fit\n  [1] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n  [8] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [15] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [22] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [29] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [36] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [43] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [50] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [57] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [64] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [71] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [78] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [85] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [92] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [99] 0.1765343 0.1765343\n\n$df\n[1] 99\n\n$residual.scale\n[1] 1.765343"
  },
  {
    "objectID": "FW680A4/regression.html#confidence-intervals",
    "href": "FW680A4/regression.html#confidence-intervals",
    "title": "Linear Regression",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nNormal Approximation\n\n# Get 90% confidence intervals (Type I error = 0.1)\n  c(\n    (preds$fit+preds$se.fit*qnorm(0.05))[1],\n    (preds$fit+preds$se.fit*qnorm(0.95))[1]\n   )\n\n        1         1 \n 9.623448 10.204195 \n\n\n\n\n  CI.Normal=confint(model1.0, level=0.9)\n  CI.Normal\n\n                 5 %     95 %\n(Intercept) 9.620705 10.20694"
  },
  {
    "objectID": "FW680A4/regression.html#section",
    "href": "FW680A4/regression.html#section",
    "title": "Linear Regression",
    "section": "",
    "text": "Fundamental Idea"
  },
  {
    "objectID": "FW680A4/regression.html#section-1",
    "href": "FW680A4/regression.html#section-1",
    "title": "Linear Regression",
    "section": "",
    "text": "Assumptions"
  },
  {
    "objectID": "FW680A4/regression.html#assumptions-5",
    "href": "FW680A4/regression.html#assumptions-5",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nNormality\n \\[\n\\epsilon_i \\sim \\text{Normal}(0,\\sigma)\n\\] \nEach \\(i^{th}\\) residual\n\n\ncomes from a Normal distribution with a mean of zero\nis symmetrically disributed around zero\nvaries around zero by \\(\\sigma\\), which is the same for each residual."
  },
  {
    "objectID": "FW680A4/regression.html#section-2",
    "href": "FW680A4/regression.html#section-2",
    "title": "Linear Regression",
    "section": "",
    "text": "lm and glm"
  },
  {
    "objectID": "FW680A4/regression.html#section-3",
    "href": "FW680A4/regression.html#section-3",
    "title": "Linear Regression",
    "section": "",
    "text": "Confidence Intervals"
  },
  {
    "objectID": "FW680A4/regression.html#section-4",
    "href": "FW680A4/regression.html#section-4",
    "title": "Linear Regression",
    "section": "",
    "text": "Case Study / Independent Variables"
  },
  {
    "objectID": "FW680A4/regression.html#why-model-data",
    "href": "FW680A4/regression.html#why-model-data",
    "title": "Linear Regression",
    "section": "Why model data?",
    "text": "Why model data?\nIn ecology, we use models to,\n\n\ndescribe relationships among outcomes and processes\nto estimate hidden (latent) processes\npredict unobserved values\nforecast future outcomes, such as responses to management"
  },
  {
    "objectID": "FW680A4/regression.html#sampling-distribution",
    "href": "FW680A4/regression.html#sampling-distribution",
    "title": "Linear Regression",
    "section": "Sampling Distribution",
    "text": "Sampling Distribution\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{i}\n\\end{align*}\n\\] \\[\\mu_{i} = 1 + 0.5 \\times x_{i}\\]\n\n\n\n\n\n\n\n\n\n\n\nPlot many replicates of y\n\n\n\n\n\n\n\n\n\n\n\n\nPlot many replicates of y-hat"
  },
  {
    "objectID": "FW680A4/regression.html#prairie-dog-calling",
    "href": "FW680A4/regression.html#prairie-dog-calling",
    "title": "Linear Regression",
    "section": "Prairie Dog Calling",
    "text": "Prairie Dog Calling\n\ny = # of calls per 5 minute at a prairie dog colony\ntemp = temperature, degrees F\ndist.human = distance of nearest human activity to colony\n\n\n  head(dat)\n\n           y     temp dist.human\n1 0.38129119 39.96298   11.75578\n2 0.57770546 47.95317   14.63583\n3 0.00347806 56.13182   22.89228\n4 0.00000000 29.76491   21.14168\n5 2.67643282 40.25998   32.41442\n6 1.71519689 38.31469   35.99573"
  },
  {
    "objectID": "FW680A4/regression.html#exploratory",
    "href": "FW680A4/regression.html#exploratory",
    "title": "Linear Regression",
    "section": "Exploratory",
    "text": "Exploratory"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting",
    "href": "FW680A4/regression.html#model-fitting",
    "title": "Linear Regression",
    "section": "Model Fitting",
    "text": "Model Fitting\n\n  model = lm(y ~ temp+dist.center, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp + dist.center, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -8.312197   1.074281  -7.737 9.65e-12 ***\ntemp         0.156393   0.024605   6.356 6.75e-09 ***\ndist.center  0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting-mean-centering",
    "href": "FW680A4/regression.html#model-fitting-mean-centering",
    "title": "Linear Regression",
    "section": "Model Fitting, Mean-Centering",
    "text": "Model Fitting, Mean-Centering\nMean-center the intercept. Slopes do not change.\n\n  model = lm(y ~ I(temp - mean(temp)) + dist.center, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ I(temp - mean(temp)) + dist.center, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          2.614311   0.895284   2.920  0.00435 ** \nI(temp - mean(temp)) 0.156393   0.024605   6.356 6.75e-09 ***\ndist.center          0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#marginal-predictions",
    "href": "FW680A4/regression.html#marginal-predictions",
    "title": "Linear Regression",
    "section": "Marginal Predictions",
    "text": "Marginal Predictions\n\\[\n\\hat{\\mu_{i}} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}\\times 0 +  \\hat{\\beta_{2}} \\times \\text{dist.human}_i\n\\]\n\n# Plot marginal predictions of dist.human\n  marginaleffects::plot_predictions(model, condition=c(\"dist.human\"))"
  },
  {
    "objectID": "FW680A4/regression.html#add-data-points",
    "href": "FW680A4/regression.html#add-data-points",
    "title": "Linear Regression",
    "section": "Add data points",
    "text": "Add data points\n\n# Plot marginal predictions of dist.human\n  plot1 = marginaleffects::plot_predictions(model, condition=c(\"dist.human\"))\n  plot1+geom_point(data=dat, aes(x=dist.human,y=y))"
  },
  {
    "objectID": "FW680A4/regression.html#combined-predictions",
    "href": "FW680A4/regression.html#combined-predictions",
    "title": "Linear Regression",
    "section": "Combined Predictions",
    "text": "Combined Predictions\n\nmarginaleffects::plot_predictions(model, condition=list(\"temp\",\"dist.human\"))"
  },
  {
    "objectID": "FW680A4/regression.html#combined-predictions-1",
    "href": "FW680A4/regression.html#combined-predictions-1",
    "title": "Linear Regression",
    "section": "Combined Predictions",
    "text": "Combined Predictions\n\nmarginaleffects::plot_predictions(model, condition=list(\"temp\",\"dist.human\" = 0:5))"
  },
  {
    "objectID": "FW680A4/regression.html#combined-predictions-2",
    "href": "FW680A4/regression.html#combined-predictions-2",
    "title": "Linear Regression",
    "section": "Combined Predictions 2",
    "text": "Combined Predictions 2"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting-1",
    "href": "FW680A4/regression.html#model-fitting-1",
    "title": "Linear Regression",
    "section": "Model Fitting 1",
    "text": "Model Fitting 1\n\n  model = lm(y ~ temp+dist.human, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp + dist.human, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -8.312197   1.074281  -7.737 9.65e-12 ***\ntemp         0.156393   0.024605   6.356 6.75e-09 ***\ndist.human   0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#taking-control",
    "href": "FW680A4/regression.html#taking-control",
    "title": "Linear Regression",
    "section": "Taking Control",
    "text": "Taking Control\n\nnewdata = expand.grid(dat$temp,0:5)\ncolnames(newdata)=c(\"temp\",\"dist.human\")\n\npreds = predict(model,newdata = newdata,interval=\"confidence\", level=0.95)\n\npred.plot = data.frame(newdata,preds)"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting-2",
    "href": "FW680A4/regression.html#model-fitting-2",
    "title": "Linear Regression",
    "section": "Model Fitting 2",
    "text": "Model Fitting 2\nMean-center the intercept. Slopes do not change.\n\n  model = lm(y ~ I(temp - mean(temp)) + dist.human, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ I(temp - mean(temp)) + dist.human, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          2.614311   0.895284   2.920  0.00435 ** \nI(temp - mean(temp)) 0.156393   0.024605   6.356 6.75e-09 ***\ndist.human           0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting-3",
    "href": "FW680A4/regression.html#model-fitting-3",
    "title": "Linear Regression",
    "section": "Model Fitting 3",
    "text": "Model Fitting 3\nWhat does the slope mean now?\n\\[\n\\mu_{i} = \\beta_0 + \\beta_1 \\times 1 + \\beta_2 \\times 0\n\\]\n\n  model = lm(y ~ temp.sc + dist.sc, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp.sc + dist.sc, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  11.8002     0.2338  50.471  &lt; 2e-16 ***\ntemp.sc       3.0958     0.4871   6.356 6.75e-09 ***\ndist.sc       5.1771     0.4871  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#linearity-assumption",
    "href": "FW680A4/regression.html#linearity-assumption",
    "title": "Linear Regression",
    "section": "Linearity Assumption",
    "text": "Linearity Assumption\n\nplot(model,1)\n\n\nIdeally, there will be no pattern and the red line should be roughly horizontal near zero."
  },
  {
    "objectID": "FW680A4/regression.html#homogeneity-of-variance",
    "href": "FW680A4/regression.html#homogeneity-of-variance",
    "title": "Linear Regression",
    "section": "Homogeneity of Variance",
    "text": "Homogeneity of Variance\n\nplot(model,3)\n\n\nResiduals should be spread equally along the ranges of predictors. We want a horizontal red line; otherwise, suggests a non-constant variances in the residuals (i.e., heteroscedasticity)."
  },
  {
    "objectID": "FW680A4/regression.html#normality-of-residuals",
    "href": "FW680A4/regression.html#normality-of-residuals",
    "title": "Linear Regression",
    "section": "Normality of Residuals",
    "text": "Normality of Residuals\n\nplot(model,2)\n\n\nShows theoretical quantiles versus empirical quantiles of the residuals. We want to see cicles on the dotted line."
  },
  {
    "objectID": "FW680A4/regression.html#outliers",
    "href": "FW680A4/regression.html#outliers",
    "title": "Linear Regression",
    "section": "Outliers",
    "text": "Outliers\n\npar(mfrow=c(1,2))\nplot(model,4)\nplot(model,5)\n\n\nOutlier: extreme value that can affect the \\(\\beta\\) estimate. Leverage plot: points in the upper right and lower right corner."
  },
  {
    "objectID": "FW680A4/regression.html#residuals",
    "href": "FW680A4/regression.html#residuals",
    "title": "Linear Regression",
    "section": "Residuals",
    "text": "Residuals"
  },
  {
    "objectID": "FW680A4/regression.html#one-sample",
    "href": "FW680A4/regression.html#one-sample",
    "title": "Linear Regression",
    "section": "One Sample",
    "text": "One Sample\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{i}\\\\\n\\mu_{i} =& 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#sampling-distributions",
    "href": "FW680A4/regression.html#sampling-distributions",
    "title": "Linear Regression",
    "section": "Sampling Distributions",
    "text": "Sampling Distributions\n\n\n\n\n\n\n\n\n\n:::\n\n\nPlot many replicates of y-hat"
  },
  {
    "objectID": "FW680A4/regression.html#sampling-distributions-of-y",
    "href": "FW680A4/regression.html#sampling-distributions-of-y",
    "title": "Linear Regression",
    "section": "Sampling Distributions of y",
    "text": "Sampling Distributions of y\n\\[\n\\begin{align*}\n\\mu_{i} = 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#sampling-distributions-of-y-hat",
    "href": "FW680A4/regression.html#sampling-distributions-of-y-hat",
    "title": "Linear Regression",
    "section": "Sampling Distributions of y-hat",
    "text": "Sampling Distributions of y-hat\n\\[\\mu_{i} = 1 + 0.5 \\times x_{i}\\]"
  },
  {
    "objectID": "FW680A4/regression.html#model-fitting-4",
    "href": "FW680A4/regression.html#model-fitting-4",
    "title": "Linear Regression",
    "section": "Model Fitting",
    "text": "Model Fitting\nWhat does the slope mean now?\n\\[\n\\mu_{i} = \\beta_0 + \\beta_1 \\times 1 + \\beta_2 \\times 0\n\\]\n\n  model = lm(y ~ temp.sc + dist.sc, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp.sc + dist.sc, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  11.8002     0.2338  50.471  &lt; 2e-16 ***\ntemp.sc       3.0958     0.4871   6.356 6.75e-09 ***\ndist.sc       5.1771     0.4871  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#normalizing-x",
    "href": "FW680A4/regression.html#normalizing-x",
    "title": "Linear Regression",
    "section": "Normalizing x",
    "text": "Normalizing x\nMean-center and standardize by std. deviation\n\n  dat$temp.sc = scale(dat$temp, center=TRUE, scale = TRUE)\n  dat$dist.sc = scale(dat$dist.human, center=TRUE, scale = TRUE)\n\n\n\n  mean(dat$temp.sc)\n\n[1] 1.40337e-16\n\n  sd(dat$temp.sc)\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/regression.html#comparison-1",
    "href": "FW680A4/regression.html#comparison-1",
    "title": "Linear Regression",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "FW680A4/regression.html#model-notation",
    "href": "FW680A4/regression.html#model-notation",
    "title": "Linear Regression",
    "section": "Model Notation",
    "text": "Model Notation\n\nequatiomatic::extract_eq(model)\n\n\\[\n\\operatorname{y} = \\alpha + \\beta_{1}(\\operatorname{temp.sc}) + \\beta_{2}(\\operatorname{dist.sc}) + \\epsilon\n\\]\n\nequatiomatic::extract_eq(model, use_coefs = TRUE)\n\n\\[\n\\operatorname{\\widehat{y}} = 11.8 + 3.1(\\operatorname{temp.sc}) + 5.18(\\operatorname{dist.sc})\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#sampling-distributions-of-hatmu",
    "href": "FW680A4/regression.html#sampling-distributions-of-hatmu",
    "title": "Linear Regression",
    "section": "Sampling Distributions of \\(\\hat{\\mu}\\)",
    "text": "Sampling Distributions of \\(\\hat{\\mu}\\)\n\\[\n\\begin{align*}\n\\mu_{i} = 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#model-notation-1",
    "href": "FW680A4/regression.html#model-notation-1",
    "title": "Linear Regression",
    "section": "Model Notation 1",
    "text": "Model Notation 1\n\nequatiomatic::extract_eq(model)\n\n\\[\n\\operatorname{y} = \\alpha + \\beta_{1}(\\operatorname{temp}) + \\beta_{2}(\\operatorname{dist.human}) + \\epsilon\n\\]\n\nequatiomatic::extract_eq(model, use_coefs = TRUE)\n\n\\[\n\\operatorname{\\widehat{y}} = -8.31 + 0.16(\\operatorname{temp}) + 0.04(\\operatorname{dist.human})\n\\]"
  },
  {
    "objectID": "FW680A4/regression.html#model-results-1",
    "href": "FW680A4/regression.html#model-results-1",
    "title": "Linear Regression",
    "section": "Model Results 1",
    "text": "Model Results 1\n\nsummary(model)\n\n\nCall:\nlm(formula = y ~ temp + dist.center, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -8.312197   1.074281  -7.737 9.65e-12 ***\ntemp         0.156393   0.024605   6.356 6.75e-09 ***\ndist.center  0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/regression.html#go-to-lab",
    "href": "FW680A4/regression.html#go-to-lab",
    "title": "Linear Regression",
    "section": "Go to Lab",
    "text": "Go to Lab"
  },
  {
    "objectID": "classfiles/regressionlab/regressionlab_BDG.html",
    "href": "classfiles/regressionlab/regressionlab_BDG.html",
    "title": "Regression Lab",
    "section": "",
    "text": "Write a report that presents code and results that evaluates the below hypotheses related to African Elephant weight. The data file is elephant.study.csv. There are three columns, where each row is an individual sampled elephant, indicating the variables of weight (weight in lbs), age.years (age of elephant in years), and lat (mean latitude of the elephants home range).\n\n\nexplore/present the data. use plots/histograms\nwrite model notation correctly or use equatiomatic\nfit the model with lm or glm to get MLEs and CI’s. Define Type I error rate\ninterpret results, in relation to hypotheses. Make statements about ‘statistical clarity’ and support or not for the hypotheses\nmake prediction plots\nevaluate model assumptions\nconclusions and caveats (think about what we have not considered)\nAppendix: present a summary of the R packages you used\n\nThroughout, add text around your code and results to allow the reader to follow your thinking. The text should be minimal.\n\n\nI hypothesize that adult African Elephants (Loxodonta africana) increase in weight as they age because they are more efficient at conserving energy and acquiring high quality resources. As such, I predict that older elephants will weigh more than younger adult elephants. Further, I hypothesize that there is a latitudinal effect on the weight of elephants across the continent of Africa because of the extreme drought in the southern part of their range. I predict that elephants further north will weigh more than elephants further south.\nI evaluated these hypotheses by aggregating data on weights of elephants from collaborators. Each individual elephant was weighed in the same manner while being fit with a GPS collar. Each individual had a known age due to longterm demographic monitoring. I derived the mean latitude of each elephants dry season home range.\n\nThis data set consists of three columns. The response variable is weight and the two independent variables are age.years and lat.\n\n  dat = read.csv(\"elephant.study.csv\")\n  head(dat)\n\n    weight age.years        lat\n1 12615.13        41   2.690077\n2 12539.55        50   2.974857\n3 13753.97        21  -4.868759\n4 17269.26        50 -28.437431\n5 16945.27        16 -26.414605\n6 14723.24        39 -11.392111\n\n  par(mfrow=c(3,1))\n    hist(dat$weight)\n    hist(dat$age.years)\n    hist(dat$lat)\n\n\n\n\n\n\n\nLooking at the data, we see a good frequency of weights ranging from 11681 to 17345. The independent variables are also well distributed and with relatively similar frequency. To make statements of statistical clarity when it comes to rejcting or no rejecting a null hypothesis of no difference, I use a Type I error (\\(\\alpha = 0.05\\)).\n\nTo evaluate my hypotheses, I will consider a linear regression model with an additive effect of age.years and lat. I mean centered the variable age.years so that the intercept can be interpreted in relation to the average weight of elephants when at the equator (lat = 0).\n\nmodel = lm(weight~I(age.years-mean(age.years))+lat, data=dat)\nsummary(model)\n\n\nCall:\nlm(formula = weight ~ I(age.years - mean(age.years)) + lat, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3567.1 -1084.3    44.6   977.9  3467.1 \n\nCoefficients:\n                                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                    13724.967    207.712  66.077  &lt; 2e-16 ***\nI(age.years - mean(age.years))    -8.172     14.431  -0.566    0.572    \nlat                              -79.872     13.833  -5.774 9.31e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1550 on 97 degrees of freedom\nMultiple R-squared:  0.2562,    Adjusted R-squared:  0.2408 \nF-statistic:  16.7 on 2 and 97 DF,  p-value: 5.842e-07\n\nequatiomatic::extract_eq(model)\n\n\\[\n\\operatorname{weight} = \\alpha + \\beta_{1}(\\operatorname{age.years\\ -\\ mean(age.years)}) + \\beta_{2}(\\operatorname{lat}) + \\epsilon\n\\]\n\n\n\\[\n\\begin{align}\n\\epsilon \\sim \\text{Normal}(0,\\sigma^2)\n\\end{align}\n\\]\n\nequatiomatic::extract_eq(model, use_coefs = TRUE)\n\n\\[\n\\operatorname{\\widehat{weight}} = 13724.97 - 8.17(\\operatorname{age.years\\ -\\ mean(age.years)}) - 79.87(\\operatorname{lat})\n\\]\n\n\nBetter Model Notation:\nFor each i\\(^th\\) elephant, we define out model as,\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i}, \\sigma)\\\\\n\\mu =& \\beta_{0} + \\beta_1 \\times (\\text{age}_{i}- \\bar{\\text{age}}) + \\beta_2 \\times \\text{latitude}_{i}.\n\\end{align*}\n\\]\n\nI found the average weight of elephants at the equator (lat = 0) was 13724 lbs. The effect of age on weight was statistically unclear (p = 0.57), not supporting my hypothesis. The estimated effect was relatively small and negative \\(\\hat{\\beta_{1}} =\\) -8.17, 95% CI = -36.81, 20.47. I found a statistically clear effect of latitude (p = 0) with an estimated effect \\(\\hat{\\beta_{2}} =\\) -79.87, 95% CI = rround(confint(model)[3,],digits=2)`. However, this does not support my hypothesis that elephants would weigh more the further north they lived. Instead, we see that weights decreas with increasing latitude.\n\n\nplot_predictions(model, condition = list(\"age.years\"))\n\n\n\n\n\n\nplot_predictions(model, condition = list(\"lat\"))\n\n\n\n\n\n\n\nThe marginal effect plots show the lack of evidence of the effect of age on weight and the support for decreasing weight with latitude. I suggest that this effect is biologically relevant, given that at the extremes in latitudes, we see that the mean weights of elephants is decreased by 18.125%.\n\nplot_predictions(model, condition = list(\"age.years\",\"lat\"))\n\n\n\n\n\n\n\nThe joint prediction plot demonstrates the same findings and the assumption of the additive effect between independent variables.\n\n\nlibrary(ggResidpanel)\nresid_panel(model)\n\n\n\n\n\n\n\nThe top-right plot shows that the residuals are equally spaced below and above zero and that the variation within predicted values are relatively similar. The top-right plot shows no departre of the empirical quantiles of the residuals compared to theoretical values. Lastly, the bottom-right plot shows the residuals look symmetric and roughly Normally-distributed.\n\npar(mfrow=c(1,2))\nplot(model,4); plot(model,5)\n\n\n\n\n\n\n\nLooking at the leverage of each observation, there appears to be a few potential outliers (measured by Cook’s distance), but overall there appears to be little concern. However, to evaluate the effect of the three most extreme values, I will drop these observations and then assess whether the interpretation of the results change.\n\n\n                                  Estimate Std. Error    t value     Pr(&gt;|t|)\n(Intercept)                    13676.98844  199.24863 68.6428229 4.095285e-82\nI(age.years - mean(age.years))   -11.89521   14.25392 -0.8345222 4.061027e-01\nlat                              -88.26940   13.38388 -6.5952033 2.466726e-09\n\n\nWe see that the estimated coefficients change relatively little. My interpretation of the results are the same.\n\nI did not find support of either my hypotheses. Rather, I found evidence of a relevant biological effect where the mean weight of elephants decreased with increasing latitude. The total amount of the data that was explained by this model was relatively weak with an \\(R^2 =\\) 0.26`.\nThere are several caveats we need to consider.\n\nSex was not controlled for. Males and female elephants are known to have different mean weights\nThe season of when an elephant was weighed is unknown and thus not controlled for\nI did not consider an interaction between age and latitude\nThe range of ages might have limited our evaluation of the hypothesis. For example, 10 year olds may not be considered adults."
  },
  {
    "objectID": "classfiles/regressionlab/regressionlab_BDG.html#software",
    "href": "classfiles/regressionlab/regressionlab_BDG.html#software",
    "title": "Regression Lab",
    "section": "Software",
    "text": "Software\nThis report was generated from the R Statistical Software (v4.2.2; R Core Team 2021) using the Markdown language and RStudio. The R packages used are acknowledged below.\n\n\n\n\n\n\n\n\n\nPackage\nVersion\nCitation\n\n\n\nbase\n4.4.1\n@base\n\n\nequatiomatic\n0.3.3\n@equatiomatic\n\n\nggResidpanel\n0.3.0\n@ggResidpanel\n\n\nknitr\n1.47\n\n@knitr2014; @knitr2015; @knitr2024\n\n\n\nmarginaleffects\n0.21.0\n@marginaleffects\n\n\nrmarkdown\n2.27\n\n@rmarkdown2018; @rmarkdown2020; @rmarkdown2024"
  },
  {
    "objectID": "classfiles/regressionlab/regressionlab.html",
    "href": "classfiles/regressionlab/regressionlab.html",
    "title": "Regression Lab",
    "section": "",
    "text": "Write a report that presents code and results that evaluates the below hypotheses related to African Elephant weight. The data file is elephant.study.csv. There are three columns, where each row is an individual sampled elephant, indicating the variables of weight (weight in lbs), age.years (age of elephant in years), and lat (mean latitude of the elephants home range).\n\n\nExplore/present the data. use plots/histograms\nWrite model notation correctly or use equatiomatic\nFit the model with lm or glm to get MLEs and CI’s. Define Type I error rate\nInterpret results. Make statements about ‘statistical clarity’ and support or not for the hypotheses\nMake prediction plots\nEvaluate model assumptions\nConclusions and caveats (think about what we have not considered)\nAppendix: present a summary of the R packages you used using grateful.\n\nThroughout, add text around your code and results to allow the reader to follow your thinking. The text however should be minimal and to the point.\n\nI hypothesize that adult African Elephants (Loxodonta africana) increase in weight as they age because they are more efficient at conserving energy and acquiring high quality resources. As such, I predict that older elephants will weigh more than younger adult elephants. Further, I hypothesize that there is a latitudinal effect on the weight of elephants across the continent of Africa because of the extreme drought in the southern part of their range. I predict that elephants further north will weigh more than elephants further south.\nI evaluated these hypotheses by aggregating data on weights of elephants from collaborators. Each individual elephant was weighed in the same manner while being fit with a GPS collar. Each individual had a known age due to longterm demographic monitoring. I derived the mean latitude of each elephants dry season home range."
  },
  {
    "objectID": "classfiles/regressionlab/regressionlab.html#software",
    "href": "classfiles/regressionlab/regressionlab.html#software",
    "title": "Regression Lab",
    "section": "Software",
    "text": "Software"
  },
  {
    "objectID": "FW680A4/regression.html",
    "href": "FW680A4/regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "fundamentals\nassumptions\nlm / glm functions\nconfidence intervals\ncase study"
  },
  {
    "objectID": "FW680A4/week4.html",
    "href": "FW680A4/week4.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Generalized Linear Models I\nLecture Code: GLM1.R\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"equatiomatic\",\"brglm\"))\n\n\n\nReadings for next class:\n\nZurr and Iano, 2016\n\n\nBackground Reading (not required):\n\n\n Zurr et al Chapter 9.\n\n\n\n\n\nDiscuss: Zurr and Iano, 2016 and assignment to co-lead application paper on topic\nLecture: Generalized Linear Models II\nDownloads: Files\n\n\nReadings for next class:\n\nFieberg, Ch. 8\nTredennick et al. 2021"
  },
  {
    "objectID": "FW680A4/week4.html#week-3",
    "href": "FW680A4/week4.html#week-3",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Likelihood and Optimization\nLecture Code: Likelihood.R\n\n\nReadings for next class:\n\nDushoff et al. 2019\nFieberg, Chapter 1.10\n\n\nBackground Reading (not required):\n\nFieberg, Chapter 1\nBolker Chapter 7\n\n\n\n\n\nLecture: Regression\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n  install.packages(c(\"marginaleffects\",\"ggResidpanel\"))\n\n\n\nWhat is biological significance and statistical significance?\nWhat is a p-value and what are the issues with null hypothesis testing?"
  },
  {
    "objectID": "FW680A4/week4.html#week-4",
    "href": "FW680A4/week4.html#week-4",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Generalized Linear Models I\nLecture Code: GLM1.R\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"equatiomatic\",\"brglm\"))\n\n\n\nReadings for next class:\n\nZurr and Iano, 2016\n\n\nBackground Reading (not required):\n\n\n Zurr et al Chapter 9.\n\n\n\n\n\nDiscuss: Zurr and Iano, 2016 and assignment to co-lead application paper on topic\nLecture: Generalized Linear Models II\nDownloads: Files\n\n\nReadings for next class:\n\nFieberg, Ch. 8\nTredennick et al. 2021"
  },
  {
    "objectID": "FW680A4/glm1.html#why-model-data",
    "href": "FW680A4/glm1.html#why-model-data",
    "title": "Generalized Linear Models",
    "section": "Why model data?",
    "text": "Why model data?\n\n\nIn ecology, we use models to,\n\ndescribe relationships among outcomes and processes\nto estimate hidden (latent) processes\npredict future outcomes, such as responses to management\n\n\n\nHistorically, ecologists focused mainly on hypothesis testing.\n\n\n\n “We found no correlation b/w bird richness and canopy cover (p &gt; 0.05)” [naked p-value]"
  },
  {
    "objectID": "FW680A4/glm1.html#glm",
    "href": "FW680A4/glm1.html#glm",
    "title": "Generalized Linear Models",
    "section": "GLM",
    "text": "GLM\n\nGeneralized linear model framework using matrix notation\n\n\n\\[\n\\begin{align*}\n\\textbf{y}\\sim& [\\textbf{y}|\\boldsymbol{\\mu},\\sigma] \\\\\n\\text{g}(\\boldsymbol{\\mu}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#glm-1",
    "href": "FW680A4/glm1.html#glm-1",
    "title": "Generalized Linear Models",
    "section": "GLM",
    "text": "GLM\n\nGeneralized linear model framework\n\n\\[\n\\begin{align*}\n\\textbf{y}\\sim& [\\textbf{y}|\\boldsymbol{\\mu},\\sigma] \\\\\n\\text{g}(\\boldsymbol{\\mu}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]\nElements\n\n\nprob. function to define the RV (\\(\\textbf{y}\\))\nparameters or moments of the prob. function (\\(\\boldsymbol{\\mu},\\sigma\\))\nlink function (\\(\\text{g}(\\boldsymbol{\\mu})\\)); deterministic transformation of parameters to new scale\ninverse-link function (\\(\\text{g}^{-1}(\\boldsymbol{\\textbf{X}\\boldsymbol{\\beta}})\\)); deterministic transformation of linear combination back to parameter scale\ndesign matrix of the explanatory variables (\\(\\textbf{X}\\)); these are known\ncoefficient parameters (\\(\\boldsymbol{\\beta}\\)); needs estimating"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-index-notation",
    "href": "FW680A4/glm1.html#linear-regression-index-notation",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Index Notation",
    "text": "Linear Regression Index Notation\n\\[\ny_{i} = \\beta_0+\\beta_1 x_i + \\epsilon_i \\\\ \\epsilon_i \\sim \\text{Normal}(0,\\sigma)\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-index-notation-better",
    "href": "FW680A4/glm1.html#linear-regression-index-notation-better",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Index Notation (better)",
    "text": "Linear Regression Index Notation (better)\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{i}\n\\end{align*}\n\\] . . .\n\\[\\mu_{i} = 1 + 0.5 \\times x_{i}\\]\n\n\n\n\n\n\n\n\n\n\n\n\nPlot many replicates of y\n\n\n[1]   21 1000\n\n\n. . ."
  },
  {
    "objectID": "FW680A4/glm1.html#vector-notation",
    "href": "FW680A4/glm1.html#vector-notation",
    "title": "Generalized Linear Models",
    "section": "Vector Notation",
    "text": "Vector Notation\n\nRow vectors\n\n\n\\(\\textbf{y} \\equiv (y_1, y_2, . . ., y_n)\\)\n\n\n\ny &lt;- matrix(c(1,2,3),nrow=1,ncol=3)\ny\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n\n\n\n\n\n\nColumn vectors\n\n\n\\(\\textbf{y} \\equiv (y_1, y_2, . . ., y_n)'\\)\n\n\n\n\ny &lt;- matrix(c(1,2,3),nrow=3,ncol=1)\ny\n\n     [,1]\n[1,]    1\n[2,]    2\n[3,]    3"
  },
  {
    "objectID": "FW680A4/glm1.html#vector-notation-1",
    "href": "FW680A4/glm1.html#vector-notation-1",
    "title": "Generalized Linear Models",
    "section": "Vector Notation",
    "text": "Vector Notation\n\nColumn vectors\n\n\n\\(\\textbf{x} \\equiv (x_1, x_2, . . ., x_n)'\\)\n\n\nx &lt;- matrix(c(0.5,1,-2),nrow=3,ncol=1)\nx\n\n     [,1]\n[1,]  0.5\n[2,]  1.0\n[3,] -2.0"
  },
  {
    "objectID": "FW680A4/glm1.html#vector-notation-2",
    "href": "FW680A4/glm1.html#vector-notation-2",
    "title": "Generalized Linear Models",
    "section": "Vector Notation",
    "text": "Vector Notation\n\nColumn vectors\n\n\n\\(\\boldsymbol{\\beta} \\equiv (\\beta_1,\\beta_2,...,\\beta_p)'\\)\n\n\np=3\nbeta &lt;- matrix(c(0,-2,2),nrow=p,ncol=1)\nbeta\n\n     [,1]\n[1,]    0\n[2,]   -2\n[3,]    2"
  },
  {
    "objectID": "FW680A4/glm1.html#vector-notation-3",
    "href": "FW680A4/glm1.html#vector-notation-3",
    "title": "Generalized Linear Models",
    "section": "Vector Notation",
    "text": "Vector Notation\n\nColumn vectors\n\n\n\\(\\mathbf{1} \\equiv (1,1,...,1)'\\)"
  },
  {
    "objectID": "FW680A4/glm1.html#matrix-notation",
    "href": "FW680A4/glm1.html#matrix-notation",
    "title": "Generalized Linear Models",
    "section": "Matrix Notation",
    "text": "Matrix Notation\n\n\\(\\textbf{X}\\equiv (\\textbf{x}_1,\\textbf{x}_2,...,\\textbf{x}_p)\\)\n\n\n\np=3\nX &lt;- matrix(c(1,2,3,4,5,6,7,8,9),nrow=3,ncol=p,byrow=FALSE)\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-algebra",
    "href": "FW680A4/glm1.html#linear-algebra",
    "title": "Generalized Linear Models",
    "section": "Linear Algebra",
    "text": "Linear Algebra\n\\(\\text{g}(\\boldsymbol{\\mu}) = \\textbf{X}\\boldsymbol{\\beta}\\)\n\n\\(\\textbf{X}\\) is called the Design Matrix.\n\\(\\boldsymbol{\\beta}\\) is a vector of coefficients.\n\n\\[\n\\textbf{X}=\n\\begin{bmatrix}\n1 & x_{1,2} & x_{1,3} \\\\\n1 & x_{2,2} & x_{2,3} \\\\\n1 & x_{3,2} & x_{3,3}\n\\end{bmatrix}\n\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n\\beta_0  \\\\\n\\beta_1 \\\\\n\\beta_2   \n\\end{bmatrix}\n\\]\n\n\n\\[\n\\textbf{X}\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n\\beta_0\\times 1 + \\beta_1\\times x_{1,2} + \\beta_2\\times x_{1,3} \\\\\n\\beta_0\\times 1 + \\beta_1\\times x_{2,2} + \\beta_2\\times x_{2,3} \\\\\n\\beta_0\\times 1 + \\beta_1\\times x_{3,2} + \\beta_2\\times x_{3,3} \\\\\n\\end{bmatrix}\\\\\n\\]\n\n\n\\[\n\\textbf{X}\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n\\beta_0 + \\beta_1 x_{1,2} + \\beta_2 x_{1,3} \\\\\n\\beta_0 + \\beta_1 x_{2,2} + \\beta_2 x_{2,3} \\\\\n\\beta_0 + \\beta_1 x_{3,2} + \\beta_2 x_{3,3} \\\\\n\\end{bmatrix}\\\\\n\\]\n\\[\n\\text{g}(\\boldsymbol{\\mu}) = \\textbf{X}\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\text{lt}_{1} \\\\\n\\text{lt}_{2} \\\\\n\\text{lt}_{3}\n\\end{bmatrix}\n\\] lt = linear terms\n\n\n\\[\n\\boldsymbol{\\mu} = \\text{g}^{-1}(\\textbf{X}\\boldsymbol{\\beta})\\ = \\textbf{X}\\boldsymbol{\\beta}  / 1= \\begin{bmatrix}\n\\text{lt}_{1}/1 \\\\\n\\text{lt}_{2}/1 \\\\\n\\text{lt}_{3}/1\n\\end{bmatrix}\n\\]\n\n\n\\[\n\\boldsymbol{\\mu} = \\textbf{X}\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\mu_{1} \\\\\n\\mu_{2} \\\\\n\\mu_{3}\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-algebra-1",
    "href": "FW680A4/glm1.html#linear-algebra-1",
    "title": "Generalized Linear Models",
    "section": "Linear Algebra",
    "text": "Linear Algebra\n\n\\(\\textbf{y}'\\textbf{y}\\)\n\\(\\textbf{y}' \\cdot \\textbf{y}\\)\n\n\n\\[\n=\\begin{bmatrix}\n1 & 2 & 3\n\\end{bmatrix}\n\\begin{bmatrix}\n1 \\\\\n2 \\\\\n3 \\\\\n\\end{bmatrix}\n\\]\n\n\n\\[\n=\\begin{bmatrix}\n(1\\times1) + (2\\times2) + (3\\times3)\\\\\n\\end{bmatrix} \\\\= [14]\n\\]\n\n\n\ny &lt;- matrix(c(1,2,3),nrow=3,ncol=1)\nt(y)%*%y\n\n     [,1]\n[1,]   14"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-algebra-2",
    "href": "FW680A4/glm1.html#linear-algebra-2",
    "title": "Generalized Linear Models",
    "section": "Linear Algebra",
    "text": "Linear Algebra\nWhen can we do matrix multiplication?\n\n\nfirst=t(y)\ndim(first)\n\n[1] 1 3\n\n\n\n\n\nsecond=y\ndim(second)\n\n[1] 3 1\n\n\n\n\n\n#When this is true\n  ncol(first)==nrow(second)\n\n[1] TRUE\n\n\n(1 x 3) (3 x 1)"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-algebra-3",
    "href": "FW680A4/glm1.html#linear-algebra-3",
    "title": "Generalized Linear Models",
    "section": "Linear Algebra",
    "text": "Linear Algebra\nNote that\n\\(\\textbf{y}'\\textbf{y} \\neq \\textbf{y}\\textbf{y}'\\)\n\n\nt(y)%*%y\n\n     [,1]\n[1,]   14\n\ny%*%t(y)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    2    4    6\n[3,]    3    6    9"
  },
  {
    "objectID": "FW680A4/glm1.html#elephant-linear-regression-example",
    "href": "FW680A4/glm1.html#elephant-linear-regression-example",
    "title": "Generalized Linear Models",
    "section": "Elephant Linear Regression Example",
    "text": "Elephant Linear Regression Example\nCategorical Variable\n\n\n     weight    sex\n1 11488.991   Male\n2  4105.442 Female\n3  4299.308 Female"
  },
  {
    "objectID": "FW680A4/glm1.html#link-functions",
    "href": "FW680A4/glm1.html#link-functions",
    "title": "Generalized Linear Models",
    "section": "Link functions",
    "text": "Link functions\n\n\\(\\text{g}(\\boldsymbol{\\mu}) = \\textbf{X}\\boldsymbol{\\beta}\\)\n\\(\\boldsymbol{\\mu} = \\text{g}^{-1}(\\textbf{X}\\boldsymbol{\\beta})\\)\n\n\nLink functions map parameters from one support to another.\n\n\n\nWhy is that important for us?\n\n\n\nTo put a linear model on parameters of interest and ensure the parameter support is maintained.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComputers do not like boundaries (e.g., 0 or 1). It’s easier to guess values to evaluate in a maximum liklihood optimization when there are no bounds. (\\(-\\infty\\), \\(\\infty\\))"
  },
  {
    "objectID": "FW680A4/glm1.html#link-functions-1",
    "href": "FW680A4/glm1.html#link-functions-1",
    "title": "Generalized Linear Models",
    "section": "Link functions",
    "text": "Link functions\nIdentity \nNo transformation is needed because the parameter support is maintained. \\[\n\\begin{align*}\n\\boldsymbol{\\mu} \\in& (-\\infty,\\infty)\\\\\n\\textbf{X}\\boldsymbol{\\beta} \\in& (-\\infty,\\infty)\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-simulation",
    "href": "FW680A4/glm1.html#linear-regression-simulation",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Simulation",
    "text": "Linear Regression Simulation\n\n#Design matrix\n  set.seed(6454)\n  Var1 = seq(0,20,by=1)+rnorm(21,0,2)\n  X = model.matrix(~Var1)\n  head(X)\n\n  (Intercept)     Var1\n1           1 1.871755\n2           1 1.965267\n3           1 3.221875\n4           1 1.761916\n5           1 3.627037\n6           1 8.805140\n\n\n\n\n#Marginal Coefficients  \n  beta = matrix(c(0,5))\n\n#linear terms\n  lt = X%*%beta\n\n#mu (link function)\n  mu = lt*1\n\n# Plot relationship b/w mean (mu) and variable of interest\n  plot(X[,2],mu,type=\"l\",lwd=4)  \n\n\n\n\n\n\n\n\n\n\n\n#sample\n  set.seed(5435)\n  sigma = 3\n  y = rnorm(length(mu),mu,sd=sigma)\n  y\n\n [1]  13.51028  10.74365  17.12227  10.72545  17.98375  44.88165  29.59957\n [8]  47.05866  49.08274  34.52391  25.02376  54.88971  55.74619  63.30454\n[15]  67.55550  87.75727  83.90235  70.66524  99.03730 103.14573  79.35456\n\n\n\n\n\n# Plot relationship b/w mean (mu) and variable of interest\n  plot(X[,2],mu,type=\"l\",lwd=4)  \n  points(X[,2],y,pch=18,col=2,cex=2)"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-estimation",
    "href": "FW680A4/glm1.html#linear-regression-estimation",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Estimation",
    "text": "Linear Regression Estimation\n\n# Fit model to sample\n  model1=glm(y~0+X,family = gaussian(link = \"identity\"))\n\n\n\n  summary(model1)\n\n\nCall:\nglm(formula = y ~ 0 + X, family = gaussian(link = \"identity\"))\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \nX(Intercept)   1.2914     1.4716   0.878    0.391    \nXVar1          4.8688     0.1254  38.839   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 11.43063)\n\n    Null deviance: 71532.62  on 21  degrees of freedom\nResidual deviance:   217.18  on 19  degrees of freedom\nAIC: 114.66\n\nNumber of Fisher Scoring iterations: 2\n\n\n\n\n\n\nlibrary(equatiomatic)\nextract_eq(model1)\n\n\\[\nE( \\operatorname{y} ) = \\beta_{1}(\\operatorname{X}_{\\operatorname{(Intercept)}}) + \\beta_{2}(\\operatorname{X}_{\\operatorname{Var1}})\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-evaluation",
    "href": "FW680A4/glm1.html#linear-regression-evaluation",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Evaluation",
    "text": "Linear Regression Evaluation\n\n #sample many times  \n  y.many = replicate(1000,rnorm(length(mu),mean=c(mu), sd=sigma))\n  dim(y.many)\n\n[1]   21 1000\n\n #Estimate coefs for all 100 samples\n  coef.est=apply(y.many,2,FUN=function(y){\n              model1=glm(y~0+X,family = gaussian(link = \"identity\"))\n              model1$coefficients\n  })\n\n  dim(coef.est)\n\n[1]    2 1000"
  },
  {
    "objectID": "FW680A4/glm1.html#logit-link",
    "href": "FW680A4/glm1.html#logit-link",
    "title": "Generalized Linear Models",
    "section": "logit link",
    "text": "logit link\n\\[\n\\begin{align*}\n\\textbf{y}\\sim& [\\textbf{y}|N,\\boldsymbol{p}]\\\\\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n[\\textbf{y}|N,\\boldsymbol{p}] =& \\text{Binomial}(N,\\boldsymbol{p})\n\\end{align*}\n\\] . . .\n\\[\n\\begin{align*}\n\\text{g}(\\boldsymbol{p}) =& \\text{logit}(\\boldsymbol{p}) = \\text{log}(\\frac{\\boldsymbol{p}}{1-\\boldsymbol{p}})\n\\end{align*}\n\\] . . .\ninverse-logit (expit)\n\\[\n\\boldsymbol{p} = g^{-1}(\\boldsymbol{\\textbf{X}\\boldsymbol{\\beta}}) = \\text{logit}^{-1}(\\textbf{X}\\boldsymbol{\\beta}) = \\frac{e^{\\textbf{X}\\boldsymbol{\\beta}}}{e^{\\textbf{X}\\boldsymbol{\\beta}}+1}\n\\]\n. . .\n\nFull model more simply as,\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Binomial}(N,\\boldsymbol{p})\\\\\n\\text{logit}(\\boldsymbol{p}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\] . . .\nRemember,  \\(\\boldsymbol{p} \\in [0,1]\\)\n\\(\\textbf{X}\\boldsymbol{\\beta} \\in (-\\infty,\\infty)\\)"
  },
  {
    "objectID": "FW680A4/glm1.html#logitp-mapping",
    "href": "FW680A4/glm1.html#logitp-mapping",
    "title": "Generalized Linear Models",
    "section": "logit/p mapping",
    "text": "logit/p mapping\n\np=seq(0.001,0.999,by=0.01)\nlogit.p=qlogis(p)\npar(cex.lab=1.5,cex.axis=1.5)\nplot(p,logit.p,type=\"l\",lwd=4,col=3,xlab='p',ylab=\"logit(p)\")"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression-simulation",
    "href": "FW680A4/glm1.html#logistic-regression-simulation",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression Simulation",
    "text": "Logistic Regression Simulation\n\n\n#Design matrix\n  set.seed(43534)\n  Var1 = rnorm(100)\n  X = model.matrix(~Var1)\n  head(X)\n\n  (Intercept)       Var1\n1           1  1.4371396\n2           1 -0.4835090\n3           1  1.0370452\n4           1 -0.5894099\n5           1  1.2633564\n6           1 -1.9008071\n\n\n\n\n\n# marginal coefficients (on logit-scale)\n  beta=c(-2,4)\n\n#linear terms\n  lt = X%*%beta\n\n#transformation via link function to probability scale\n  p=plogis(lt)\n  head(round(p,digits=2))\n\n  [,1]\n1 0.98\n2 0.02\n3 0.90\n4 0.01\n5 0.95\n6 0.00\n\n#sample\n  set.seed(14353)\n  y = rbinom(n=length(p),size=1,p)\n  y\n\n  [1] 1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0\n [38] 0 1 1 0 1 0 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0\n [75] 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 1 0\n\n\n\n\n\n#Plot the linear 'terms'  and explantory variable\n  par(cex.lab=1.2,cex.axis=1.2)\n  plot(Var1,lt,type=\"b\",lwd=3,col=2,\n       xlab=\"x\",ylab=\"Linear Terms (logit-value)\")  \n\n\n\n\n\n\n\n  index=order(Var1)\n  plot(Var1[index],p[index],type=\"b\",lwd=3,col=2,xlab=\"x\",ylab=\"Probability\")"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression-estimation",
    "href": "FW680A4/glm1.html#logistic-regression-estimation",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression Estimation",
    "text": "Logistic Regression Estimation\n\n# Fit model to sample \n  model1=glm(y~0+X, family = binomial(link = \"logit\"))\n  summary(model1)\n\n\nCall:\nglm(formula = y ~ 0 + X, family = binomial(link = \"logit\"))\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \nX(Intercept)  -2.5304     0.6473  -3.909 9.25e-05 ***\nXVar1          5.4198     1.2232   4.431 9.38e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.63  on 100  degrees of freedom\nResidual deviance:  39.14  on  98  degrees of freedom\nAIC: 43.14\n\nNumber of Fisher Scoring iterations: 7"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression-evaluation",
    "href": "FW680A4/glm1.html#logistic-regression-evaluation",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression Evaluation",
    "text": "Logistic Regression Evaluation\n\n #sample many times  \n  n.sim=1000\n  y.many = replicate(n.sim,rbinom(n=length(p),size=1,p))\n  dim(y.many)\n\n[1]  100 1000\n\n #Estimate coefs for all 100 samples\n  coef.est=apply(y.many,2,FUN=function(y){\n          model1=glm(y~0+X, family = binomial(link = \"logit\"))\n          \n  model1$coefficients\n  })\n\n  dim(coef.est)\n\n[1]    2 1000"
  },
  {
    "objectID": "FW680A4/glm1.html#plot-intercept",
    "href": "FW680A4/glm1.html#plot-intercept",
    "title": "Generalized Linear Models",
    "section": "Plot Intercept",
    "text": "Plot Intercept"
  },
  {
    "objectID": "FW680A4/glm1.html#plot-slope",
    "href": "FW680A4/glm1.html#plot-slope",
    "title": "Generalized Linear Models",
    "section": "Plot Slope",
    "text": "Plot Slope"
  },
  {
    "objectID": "FW680A4/glm1.html#evaluate-sampling-distributions",
    "href": "FW680A4/glm1.html#evaluate-sampling-distributions",
    "title": "Generalized Linear Models",
    "section": "Evaluate Sampling Distributions",
    "text": "Evaluate Sampling Distributions\nIs our model biased?\n\n# Relative Bias\n  (mean(coef.est[1,])-beta[1])/beta[1]\n\n[1] 0.0879452\n\n  (mean(coef.est[2,])-beta[2])/beta[2]\n\n[1] 0.09751027"
  },
  {
    "objectID": "FW680A4/glm1.html#evaluate-sampling-distributions-1",
    "href": "FW680A4/glm1.html#evaluate-sampling-distributions-1",
    "title": "Generalized Linear Models",
    "section": "Evaluate Sampling Distributions",
    "text": "Evaluate Sampling Distributions\nAre we going to estimate the sign of the coef correctly?\n\n# Probability of estimating a coef sign correctly\n  length(which(coef.est[1,]&lt;0))/n.sim\n\n[1] 1\n\n  length(which(coef.est[2,]&gt;0))/n.sim\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/glm1.html#evaluate-sampling-distributions-2",
    "href": "FW680A4/glm1.html#evaluate-sampling-distributions-2",
    "title": "Generalized Linear Models",
    "section": "Evaluate Sampling Distributions",
    "text": "Evaluate Sampling Distributions\n\n# Probability of estimating the slope 2x the truth\n    length(which(coef.est[2,]&gt;2*beta[2]))/n.sim\n\n[1] 0.013"
  },
  {
    "objectID": "FW680A4/glm1.html#evaluate-sampling-distributions-3",
    "href": "FW680A4/glm1.html#evaluate-sampling-distributions-3",
    "title": "Generalized Linear Models",
    "section": "Evaluate Sampling Distributions",
    "text": "Evaluate Sampling Distributions\n\n# Probability of estimating the slope within 1\nlength(which(coef.est[2,]&gt;=beta[2]-1 & coef.est[2,]&lt;=beta[2]+1))/n.sim\n\n[1] 0.741"
  },
  {
    "objectID": "FW680A4/glm1.html#a-model-by-another-name",
    "href": "FW680A4/glm1.html#a-model-by-another-name",
    "title": "Generalized Linear Models",
    "section": "A Model by another name",
    "text": "A Model by another name\n\n\n\n\n\n\n\n\n\nModel Name\n\\([y|\\boldsymbol{\\theta}]\\)\nLink\n\n\n\n\nANOVA (\\(x_{1}\\) is categorical/multiple levels)\nNormal\nidentity\n\n\nANCOVA (\\(x_{1}\\) is categorical, \\(x_{2}\\) is continuous))\nNormal\nidentity\n\n\nt-test (\\(x_{1}\\) is categorical with 2 levels)\nNormal\nidentity\n\n\nLinear Regression \\(x_{1}\\) is continuous\nNormal\nidentity\n\n\nMultiple Linear Regression \\(x_{p}\\) is continuous\nNormal\nidentity\n\n\nLogistic Regression\nBinomial\nlogit\n\n\nProbit Regression\nBinomial\nprobit\n\n\nLog-linear Regression\nPoisson\nlog\n\n\nPoisson Regression\nPoisson\nlog\n\n\nSurvival Analysis\nExponential\nlog\n\n\nInverse Polynomial\nGamma\nReciprocal\n\n\n\nNelder and Wedderburn (1972)"
  },
  {
    "objectID": "FW680A4/glm1.html#multi-collinearity",
    "href": "FW680A4/glm1.html#multi-collinearity",
    "title": "Generalized Linear Models",
    "section": "Multi-Collinearity",
    "text": "Multi-Collinearity\n\n\nCorrelation among explantory variables\n\nCan happen when \\(r \\geq 0.28\\) or \\(r^2 \\geq 0.08\\)\ncauses inaccurate estimation\ndecreases statistical power\nleads to exclusion of important predictor variables"
  },
  {
    "objectID": "FW680A4/glm1.html#multi-collinearity-code",
    "href": "FW680A4/glm1.html#multi-collinearity-code",
    "title": "Generalized Linear Models",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\nlibrary(faux)\nn=100\nset.seed(543531)\nx.var &lt;- rnorm_multi(n = n, \n                  mu = c(10, 20),\n                  sd = c(1, 1),\n                  r = c(0), \n                  varnames = c(\"A\", \"B\"),\n                  empirical = FALSE)\n\nset.seed(54353)\nx.var.cor &lt;- rnorm_multi(n = n, \n                  mu = c(10, 20),\n                  sd = c(1, 1),\n                  r = c(0.8), \n                  varnames = c(\"A\", \"B\"),\n                  empirical = FALSE)\n\n#Correlation\n  cor(x.var)\n\n           A          B\nA 1.00000000 0.04340106\nB 0.04340106 1.00000000\n\n  cor(x.var.cor)\n\n          A         B\nA 1.0000000 0.8354425\nB 0.8354425 1.0000000"
  },
  {
    "objectID": "FW680A4/glm1.html#multi-collinearity-code-1",
    "href": "FW680A4/glm1.html#multi-collinearity-code-1",
    "title": "Generalized Linear Models",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\npar(mfrow=c(1,2))\n  plot(x.var.cor$A,x.var.cor$B)\n  plot(x.var$A,x.var$B)"
  },
  {
    "objectID": "FW680A4/glm1.html#multi-collinearity-code-2",
    "href": "FW680A4/glm1.html#multi-collinearity-code-2",
    "title": "Generalized Linear Models",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\n#Design matrices\n  X.cor=model.matrix(~x.var.cor$A+x.var.cor$B)\n  X=model.matrix(~x.var$A+x.var$B)\n\n#True coefs  \n  beta=c(1,2,3)\n\n#Derive mu  \n  mu=X%*%beta\n  mu.cor=X.cor%*%beta\n\n#simulate data  \n  set.seed(54353)\n  y=rnorm(n,mu,2)\n  y.cor=rnorm(n,mu.cor,2)"
  },
  {
    "objectID": "FW680A4/glm1.html#model-estimates",
    "href": "FW680A4/glm1.html#model-estimates",
    "title": "Generalized Linear Models",
    "section": "Model Estimates",
    "text": "Model Estimates\n\nsummary(glm(y~0+X))\n\n\nCall:\nglm(formula = y ~ 0 + X)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \nX(Intercept)   0.3514     4.5494   0.077    0.939    \nXx.var$A       2.0619     0.2100   9.820 3.29e-16 ***\nXx.var$B       3.0029     0.2087  14.390  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 4.288366)\n\n    Null deviance: 645623.40  on 100  degrees of freedom\nResidual deviance:    415.97  on  97  degrees of freedom\nAIC: 434.33\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/glm1.html#model-estimates-1",
    "href": "FW680A4/glm1.html#model-estimates-1",
    "title": "Generalized Linear Models",
    "section": "Model Estimates",
    "text": "Model Estimates\n\nsummary(glm(y~0+X.cor))\n\n\nCall:\nglm(formula = y ~ 0 + X.cor)\n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nX.cor(Intercept) 38.361082   7.926825   4.839 4.91e-06 ***\nX.corx.var.cor$A  0.002467   0.681426   0.004  0.99712    \nX.corx.var.cor$B  2.094430   0.634710   3.300  0.00135 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 13.3163)\n\n    Null deviance: 645623.4  on 100  degrees of freedom\nResidual deviance:   1291.7  on  97  degrees of freedom\nAIC: 547.64\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/glm1.html#objectives",
    "href": "FW680A4/glm1.html#objectives",
    "title": "Generalized Linear Models",
    "section": "Objectives",
    "text": "Objectives\n\n\n\nGLM framework\nmatrix notation\nlinear algebra\ndesign matrix / categorical variable\nglm function\nlink functions\nlogistic regression"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression-notation",
    "href": "FW680A4/glm1.html#linear-regression-notation",
    "title": "Generalized Linear Models",
    "section": "Linear Regression Notation",
    "text": "Linear Regression Notation\nindex notation\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i}\n\\end{align*}\n\\]\n\n\nmatrix notation\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Normal}(\\boldsymbol{\\mu},\\sigma) \\\\\n\\boldsymbol{\\mu} =& \\text{g}(\\boldsymbol{\\mu}) = \\mathbf{1}'\\boldsymbol{\\mu} = \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]\n\n\n\\[\\begin{align*}\n\n\\textbf{y} =\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\ny_{3} \\\\\n. \\\\\n. \\\\\ny_{n} &\n\\end{bmatrix}\n\n\n\\textbf{X} =\n\\begin{bmatrix}\n1 & x^{1}_1 & x^{2}_1 \\\\\n1 & x^{1}_2 & x^{2}_2 \\\\\n1 & x^{1}_3 & x^{2}_3 \\\\\n. & . .\\\\\n. & . .\\\\\nn & x^{1}_n & x^{2}_n\n\\end{bmatrix}\n\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\end{bmatrix}\n\\end{align*}\\]\nn = sample size"
  },
  {
    "objectID": "FW680A4/glm1.html#motivation",
    "href": "FW680A4/glm1.html#motivation",
    "title": "Generalized Linear Models",
    "section": "Motivation",
    "text": "Motivation\n\nGLMs:\n\n\nt-test\nANOVA/ANCOVA\nlinear regression\nlogistic / probit regression\nPoisson regression\nlog-linear regression\nsurvival analysis\nAND MORE!"
  },
  {
    "objectID": "FW680A4/glm1.html#matrix-notation-1",
    "href": "FW680A4/glm1.html#matrix-notation-1",
    "title": "Generalized Linear Models",
    "section": "Matrix Notation",
    "text": "Matrix Notation\n\n\\(\\textbf{X}\\equiv (\\textbf{x}_1,\\textbf{x}_2,...,\\textbf{x}_p)\\)\n\n\n\np=3\nX &lt;- matrix(c(1,2,3,4,5,6,7,8,9),nrow=3,ncol=p,byrow=FALSE)\nX\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9"
  },
  {
    "objectID": "FW680A4/glm1.html#linear-regression",
    "href": "FW680A4/glm1.html#linear-regression",
    "title": "Generalized Linear Models",
    "section": "Linear Regression",
    "text": "Linear Regression\nindex notation\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{1i} + \\beta_{2}x_{2i}\n\\end{align*}\n\\]\n\n\nmatrix notation\n\\[\n\\begin{align*}\n\\textbf{y}\\sim& \\text{Normal}(\\boldsymbol{\\mu},\\sigma)\\\\\n\\boldsymbol{\\mu} =& \\text{g}^{-1}(\\textbf{X}\\boldsymbol{\\beta})\\\\\n\\text{g}(\\boldsymbol{\\mu}) =&   \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]\n\n\n\\[\\begin{align*}\n\n\\textbf{y} =\n\\begin{bmatrix}\ny_{1} \\\\\ny_{2} \\\\\ny_{3} \\\\\n. \\\\\n. \\\\\ny_{n}  \n\\end{bmatrix}\n\n\n\\textbf{X} =\n\\begin{bmatrix}\n1 & x_{1,2} & x_{1,3} \\\\\n1 & x_{2,2} & x_{2,3} \\\\\n1 & x_{3,2} & x_{3,3} \\\\\n. & . .\\\\\n. & . .\\\\\nn & x_{n,2} & x_{n,3}\n\\end{bmatrix}\n\n\\boldsymbol{\\beta} = \\begin{bmatrix}\n\\beta_0 \\\\\n\\beta_1 \\\\\n\\beta_2 \\\\\n\\end{bmatrix}\n\\end{align*}\\]\nn = sample size x\\(_{2}\\) & x\\(_{3}\\) are independent variables"
  },
  {
    "objectID": "FW680A4/glm1.html#elephant-linear-regression-example-1",
    "href": "FW680A4/glm1.html#elephant-linear-regression-example-1",
    "title": "Generalized Linear Models",
    "section": "Elephant Linear Regression Example",
    "text": "Elephant Linear Regression Example\nCategorical Variable\n\nmodel = glm(weight~sex, \n            data=dat,\n            family=gaussian(link = identity)\n            )\nsummary(model)\n\n\nCall:\nglm(formula = weight ~ sex, family = gaussian(link = identity), \n    data = dat)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4970.9      120.9   41.11   &lt;2e-16 ***\nsexMale       6848.1      180.2   37.99   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1608053)\n\n    Null deviance: 2639772182  on 199  degrees of freedom\nResidual deviance:  318394574  on 198  degrees of freedom\nAIC: 3429.7\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/glm1.html#elephant-linear-regression-example-2",
    "href": "FW680A4/glm1.html#elephant-linear-regression-example-2",
    "title": "Generalized Linear Models",
    "section": "Elephant Linear Regression Example",
    "text": "Elephant Linear Regression Example\nCategorical Variable\n\\(x_{2}\\) as an indicator of sex, female (0) or male (1)\n\\(x_{3}\\) elephant age\n\n\\[\n\\textbf{weight} \\sim \\text{Normal}(\\boldsymbol{\\mu},\\sigma)\\\\ \\\\\n\\boldsymbol{\\mu} =\\textbf{X}\\boldsymbol{\\beta} =\n\\begin{bmatrix}\n\\beta_0 + (\\beta_1\\times 1) + (\\beta_2\\times 10) \\\\\n\\beta_0 + (\\beta_1\\times 0) + (\\beta_2\\times 12) \\\\\n\\beta_0 + (\\beta_1\\times 0) + (\\beta_2\\times 15) \\\\\n\\end{bmatrix}\\\\\n\\]\n\n\n\\[\n\\hat{\\boldsymbol{\\mu}} = \\textbf{X}\\hat{\\boldsymbol{\\beta}} =\n\\begin{bmatrix}\n2552.82 + (6828.96\\times 1) + (145.74\\times 10) \\\\\n2552.82 + (6828.96\\times 0) + (145.74\\times 12) \\\\\n2552.82 + (6828.96\\times 0) + (145.74\\times 15) \\\\\n\\end{bmatrix}\\\\\n\\]\n\n\n\\[\n\\hat{\\boldsymbol{\\mu}} = \\textbf{X}\\hat{\\boldsymbol{\\beta}} =\n\\begin{bmatrix}\n2552.82 + 6828.96 + 1457.4 \\\\\n2552.82 + 0 + 1748.88 \\\\\n2552.82 + 0 + 2186.1 \\\\\n\\end{bmatrix}\\\\\n\\]\n\n\n\\[\n\\hat{\\boldsymbol{\\mu}} = \\textbf{X}\\hat{\\boldsymbol{\\beta}} =\n\\begin{bmatrix}\n10401.98     \\\\\n6779.52 \\\\\n5322.02 \\\\\n\\end{bmatrix}\\\\\n\\]\n\n\nSo, what does \\(\\beta_1\\) mean?"
  },
  {
    "objectID": "FW680A4/glm1.html#an-estimator-with-linear-algebra",
    "href": "FW680A4/glm1.html#an-estimator-with-linear-algebra",
    "title": "Generalized Linear Models",
    "section": "An Estimator with Linear Algebra",
    "text": "An Estimator with Linear Algebra\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\textbf{X}'\\textbf{X})^{-1}\\textbf{X}'\\textbf{y}\n\\]\n\n\n\n  (Intercept) sexMale age.years\n1           1       1        10\n2           1       0        12\n3           1       0        15\n4           1       0        12\n5           1       1        20\n6           1       1         4\n\n\nX(Intercept)     XsexMale   Xage.years \n   2552.8203    6828.9645     145.7483 \n\n\n\n\n\n\n# Linear Algebra Coefs\n  y=dat$weight\n  c(solve(t(X)%*%X)%*%t(X)%*%y)\n\n[1] 2552.8203 6828.9645  145.7483"
  },
  {
    "objectID": "FW680A4/glm1.html#elephant-linear-regression-example-3",
    "href": "FW680A4/glm1.html#elephant-linear-regression-example-3",
    "title": "Generalized Linear Models",
    "section": "Elephant Linear Regression Example",
    "text": "Elephant Linear Regression Example\nCategorical Variable"
  },
  {
    "objectID": "FW680A4/glm1.html#glm-and-design-matix",
    "href": "FW680A4/glm1.html#glm-and-design-matix",
    "title": "Generalized Linear Models",
    "section": "glm and design matix",
    "text": "glm and design matix\n\n# GLM coefs\n  X = model.matrix(~sex+age.years,data=dat)\n  head(X)\n\n  (Intercept) sexMale age.years\n1           1       1        10\n2           1       0        12\n3           1       0        15\n4           1       0        12\n5           1       1        20\n6           1       1         4\n\n\n\n\n  glm(weight~0+X,data=dat)\n\n\nCall:  glm(formula = weight ~ 0 + X, data = dat)\n\nCoefficients:\nX(Intercept)      XsexMale    Xage.years  \n      2552.8        6829.0         145.7  \n\nDegrees of Freedom: 200 Total (i.e. Null);  197 Residual\nNull Deviance:      1.561e+10 \nResidual Deviance: 75320000     AIC: 3143\n\n\n\nSex variable is arranged by ‘Dummy Coding’"
  },
  {
    "objectID": "FW680A4/glm1.html#mle-estimator-with-linear-algebra",
    "href": "FW680A4/glm1.html#mle-estimator-with-linear-algebra",
    "title": "Generalized Linear Models",
    "section": "MLE Estimator with Linear Algebra",
    "text": "MLE Estimator with Linear Algebra\n\\[\n\\hat{\\boldsymbol{\\beta}} = (\\textbf{X}'\\textbf{X})^{-1}\\textbf{X}'\\textbf{y}\n\\]\n\n\n\nX(Intercept)     XsexMale   Xage.years \n   2552.8203    6828.9645     145.7483 \n\n\n\n\n\n\n# Linear Algebra Maximum Likelihood Estimate\n  y=dat$weight\n  c(solve(t(X)%*%X)%*%t(X)%*%y)\n\n[1] 2552.8203 6828.9645  145.7483"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression-logit-link",
    "href": "FW680A4/glm1.html#logistic-regression-logit-link",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression (logit link)",
    "text": "Logistic Regression (logit link)\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Binomial}(N,\\boldsymbol{p})\n\\end{align*}\n\\]\n\n\\[\n\\begin{align*}\n\\text{g}(\\boldsymbol{p}) =& \\text{logit}(\\boldsymbol{p}) = \\text{log}(\\frac{\\boldsymbol{p}}{1-\\boldsymbol{p}})\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#inverse-logit-expit",
    "href": "FW680A4/glm1.html#inverse-logit-expit",
    "title": "Generalized Linear Models",
    "section": "inverse-logit (expit)",
    "text": "inverse-logit (expit)\n\\[\n\\boldsymbol{p} = g^{-1}(\\boldsymbol{\\textbf{X}\\boldsymbol{\\beta}}) = \\text{logit}^{-1}(\\textbf{X}\\boldsymbol{\\beta}) = \\frac{e^{\\textbf{X}\\boldsymbol{\\beta}}}{e^{\\textbf{X}\\boldsymbol{\\beta}}+1}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression",
    "href": "FW680A4/glm1.html#logistic-regression",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression",
    "text": "Logistic Regression\nFull model\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Binomial}(N,\\boldsymbol{p})\\\\\n\\text{logit}(\\boldsymbol{p}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]\n\nRemember,  \\(\\boldsymbol{p} \\in [0,1]\\)\n\\(\\textbf{X}\\boldsymbol{\\beta} \\in (-\\infty,\\infty)\\)"
  },
  {
    "objectID": "FW680A4/glm2.html#objectives",
    "href": "FW680A4/glm2.html#objectives",
    "title": "Generalized Linear Models II ",
    "section": "Objectives",
    "text": "Objectives\n\n\n\nPoisson Regression\nNumerical Optimization\nCategorical variables &gt;2 levels\nEffect Coding\nVariable Combinations"
  },
  {
    "objectID": "FW680A4/glm2.html#poisson-regression",
    "href": "FW680A4/glm2.html#poisson-regression",
    "title": "Generalized Linear Models II ",
    "section": "Poisson Regression",
    "text": "Poisson Regression\nWe model the counts of American pika (\\(y_{i}\\)) at each site \\(i = 1...n\\) as a Poisson random variable with parameter \\(\\lambda\\) being a function of our \\(p\\) site-level variables in \\(n\\) x \\(p\\) design matrix (\\(\\textbf{X}\\)) and coefficients \\(\\boldsymbol{\\beta}\\) as,\n\\[\n\\begin{align*}\n\\textbf{y} \\sim & \\text{Poisson}(\\boldsymbol{\\lambda})\\\\\n\\text{log}(\\boldsymbol{\\lambda}) =& \\textbf{X}\\boldsymbol{\\beta}\\\\\n\\boldsymbol{\\lambda} =& e^{\\textbf{X}\\boldsymbol{\\beta}}.\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm2.html#data-and-variable",
    "href": "FW680A4/glm2.html#data-and-variable",
    "title": "Generalized Linear Models II ",
    "section": "Data and Variable",
    "text": "Data and Variable\nVariable indicating a unique area or site\n\n\n\n  [1] Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1\n [11] Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2\n [21] Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3\n [31] Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1\n [41] Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2\n [51] Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3\n [61] Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1\n [71] Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2\n [81] Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3\n [91] Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1\n[101] Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2\n[111] Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3 Site 1 Site 2 Site 3\nLevels: Site 1 Site 2 Site 3"
  },
  {
    "objectID": "FW680A4/glm2.html#fit-model",
    "href": "FW680A4/glm2.html#fit-model",
    "title": "Generalized Linear Models II ",
    "section": "Fit Model",
    "text": "Fit Model\nInterpret the Coefficients\n\nmodel = glm(y~site,\n            data=dat, \n            family = poisson(link = 'log')\n            )\n\n\n\nsummary(model)\n\n\nCall:\nglm(formula = y ~ site, family = poisson(link = \"log\"), data = dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.6549     0.1140   5.747 9.09e-09 ***\nsiteSite 2   -1.0116     0.2207  -4.584 4.56e-06 ***\nsiteSite 3    0.1221     0.1565   0.780    0.435    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 341.36  on 119  degrees of freedom\nResidual deviance: 305.76  on 117  degrees of freedom\nAIC: 496.33\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "FW680A4/glm2.html#data",
    "href": "FW680A4/glm2.html#data",
    "title": "Generalized Linear Models II ",
    "section": "Data",
    "text": "Data"
  },
  {
    "objectID": "FW680A4/glm2.html#counts-by-site",
    "href": "FW680A4/glm2.html#counts-by-site",
    "title": "Generalized Linear Models II ",
    "section": "Counts by Site",
    "text": "Counts by Site"
  },
  {
    "objectID": "FW680A4/glm2.html#optimization",
    "href": "FW680A4/glm2.html#optimization",
    "title": "Generalized Linear Models II ",
    "section": "Optimization",
    "text": "Optimization\n\nmodel$converged\n\n[1] TRUE\n\nmodel$method\n\n[1] \"glm.fit\"\n\nmodel$boundary\n\n[1] FALSE\n\nmodel$iter\n\n[1] 5\n\nmodel$control\n\n$epsilon\n[1] 1e-08\n\n$maxit\n[1] 25\n\n$trace\n[1] FALSE"
  },
  {
    "objectID": "FW680A4/glm2.html#side-bar-maximum-likelihood-optimization",
    "href": "FW680A4/glm2.html#side-bar-maximum-likelihood-optimization",
    "title": "Generalized Linear Models II ",
    "section": "Side-Bar: Maximum Likelihood Optimization",
    "text": "Side-Bar: Maximum Likelihood Optimization\n\n  #Here is our negative log-likelihood function with three\n  #parameters - the beta0 (2) and beta1 (1)\n  neg.log.like = function(par,X) {\n    lam=par[1]*X[,1]+par[2]*X[,2]+par[3]*X[,3]\n    sum(-dpois(y,lambda = exp(lam),log = TRUE))\n  }\n\n\n\n### Use our function in an optimization function\n\n  #use optim with initial values and define the lower and upper limits of the possible values\n  fit1 &lt;- optim(\n    par = c(0, 0,1),\n    X=X,\n    fn = neg.log.like,\n    method = \"L-BFGS-B\",\n    lower = c(-10, -10, -10),\n    upper = c(10, 10, 10)\n  )\n\nrbind(fit1$par,\n      coef(model)\n           )\n\n     (Intercept) siteSite 2 siteSite 3\n[1,]    1.090244 -0.4886637  0.3741687\n[2,]    1.090244 -0.4886641  0.3741681"
  },
  {
    "objectID": "FW680A4/glm2.html#numerical-optimization-of-likelihood",
    "href": "FW680A4/glm2.html#numerical-optimization-of-likelihood",
    "title": "Generalized Linear Models II ",
    "section": "Numerical Optimization of Likelihood",
    "text": "Numerical Optimization of Likelihood\n\nmodel$converged\n\n[1] TRUE\n\nmodel$method\n\n[1] \"glm.fit\"\n\nmodel$boundary\n\n[1] FALSE\n\nmodel$iter\n\n[1] 6\n\nmodel$control\n\n$epsilon\n[1] 1e-08\n\n$maxit\n[1] 25\n\n$trace\n[1] FALSE"
  },
  {
    "objectID": "FW680A4/glm2.html#side-bar-negative-log-likelihood-fucntion",
    "href": "FW680A4/glm2.html#side-bar-negative-log-likelihood-fucntion",
    "title": "Generalized Linear Models II ",
    "section": "Side-Bar: Negative Log-Likelihood Fucntion",
    "text": "Side-Bar: Negative Log-Likelihood Fucntion\n\n  #Here is our negative log-likelihood function with three\n  #parameters - beta0, beta1, and beta2 (1)\n  #inputs = design matrix X\n  neg.log.like = function(par,X) {\n    lam=par[1]*X[,1]+par[2]*X[,2]+par[3]*X[,3]\n    sum(-dpois(y,lambda = exp(lam),log = TRUE))\n  }"
  },
  {
    "objectID": "FW680A4/glm2.html#numerical-optim.-for-mles",
    "href": "FW680A4/glm2.html#numerical-optim.-for-mles",
    "title": "Generalized Linear Models II ",
    "section": "Numerical Optim. for MLEs",
    "text": "Numerical Optim. for MLEs\n\n#Use optim function with initial values and define the lower and upper limits of the possible values\n  fit1 &lt;- optim(\n    par = c(0,0,0), #start\n    X = X,\n    fn = neg.log.like,\n    method = \"L-BFGS-B\",\n    lower = c(-10, -10, -10),\n    upper = c(10, 10, 10)\n  )\n\n\n\nComparison\n\n\n        (Intercept) siteSite 2 siteSite 3\nglm.fit   0.6549253  -1.011598  0.1221050\nours      0.6549260  -1.011601  0.1221027"
  },
  {
    "objectID": "FW680A4/glm2.html#comparison",
    "href": "FW680A4/glm2.html#comparison",
    "title": "Generalized Linear Models II ",
    "section": "Comparison",
    "text": "Comparison\n\n\n     (Intercept) siteSite 2 siteSite 3\nglm    0.9932507 -0.5232463  0.5543119\nours   0.9932518 -0.5232481  0.5543107"
  },
  {
    "objectID": "FW680A4/glm2.html#controlling-dummy-coding",
    "href": "FW680A4/glm2.html#controlling-dummy-coding",
    "title": "Generalized Linear Models II ",
    "section": "Controlling Dummy Coding",
    "text": "Controlling Dummy Coding\nMake ‘Site 2’ the intercept\n\ndat$site.re=relevel(dat$site,ref=\"Site 2\")\nlevels(dat$site.re) \n\n[1] \"Site 2\" \"Site 1\" \"Site 3\"\n\n\n\n\n\nmodel2 = glm(y~site.re,\n             data=dat, \n             family = poisson(link = 'log')\n            )\nsummary(model2)\n\n\nCall:\nglm(formula = y ~ site.re, family = poisson(link = \"log\"), data = dat)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     0.5158     0.1222   4.222 2.42e-05 ***\nsite.reSite 1   0.5138     0.1544   3.327 0.000879 ***\nsite.reSite 3   1.0936     0.1412   7.748 9.37e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 209.44  on 119  degrees of freedom\nResidual deviance: 137.65  on 117  degrees of freedom\nAIC: 467.21\n\nNumber of Fisher Scoring iterations: 5"
  },
  {
    "objectID": "FW680A4/glm2.html#same-model-different-estimates",
    "href": "FW680A4/glm2.html#same-model-different-estimates",
    "title": "Generalized Linear Models II ",
    "section": "Same Model Different Estimates",
    "text": "Same Model Different Estimates\nCoeficients\n\n\n       (Intercept) siteSite 2 siteSite 3\nModel1      0.6549    -1.0116     0.1221\nModel2     -0.3567     1.0116     1.1337\n\n\nPredictions\n\n\n           1   2     3     4   5\nModel1 1.925 0.7 2.175 1.925 0.7\nModel2 1.925 0.7 2.175 1.925 0.7\n\n\n\n\nDesign Matrix\n\n\n  (Intercept) dat$siteSite 2 dat$siteSite 3\n1           1              0              0\n2           1              1              0\n3           1              0              1\n4           1              0              0\n5           1              1              0\n\n\n  (Intercept) dat$site.reSite 1 dat$site.reSite 3\n1           1                 1                 0\n2           1                 0                 0\n3           1                 0                 1\n4           1                 1                 0\n5           1                 0                 0"
  },
  {
    "objectID": "FW680A4/glm2.html#more-control-of-your-coefecients",
    "href": "FW680A4/glm2.html#more-control-of-your-coefecients",
    "title": "Generalized Linear Models II ",
    "section": "More Control of your coefecients!",
    "text": "More Control of your coefecients!\ncontrasts\n\n#Use effect coding to make the intercept the grand mean\n  model4=glm(y~0+site, data=dat, \n            family = poisson(link = 'log')\n            )\n\n  coef(model4)\n\nsiteSite 1 siteSite 2 siteSite 3 \n 0.7997569  0.4219944  1.4170660 \n\n# No shared intercept\nhead(model.matrix(~0+site,data=dat),n=6)\n\n  siteSite 1 siteSite 2 siteSite 3\n1          1          0          0\n2          0          1          0\n3          0          0          1\n4          1          0          0\n5          0          1          0\n6          0          0          1"
  },
  {
    "objectID": "FW680A4/glm2.html#more-control-of-your-coefecients-1",
    "href": "FW680A4/glm2.html#more-control-of-your-coefecients-1",
    "title": "Generalized Linear Models II ",
    "section": "More Control of your coefecients!",
    "text": "More Control of your coefecients!\ncontrasts\n\n\nsiteSite 1 siteSite 2 siteSite 3 \n 0.7178398  0.5158132  1.5422292 \n\n\n  siteSite 1 siteSite 2 siteSite 3\n1          1          0          0\n2          0          1          0\n3          0          0          1\n4          1          0          0\n5          0          1          0\n6          0          0          1"
  },
  {
    "objectID": "FW680A4/glm2.html#same-model-different-estimates-1",
    "href": "FW680A4/glm2.html#same-model-different-estimates-1",
    "title": "Generalized Linear Models II ",
    "section": "Same Model Different Estimates",
    "text": "Same Model Different Estimates\nCoeficients\n\n\n       (Intercept) siteSite 2 siteSite 3\nModel1   0.6549260 -1.0116009  0.1221027\nModel2  -0.3566749  1.0116009  1.1337036\nModel3   0.3584266  0.2964994 -0.7151015\nModel4   0.6549260 -0.3566749  0.7770287\n\n\nPredictions\n\n\n           1   2     3     4   5\nModel1 1.925 0.7 2.175 1.925 0.7\nModel2 1.925 0.7 2.175 1.925 0.7\nModel3 1.925 0.7 2.175 1.925 0.7\nModel4 1.925 0.7 2.175 1.925 0.7\n\n\nDeviance\n\n\n           [,1]\nModel1 305.7557\nModel2 305.7557\nModel3 305.7557\nModel4 305.7557"
  },
  {
    "objectID": "FW680A4/glm2.html#side-bar-negative-log-likelihood-function",
    "href": "FW680A4/glm2.html#side-bar-negative-log-likelihood-function",
    "title": "Generalized Linear Models II ",
    "section": "Side-Bar: Negative Log-Likelihood Function",
    "text": "Side-Bar: Negative Log-Likelihood Function\n\n  #Here is our negative log-likelihood function with three\n  #parameters - beta0, beta1, and beta2 (1)\n  #inputs = design matrix X\n  neg.log.like = function(par,X) {\n    \n    #linear model of parameters par and design matrix (X)\n    lam=par[1]*X[,1]+par[2]*X[,2]+par[3]*X[,3]\n    \n    #neg log-likelihood\n    sum(-dpois(y,lambda = exp(lam),log = TRUE))\n  }"
  },
  {
    "objectID": "FW680A4/glm2.html#more-control",
    "href": "FW680A4/glm2.html#more-control",
    "title": "Generalized Linear Models II ",
    "section": "More Control!",
    "text": "More Control!\nDeviation/Effect Coding Link\nLots of options\n\n  model3=glm(y~site, \n             data = dat, \n             family = poisson(link = 'log'),\n             contrasts = list(site = contr.sum)\n            )"
  },
  {
    "objectID": "FW680A4/glm2.html#take-control",
    "href": "FW680A4/glm2.html#take-control",
    "title": "Generalized Linear Models II ",
    "section": "Take Control",
    "text": "Take Control\n\nX = model.matrix(~STUFF)\n\nmodel = glm(y~ 0 + X, ...)"
  },
  {
    "objectID": "FW680A4/glm2.html#deviaion-coding-interpretation",
    "href": "FW680A4/glm2.html#deviaion-coding-interpretation",
    "title": "Generalized Linear Models II ",
    "section": "Deviaion Coding Interpretation",
    "text": "Deviaion Coding Interpretation\n\n# Intercept = grand mean of site-means (log-scale)\n# Coef 1 = effect difference of Site 1 from Grand Mean\n# Coef 2 = effect difference of Site 2 from Grand Mean\n\ncoef(model3)\n\n(Intercept)       site1       site2 \n 0.87960578 -0.07984887 -0.45761137 \n\n#The coefficient for site-level 3 (difference from the grand mean) \n sum(coef(model3)[-1]*(-1))\n\n[1] 0.5374602"
  },
  {
    "objectID": "FW680A4/glm2.html#deviation-coding-interpretation",
    "href": "FW680A4/glm2.html#deviation-coding-interpretation",
    "title": "Generalized Linear Models II ",
    "section": "Deviation Coding Interpretation",
    "text": "Deviation Coding Interpretation\n\ncoef(model3)\n\n(Intercept)       site1       site2 \n  0.3584266   0.2964994  -0.7151015 \n\n\nIntercept = grand mean of site-means (log-scale), not mean of all observations\n\n\\(\\beta_{0} + \\beta_{1} \\times 1 + \\beta_{2}\\times 0\\)\n\n\n\\(0.3584266 + 0.2964994   \\times 1 + 0\\)\n\n\n\\(\\beta_{1}\\) = effect difference of Site 1 from Grand Mean\n\n\n\\(\\beta_{2}\\) = effect difference of Site 2 from Grand Mean\n\n\n\nThe coefficient for site-level 3 (difference from the grand mean)\n\nsum(coef(model3)[-1]*(-1))\n\n[1] 0.4186021"
  },
  {
    "objectID": "FW680A4/glm2.html#more-control-again",
    "href": "FW680A4/glm2.html#more-control-again",
    "title": "Generalized Linear Models II ",
    "section": "More Control Again",
    "text": "More Control Again\nContrasts\nNo shared connection among these partial intercepts\n\n  model4=glm(y~0+site, \n             data=dat, \n             family = poisson(link = 'log')\n            )\n\n# No shared intercept\nhead(model.matrix(~0 + site, data = dat), n = 6)\n\n  siteSite 1 siteSite 2 siteSite 3\n1          1          0          0\n2          0          1          0\n3          0          0          1\n4          1          0          0\n5          0          1          0\n6          0          0          1"
  },
  {
    "objectID": "FW680A4/glm2.html#taking-control",
    "href": "FW680A4/glm2.html#taking-control",
    "title": "Generalized Linear Models II ",
    "section": "Taking Control",
    "text": "Taking Control\n\nX = model.matrix(~Independent Variables)\n\n#all variables in dat (additive)\nX = model.matrix(~., data = dat)\n\n#all variables in dat (pair-wise interactions)\nX = model.matrix(~.^2, data = dat)\n\n#all variables in dat (three way- interactions)\nX = model.matrix(~.^3, data = dat) \n\nmodel = glm(y~ 0 + X, ...)"
  },
  {
    "objectID": "FW680A4/glm2.html#section",
    "href": "FW680A4/glm2.html#section",
    "title": "Generalized Linear Models II ",
    "section": "",
    "text": "Variable Combinations"
  },
  {
    "objectID": "FW680A4/glm2.html#poisson-regression-to-model-rates",
    "href": "FW680A4/glm2.html#poisson-regression-to-model-rates",
    "title": "Generalized Linear Models II ",
    "section": "Poisson Regression to Model Rates",
    "text": "Poisson Regression to Model Rates\nWhat if our counts of pika are at plots with different sizes?\nPlot size (\\(\\textbf{A}\\)) needs to be controlled for.\n\\[\n\\begin{align*}\n\\textbf{y} \\sim & \\text{Poisson}(\\frac{\\boldsymbol{\\lambda}}{\\textbf{A}})\\\\\n\\text{log}(\\frac{\\boldsymbol{\\lambda}}{\\textbf{A}}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm2.html#offset",
    "href": "FW680A4/glm2.html#offset",
    "title": "Generalized Linear Models II ",
    "section": "Offset",
    "text": "Offset\nEquivalent\n\\[\n\\begin{align*}\n\\text{log}(\\frac{\\boldsymbol{\\lambda}}{\\textbf{A}}) =& \\beta_0 + \\beta_1 \\textbf{x}_{1}\\\\\n\\text{log}(\\boldsymbol{\\lambda}) =& \\beta_0 + \\beta_1 \\textbf{x}_{1} + 1\\times \\textbf{A}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm2.html#offset-code",
    "href": "FW680A4/glm2.html#offset-code",
    "title": "Generalized Linear Models II ",
    "section": "Offset Code",
    "text": "Offset Code\n\nmodel.rate1 = glm(y~site+offset(log(area)),\n            data=dat, \n            family = poisson(link = 'log')\n            )\n\nmodel.rate2 = glm(y~site,\n            offset = log(area),\n            data=dat, \n            family = poisson(link = 'log')\n            )\n\ncoef(model.rate1)\n\n(Intercept)  siteSite 2  siteSite 3 \n -0.8036891  -0.4692766  -0.0582790 \n\ncoef(model.rate2)\n\n(Intercept)  siteSite 2  siteSite 3 \n -0.8036891  -0.4692766  -0.0582790"
  },
  {
    "objectID": "FW680A4/glm2.html#poisson-regression-offset",
    "href": "FW680A4/glm2.html#poisson-regression-offset",
    "title": "Generalized Linear Models II ",
    "section": "Poisson Regression (offset)",
    "text": "Poisson Regression (offset)\nWhat if our counts of pika are at plots with different sizes?\n\nPlot size (\\(\\textbf{A}\\)) needs to be controlled for. But, we don’t want to estimate an effect as it’s part of the design. Rather, we want to model the rate - counts per unit area.\n\n\n\\[\n\\begin{align*}\n\\textbf{y} \\sim & \\text{Poisson}(\\frac{\\boldsymbol{\\lambda}}{\\textbf{A}})\\\\\n\\text{log}(\\frac{\\boldsymbol{\\lambda}}{\\textbf{A}}) =& \\textbf{X}\\boldsymbol{\\beta}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/glm1.html#logistic-regression-biased-correction",
    "href": "FW680A4/glm1.html#logistic-regression-biased-correction",
    "title": "Generalized Linear Models",
    "section": "Logistic Regression Biased Correction",
    "text": "Logistic Regression Biased Correction\nbrglm: Bias Reduction in Binomial-Response Generalized Linear Models\n\nbrglm::brglm(y~0+X, family = binomial(link = \"logit\"))\n\n\n\n# Relative Bias\n  (mean(coef.est[1,])-beta[1])/beta[1]\n\n[1] 0.007785692\n\n  (mean(coef.est[2,])-beta[2])/beta[2]\n\n[1] 0.008799186"
  },
  {
    "objectID": "FW680A4/glm2.html#pika-study",
    "href": "FW680A4/glm2.html#pika-study",
    "title": "Generalized Linear Models II ",
    "section": "Pika Study",
    "text": "Pika Study\n\nWe sample plots of high elevation rocky outcrops, counting the number of American Pika within each plot; plot sizes are the same size."
  },
  {
    "objectID": "FW680A4/glm2.html#intuition-check",
    "href": "FW680A4/glm2.html#intuition-check",
    "title": "Generalized Linear Models II ",
    "section": "Intuition Check",
    "text": "Intuition Check\n\nmean.group = aggregate(y, by=list(site=site),FUN=mean)\nmean.group\n\n    site     x\n1 Site 1 1.925\n2 Site 2 0.700\n3 Site 3 2.175\n\n\n\n\n#Site 1\nexp(0.3584266 + 0.2964994)\n\n[1] 1.925\n\nas.numeric(predict(model3,type=\"response\")[1])\n\n[1] 1.925\n\n\n\n\n\n\n#Site 2\nexp(0.3584266 + -0.7151015 )\n\n[1] 0.7\n\nas.numeric(predict(model3,type=\"response\")[2])\n\n[1] 0.7\n\n\n\n\n\n\n#Site 3\nexp(0.3584266 + 0.4186021)\n\n[1] 2.175\n\nas.numeric(predict(model3,type=\"response\")[3])\n\n[1] 2.175"
  },
  {
    "objectID": "FW680A4/glm2.html#additive",
    "href": "FW680A4/glm2.html#additive",
    "title": "Generalized Linear Models II ",
    "section": "Additive",
    "text": "Additive\nContinuous and Categorical\nLinear Combination on log-scale\n\nm1 = glm(y~site+herb.cover,data=dat,family = poisson(link = 'log'))\nmarginaleffects::plot_predictions(m1, condition=c(\"herb.cover\",\"site\"),type=\"link\")\n\n\n\n\n\n\n\n\nLinear Combination on response-scale\n\nmarginaleffects::plot_predictions(m1, \n                                  condition=c(\"herb.cover\",\"site\"),\n                                  type=\"response\")"
  },
  {
    "objectID": "FW680A4/glm2.html#interaction",
    "href": "FW680A4/glm2.html#interaction",
    "title": "Generalized Linear Models II ",
    "section": "Interaction",
    "text": "Interaction\nContinuous and Categorical\n\nm3 = glm(y~site*herb.cover,data=dat,family = poisson(link = 'log'))\nm3 = glm(y~site+herb.cover+site:herb.cover,data=dat,family = poisson(link = 'log'))\nhead(model.matrix(~site*herb.cover,data=dat))\n\n  (Intercept) siteSite 2 siteSite 3  herb.cover siteSite 2:herb.cover\n1           1          0          0 -0.22630093            0.00000000\n2           1          1          0  0.02221148            0.02221148\n3           1          0          1 -1.01517375            0.00000000\n4           1          0          0  1.18038309            0.00000000\n5           1          1          0 -2.04470642           -2.04470642\n6           1          0          1  2.44433686            0.00000000\n  siteSite 3:herb.cover\n1              0.000000\n2              0.000000\n3             -1.015174\n4              0.000000\n5              0.000000\n6              2.444337"
  },
  {
    "objectID": "FW680A4/glm2.html#polynomial",
    "href": "FW680A4/glm2.html#polynomial",
    "title": "Generalized Linear Models II ",
    "section": "Polynomial",
    "text": "Polynomial\nQuadratic\n\nm5 = glm(y~poly(dist.trail,2),data=dat,family = poisson(link = 'log'))\nm5 = glm(y~dist.trail+I(dist.trail^2),data=dat,family = poisson(link = 'log'))\nmarginaleffects::plot_predictions(m5,condition=c(\"dist.trail\"),type=\"link\")\n\n\n\n\n\n\n\n\n\nm5 = glm(y~poly(dist.trail,2),data=dat,family = poisson(link = 'log'))\nm5 = glm(y~dist.trail+I(dist.trail^2),data=dat,family = poisson(link = 'log'))\nmarginaleffects::plot_predictions(m5,condition=c(\"dist.trail\"),type=\"response\")"
  },
  {
    "objectID": "FW680A4/glm2.html#transormations",
    "href": "FW680A4/glm2.html#transormations",
    "title": "Generalized Linear Models II ",
    "section": "Transormations",
    "text": "Transormations\nlog\n\nglm(y~site*I(log(herb.cover)),data=dat,family = poisson(link = 'log'))"
  },
  {
    "objectID": "R1day/index.html#section",
    "href": "R1day/index.html#section",
    "title": "Introduction to R",
    "section": "",
    "text": "Next: Data input and output (Kyle)"
  },
  {
    "objectID": "FW680A4/glm2.html#side-bar",
    "href": "FW680A4/glm2.html#side-bar",
    "title": "Generalized Linear Models II ",
    "section": "Side-Bar",
    "text": "Side-Bar\nNegative Log-Likelihood Function\n\n  #Here is our negative log-likelihood function with three\n  #parameters - beta0, beta1, and beta2 (1)\n  #inputs = design matrix X\n  neg.log.like = function(par,X) {\n    \n    #linear model of parameters par and design matrix (X)\n    lam=par[1]*X[,1]+par[2]*X[,2]+par[3]*X[,3]\n    \n    #neg log-likelihood\n    sum(-dpois(y,lambda = exp(lam),log = TRUE))\n  }"
  },
  {
    "objectID": "FW680A4/glm2.html#control-over-dummy-coding",
    "href": "FW680A4/glm2.html#control-over-dummy-coding",
    "title": "Generalized Linear Models II ",
    "section": "Control over Dummy Coding",
    "text": "Control over Dummy Coding\nMake ‘Site 2’ the intercept\n\ndat$site.re = relevel(dat$site,ref=\"Site 2\")\nlevels(dat$site.re) \n\n[1] \"Site 2\" \"Site 1\" \"Site 3\"\n\n\n\n\n\nmodel2 = glm(y~site.re,\n             data = dat, \n             family = poisson(link = 'log')\n            )\nsummary(model2)\n\n\nCall:\nglm(formula = y ~ site.re, family = poisson(link = \"log\"), data = dat)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -0.3567     0.1890  -1.887   0.0591 .  \nsite.reSite 1   1.0116     0.2207   4.584 4.56e-06 ***\nsite.reSite 3   1.1337     0.2173   5.218 1.81e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 341.36  on 119  degrees of freedom\nResidual deviance: 305.76  on 117  degrees of freedom\nAIC: 496.33\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "FW680A4/glm2.html#additive-1",
    "href": "FW680A4/glm2.html#additive-1",
    "title": "Generalized Linear Models II ",
    "section": "Additive",
    "text": "Additive\nContinuous and Continuous\nLinear Combination on log-scale\n\nm2 = glm(y~dist.trail+herb.cover,data=dat,family = poisson(link = 'log'))\nmarginaleffects::plot_predictions(m2, \n                                  condition=c(\"dist.trail\",\"herb.cover\"),\n                                  type=\"link\")\n\n\n\n\n\n\n\n\nLinear Combination on response-scale\n\nmarginaleffects::plot_predictions(m2, \n                                  condition=c(\"dist.trail\",\"herb.cover\"),\n                                  type=\"response\")"
  },
  {
    "objectID": "FW680A4/glm2.html#interaction-1",
    "href": "FW680A4/glm2.html#interaction-1",
    "title": "Generalized Linear Models II ",
    "section": "Interaction",
    "text": "Interaction\nContinuous and Categorical\n\nsummary(m3)\n\n\nCall:\nglm(formula = y ~ site + herb.cover + site:herb.cover, family = poisson(link = \"log\"), \n    data = dat)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)             0.2495     0.1609   1.551   0.1209    \nsiteSite 2             -0.6522     0.2561  -2.546   0.0109 *  \nsiteSite 3              0.4728     0.1987   2.379   0.0174 *  \nherb.cover             -0.9102     0.1626  -5.597 2.18e-08 ***\nsiteSite 2:herb.cover   1.1299     0.2665   4.240 2.24e-05 ***\nsiteSite 3:herb.cover   1.0650     0.1948   5.466 4.61e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 341.36  on 119  degrees of freedom\nResidual deviance: 267.16  on 114  degrees of freedom\nAIC: 463.74\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "FW680A4/glm2.html#data-1",
    "href": "FW680A4/glm2.html#data-1",
    "title": "Generalized Linear Models II ",
    "section": "Data",
    "text": "Data\n\nhead(dat)\n\n  y   site  herb.cover  dist.trail site.re area\n1 0 Site 1 -0.22630093  0.06679655  Site 1    2\n2 1 Site 2  0.02221148 -0.24641488  Site 2    5\n3 0 Site 3 -1.01517375 -0.73612867  Site 3    2\n4 1 Site 1  1.18038309  0.07586011  Site 1    3\n5 0 Site 2 -2.04470642 -0.81595409  Site 2    2\n6 2 Site 3  2.44433686  0.17929858  Site 3    2"
  },
  {
    "objectID": "FW680A4/glm2.html#variable-combinations",
    "href": "FW680A4/glm2.html#variable-combinations",
    "title": "Generalized Linear Models II ",
    "section": "Variable Combinations",
    "text": "Variable Combinations\nAdditive & Interaction combinations of categorical and continuous variables\n\nsite (categorical)\nherb.cover (continuous)\ndist.trail (continuous)\n\n\n\nhead(dat)\n\n  y   site  herb.cover  dist.trail site.re area\n1 0 Site 1 -0.22630093  0.06679655  Site 1    2\n2 1 Site 2  0.02221148 -0.24641488  Site 2    5\n3 0 Site 3 -1.01517375 -0.73612867  Site 3    2\n4 1 Site 1  1.18038309  0.07586011  Site 1    3\n5 0 Site 2 -2.04470642 -0.81595409  Site 2    2\n6 2 Site 3  2.44433686  0.17929858  Site 3    2"
  },
  {
    "objectID": "FW680A4/glm2.html#section-1",
    "href": "FW680A4/glm2.html#section-1",
    "title": "Generalized Linear Models II ",
    "section": "",
    "text": "Lab"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html",
    "href": "FW680A4/temp.multicollinear.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": ". . .\nCorrelation among explantory variables\n\nCan happen when \\(r \\geq 0.28\\) or \\(r^2 \\geq 0.08\\)\n\ncauses inaccurate estimation\ndecreases statistical power\nleads to exclusion of important predictor variables"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#multi-collinearity",
    "href": "FW680A4/temp.multicollinear.html#multi-collinearity",
    "title": "Brian D. Gerber",
    "section": "",
    "text": ". . .\nCorrelation among explantory variables\n\nCan happen when \\(r \\geq 0.28\\) or \\(r^2 \\geq 0.08\\)\n\ncauses inaccurate estimation\ndecreases statistical power\nleads to exclusion of important predictor variables"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#multi-collinearity-code",
    "href": "FW680A4/temp.multicollinear.html#multi-collinearity-code",
    "title": "Brian D. Gerber",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\nlibrary(faux)\n\n\n************\nWelcome to faux. For support and examples visit:\nhttps://debruine.github.io/faux/\n- Get and set global package options with: faux_options()\n************\n\nn=100\nset.seed(543531)\nx.var &lt;- rnorm_multi(n = n, \n                  mu = c(10, 20),\n                  sd = c(1, 1),\n                  r = c(0), \n                  varnames = c(\"A\", \"B\"),\n                  empirical = FALSE)\n\nset.seed(54353)\nx.var.cor &lt;- rnorm_multi(n = n, \n                  mu = c(10, 20),\n                  sd = c(1, 1),\n                  r = c(0.8), \n                  varnames = c(\"A\", \"B\"),\n                  empirical = FALSE)\n\n#Correlation\n  cor(x.var)\n\n           A          B\nA 1.00000000 0.04340106\nB 0.04340106 1.00000000\n\n  cor(x.var.cor)\n\n          A         B\nA 1.0000000 0.8354425\nB 0.8354425 1.0000000"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#multi-collinearity-code-1",
    "href": "FW680A4/temp.multicollinear.html#multi-collinearity-code-1",
    "title": "Brian D. Gerber",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\npar(mfrow=c(1,2))\n  plot(x.var.cor$A,x.var.cor$B)\n  plot(x.var$A,x.var$B)"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#multi-collinearity-code-2",
    "href": "FW680A4/temp.multicollinear.html#multi-collinearity-code-2",
    "title": "Brian D. Gerber",
    "section": "Multi-Collinearity (Code)",
    "text": "Multi-Collinearity (Code)\n\n#Design matrices\n  X.cor=model.matrix(~x.var.cor$A+x.var.cor$B)\n  X=model.matrix(~x.var$A+x.var$B)\n\n#True coefs  \n  beta=c(1,2,3)\n\n#Derive mu  \n  mu=X%*%beta\n  mu.cor=X.cor%*%beta\n\n#simulate data  \n  set.seed(54353)\n  y=rnorm(n,mu,2)\n  y.cor=rnorm(n,mu.cor,2)"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#model-estimates",
    "href": "FW680A4/temp.multicollinear.html#model-estimates",
    "title": "Brian D. Gerber",
    "section": "Model Estimates",
    "text": "Model Estimates\n\nsummary(glm(y~0+X))\n\n\nCall:\nglm(formula = y ~ 0 + X)\n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \nX(Intercept)   0.3514     4.5494   0.077    0.939    \nXx.var$A       2.0619     0.2100   9.820 3.29e-16 ***\nXx.var$B       3.0029     0.2087  14.390  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 4.288366)\n\n    Null deviance: 645623.40  on 100  degrees of freedom\nResidual deviance:    415.97  on  97  degrees of freedom\nAIC: 434.33\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/temp.multicollinear.html#model-estimates-1",
    "href": "FW680A4/temp.multicollinear.html#model-estimates-1",
    "title": "Brian D. Gerber",
    "section": "Model Estimates",
    "text": "Model Estimates\n\nsummary(glm(y~0+X.cor))\n\n\nCall:\nglm(formula = y ~ 0 + X.cor)\n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nX.cor(Intercept) 38.361082   7.926825   4.839 4.91e-06 ***\nX.corx.var.cor$A  0.002467   0.681426   0.004  0.99712    \nX.corx.var.cor$B  2.094430   0.634710   3.300  0.00135 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 13.3163)\n\n    Null deviance: 645623.4  on 100  degrees of freedom\nResidual deviance:   1291.7  on  97  degrees of freedom\nAIC: 547.64\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/glm1.html",
    "href": "FW680A4/glm1.html",
    "title": "Generalized Linear Models",
    "section": "",
    "text": "GLM framework\nmatrix notation\nlink functions\nglm function\ncategorical independent variable\nlinear and logistic regression"
  },
  {
    "objectID": "classfiles/glmlab/Assignment.GLM.html",
    "href": "classfiles/glmlab/Assignment.GLM.html",
    "title": "GLM Assignment",
    "section": "",
    "text": "Objective: Create a report using Markdown that presents code, results, and summarized findings that uses pilot study data to then inform an evaluation of a study design to monitor Canada lynx (Lynx canadensis) in the southern Rocky Mountains.\nOverview\nA colleague sampled the occurrence (0 or 1) of Canada lynx at 75 grid cells using camera-traps. They are interested in you helping 1) fit a model to estimate the occurrence probability of lynx and investigate the influence of two variables, and 2) use these estimates to inform future study design scenarios.\n\n\nData and Hypothesis\nA colleague used camera traps to sample whether a lynx was present (1) or assumed absent (0) at each grid cell or ‘site’ (y) during the winter (December to February); we will assume there are no false-positives or false-negatives in these data. They designed the sampling and site selection such they had variation in two important covariates: the distance the camera was from a road (dist.road) and the percentage of forest cover (cover). Their hypothesis is that lynx will avoid human activity by occurring further from roads when they are not under cover, but will occur near roads that are under cover as they are able to remain hidden.\nTo do\nFit the data (lynx.data.csv) using a model that captures the hypothesis of your colleague.\n\ninterpret coefficients\nmake prediction plots\nsummarize results\nStudy Design Evaluation\nYour colleague would like these data to inform them on whether they are sampling enough grid cells/sites. They specifically want to know whether the sample size provides them enough statistical power to be confident that they will reject the null hypothesis of no difference with zero for each of the estimated coefficient at a type I error rate of 0.05. The power they want to achieve is 0.80 probability. Note- in a simulation context - think of getting the sampling distribution of the p-value for each coefficient and evaluating whether the proportion of p-values is below the type I error rate.\nTo do\nUse the estimated coefficients to simulate many data sets (&gt;1000). Fit each data set using the same model as you used to fit the empirical data. Extract the p-value of each coefficient to evaluate whether there is adequate statistical power based on your colleagues desire. If there is not adequate power, consider increasing the sample size.\n\nsimulate many datasets\nfit the same model to each dataset\ncalculate statistical power\nsummarize results and inform your colleague one what they need to know"
  },
  {
    "objectID": "FW680A4/glm2.html#recap",
    "href": "FW680A4/glm2.html#recap",
    "title": "Generalized Linear Models II ",
    "section": "Recap",
    "text": "Recap\n\n\nPoisson Regression\nNumerical Optimization\nCategorical variables &gt;2 levels\nEffect Coding\nVariable Combinations"
  },
  {
    "objectID": "FW680A4/week5.html",
    "href": "FW680A4/week5.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Summarize exploration, inference/explain, and prediction (Table 8.1) or Table 2\nWhat is stepwise selection? How does it perform?\nWhy fit only one model? Drawbacks? How to decide on how many variables?\nWhat is AIC?\nWhat is Regularization using penalization?\n“Model selection is the Black Hole of Statistics”. What do you think?\nCovariate selection vs. model selection?\n\nVariable Combinations\n\n\nBackground Reading (not required):\n\n\n Gelman and Hill Ch. 11 and 12.\n\n\n\n\n\n\nLecture: Hierarchical Models\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"glmmTMB\",\"broom.mixed\",\"lme4\"))\n\n\n\n\n Kery and Kellner Ch. 2, sections 2.7-2.10."
  },
  {
    "objectID": "FW680A4/week5.html#week-5",
    "href": "FW680A4/week5.html#week-5",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Summarize exploration, inference/explain, and prediction (Table 8.1) or Table 2\nWhat is stepwise selection? How does it perform?\nWhy fit only one model? Drawbacks? How to decide on how many variables?\nWhat is AIC?\nWhat is Regularization using penalization?\n“Model selection is the Black Hole of Statistics”. What do you think?\nCovariate selection vs. model selection?\n\nVariable Combinations\n\n\nBackground Reading (not required):\n\n\n Gelman and Hill Ch. 11 and 12.\n\n\n\n\n\n\nLecture: Hierarchical Models\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"glmmTMB\",\"broom.mixed\",\"lme4\"))\n\n\n\n\n Kery and Kellner Ch. 2, sections 2.7-2.10."
  },
  {
    "objectID": "FW680A4/hierarchical.html#objectives",
    "href": "FW680A4/hierarchical.html#objectives",
    "title": "Hierarchical Models",
    "section": "Objectives",
    "text": "Objectives\n\n\nGeneral Use and Language\nExamples\nCase studies\n\nrandom intercept\nrandom intercept & slope\n\nConsiderations"
  },
  {
    "objectID": "FW680A4/hierarchical.html#section",
    "href": "FW680A4/hierarchical.html#section",
    "title": "Hierarchical Models",
    "section": "",
    "text": "Case Study"
  },
  {
    "objectID": "FW680A4/hierarchical.html#data-and-problem",
    "href": "FW680A4/hierarchical.html#data-and-problem",
    "title": "Hierarchical Models",
    "section": "Data and Problem",
    "text": "Data and Problem\nWe sample Amur Leopards in five different vegetation types of Land of the Leopard National Park.\n\nInterested in detection rate by vegetation type and overall."
  },
  {
    "objectID": "FW680A4/hierarchical.html#situations",
    "href": "FW680A4/hierarchical.html#situations",
    "title": "Hierarchical Models",
    "section": "Situations",
    "text": "Situations\n\nstudent grades within classroom, within school\nmeasurement of individual within population\nunobserved latent state or process"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarhcical-structure-to-data",
    "href": "FW680A4/hierarchical.html#hierarhcical-structure-to-data",
    "title": "Hierarchical Models",
    "section": "Hierarhcical Structure to Data",
    "text": "Hierarhcical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-1",
    "href": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-1",
    "title": "Hierarchical Models",
    "section": "Hierarhcical Structure to Data",
    "text": "Hierarhcical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-2",
    "href": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-2",
    "title": "Hierarchical Models",
    "section": "Hierarhcical Structure to Data",
    "text": "Hierarhcical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-3",
    "href": "FW680A4/hierarchical.html#hierarhcical-structure-to-data-3",
    "title": "Hierarchical Models",
    "section": "Hierarhcical Structure to Data",
    "text": "Hierarhcical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#data-and-problem-1",
    "href": "FW680A4/hierarchical.html#data-and-problem-1",
    "title": "Hierarchical Models",
    "section": "Data and Problem",
    "text": "Data and Problem\nWe sample Amur Leopards in five different vegetation types of Land of the Leopard National Park.\n\nDetection Rate = Independent Counts / Effort"
  },
  {
    "objectID": "FW680A4/hierarchical.html#code",
    "href": "FW680A4/hierarchical.html#code",
    "title": "Hierarchical Models",
    "section": "Code",
    "text": "Code"
  },
  {
    "objectID": "FW680A4/hierarchical.html#types",
    "href": "FW680A4/hierarchical.html#types",
    "title": "Hierarchical Models",
    "section": "Types",
    "text": "Types\n\nRandom Effect / Multi-level Model\nlatent/unobserved state or process"
  },
  {
    "objectID": "FW680A4/hierarchical.html#example-1",
    "href": "FW680A4/hierarchical.html#example-1",
    "title": "Hierarchical Models",
    "section": "Example 1",
    "text": "Example 1\n\nstudent grades within classroom, within school"
  },
  {
    "objectID": "FW680A4/hierarchical.html#example-2",
    "href": "FW680A4/hierarchical.html#example-2",
    "title": "Hierarchical Models",
    "section": "Example 2",
    "text": "Example 2\n\nforest cover effect on occurrence of bobcats at different protected areas"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-effect-multi-level-model",
    "href": "FW680A4/hierarchical.html#random-effect-multi-level-model",
    "title": "Hierarchical Models",
    "section": "Random Effect / Multi-level Model",
    "text": "Random Effect / Multi-level Model\n\nrepeated measurements of individual within population\nrepeated measurements at a small spatial scale that is part of a larger one"
  },
  {
    "objectID": "FW680A4/hierarchical.html#latent-state",
    "href": "FW680A4/hierarchical.html#latent-state",
    "title": "Hierarchical Models",
    "section": "Latent State",
    "text": "Latent State"
  },
  {
    "objectID": "FW680A4/hierarchical.html#latent-state-1",
    "href": "FW680A4/hierarchical.html#latent-state-1",
    "title": "Hierarchical Models",
    "section": "Latent State",
    "text": "Latent State"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hobbs-and-hooten-2015-pg.-109",
    "href": "FW680A4/hierarchical.html#hobbs-and-hooten-2015-pg.-109",
    "title": "Hierarchical Models",
    "section": "Hobbs and Hooten 2015 (pg. 109)",
    "text": "Hobbs and Hooten 2015 (pg. 109)\n\n\nRepresenting variation among individuals arising, for example, from genetics, location, or experience.\nStudying phenomena operating at more than one spatial scale or level of ecological organization.\nModeling a process as well as uncertainty that results from imperfect observations of the process.\nUnderstanding changes in states of ecological systems that cannot be observed directly. These states arise from “hidden” processes."
  },
  {
    "objectID": "FW680A4/hierarchical.html#data",
    "href": "FW680A4/hierarchical.html#data",
    "title": "Hierarchical Models",
    "section": "Data",
    "text": "Data\n\n\n\n\n   y  veg effort\n1 15 Veg1      5\n2 18 Veg1      5\n3 12 Veg2      5\n4 14 Veg2      5\n5 12 Veg2      5\n6 14 Veg2      5\n\n\n\nVeg1 Veg2 Veg3 Veg4 Veg5 \n   2   20   20   10   10"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-1",
    "href": "FW680A4/hierarchical.html#model-1",
    "title": "Hierarchical Models",
    "section": "Model 1",
    "text": "Model 1\n\nlibrary(glmmTMB)\nlibrary(broom.mixed)\n\nmodel1 = glmmTMB(y~1, family=poisson(link=\"log\"),data=dat)\nsummary(model1)\n\n Family: poisson  ( log )\nFormula:          y ~ 1\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n  1234.4   1236.3   -616.2   1232.4       49 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  3.19867    0.02857     112   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ntidy(model1, conf.int = TRUE)\n\n# A tibble: 1 × 9\n  effect component term  estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;  &lt;chr&gt;     &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 fixed  cond      (Int…     3.20    0.0286      112.       0     3.14      3.25"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-2",
    "href": "FW680A4/hierarchical.html#model-2",
    "title": "Hierarchical Models",
    "section": "Model 2",
    "text": "Model 2\n\nmodel2 = glmmTMB(y~x, family=poisson(link=\"log\"),data=dat)\nsummary(model2)\n\n Family: poisson  ( log )\nFormula:          y ~ x\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   666.0    673.6   -329.0    658.0       46 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.2925     0.1005  22.810  &lt; 2e-16 ***\nxVeg2        -1.1939     0.2084  -5.729 1.01e-08 ***\nxVeg3         1.2614     0.1074  11.746  &lt; 2e-16 ***\nxVeg5         1.3888     0.1123  12.363  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3",
    "href": "FW680A4/hierarchical.html#model-3",
    "title": "Hierarchical Models",
    "section": "Model 3",
    "text": "Model 3\n\nmodel3 = glmmTMB(y~1+(1|x), family=poisson(link=\"log\"),data=dat)\nsummary(model3)\n\n Family: poisson  ( log )\nFormula:          y ~ 1 + (1 | x)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   686.9    690.7   -341.4    682.9       48 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev.\n x      (Intercept) 1.089    1.044   \nNumber of obs: 50, groups:  x, 4\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.6624     0.5246   5.075 3.87e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3b",
    "href": "FW680A4/hierarchical.html#model-3b",
    "title": "Hierarchical Models",
    "section": "Model 3b",
    "text": "Model 3b\n\nlibrary(lme4)\nmodel3b = glmer(y~1+(1|veg), family=poisson(link=\"log\"),data=dat)\n\n\n\nequatiomatic::extract_eq(model3b)\n\n\\[\n\\begin{aligned}\n  \\operatorname{y}_{i}  &\\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n    \\log(\\lambda_i) &=\\alpha_{j[i]} \\\\\n    \\alpha_{j}  &\\sim N \\left(\\mu_{\\alpha_{j}}, \\sigma^2_{\\alpha_{j}} \\right)\n    \\text{, for veg j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-1-no-difference",
    "href": "FW680A4/hierarchical.html#model-1-no-difference",
    "title": "Hierarchical Models",
    "section": "Model 1 (No Difference)",
    "text": "Model 1 (No Difference)\n\nlibrary(glmmTMB)\nlibrary(broom.mixed)\n\nmodel1 = glmmTMB(y~1, family=poisson(link=\"log\"),data=dat)\n\n\n\n\nsummary(model1)\n\n Family: poisson  ( log )\nFormula:          y ~ 1\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   532.2    534.4   -265.1    530.2       61 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.91165    0.02962   98.31   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-2-all-different",
    "href": "FW680A4/hierarchical.html#model-2-all-different",
    "title": "Hierarchical Models",
    "section": "Model 2 (All Different)",
    "text": "Model 2 (All Different)\n\nmodel2 = glmmTMB(y~veg, family=poisson(link=\"log\"),data=dat,\n                 contrasts = list(veg = \"contr.sum\"))\n\n\n\nsummary(model2)\n\n Family: poisson  ( log )\nFormula:          y ~ veg\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   369.4    380.1   -179.7    359.4       57 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.93764    0.04235   69.37  &lt; 2e-16 ***\nveg1        -0.13427    0.14133   -0.95    0.342    \nveg2        -0.42398    0.06498   -6.52 6.82e-11 ***\nveg3        -0.29146    0.06262   -4.65 3.25e-06 ***\nveg4         0.47681    0.06138    7.77 7.94e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-2-all-different-1",
    "href": "FW680A4/hierarchical.html#model-2-all-different-1",
    "title": "Hierarchical Models",
    "section": "Model 2 (All Different)",
    "text": "Model 2 (All Different)\n\nmarginaleffects::predictions(model2, \n                             newdata = data.frame(veg=c(\"Veg1\",\"Veg2\",\"Veg3\",\"Veg4\",\"Veg5\")),\n                             re.form=NA)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     16.5      2.872  5.74   &lt;0.001  26.7  10.9   22.1\n     12.4      0.786 15.72   &lt;0.001 182.5  10.8   13.9\n     14.1      0.840 16.79   &lt;0.001 207.8  12.5   15.7\n     30.4      1.744 17.44   &lt;0.001 223.7  27.0   33.8\n     27.4      1.655 16.55   &lt;0.001 202.0  24.2   30.6\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, veg, y \nType:  response"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3-middle-ground",
    "href": "FW680A4/hierarchical.html#model-3-middle-ground",
    "title": "Hierarchical Models",
    "section": "Model 3 (middle-ground)",
    "text": "Model 3 (middle-ground)\n\nmodel3 = glmmTMB(y~1+(1|veg), family=poisson(link=\"log\"),data=dat)\n\n\n\nsummary(model3)\n\n Family: poisson  ( log )\nFormula:          y ~ 1 + (1 | veg)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   384.4    388.6   -190.2    380.4       60 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev.\n veg    (Intercept) 0.1299   0.3604  \nNumber of obs: 62, groups:  veg, 5\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.9391     0.1662   17.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-specificaiton",
    "href": "FW680A4/hierarchical.html#model-specificaiton",
    "title": "Hierarchical Models",
    "section": "Model Specificaiton",
    "text": "Model Specificaiton\nGLMM FAQ\n\nmodel specifications\npredictions with uncertainty\nTesting RE’s"
  },
  {
    "objectID": "FW680A4/hierarchical.html#alt-model-notation",
    "href": "FW680A4/hierarchical.html#alt-model-notation",
    "title": "Hierarchical Models",
    "section": "Alt Model Notation",
    "text": "Alt Model Notation\n\\[\\begin{align*}\ny_{i} \\sim& \\text{Poisson}(\\lambda_{i})\\\\\n\\text{log}(\\lambda_{i}) =& \\mu + \\alpha_{j[i]}\\\\\n\\alpha_{j} \\sim& \\text{Normal}(0, \\sigma^2_{\\alpha})\n\n\\end{align*}\\]"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-to-data",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-to-data",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure to Data",
    "text": "Hierarchical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-to-data-1",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-to-data-1",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure to Data",
    "text": "Hierarchical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-to-data-2",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-to-data-2",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure to Data",
    "text": "Hierarchical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-to-data-3",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-to-data-3",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure to Data",
    "text": "Hierarchical Structure to Data"
  },
  {
    "objectID": "FW680A4/hierarchical.html#testing-res",
    "href": "FW680A4/hierarchical.html#testing-res",
    "title": "Hierarchical Models",
    "section": "Testing RE’s",
    "text": "Testing RE’s\n\nanova(model2, model3)\n\nData: dat\nModels:\nmodel3: y ~ 1 + (1 | x), zi=~0, disp=~1\nmodel2: y ~ x, zi=~0, disp=~1\n       Df    AIC    BIC  logLik deviance  Chisq Chi Df Pr(&gt;Chisq)    \nmodel3  2 1390.4 1397.5 -693.22   1386.4                             \nmodel2  5 1357.8 1375.4 -673.90   1347.8 38.639      3   2.07e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-intercept-slope",
    "href": "FW680A4/hierarchical.html#random-intercept-slope",
    "title": "Hierarchical Models",
    "section": "Random Intercept + Slope",
    "text": "Random Intercept + Slope\nLeopard detection varies by cover and veg, where the effect of cover comes from a shared distribution\n\n\n  y         cov  veg\n1 3  0.40161608 Veg1\n2 0 -0.12360373 Veg1\n3 3  0.62883136 Veg1\n4 0  0.07607150 Veg1\n5 2  0.04150764 Veg1\n6 0 -0.39289231 Veg1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#general-types",
    "href": "FW680A4/hierarchical.html#general-types",
    "title": "Hierarchical Models",
    "section": "General Types",
    "text": "General Types\n\nRandom Effect / Multi-level Model\nlatent/unobserved state or process"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-1-no-difference-1",
    "href": "FW680A4/hierarchical.html#model-1-no-difference-1",
    "title": "Hierarchical Models",
    "section": "Model 1 (No Difference)",
    "text": "Model 1 (No Difference)\n\nmarginaleffects::predictions(model1,type = \"response\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n--- 52 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, y \nType:  response"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3-middle-ground-1",
    "href": "FW680A4/hierarchical.html#model-3-middle-ground-1",
    "title": "Hierarchical Models",
    "section": "Model 3 (middle-ground)",
    "text": "Model 3 (middle-ground)\n\nranef(model3)\n\n$veg\n     (Intercept)\nVeg1  -0.1103110\nVeg2  -0.4126484\nVeg3  -0.2851561\nVeg4   0.4635429\nVeg5   0.3612502\n\n\n\n\n\nbroom.mixed::tidy(model3, effects = \"ran_vals\", conf.int = TRUE)\n\n# A tibble: 5 × 9\n  effect   component group level term      estimate std.error conf.low conf.high\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 ran_vals cond      veg   Veg1  (Interce…   -0.110     0.206  -0.514     0.294 \n2 ran_vals cond      veg   Veg2  (Interce…   -0.413     0.173  -0.751    -0.0738\n3 ran_vals cond      veg   Veg3  (Interce…   -0.285     0.172  -0.622     0.0520\n4 ran_vals cond      veg   Veg4  (Interce…    0.464     0.172   0.126     0.801 \n5 ran_vals cond      veg   Veg5  (Interce…    0.361     0.173   0.0230    0.699 \n\n\n\n\n\n\nconfint(model3, component = c(\"all\"))\n\n                            2.5 %    97.5 %  Estimate\n(Intercept)             2.6134002 3.2647754 2.9390878\nStd.Dev.(Intercept)|veg 0.1896794 0.6846043 0.3603545\n\n\n\n\n\n\n\n\n\n\n\n\nfixef(model3)\n\n\nConditional model:\n(Intercept)  \n      2.939  \n\n\n\n\n\n\n#Predictions - does not include RE uncertainty\npreds = predict(model3,\n                newdata=data.frame(veg=c(\"Veg1\",\"Veg2\",\"Veg3\",\"Veg4\",\"Veg5\")),\n                type=\"link\",\n                re.form=NULL,\n                se.fit = TRUE\n                )\n\n\npreds$LCL = exp(preds$fit-1.96*preds$se.fit)\npreds$UCL = exp(preds$fit+1.96*preds$se.fit)\npreds$fit = exp(preds$fit)\n\ndata.frame(preds)\n\n       fit     se.fit      LCL      UCL\n1 16.92475 0.15877885 12.39843 23.10348\n2 12.50889 0.06300056 11.05583 14.15291\n3 14.20980 0.05890828 12.66030 15.94893\n4 30.04303 0.05761047 26.83519 33.63433\n5 27.12181 0.06039730 24.09392 30.53021\n\n\n\n\n\n\n#A typical site\npredict(model3,type=\"response\",re.form=NA)[1]\n\n[1] 18.8986"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-intercept-slope-1",
    "href": "FW680A4/hierarchical.html#random-intercept-slope-1",
    "title": "Hierarchical Models",
    "section": "Random Intercept + Slope",
    "text": "Random Intercept + Slope\n\nre.model = glmer(y~cov+(cov|veg), family=poisson(link=\"log\"),data=dat2)\n\n\n\nsummary(re.model)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: poisson  ( log )\nFormula: y ~ cov + (cov | veg)\n   Data: dat2\n\n     AIC      BIC   logLik deviance df.resid \n 14274.7  14295.8  -7132.4  14264.7      495 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n -4.798  -2.443  -1.630  -0.946 145.188 \n\nRandom effects:\n Groups Name        Variance Std.Dev. Corr\n veg    (Intercept) 0.4896   0.6997       \n        cov         0.1392   0.3732   0.14\nNumber of obs: 500, groups:  veg, 5\n\nFixed effects:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   1.6210     0.3137   5.166 2.39e-07 ***\ncov           0.1121     0.1683   0.666    0.505    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n    (Intr)\ncov 0.140"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-intercept-slope-2",
    "href": "FW680A4/hierarchical.html#random-intercept-slope-2",
    "title": "Hierarchical Models",
    "section": "Random Intercept + Slope",
    "text": "Random Intercept + Slope\n\nCalled conditional mean predictions\n\n\nmarginaleffects::plot_predictions(re.model, condition=c(\"cov\",\"veg\"),\n                                  type=\"link\", re.form=NULL)"
  },
  {
    "objectID": "FW680A4/hierarchical.html#lab",
    "href": "FW680A4/hierarchical.html#lab",
    "title": "Hierarchical Models",
    "section": "Lab",
    "text": "Lab"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-intercept-slope-3",
    "href": "FW680A4/hierarchical.html#random-intercept-slope-3",
    "title": "Hierarchical Models",
    "section": "Random Intercept + Slope",
    "text": "Random Intercept + Slope\n\npredictions for a ‘typical site’; not an average site Stats4Ecologists\n\n\nmarginaleffects::plot_predictions(re.model, condition=c(\"cov\",\"veg\"),\n                                  type=\"link\", re.form=NA)"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-intercept-slope-4",
    "href": "FW680A4/hierarchical.html#random-intercept-slope-4",
    "title": "Hierarchical Models",
    "section": "Random Intercept + Slope",
    "text": "Random Intercept + Slope\n\nequatiomatic::extract_eq(re.model)\n\n\\[\n\\begin{aligned}\n  \\operatorname{y}_{i}  &\\sim \\operatorname{Poisson}(\\lambda_i) \\\\\n    \\log(\\lambda_i) &=\\alpha_{j[i]} + \\beta_{1j[i]}(\\operatorname{cov}) \\\\    \n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\alpha_{j} \\\\\n      &\\beta_{1j}\n    \\end{aligned}\n  \\end{array}\n\\right)\n  &\\sim N \\left(\n\\left(\n  \\begin{array}{c}\n    \\begin{aligned}\n      &\\mu_{\\alpha_{j}} \\\\\n      &\\mu_{\\beta_{1j}}\n    \\end{aligned}\n  \\end{array}\n\\right)\n,\n\\left(\n  \\begin{array}{cc}\n     \\sigma^2_{\\alpha_{j}} & \\rho_{\\alpha_{j}\\beta_{1j}} \\\\\n     \\rho_{\\beta_{1j}\\alpha_{j}} & \\sigma^2_{\\beta_{1j}}\n  \\end{array}\n\\right)\n\\right)\n    \\text{, for veg j = 1,} \\dots \\text{,J}\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-effect-or-not",
    "href": "FW680A4/hierarchical.html#random-effect-or-not",
    "title": "Hierarchical Models",
    "section": "Random Effect or Not?",
    "text": "Random Effect or Not?"
  },
  {
    "objectID": "FW680A4/hierarchical.html#faq",
    "href": "FW680A4/hierarchical.html#faq",
    "title": "Hierarchical Models",
    "section": "FAQ",
    "text": "FAQ\nGLMM FAQ\n\nmodel specifications\npredictions with uncertainty\nTesting RE’s"
  },
  {
    "objectID": "FW680A4/hierarchical.html#considerations",
    "href": "FW680A4/hierarchical.html#considerations",
    "title": "Hierarchical Models",
    "section": "Considerations",
    "text": "Considerations\n\nShrinkage/Regularization\nWhen to use a random effect?"
  },
  {
    "objectID": "classfiles/glmmlab/Assignment.GLMM.html",
    "href": "classfiles/glmmlab/Assignment.GLMM.html",
    "title": "GLMM Assignment",
    "section": "",
    "text": "Objective\nCreate a report using Markdown that presents code, results, and summarized findings that makes inference to the occurence of the Annamite striped rabbit (Nesolagus timminsi) across multiple protected areas in Vietnam.\nBackground\nThis is not real data. However, the basic premise has been adopted from the paper, Getting the big picture: Landscape-scale occupancy patterns of two Annamite endemics among multiple protected areas.\nOverview\nThe Annamite striped rabbit is a forest-dwelling lagomorph that was discovered by science in the mid-1990s. Little is known about this species. What has been done indicates that hunting pressure is a primary driver of its distribution. As such, protected areas are paramount to their conservation. However, protected areas vary in their effectiveness in limiting hunting and some protected areas are founded on multi-use, such that hunting is still allowed.\n\n\nData and Hypothesis\nA camera trap study was conducted in the Annamite mountain range of Vietnam to better understand the distribution of the unique mammal fauna. A central focus was to learn about the effects of anthropogenic activity on the distribution of the Annamite striped rabbit. A total of 50 camera traps were deployed at 5 different protected areas. The cameras were placed systematically with a random starting point to capture variation in the Euclidean distance between a camera and the nearest center of human activity (i.e., village/town). A colleague organized the data, such that for each camera site, the presence (1) or assumed absence (0) of the rabbit was recorded (occur); we will assume there are no false-positives or false-negatives in these data. The main variables of interest are the protected areas (PA) and the distance to human activity (dist.human).\nWorking with your colleagues, they outline their hypothesis that the main driver of rabbit occurrence is hunting within the protected areas. They predict that increasing distance away from human activity will lead to higher rabbit occupancy because people will only travel so far in difficult mountainous terrain. They also hypothesize that this effect will vary by protected area because there is different levels of patrolling and enforcement. But, regardless of protected area, they hypothesize that occurrence at the edge of the protected areas nearest to human activity will be the same because of the similar density of people and that occurrence will be very low.\nTo do\nFit the data (rabbit.occ.data.csv) using a model that captures the hypothesis of your colleague.\n\npresent all parameters with measures of uncertainty\nmake sure to provide evidence whether there is or is not variation of ‘dist.human’ across protected areas\nmake prediction plots that display all relevant variables\nmake a prediction plot for a ‘typical’ protected area; make it clear why this results is important\nsummarize results and offer suggestions for the type of followup study that would be useful"
  },
  {
    "objectID": "FW680A4/hierarchical.html",
    "href": "FW680A4/hierarchical.html",
    "title": "Hierarchical Models",
    "section": "",
    "text": "General Use and Language\nExamples\nCase studies\n\nrandom intercept\nrandom intercept & slope\n\n\nConsiderations"
  },
  {
    "objectID": "FW680A4/BigPicture.html#which-is-worse",
    "href": "FW680A4/BigPicture.html#which-is-worse",
    "title": "Big Picture  Science and Modeling",
    "section": "Which is worse?",
    "text": "Which is worse?\n\nunbiased imprecise result\nprecise biased result"
  },
  {
    "objectID": "FW680A4/bayesian.html#all-things-bayesian",
    "href": "FW680A4/bayesian.html#all-things-bayesian",
    "title": "Bayes the way",
    "section": "All things Bayesian",
    "text": "All things Bayesian\n\n\n\n\nBayesian Inference\n\n\nBayes Thereom\n\n\nBayesian Components\n\n\nlikelihood, prior, evidence, posterior\n\n\nConjugacy\n\n\nHippo Case Study\n\n\nBayesian Computation"
  },
  {
    "objectID": "FW680A4/bayesian.html#probability-data-and-parameters",
    "href": "FW680A4/bayesian.html#probability-data-and-parameters",
    "title": "Bayes the way",
    "section": "Probability, Data, and Parameters",
    "text": "Probability, Data, and Parameters\nWhat do we want our model to tell us?\n\n\nDo we want to make probability statements about our data?\n\n\n\n\nLikelihood = P(data|parameters)\n\n\n\n90% CI: the long-run proportion of corresponding CIs that will contain the true value 90% of the time."
  },
  {
    "objectID": "FW680A4/bayesian.html#probability-data-and-parameters-1",
    "href": "FW680A4/bayesian.html#probability-data-and-parameters-1",
    "title": "Bayes the way",
    "section": "Probability, Data, and Parameters",
    "text": "Probability, Data, and Parameters\nWhat do we want our model to tell us?\n\nDo we want to make probability statements about our parameters?\n\n\n\nPosterior = P(parameters|data)\n\nAlternative Interval: 90% probability that the true value lies within the interval, given the evidence from the observed data."
  },
  {
    "objectID": "FW680A4/bayesian.html#likelihood-inference",
    "href": "FW680A4/bayesian.html#likelihood-inference",
    "title": "Bayes the way",
    "section": "Likelihood Inference",
    "text": "Likelihood Inference\nEstimate of the population size of hedgehogs at two sites."
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-inference",
    "href": "FW680A4/bayesian.html#bayesian-inference",
    "title": "Bayes the way",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\nPosterior Samples\n\n\n\n [1] 102.67671  81.11546  81.75260  87.77246  73.99043  80.70631  76.26219\n [8]  83.99927  64.74208  26.93133"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-inference-1",
    "href": "FW680A4/bayesian.html#bayesian-inference-1",
    "title": "Bayes the way",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\nPosterior Samples\n\n\n [1] 102.67671  81.11546  81.75260  87.77246  73.99043  80.70631  76.26219\n [8]  83.99927  64.74208  26.93133"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-inference-2",
    "href": "FW680A4/bayesian.html#bayesian-inference-2",
    "title": "Bayes the way",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\n\n\ndiff=post2-post1\nlength(which(diff&gt;0))/length(diff)\n\n[1] 0.8362"
  },
  {
    "objectID": "FW680A4/bayesian.html#likelihood-inference-coeficient",
    "href": "FW680A4/bayesian.html#likelihood-inference-coeficient",
    "title": "Bayes the way",
    "section": "Likelihood Inference (coeficient)",
    "text": "Likelihood Inference (coeficient)\ny is Body size of a beetle species\nx is elevation\n\n\nsummary(glm(y~x))\n\n\nCall:\nglm(formula = y ~ x)\n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   0.9862     0.2435   4.049 0.000684 ***\nx             0.5089     0.4022   1.265 0.221093    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 1.245548)\n\n    Null deviance: 25.659  on 20  degrees of freedom\nResidual deviance: 23.665  on 19  degrees of freedom\nAIC: 68.105\n\nNumber of Fisher Scoring iterations: 2"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-inference-coeficient",
    "href": "FW680A4/bayesian.html#bayesian-inference-coeficient",
    "title": "Bayes the way",
    "section": "Bayesian Inference (coeficient)",
    "text": "Bayesian Inference (coeficient)"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-inference-coeficient-1",
    "href": "FW680A4/bayesian.html#bayesian-inference-coeficient-1",
    "title": "Bayes the way",
    "section": "Bayesian Inference (coeficient)",
    "text": "Bayesian Inference (coeficient)\n\n#Posterior Mean\n  mean(post)\n\n[1] 0.5185186\n\n\n\n\n\n#Credible/Probability Intervals \n  quantile(post,prob=c(0.025,0.975))\n\n     2.5%     97.5% \n-1.461887  2.403232 \n\n\n\n\n\n\n# #Probabilty of a postive effect\n length(which(post&gt;0))/length(post)\n\n[1] 0.709\n\n\n\n\n\n\n# #Probabilty of a negative effect\n length(which(post&lt;0))/length(post)\n\n[1] 0.291"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-theorem",
    "href": "FW680A4/bayesian.html#bayes-theorem",
    "title": "Bayes the way",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\nLink\n\n\n\n\nMarginal Probability\n\n\n\\(P(A)\\)\n\\(P(B)\\)\n\n\n\n\nClick for Answer\n#P(A)\n3/10 = 0.3\n\n#P(B)\n5/10 = 0.5\n\n\n\n\n\nSampled N = 10 locations"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-theorem-1",
    "href": "FW680A4/bayesian.html#bayes-theorem-1",
    "title": "Bayes the way",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\n\n\n\n\nJoint Probability\n\n\n\\(P(A \\cap B)\\)  \n\n\n\n\nClick for Answer\n#P(A and B)\n2/10 = 0.2\n\n\n\n\n\nSampled N = 10 locations"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-theorem-2",
    "href": "FW680A4/bayesian.html#bayes-theorem-2",
    "title": "Bayes the way",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\n\n\n\n\nConditional Probability\n\n\n\\(P(A|B)\\)\n\\(P(B|A)\\)  \n\n\n\n\nClick for Answer\n#P(A|B)\n2/5 = 0.4\n\n#P(B|A)\n2/3 = 0.6666\n\n\n\n\n\nSampled N = 10 locations"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-theorem-3",
    "href": "FW680A4/bayesian.html#bayes-theorem-3",
    "title": "Bayes the way",
    "section": "Bayes Theorem",
    "text": "Bayes Theorem\n\n\n\n\nOR Probability\n\n\n\\(P(A\\cup B)\\)\n\n\n\n\nClick for Answer\n# P(A or B)\n# P(A) + P(B) - P(A and B)\n\n0.3 + 0.5 - 0.2 = 0.6\n\n\n\n\n\nSampled N = 10 locations"
  },
  {
    "objectID": "FW680A4/bayesian.html#notice-that",
    "href": "FW680A4/bayesian.html#notice-that",
    "title": "Bayes the way",
    "section": "Notice that…",
    "text": "Notice that…\n\\[\n\\begin{equation}\nP(A \\cap B) = 0.2 \\\\\nP(A|B)P(B) = 0.4 \\times 0.5 = 0.2 \\\\\nP(B|A)P(A) = 0.6666 \\times 0.3 = 0.2 \\\\\n\\end{equation}\n\\]\n\n\\[\n\\begin{equation}\nP(A|B)P(B) = P(A \\cap B) \\\\\nP(B|A)P(A) = P(A \\cap B) \\\\\n\\end{equation}\n\\]\n\n\n\\[\n\\begin{equation}\nP(B|A)P(A) = P(A|B)P(B)\n\\end{equation}\n\\]"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-components",
    "href": "FW680A4/bayesian.html#bayes-components",
    "title": "Bayes the way",
    "section": "Bayes Components",
    "text": "Bayes Components\nparam = parameters \\[\n\\begin{equation}\nP(\\text{param}|\\text{data}) = \\frac{P(\\text{data}|\\text{param})P(\\text{param})}{P(\\text{data})} \\\\\n\\end{equation}\n\\]\n\n\nPosterior Probability/Belief\n\n\n\n\nLikelihood\n\n\n\n\nPrior Probability\n\n\n\n\nEvidence or Marginal Likelihood"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-components-1",
    "href": "FW680A4/bayesian.html#bayes-components-1",
    "title": "Bayes the way",
    "section": "Bayes Components",
    "text": "Bayes Components\nparam = parameters\n\\[\n\\begin{equation}\nP(\\text{param}|\\text{data}) = \\frac{P(\\text{data}|\\text{param})P(\\text{param})}{\\int_{\\forall \\text{ Param}} P(\\text{data}|\\text{param})P(\\text{param})}\n\\end{equation}\n\\]\n\nPosterior Probability/Belief\n\n\nLikelihood\n\n\nPrior Probability\n\n\nEvidence or Marginal Likelihood"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-components-2",
    "href": "FW680A4/bayesian.html#bayes-components-2",
    "title": "Bayes the way",
    "section": "Bayes Components",
    "text": "Bayes Components\n\\[\n\\begin{equation}\n\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Evidence}} \\\\\n\\end{equation}\n\\]\n\n\\[\n\\begin{equation}\n\\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior} \\end{equation}\n\\]\n\n\n\\[\n\\begin{equation}\n\\text{Posterior} \\propto \\text{Likelihood}\n\\end{equation}\n\\]"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior",
    "href": "FW680A4/bayesian.html#the-prior",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nAll parameters in a Bayesian model require a prior specified; parameters are random variables.\n\\(y_{i} \\sim \\text{Binom}(N, \\theta)\\)\n\n\\(\\theta \\sim \\text{Beta}(\\alpha = 4, \\beta=2)\\)\n\n\n\ncurve(dbeta(x, 4,2),xlim=c(0,1),lwd=5)"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-1",
    "href": "FW680A4/bayesian.html#the-prior-1",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\n\\(\\theta \\sim \\text{Beta}(\\alpha = 1, \\beta=1)\\)\n\n\ncurve(dbeta(x, 1,1),xlim=c(0,1),lwd=5)"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-2",
    "href": "FW680A4/bayesian.html#the-prior-2",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\n\n\nThe prior describes what we know about the parameter before we collect any data\nPriors can contain a lot of information (informative priors ) or very little (diffuse priors )\nWell-constructed priors can also improve the behavior of our models (computational advantage)\nNo such thing as a ‘non-informative’ prior"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-3",
    "href": "FW680A4/bayesian.html#the-prior-3",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nUse diffuse priors as a starting point\n\nIt’s fine to use diffuse priors as you develop your model but you should always prefer to use “appropriate, well-contructed informative priors” (Hobbs & Hooten, 2015)"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-4",
    "href": "FW680A4/bayesian.html#the-prior-4",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nUse your “domain knowledge”\n\nWe can often come up with weakly informative priors just by knowing something about the range of plausible values of our parameters."
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-5",
    "href": "FW680A4/bayesian.html#the-prior-5",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nDive into the literature\n\nFind published estimates and use moment matching and other methods to convert published estimates into prior distributions"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayesian-model",
    "href": "FW680A4/bayesian.html#bayesian-model",
    "title": "Bayes the way",
    "section": "Bayesian Model",
    "text": "Bayesian Model\n\nModel\n\n\\[\n\\textbf{y} \\sim \\text{Bernoulli}(p)\n\\]\n\n\nPrior\n\n\\[\np \\sim \\text{Beta}( \\alpha, \\beta) \\\\\n\\]\n\nThese are called Prior hyperparameters\n\\[\n\\alpha = 1 \\\\\n\\beta = 1\n\\]\n\n\n\ncurve(dbeta(x,1,1),xlim=c(0,1),lwd=3,col=2,xlab=\"p\",\n      ylab = \"Prior Probability Density\")"
  },
  {
    "objectID": "FW680A4/bayesian.html#conjugate-distribution",
    "href": "FW680A4/bayesian.html#conjugate-distribution",
    "title": "Bayes the way",
    "section": "Conjugate Distribution",
    "text": "Conjugate Distribution\n\nLikelihood (Joint Probability of y)\n\n\\[\n\\mathscr{L}(p|y) = \\prod_{i=1}^{n} P(y_{i}|p)  = \\prod_{i=1}^{N}(p^{y}(1-p)^{1-y_{i}})\n\\]\n\n\nPrior Distribution\n\n\\[\nP(p) = \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{B(\\alpha,\\beta)}\n\\]\n\n\n\nPosterior Distribution of p\n\n\\[\nP(p|y) = \\frac{\\prod_{i=1}^{N}(p^{y}(1-p)^{1-y_{i}}) \\times \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{B(\\alpha,\\beta)} }{\\int_{p}(\\text{numerator})}\n\\]\n\n\nCONJUGACY!\n\n\n\n\\[\nP(p|y) \\sim \\text{Beta}(\\alpha^*,\\beta^*)\n\\]\n\n\n\\(\\alpha^*\\) and \\(\\beta^*\\) are called Posterior hyperparameters\n\\[\n\\alpha^* = \\alpha + \\sum_{i=1}^{N}y_i \\\\\n\\beta^* = \\beta + N - \\sum_{i=1}^{N}y_i \\\\\n\\]\nWikipedia Conjugate Page\nConjugate Derivation"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos",
    "href": "FW680A4/bayesian.html#hippos",
    "title": "Bayes the way",
    "section": "Hippos",
    "text": "Hippos\nWe do a small study on hippo survival and get these data…\n\n\n\n7 Hippos Died\n\n \n\n2 Hippos Lived"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-likelihood-model",
    "href": "FW680A4/bayesian.html#hippos-likelihood-model",
    "title": "Bayes the way",
    "section": "Hippos: Likelihood Model",
    "text": "Hippos: Likelihood Model\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Binomial}(N,p)\\\\\n\\end{align*}\n\\]\n\n\n# Survival outcomes of three adult hippos\n  y1=c(0,0,0,0,0,0,0,1,1)\n  N1=length(y1)\n  mle.p=mean(y1)\n  mle.p\n\n[1] 0.2222222"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-prior-1",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-prior-1",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Prior 1)",
    "text": "Hippos: Bayesian Model (Prior 1)\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Binomial}(N,p)\\\\\np \\sim& \\text{Beta}(\\alpha,\\beta)\n\\end{align*}\n\\]\n\n  alpha.prior1=1\n  beta.prior1=1"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-prior-2",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-prior-2",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Prior 2)",
    "text": "Hippos: Bayesian Model (Prior 2)\n\n  alpha.prior2=10\n  beta.prior2=2"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-prior-3",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-prior-3",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Prior 3)",
    "text": "Hippos: Bayesian Model (Prior 3)\n\n  alpha.prior3=150\n  beta.prior3=15"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Posteriors)",
    "text": "Hippos: Bayesian Model (Posteriors)\n\\[\nP(p|y) \\sim \\text{Beta}(\\alpha^*,\\beta^*)\\\\\n\\alpha^* = \\alpha + \\sum_{i=1}^{N}y_i \\\\\n\\beta^* = \\beta + N - \\sum_{i=1}^{N}y_i \\\\\n\\]\n\n# Note- the data are the same, but the prior is changing.\n# Gibbs sampler\n  post.1=rbeta(10000,alpha.prior1+sum(y1),beta.prior1+N1-sum(y1))\n  post.2=rbeta(10000,alpha.prior2+sum(y1),beta.prior2+N1-sum(y1))\n  post.3=rbeta(10000,alpha.prior3+sum(y1),beta.prior3+N1-sum(y1))"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-1",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-1",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Posteriors)",
    "text": "Hippos: Bayesian Model (Posteriors)"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-2",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-2",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Posteriors)",
    "text": "Hippos: Bayesian Model (Posteriors)"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-3",
    "href": "FW680A4/bayesian.html#hippos-bayesian-model-posteriors-3",
    "title": "Bayes the way",
    "section": "Hippos: Bayesian Model (Posteriors)",
    "text": "Hippos: Bayesian Model (Posteriors)"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-more-data-prior-1",
    "href": "FW680A4/bayesian.html#hippos-more-data-prior-1",
    "title": "Bayes the way",
    "section": "Hippos: More data! (Prior 1)",
    "text": "Hippos: More data! (Prior 1)\n\ny2=c(0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,0,\n     1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1)\nlength(y2)\n\n[1] 40"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-more-data-prior-2",
    "href": "FW680A4/bayesian.html#hippos-more-data-prior-2",
    "title": "Bayes the way",
    "section": "Hippos: More data! (Prior 2)",
    "text": "Hippos: More data! (Prior 2)"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-more-data-prior-3",
    "href": "FW680A4/bayesian.html#hippos-more-data-prior-3",
    "title": "Bayes the way",
    "section": "Hippos: More data! (Prior 3)",
    "text": "Hippos: More data! (Prior 3)"
  },
  {
    "objectID": "FW680A4/bayesian.html#hippos-dataprior-comparison",
    "href": "FW680A4/bayesian.html#hippos-dataprior-comparison",
    "title": "Bayes the way",
    "section": "Hippos: Data/prior Comparison",
    "text": "Hippos: Data/prior Comparison"
  },
  {
    "objectID": "FW680A4/bayesian.html#markov-chain-monte-carlo",
    "href": "FW680A4/bayesian.html#markov-chain-monte-carlo",
    "title": "Bayes the way",
    "section": "Markov Chain Monte Carlo",
    "text": "Markov Chain Monte Carlo\nOften don’t have conjugate likelihood and priors, so we use MCMC algorithims to sample posteriors.\nClass of algorithim\n\nMetropolis-Hastings\nGibbs\nReversible-Juno\nNo U-turn Sampling\n\n\n\\[\nP(p|y) = \\frac{\\prod_{i=1}^{N}(p^{y}(1-p)^{1-y_{i}}) \\times \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{B(\\alpha,\\beta)} }{\\int_{p}(\\text{numerator})}\n\\]\n\n\n\\[\nP(p|y) \\propto\\prod_{i=1}^{N}(p^{y}(1-p)^{1-y_{i}}) \\times \\frac{p^{\\alpha-1}(1-p)^{\\beta-1}}{B(\\alpha,\\beta)}\n\\]"
  },
  {
    "objectID": "FW680A4/bayesian.html#mcmc-sampling",
    "href": "FW680A4/bayesian.html#mcmc-sampling",
    "title": "Bayes the way",
    "section": "MCMC Sampling",
    "text": "MCMC Sampling\n\nnumber of sample (iterations)\nthinning (which iterations to keep), every one (1), ever other one (2), every third one (3)\nburn-in (how many of the first samples to remove)\nchains (unique sets of samples; needed for convergence tests)"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-6",
    "href": "FW680A4/bayesian.html#the-prior-6",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nVisualize your prior distribution\n\nBe sure to look at the prior in terms of the parameters you want to make inferences about (use simulation!)"
  },
  {
    "objectID": "FW680A4/bayesian.html#the-prior-7",
    "href": "FW680A4/bayesian.html#the-prior-7",
    "title": "Bayes the way",
    "section": "The Prior",
    "text": "The Prior\nDo a sensitivity analysis\n\nDoes changing the prior change your posterior inference? If not, don’t sweat it. If it does, you’ll need to return to point 2 and justify your prior choice"
  },
  {
    "objectID": "FW680A4/bayesian.html#section",
    "href": "FW680A4/bayesian.html#section",
    "title": "Bayes the way",
    "section": "",
    "text": "Bayesian Inference"
  },
  {
    "objectID": "FW680A4/bayesian.html#section-1",
    "href": "FW680A4/bayesian.html#section-1",
    "title": "Bayes the way",
    "section": "",
    "text": "Bayesian Theorem"
  },
  {
    "objectID": "FW680A4/bayesian.html#section-2",
    "href": "FW680A4/bayesian.html#section-2",
    "title": "Bayes the way",
    "section": "",
    "text": "Bayesian Components"
  },
  {
    "objectID": "FW680A4/bayesian.html#bayes-theoreom",
    "href": "FW680A4/bayesian.html#bayes-theoreom",
    "title": "Bayes the way",
    "section": "Bayes Theoreom",
    "text": "Bayes Theoreom\n\\[\n\\begin{equation}\nP(B|A) = \\frac{P(A|B)P(B)}{P(A)} \\\\\n\\end{equation}\n\\]\n\n\\[\n\\begin{equation}\nP(B|A) = \\frac{P(A \\cap B)}{P(A)} \\\\\n\\end{equation}\n\\]"
  },
  {
    "objectID": "FW680A4/bayesian.html#section-3",
    "href": "FW680A4/bayesian.html#section-3",
    "title": "Bayes the way",
    "section": "",
    "text": "Conjugacy"
  },
  {
    "objectID": "FW680A4/bayesian.html#section-4",
    "href": "FW680A4/bayesian.html#section-4",
    "title": "Bayes the way",
    "section": "",
    "text": "Case Study"
  },
  {
    "objectID": "FW680A4/bayesian.html#sofware-options",
    "href": "FW680A4/bayesian.html#sofware-options",
    "title": "Bayes the way",
    "section": "Sofware Options",
    "text": "Sofware Options\n\nWrite your own algorithim\nWinBUGS/OpenBUGS, JAGS, Stan, Nimble"
  },
  {
    "objectID": "FW680A4/bayesian.html#section-5",
    "href": "FW680A4/bayesian.html#section-5",
    "title": "Bayes the way",
    "section": "",
    "text": "Bayesian Computation"
  },
  {
    "objectID": "FW680A4/week6.html",
    "href": "FW680A4/week6.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Bayesian Inference\nLecture Code: bayesian.R\n\n\n Ellison 2004.\n\nBackground Reading (not required):\n\n\n Hobbs and Hooten Ch5.\n\n Fieberg Chapter 11.\n\n Fieberg Chapter 12.\n\n\n\n\n\n\nLecture: Continue with: Bayesian Inference\nDownloads: Files (9/27)\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"rjags\",\"bayesplot\",\"rstanarm\"))\n\n\nInstall External Software Program JAGS\n\n\n\nBayes Quiz on Canvas\n\n\nBackground Reading (not required):\n\nKurz, 2023; Doing Bayesian Data Analysis in brms and the tidyverse"
  },
  {
    "objectID": "FW680A4/week6.html#week-6",
    "href": "FW680A4/week6.html#week-6",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Bayesian Inference\nLecture Code: bayesian.R\n\n\n Ellison 2004.\n\nBackground Reading (not required):\n\n\n Hobbs and Hooten Ch5.\n\n Fieberg Chapter 11.\n\n Fieberg Chapter 12.\n\n\n\n\n\n\nLecture: Continue with: Bayesian Inference\nDownloads: Files (9/27)\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"rjags\",\"bayesplot\",\"rstanarm\"))\n\n\nInstall External Software Program JAGS\n\n\n\nBayes Quiz on Canvas\n\n\nBackground Reading (not required):\n\nKurz, 2023; Doing Bayesian Data Analysis in brms and the tidyverse"
  },
  {
    "objectID": "FW680A4/bayesian.html",
    "href": "FW680A4/bayesian.html",
    "title": "Bayes the way",
    "section": "",
    "text": "Bayesian Inference\n\n\nBayes Thereom\n\n\n\nBayesian Components\n\n\nlikelihood, prior, evidence, posterior\n\n\n\nConjugacy\n\n\nHippo Case Study\n\n\nBayesian Computation"
  },
  {
    "objectID": "classfiles/bayeslab/Assignment.Bayesian.html",
    "href": "classfiles/bayeslab/Assignment.Bayesian.html",
    "title": "Bayesian Assignment",
    "section": "",
    "text": "Objective: To understand Bayesian inference and computation.\nBackground\nIn th lecture, we were able to draw samples from the posterior distribution of \\(p\\), the probability of hippo survival, because of the conjugacy of the Binomial likelihood and Beta prior probability distribution of \\(p\\).\nAnother conjugate relationship is between a Poisson likelihood and a Gamma prior probability on \\(\\lambda\\) (the mean of the Poisson).\n\\[\n\\begin{align*}\n\\textbf{y} \\sim& \\text{Poisson}(\\lambda)\\\\\n\\lambda \\sim& \\text{Gamma}(\\kappa,\\theta)\n\\end{align*}\n\\] where, the posterior distribution of lambda is\n\\[\n\\begin{align*}\n[\\lambda|\\textbf{y}] \\sim& \\text{Gamma}(\\kappa^*,\\theta^*).\n\\end{align*}\n\\] #### Data\n\nI am providing two data sets of counts of Brown mouse lemurs (Microcebus rufus) with different sample sizes. We know in the sampling area that this primate is rare. This prior knowledge should inform how we specify the prior probability distribution.\nPart 1\nFit a Bayesian model to the two data sets provided, each using two different prior distributions on \\(\\lambda\\).\nFit the model by sampling from the posterior distribution directly. You can do this by using the Wikipedia Conjugate Page to look up the posterior hyperparameters.\nTo decide on your two different prior probability distributions, you need to understand the shape (\\(\\kappa\\)) and scale (\\(\\theta\\)) parameters of the Gamma distribution. I suggest looking at the Gamma distribution wikipedia page, choosing values, and then plotting the distributions. The two prior probability distribution you choose should be a ‘highly informative’ and a ‘low/less informative’ prior distribution. Investigate possible prior probability distributions before looking at the data.\nThe markdown should include\n\nTwo plots of the prior probability distributions\nFour plots of posterior distributions (2 for each data set using each of the two priors).\nA table or list of the posterior means or medians along with 95% credible intervals, as well as a description of what these intervals mean.\nA description of how the different priors influenced the first and second data sets. Did each prior have the same importance with each data set? Why?\nPart 2\nHere, the goal is to replicate the above 4 analyses (2 data sets and 2 priors) using JAGS via the r pacakge ‘rjags’ or Stan via the rpackage ‘rstanarm’.\nFor JAGS, you will need to setup a model.jags file that has the likelihood and prior. Note, that the probability density funcitons in JAGS for Gamma and Poisson are dgamma, and dpois, respectively.\nFor Stan, use the code provided and adapt it based on what you know from the GLM homework.\nThe markdown should include\n\nFour plots of posterior distributions (2 for each data set using each of the two priors).\nA table or list of the posterior means or medians along with 95% credible intervals."
  },
  {
    "objectID": "FW680A4/hierarchical.html#random-effect",
    "href": "FW680A4/hierarchical.html#random-effect",
    "title": "Hierarchical Models",
    "section": "Random Effect",
    "text": "Random Effect\nAndrew Gelman Blog Post\nPaper Link\n“People are always asking me if I want to use a fixed or random effects model for this or that.”\n\n\n“I always reply that these terms have no agreed-upon definition.”\n\n\n\n“People with their own favorite definitions don’t always realize that other definitions are out there. Worse, people conflate different definitions”."
  },
  {
    "objectID": "FW680A4/hierarchical.html#pooling-information",
    "href": "FW680A4/hierarchical.html#pooling-information",
    "title": "Hierarchical Models",
    "section": "Pooling Information",
    "text": "Pooling Information"
  },
  {
    "objectID": "FW680A4/hierarchical.html#pooling-information-1",
    "href": "FW680A4/hierarchical.html#pooling-information-1",
    "title": "Hierarchical Models",
    "section": "Pooling Information",
    "text": "Pooling Information"
  },
  {
    "objectID": "FW680A4/hierarchical.html#pooling-information-2",
    "href": "FW680A4/hierarchical.html#pooling-information-2",
    "title": "Hierarchical Models",
    "section": "Pooling Information",
    "text": "Pooling Information"
  },
  {
    "objectID": "FW680A4/week7.html",
    "href": "FW680A4/week7.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Please bring your laptop today\nBoard work for statistical notation and JAGS syntax for Bayesian generalized linear models\n\n\n\n\nDiscuss Project\nStatistical Notation for Bayesian Logistic Regression Model for Annamite Rabbits\nBoard work for statistical notation and JAGS syntax for hierarchical Bayesian generalized linear models\nFit models specified in the previous class\nNo lab to turn in next week.\nDownloads: Bayesian Hierarchical Model Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"brms\",\"bayesplot\"))\n\n\n\nReadings for next class:\n\nWidmer et al 2021\nGuillera‐Arroita et al. 2015\n\n\nBackground Reading (not required):\n\nSoley-Guardia et al. 2024\n\n Valavi et al. 2021 (assessment of modeling methods).\n\n Moudry et al. 2024 (data considerations)."
  },
  {
    "objectID": "FW680A4/week7.html#week-7",
    "href": "FW680A4/week7.html#week-7",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Please bring your laptop today\nBoard work for statistical notation and JAGS syntax for Bayesian generalized linear models\n\n\n\n\nDiscuss Project\nStatistical Notation for Bayesian Logistic Regression Model for Annamite Rabbits\nBoard work for statistical notation and JAGS syntax for hierarchical Bayesian generalized linear models\nFit models specified in the previous class\nNo lab to turn in next week.\nDownloads: Bayesian Hierarchical Model Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"brms\",\"bayesplot\"))\n\n\n\nReadings for next class:\n\nWidmer et al 2021\nGuillera‐Arroita et al. 2015\n\n\nBackground Reading (not required):\n\nSoley-Guardia et al. 2024\n\n Valavi et al. 2021 (assessment of modeling methods).\n\n Moudry et al. 2024 (data considerations)."
  },
  {
    "objectID": "FW680A4/hierarchical.html#names",
    "href": "FW680A4/hierarchical.html#names",
    "title": "Hierarchical Models",
    "section": "Names",
    "text": "Names\n\nmultilevel model\nmixed model\nrandom effects model\nnested data model\nsplit-plot model"
  },
  {
    "objectID": "FW680A4/hierarchical.html#sort-of-definitions",
    "href": "FW680A4/hierarchical.html#sort-of-definitions",
    "title": "Hierarchical Models",
    "section": "Sort of definitions",
    "text": "Sort of definitions\n\nmodels where parameters vary at more than one level\nmodels in which lower levels are sorted under a hierarchy of successive higher-level units\nGeneralization of linear and generalized linear modeling in which regression coefficients are themselves given a model whose parameters are also estimated from data (Gelman)\nModel where unobserved parameters are estimated as a function of other unobserved parameters"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-example",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-example",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure Example",
    "text": "Hierarchical Structure Example\nStudy goals\n\nEstimate state-wide average mass\nUnderstand site-level variation"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-example-1",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-example-1",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure Example",
    "text": "Hierarchical Structure Example"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-example-2",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-example-2",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure Example",
    "text": "Hierarchical Structure Example\nPartial Pooling"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-example-3",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-example-3",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure Example",
    "text": "Hierarchical Structure Example\nPartial Pooling"
  },
  {
    "objectID": "FW680A4/hierarchical.html#hierarchical-structure-example-4",
    "href": "FW680A4/hierarchical.html#hierarchical-structure-example-4",
    "title": "Hierarchical Models",
    "section": "Hierarchical Structure Example",
    "text": "Hierarchical Structure Example\nPartial Pooling"
  },
  {
    "objectID": "FW680A4/hierarchical.html#complete-pooling",
    "href": "FW680A4/hierarchical.html#complete-pooling",
    "title": "Hierarchical Models",
    "section": "Complete Pooling",
    "text": "Complete Pooling\n\nIgnores variance across sites, which is a goal of study\nData within sampling site might not be independent, leading to pseudoreplication (depressed variance)"
  },
  {
    "objectID": "FW680A4/hierarchical.html#no-pooling",
    "href": "FW680A4/hierarchical.html#no-pooling",
    "title": "Hierarchical Models",
    "section": "No Pooling",
    "text": "No Pooling\n\nNo state-level estimate\nEstimator for each site may be biased, particularly at low sample sizes"
  },
  {
    "objectID": "FW680A4/hierarchical.html#partial-pooling-hierarhical-model",
    "href": "FW680A4/hierarchical.html#partial-pooling-hierarhical-model",
    "title": "Hierarchical Models",
    "section": "Partial Pooling (Hierarhical Model)",
    "text": "Partial Pooling (Hierarhical Model)"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-1-complete-pooling",
    "href": "FW680A4/hierarchical.html#model-1-complete-pooling",
    "title": "Hierarchical Models",
    "section": "Model 1 (Complete Pooling)",
    "text": "Model 1 (Complete Pooling)\n\nlibrary(glmmTMB)\nlibrary(broom.mixed)\n\nmodel1 = glmmTMB(y~1, family=poisson(link=\"log\"),data=dat)\n\n\n\n\nsummary(model1)\n\n Family: poisson  ( log )\nFormula:          y ~ 1\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   532.2    534.4   -265.1    530.2       61 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.91165    0.02962   98.31   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-1-complete-pooling-1",
    "href": "FW680A4/hierarchical.html#model-1-complete-pooling-1",
    "title": "Hierarchical Models",
    "section": "Model 1 (Complete Pooling)",
    "text": "Model 1 (Complete Pooling)\n\nmarginaleffects::predictions(model1,type = \"response\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n--- 52 rows omitted. See ?avg_predictions and ?print.marginaleffects --- \n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\n     18.4      0.545 33.8   &lt;0.001 827.7  17.3   19.5\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, y \nType:  response"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-2-no-pooling",
    "href": "FW680A4/hierarchical.html#model-2-no-pooling",
    "title": "Hierarchical Models",
    "section": "Model 2 (No Pooling)",
    "text": "Model 2 (No Pooling)\n\nmodel2 = glmmTMB(y~veg, family=poisson(link=\"log\"),data=dat,\n                 contrasts = list(veg = \"contr.sum\"))\n\n\n\nsummary(model2)\n\n Family: poisson  ( log )\nFormula:          y ~ veg\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   369.4    380.1   -179.7    359.4       57 \n\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  2.93764    0.04235   69.37  &lt; 2e-16 ***\nveg1        -0.13427    0.14133   -0.95    0.342    \nveg2        -0.42398    0.06498   -6.52 6.82e-11 ***\nveg3        -0.29146    0.06262   -4.65 3.25e-06 ***\nveg4         0.47681    0.06138    7.77 7.94e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-2-no-pooling-1",
    "href": "FW680A4/hierarchical.html#model-2-no-pooling-1",
    "title": "Hierarchical Models",
    "section": "Model 2 (No Pooling)",
    "text": "Model 2 (No Pooling)\n\nmarginaleffects::predictions(model2, \n                             newdata = data.frame(veg=c(\"Veg1\",\"Veg2\",\"Veg3\",\"Veg4\",\"Veg5\")),\n                             re.form=NA)\n\n\n Estimate Std. Error     z Pr(&gt;|z|)     S 2.5 % 97.5 %\n     16.5      2.872  5.74   &lt;0.001  26.7  10.9   22.1\n     12.4      0.786 15.72   &lt;0.001 182.5  10.8   13.9\n     14.1      0.840 16.79   &lt;0.001 207.8  12.5   15.7\n     30.4      1.744 17.44   &lt;0.001 223.7  27.0   33.8\n     27.4      1.655 16.55   &lt;0.001 202.0  24.2   30.6\n\nColumns: rowid, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, veg, y \nType:  response"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3-partial-pooling",
    "href": "FW680A4/hierarchical.html#model-3-partial-pooling",
    "title": "Hierarchical Models",
    "section": "Model 3 (Partial Pooling)",
    "text": "Model 3 (Partial Pooling)\n\nmodel3 = glmmTMB(y~1+(1|veg), family=poisson(link=\"log\"),data=dat)\n\n\n\nsummary(model3)\n\n Family: poisson  ( log )\nFormula:          y ~ 1 + (1 | veg)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   384.4    388.6   -190.2    380.4       60 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev.\n veg    (Intercept) 0.1299   0.3604  \nNumber of obs: 62, groups:  veg, 5\n\nConditional model:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   2.9391     0.1662   17.69   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "FW680A4/hierarchical.html#model-3-partial-pooling-1",
    "href": "FW680A4/hierarchical.html#model-3-partial-pooling-1",
    "title": "Hierarchical Models",
    "section": "Model 3 (Partial Pooling)",
    "text": "Model 3 (Partial Pooling)\n\nranef(model3)\n\n$veg\n     (Intercept)\nVeg1  -0.1103110\nVeg2  -0.4126484\nVeg3  -0.2851561\nVeg4   0.4635429\nVeg5   0.3612502\n\n\n\n\n\nbroom.mixed::tidy(model3, effects = \"ran_vals\", conf.int = TRUE)\n\n# A tibble: 5 × 9\n  effect   component group level term      estimate std.error conf.low conf.high\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 ran_vals cond      veg   Veg1  (Interce…   -0.110     0.206  -0.514     0.294 \n2 ran_vals cond      veg   Veg2  (Interce…   -0.413     0.173  -0.751    -0.0738\n3 ran_vals cond      veg   Veg3  (Interce…   -0.285     0.172  -0.622     0.0520\n4 ran_vals cond      veg   Veg4  (Interce…    0.464     0.172   0.126     0.801 \n5 ran_vals cond      veg   Veg5  (Interce…    0.361     0.173   0.0230    0.699 \n\n\n\n\n\n\nconfint(model3, component = c(\"all\"))\n\n                            2.5 %    97.5 %  Estimate\n(Intercept)             2.6134002 3.2647754 2.9390878\nStd.Dev.(Intercept)|veg 0.1896794 0.6846043 0.3603545\n\n\n\n\n\n\n\n\n\n\n\n\nfixef(model3)\n\n\nConditional model:\n(Intercept)  \n      2.939  \n\n\n\n\n\n\n#Predictions - does not include RE uncertainty\npreds = predict(model3,\n                newdata=data.frame(veg=c(\"Veg1\",\"Veg2\",\"Veg3\",\"Veg4\",\"Veg5\")),\n                type=\"link\",\n                re.form=NULL,\n                se.fit = TRUE\n                )\n\n\npreds$LCL = exp(preds$fit-1.96*preds$se.fit)\npreds$UCL = exp(preds$fit+1.96*preds$se.fit)\npreds$fit = exp(preds$fit)\n\ndata.frame(preds)\n\n       fit     se.fit      LCL      UCL\n1 16.92475 0.15877885 12.39843 23.10348\n2 12.50889 0.06300056 11.05583 14.15291\n3 14.20980 0.05890828 12.66030 15.94893\n4 30.04303 0.05761047 26.83519 33.63433\n5 27.12181 0.06039730 24.09392 30.53021\n\n\n\n\n\n\n#A typical site (non an average site)\n# Done by setting the random effect mean to 0\npredict(model3,type=\"response\",re.form=NA)[1]\n\n[1] 18.8986"
  },
  {
    "objectID": "FW680A4/glm1.html#recap",
    "href": "FW680A4/glm1.html#recap",
    "title": "Generalized Linear Models",
    "section": "Recap",
    "text": "Recap\n\nGLM framework: What are key components?\nmatrix notation - why learn this?\nlink functions - what are they?"
  },
  {
    "objectID": "FW680A4/glm2.html#interaction-2",
    "href": "FW680A4/glm2.html#interaction-2",
    "title": "Generalized Linear Models II ",
    "section": "Interaction",
    "text": "Interaction\nContinuous and Categorical\n\nmarginaleffects::plot_predictions(m3,condition=c(\"herb.cover\",\"site\"))"
  },
  {
    "objectID": "FW680A4/glm2.html#interaction-3",
    "href": "FW680A4/glm2.html#interaction-3",
    "title": "Generalized Linear Models II ",
    "section": "Interaction",
    "text": "Interaction\nContinuous and Continuous\n\nm4 = glm(y~herb.cover*dist.trail,data=dat, family = poisson(link = 'log'))\nm4 = glm(y~herb.cover+dist.trail+herb.cover:dist.trail,data=dat,family = poisson(link = 'log'))\nmarginaleffects::plot_predictions(m4, condition=c(\"herb.cover\",\"dist.trail\"))"
  },
  {
    "objectID": "FW680A4/index.html#groups",
    "href": "FW680A4/index.html#groups",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Species Distribution Model (10/8): Libby Mojica, Travis Rainey\nMark Recapture (10/11): Alex Badeaux, Noel Clark, Elke Tukker\nN mixture or Integrated Data Models (10/22):= Sarah Gaulke, Sean Ingram\nAnimal Movement (10/25): Jeremy Alder, Becca Windell\nHabitat Selection (11/1): Waverly Davis, Lisa Roerk\nCommunity Modeling (11/12): Cat Adams, Bijoya Paul"
  },
  {
    "objectID": "FW680A4/index.html#assigned-groups",
    "href": "FW680A4/index.html#assigned-groups",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Species Distribution Model (10/8): Libby Mojica, Travis Rainey\nMark Recapture (10/11): Alex Badeaux, Noel Clark, Elke Tukker\nN mixture or Integrated Data Models (10/25): Sarah Gaulke, Sean Ingram\nAnimal Movement (10/29): Jeremy Alder, Becca Windell\nHabitat Selection (11/5): Waverly Davis, Lisa Roerk\nCommunity Modeling (11/12): Cat Adams, Bijoya Paul"
  },
  {
    "objectID": "classfiles/glmmlab/Assignment.GLMM.BDG.html",
    "href": "classfiles/glmmlab/Assignment.GLMM.BDG.html",
    "title": "GLMM Assignment",
    "section": "",
    "text": "Objective\nCreate a report using Markdown that presents code, results, and summarized findings that makes inference to the occurence of the Annamite striped rabbit (Nesolagus timminsi) across multiple protected areas in Vietnam.\nBackground\nThis is not real data. However, the basic premise has been adopted from the paper, Getting the big picture: Landscape-scale occupancy patterns of two Annamite endemics among multiple protected areas.\nOverview\nThe Annamite striped rabbit is a forest-dwelling lagomorph that was discovered by science in the mid-1990s. Little is known about this species. What has been done indicates that hunting pressure is a primary driver of its distribution. As such, protected areas are paramount to their conservation. However, protected areas vary in their effectiveness in limiting hunting and some protected areas are founded on multi-use, such that hunting is still allowed.\n\n\nData and Hypothesis\nA camera trap study was conducted in the Annamite mountain range of Vietnam to better understand the distribution of the unique mammal fauna. A central focus was to learn about the effects of anthropogenic activity on the distribution of the Annamite striped rabbit. A total of 50 camera traps were deployed at 5 different protected areas. The cameras were placed systematically with a random starting point to capture variation in the Euclidean distance between a camera and the nearest center of human activity (i.e., village/town). A colleague organized the data, such that for each camera site, the presence (1) or assumed absence (0) of the rabbit was recorded (occur); we will assume there are no false-positives or false-negatives in these data. The main variables of interest are the protected areas (PA) and the distance to human activity (dist.human) in meters.\nWorking with your colleagues, they outline their hypothesis that the main driver of rabbit occurrence is hunting within the protected areas. However, there is no spatial variable or direct measure of hunting pressure throughout the park. Rather, they predict that increasing distance away from human activity will lead to higher rabbit occupancy because people will only travel so far in difficult mountainous terrain. They also hypothesize that this effect will vary by protected area because there is different levels of patrolling and enforcement. But, regardless of protected area, they hypothesize that occurrence at the edge of the protected areas nearest to human activity will be the same because of the similar density of people and that occurrence will be very low.\n\nTo do\nFit the data (rabbit.occ.data.csv) using a single model that captures the hypothesis of your colleague.\n\nvisualize and summarize the data\npresent all parameters with measures of uncertainty\ndescribe what each parameter means; discuss relevant measures of statistical clarity using hypothesis tests or confidence intervals\nmake sure to provide evidence whether there is or is not variation of ‘dist.human’ across protected areas\nmake prediction plots that display all relevant variables: PA and dist.human\n\nmake a prediction plot for a ‘typical’ protected area; make it clear why this results is important\nsummarize results and offer suggestions for the type of followup study that would be useful\n\n\nVisualize the Data\n\nlibrary(ggplot2)\ndat = read.csv(\"rabbit.occ.data.csv\")\n\n# data structure and attributes\n  str(dat)\n\n'data.frame':   250 obs. of  5 variables:\n $ X         : int  1 2 3 4 5 6 7 8 9 10 ...\n $ PA        : chr  \"PA1\" \"PA1\" \"PA1\" \"PA1\" ...\n $ camera    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ occur     : int  0 0 0 0 0 0 0 0 0 1 ...\n $ dist.human: num  140 188 363 408 504 ...\n\n# frequency of 0's and 1's\n  table(dat$occur)\n\n\n  0   1 \n107 143 \n\n# how many cameras at each protected area\n  table(dat$PA)\n\n\nPA1 PA2 PA3 PA4 PA5 \n 50  50  50  50  50 \n\n# histogram of distance to human activity\n  hist(dat$dist.human)\n\n\n\n\n\n\n# histograms of human activity measured across PA's  \nggplot(dat, aes(x=dist.human))+\n  geom_histogram(color=\"black\", fill=\"white\")+\n  facet_grid(PA ~ .)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nModel Fitting\nTo evaluate the hypothesis, I fit a hierarchical binomial regression model to the rabbit occurrence data. First, to improve model convergence and maintain the main covariate of interest in terms of an understandable measure of distance, I scaled the dist.human variable by 1000 to obtain distance in kilometers. This also allows the intercept to reflect the logit-value of occurence when dist.human is zero, which is a consideration of the hypothesis.\nThe model includes a fixed effect intercept (i.e., does not very by protected area) and a random effect for scaled distance to human activity (dist.human.sc) by protected area (i.e., the slope does vary by protected area). This model structure captures the types of variation proposed in the hypothesis. I will use \\(\\alpha = 0.05\\) to determine statistical clarity.\n\nlibrary(glmmTMB)\n\n#scale distances to kilometers\ndat$dist.human.sc = dat$dist.human/1000\n\nmodel = glmmTMB(occur~dist.human.sc+(0+dist.human.sc||PA),\n                family=binomial(link=\"logit\"), \n                data=dat\n                )\n\nResults\n\nsummary(model)\n\n Family: binomial  ( logit )\nFormula:          occur ~ dist.human.sc + (0 + dist.human.sc || PA)\nData: dat\n\n     AIC      BIC   logLik deviance df.resid \n   268.5    279.1   -131.3    262.5      247 \n\nRandom effects:\n\nConditional model:\n Groups Name          Variance Std.Dev.\n PA     dist.human.sc 0.1118   0.3343  \nNumber of obs: 250, groups:  PA, 5\n\nConditional model:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)    -1.9236     0.3310  -5.811 6.21e-09 ***\ndist.human.sc   0.9798     0.2057   4.764 1.90e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nconfint(model)\n\n                              2.5 %     97.5 %   Estimate\n(Intercept)              -2.5723889 -1.2747725 -1.9235807\ndist.human.sc             0.5766640  1.3829012  0.9797826\nStd.Dev.dist.human.sc|PA  0.1377511  0.8115265  0.3343481\n\n\nIn our summary outputs, we see that the population mean (across protected areas) slope is statistically clearly different than zero (p-value is &lt; \\(\\alpha\\) and 95% confidence intervals do not include zero) and is positive. As such, across all protected areas (including unsampled areas), a ‘typical’ protected area is expected to have increasing occurrence of the striped rabbit the further from centers of human activity. The prediction that striped rabbit occurrence would be low near human activity is supported with a predicted occurrence of 0.13 (i.e., plogis(-1.9236)) at a distance of zero. We also see that there is support for variation in the effect of dist.human.sc as the standard deviation of the protected area slope differences is well above zero at 0.33 and the 95% confidence intervals do not include zero.\n\nbroom.mixed::tidy(model, effects = \"ran_vals\", conf.int = TRUE)\n\n# A tibble: 5 × 9\n  effect   component group level term      estimate std.error conf.low conf.high\n  &lt;chr&gt;    &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 ran_vals cond      PA    PA1   dist.hum…  -0.192      0.188  -0.561     0.177 \n2 ran_vals cond      PA    PA2   dist.hum…   0.0409     0.191  -0.334     0.416 \n3 ran_vals cond      PA    PA3   dist.hum…  -0.349      0.189  -0.720     0.0211\n4 ran_vals cond      PA    PA4   dist.hum…   0.533      0.264   0.0159    1.05  \n5 ran_vals cond      PA    PA5   dist.hum…  -0.0941     0.189  -0.465     0.277 \n\n\nLooking at the protected area specific differences from the population-mean (i.e., the random effect values), we see the largest difference of 0.53 for protected area 4, which is statistically clearly different than zero as the 95% confidence intervals do not include 0. No other random effect are statistically clearly different than the population mean. This suggests an increase in power is warranted by sampling more sites at each protected area.\nIf we combine the population mean effect and the differences by protected area, we get the mean slope of dist.human.sc by protected area. We see that all slopes are positive, indicating that there is no evidence that increasing distances reduces rabbit occurence.\n\nfixef(model)[[1]][2]+ranef(model)[[1]]$PA\n\n    dist.human.sc\nPA1     0.7876961\nPA2     1.0206335\nPA3     0.6305017\nPA4     1.5128966\nPA5     0.8857225\n\n\nNext, lets visualize the probability of rabbit occurrence at a typical site. This is an important result, as it captures the relationship we would expect at protected areas we have not sampled.\n\nmarginaleffects::plot_predictions(model,\n                                  condition=c(\"dist.human.sc\",\"PA\"),\n                                  type=\"response\",\n                                  re.form=NA,\n                                  vcov=TRUE\n)\n\n\n\n\n\n\n\nNext, we see that there is clear variation of the effect of dist.human.sc by protected area and that none of the slopes are negative.\n\nmarginaleffects::plot_predictions(model,\n                                  condition=c(\"dist.human.sc\",\"PA\"),\n                                  type=\"response\",\n                                  re.form=NULL,\n                                  vcov=TRUE\n)\n\n\n\n\n\n\n\nConclusion\nWe found support for our hypothesis. There is evidence for variation of the effect of distance to human activity on striped rabbit occurence and that as distances increases, occurrence increases. We are measuring a proxy for hunting pressure, but assuming distance relates to human hunting pressure and not other confounding factors, our hypothesis is supported. A follow up study might want to plan for increasing the sampling at each protected area to better test for differences of the main effect by protected area (i.e., increase the statistical power). Second, we may want to consider a random intercept to evaluate the hypothesis that there is variation of rabbit occurrence near human activity."
  },
  {
    "objectID": "classfiles/glmlab/Assignment.GLM.BDG.html",
    "href": "classfiles/glmlab/Assignment.GLM.BDG.html",
    "title": "GLM Assignment",
    "section": "",
    "text": "Objective: Create a report using Markdown that presents code, results, and summarized findings that evaluates a hypothesis reagarding the occurence of lynx (Lynx canadensis) in the southern Rocky Mountains.\nOverview\nA colleague sampled the occurrence (0 or 1) of Canada lynx at 75 grid cells using camera-traps. They are interested in you helping fit a model to estimate the occurrence probability of lynx and evaluate their hypothesis.\n\n\nData and Hypothesis\nA colleague used camera traps to sample whether a lynx was present (1) or assumed absent (0) at each grid cell or ‘site’ (y) during the winter (December to February); we will assume there are no false-positives or false-negatives in these data. They designed the sampling and site selection such they had variation in two important covariates: the Euclidean distance the camera was from the nearest road (dist.road) and the percentage of forest cover (cover) at the site. Their hypothesis is that lynx will avoid human activity by occurring further from roads when they are not under cover, but will occur near roads that are under cover as they are able to remain hidden.\nTo do\nFit the data (lynx.data.csv) using a single model that allows you to evaluate the hypothesis of your colleague.\n\ninterpret coefficients (what they mean exactly)\nmake prediction plot(s)\nsummarize results and evaluate hypothesis support or not\nprovide any nuance in findings that are outside of the core hypothesis\nModeling\nTo represent the hypothesis about the occurrence of Lynx, I fit a binomial regression model with a logit link and an interaction between the two variables of interest (scaled and centered), the Euclidean distance the camera was from a road (dist.road) and the percentage of forest cover (cover). This interaction allows the slope of one variable to vary across values of the other variable. The interpretation of estimate coefficients and predictions will allow me to evaluate the hypothesis. I will use a Type I error rate of \\(\\alpha = 0.05\\) to determine statical clarity.\n\ndat = read.csv(\"lynx.data.csv\")\n\n# Scale and center the covariates and create new columns\ndat$dist.road.sc=scale(dat$dist.road)\ndat$cover.sc=scale(dat$cover)\n\n\n#Fit model\nmodel = glm(y~dist.road.sc*cover.sc, family = binomial(link=\"logit\"),data=dat)\n\n#Look at estimated coefficients\nsummary(model)\n\n\nCall:\nglm(formula = y ~ dist.road.sc * cover.sc, family = binomial(link = \"logit\"), \n    data = dat)\n\nCoefficients:\n                      Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)             0.5149     0.3300   1.560  0.11871    \ndist.road.sc            1.6223     0.5034   3.222  0.00127 ** \ncover.sc                0.6938     0.3730   1.860  0.06284 .  \ndist.road.sc:cover.sc  -2.5295     0.6480  -3.904 9.48e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 102.353  on 74  degrees of freedom\nResidual deviance:  62.346  on 71  degrees of freedom\nAIC: 70.346\n\nNumber of Fisher Scoring iterations: 6\n\n\nResults\nWe see that the conditional effect of dist.road.sc and the interaction effect of the two variables, dist.road.sc:cover.sc, are both statistically clearly different than zero. The intercept represents the occurrence probability on the logit scale (0.5149) at the mean level (i.e., scaled variables = 0) of both variables, which translates to a probability of occurence of 0.62 (i.e. plogis(0.5149)). The effect of dist.road.sc is the conditional effect on the logit-scale when cover.sc is at its mean value (i.e., 0.45, untransformed). The coefficient being positive indicates that when cover is at the mean level, increasing distances from the nearest road leads to increasing probability of lynx occurrence.\nThe effect of cover.sc is the conditional effect on the logit-scale when dist.road.sc is at its mean value (i.e., 962 m, untransformed). The coefficient being positive indicates that when dist.road.sc is at the mean level, increasing cover leads to increasing probability of lynx occurrence. However, this effect was not statistically clearly different zero.\nThe effect of the interaction, dist.road.sc:cover.sc, is how the slopes/coefficients of each conditional effect is modified when both variables are not at the mean value (i.e., 0). Since this effect is statistically clearly different than zero, we know that we can’t understand the occurrence probability of lynx by just knowing cover or just knowing distance to the nearest road. We need both these values, as the slope of one variable changes in the context of the other variable. Since the estimated interaction effect was negative, we know that when either cover or dist.road is below the mean (&lt;0), but not both, occupancy will be higher than the implied probability of the intercept (0.62). However, if both variables are below their means (&lt;0) or above the means (&gt;0) than occupancy will be lower than the implied probability of the intercept. To visualize and fully evaluate the hypothesos, I will plot the predicted occupancy of lynx under both combinations of cover and dist.road.\n\n# Predict the probability of occurence\nmarginaleffects::plot_predictions(model,condition=c(\"dist.road.sc\",\"cover.sc\"))\n\n\n\n\n\n\n\nWe can see that when cover is high (e.g. 1.98 (scaled); purple line; unscaled this value of cover is 0.94), lynx probability of occupancy is near 1 when close to roads, but decreases at increasing distance from the nearest road. Conversely, when cover is low (e.g., -1.7; red line; unscaled this value of cover is 0.03), lynx have low to no occupancy near roads, but high occupancy far from roads.\nConclusion\nThese result supports the hypothesis stated above. There are also some interesting findings that are not represeted in the hypothesis. For example, at medium cover (e.g., 0.77 scaled value) the effect of roads is minimal (blue line). Also, it was unexpected that lynx would not occur with high probability far from roads at high cover. Based on these findings, there seems to be some tradeoff, where far from roads lynx occurence is high at low and medium cover. This may have to do with finding open travel routes and seeking areas of cover for hunting."
  },
  {
    "objectID": "FW680A4/VariableComb.html",
    "href": "FW680A4/VariableComb.html",
    "title": "Linear Regression",
    "section": "",
    "text": "fundamentals\nassumptions\nlm / glm functions\nconfidence intervals\ncase study"
  },
  {
    "objectID": "FW680A4/VariableComb.html#objectives",
    "href": "FW680A4/VariableComb.html#objectives",
    "title": "Linear Regression",
    "section": "",
    "text": "fundamentals\nassumptions\nlm / glm functions\nconfidence intervals\ncase study"
  },
  {
    "objectID": "FW680A4/VariableComb.html#section",
    "href": "FW680A4/VariableComb.html#section",
    "title": "Linear Regression",
    "section": "",
    "text": "Fundamental Idea"
  },
  {
    "objectID": "FW680A4/VariableComb.html#why-model-data",
    "href": "FW680A4/VariableComb.html#why-model-data",
    "title": "Linear Regression",
    "section": "Why model data?",
    "text": "Why model data?\nIn ecology, we use models to,\n\n\ndescribe relationships among outcomes and processes\nto estimate hidden (latent) processes\npredict unobserved values\nforecast future outcomes, such as responses to management"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-motivation",
    "href": "FW680A4/VariableComb.html#linear-regression-motivation",
    "title": "Linear Regression",
    "section": "Linear Regression (motivation)",
    "text": "Linear Regression (motivation)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-equation",
    "href": "FW680A4/VariableComb.html#linear-regression-equation",
    "title": "Linear Regression",
    "section": "Linear Regression (Equation)",
    "text": "Linear Regression (Equation)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-equation-2",
    "href": "FW680A4/VariableComb.html#linear-regression-equation-2",
    "title": "Linear Regression",
    "section": "Linear Regression (Equation 2)",
    "text": "Linear Regression (Equation 2)\n\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma)\\\\\n\\mu_{i} = \\beta_0 + \\beta_1 \\times x_i \\\\\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-line-1",
    "href": "FW680A4/VariableComb.html#linear-regression-line-1",
    "title": "Linear Regression",
    "section": "Linear Regression Line 1",
    "text": "Linear Regression Line 1\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-line-2",
    "href": "FW680A4/VariableComb.html#linear-regression-line-2",
    "title": "Linear Regression",
    "section": "Linear Regression Line 2",
    "text": "Linear Regression Line 2\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linear-regression-line-3",
    "href": "FW680A4/VariableComb.html#linear-regression-line-3",
    "title": "Linear Regression",
    "section": "Linear Regression Line 3",
    "text": "Linear Regression Line 3\n\\[\n\\hat{\\mu_{i}} = 9.06 + 2\\times x_i\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#residuals",
    "href": "FW680A4/VariableComb.html#residuals",
    "title": "Linear Regression",
    "section": "Residuals",
    "text": "Residuals\n\nlibrary(ggplot2)\nlibrary(ggthemes)\nm1=broom::augment(lm.out)\n\nggplot(m1, aes(x, y)) +\n  geom_point() +\n  stat_smooth(method = lm, se = FALSE,linewidth=2) +\n  geom_segment(aes(xend = x, yend = .fitted), color = \"red\", size = 0.3)+theme_base()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "FW680A4/VariableComb.html#one-sample",
    "href": "FW680A4/VariableComb.html#one-sample",
    "title": "Linear Regression",
    "section": "One Sample",
    "text": "One Sample\n\\[\n\\begin{align*}\ny_{i} \\sim& \\text{Normal}(\\mu_{i},\\sigma) \\\\\n\\mu_{i} =& \\beta_{0} + \\beta_{1}x_{i}\\\\\n\\mu_{i} =& 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#sampling-distributions-of-y",
    "href": "FW680A4/VariableComb.html#sampling-distributions-of-y",
    "title": "Linear Regression",
    "section": "Sampling Distributions of y",
    "text": "Sampling Distributions of y\n\\[\n\\begin{align*}\n\\mu_{i} = 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#sampling-distributions-of-hatmu",
    "href": "FW680A4/VariableComb.html#sampling-distributions-of-hatmu",
    "title": "Linear Regression",
    "section": "Sampling Distributions of \\(\\hat{\\mu}\\)\n",
    "text": "Sampling Distributions of \\(\\hat{\\mu}\\)\n\n\\[\n\\begin{align*}\n\\mu_{i} = 1 + 0.5 \\times x_{i}\n\\end{align*}\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#section-1",
    "href": "FW680A4/VariableComb.html#section-1",
    "title": "Linear Regression",
    "section": "",
    "text": "Assumptions"
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumptions",
    "href": "FW680A4/VariableComb.html#assumptions",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nIndependence of the errors\n\nCorrelation(\\(\\epsilon_{i}\\),\\(\\epsilon_{j}\\)) = 0, \\(\\forall\\) pairs of \\(i\\) and \\(j\\)\n\nThis means that knowing how far observation \\(i\\) will be from the true regression line tells us nothing about how far observation \\(j\\) will be from the regression line."
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumptions-1",
    "href": "FW680A4/VariableComb.html#assumptions-1",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nHomogeniety of the variance\nvar(\\(\\epsilon_{i}\\)) = \\(\\sigma^2\\)\nConstancy in the scatter of observations above and below the line, going left to right."
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumptions-2",
    "href": "FW680A4/VariableComb.html#assumptions-2",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nHeteroskedasticity"
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumptions-3",
    "href": "FW680A4/VariableComb.html#assumptions-3",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nLinearity\n\\[\nE[y_i|x_i] = \\mu_i = \\beta_0 + \\beta_1 \\times x_i \\\\\n\\] \nThe hypothesis about the variables included in the model (e.g., \\(x_i\\)) characterizes the mean well."
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumptions-4",
    "href": "FW680A4/VariableComb.html#assumptions-4",
    "title": "Linear Regression",
    "section": "Assumptions",
    "text": "Assumptions\nNormality\n\\[\n\\epsilon_i \\sim \\text{Normal}(0,\\sigma)\n\\] \nEach \\(i^{th}\\) residual\n\n\ncomes from a Normal distribution with a mean of zero\nis symmetrically disributed around zero\nvaries around zero by \\(\\sigma\\), which is the same for each residual."
  },
  {
    "objectID": "FW680A4/VariableComb.html#assumption-violations",
    "href": "FW680A4/VariableComb.html#assumption-violations",
    "title": "Linear Regression",
    "section": "Assumption Violations",
    "text": "Assumption Violations\nRobustness\n\nLinearity and constant variance are often more important than the assumption of normality (see e.g., Knief & Forstmeier, 2021 and references therein)\n\n\n\nThis is especially true for large sample sizes"
  },
  {
    "objectID": "FW680A4/VariableComb.html#section-2",
    "href": "FW680A4/VariableComb.html#section-2",
    "title": "Linear Regression",
    "section": "",
    "text": "lm and glm"
  },
  {
    "objectID": "FW680A4/VariableComb.html#intercept-only-model",
    "href": "FW680A4/VariableComb.html#intercept-only-model",
    "title": "Linear Regression",
    "section": "Intercept-Only Model",
    "text": "Intercept-Only Model\n\\[\ny_{i} \\sim \\text{Normal}(\\mu_{i}, \\sigma^2)\\\\\n\\mu_{i} = \\beta_0\n\\]\n\nGenerate Data\n\n#Setup parameters\n  n = 100 # sample size\n  beta0 = 10 # true mean\n  sigma = 2 # true std.dev\n\n# Simulate a data set of observations\n  set.seed(43243)\n  y = rnorm(n, mean = beta0, sd = sigma)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#visualize-intercept-only-model",
    "href": "FW680A4/VariableComb.html#visualize-intercept-only-model",
    "title": "Linear Regression",
    "section": "Visualize Intercept-Only Model",
    "text": "Visualize Intercept-Only Model\n\n  hist(y)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#fit-intercept-only-model",
    "href": "FW680A4/VariableComb.html#fit-intercept-only-model",
    "title": "Linear Regression",
    "section": "Fit Intercept-Only Model",
    "text": "Fit Intercept-Only Model\n\n# Fit model/hypothesis using maximum likelihood\n  model1.0 = lm(y~1)\n\n  model1.1 = glm(y~1)\n\n  model1.2 = glm(y~1, family=gaussian(link = identity))\n\n  \n  \n# Compare Results  \n  data.frame(intercept=c(model1.0$coefficients,model1.1$coefficients, model1.2$coefficients),\n             SE = c(summary(model1.0)$coefficients[, 2], summary(model1.1)$coefficients[, 2],summary(model1.2)$coefficients[, 2])\n            )\n\n  intercept        SE\n1  9.913821 0.1765343\n2  9.913821 0.1765343\n3  9.913821 0.1765343"
  },
  {
    "objectID": "FW680A4/VariableComb.html#fit-intercept-only-model-1",
    "href": "FW680A4/VariableComb.html#fit-intercept-only-model-1",
    "title": "Linear Regression",
    "section": "Fit Intercept-Only Model",
    "text": "Fit Intercept-Only Model\n\n# Summary of model results  \n  summary(model1.0)\n\n\nCall:\nlm(formula = y ~ 1)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7815 -1.2733 -0.0581  1.1558  4.4979 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   9.9138     0.1765   56.16   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.765 on 99 degrees of freedom"
  },
  {
    "objectID": "FW680A4/VariableComb.html#fitted-values",
    "href": "FW680A4/VariableComb.html#fitted-values",
    "title": "Linear Regression",
    "section": "Fitted-values",
    "text": "Fitted-values\n\n#Predict response for all data\n  preds = predict(model1.0, se.fit = TRUE)\n  preds\n\n$fit\n       1        2        3        4        5        6        7        8 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n       9       10       11       12       13       14       15       16 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      17       18       19       20       21       22       23       24 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      25       26       27       28       29       30       31       32 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      33       34       35       36       37       38       39       40 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      41       42       43       44       45       46       47       48 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      49       50       51       52       53       54       55       56 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      57       58       59       60       61       62       63       64 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      65       66       67       68       69       70       71       72 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      73       74       75       76       77       78       79       80 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      81       82       83       84       85       86       87       88 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      89       90       91       92       93       94       95       96 \n9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 9.913821 \n      97       98       99      100 \n9.913821 9.913821 9.913821 9.913821 \n\n$se.fit\n  [1] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n  [8] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [15] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [22] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [29] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [36] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [43] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [50] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [57] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [64] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [71] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [78] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [85] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [92] 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343 0.1765343\n [99] 0.1765343 0.1765343\n\n$df\n[1] 99\n\n$residual.scale\n[1] 1.765343"
  },
  {
    "objectID": "FW680A4/VariableComb.html#section-3",
    "href": "FW680A4/VariableComb.html#section-3",
    "title": "Linear Regression",
    "section": "",
    "text": "Confidence Intervals"
  },
  {
    "objectID": "FW680A4/VariableComb.html#what-is-a-ci",
    "href": "FW680A4/VariableComb.html#what-is-a-ci",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?\n. . .\n“A confidence interval for a parameter is an interval computed using sample data …\n. . .\n“… by a method that will contain the parameter for a specified proportion of all samples.\n. . .\nThe success rate (proportion of all samples whose intervals contain the parameter) is known as the confidence level.” R. H. Lock et al. (2020)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#what-is-a-ci-1",
    "href": "FW680A4/VariableComb.html#what-is-a-ci-1",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?\nKey\n\nthe parameter we are trying to estimate is a fixed unknown (i.e., it is not varying across samples)\n\n\n\nthe endpoints of our confidence interval are random and will change every time we collect a new data set (the endpoints themselves actually have a sampling distribution!)\n\n\nMore at Stats4Ecologists"
  },
  {
    "objectID": "FW680A4/VariableComb.html#what-is-a-ci-2",
    "href": "FW680A4/VariableComb.html#what-is-a-ci-2",
    "title": "Linear Regression",
    "section": "What is a CI?",
    "text": "What is a CI?"
  },
  {
    "objectID": "FW680A4/VariableComb.html#confidence-intervals",
    "href": "FW680A4/VariableComb.html#confidence-intervals",
    "title": "Linear Regression",
    "section": "Confidence Intervals",
    "text": "Confidence Intervals\nNormal Approximation\n\n# Get 90% confidence intervals (Type I error = 0.1)\n  c(\n    (preds$fit+preds$se.fit*qnorm(0.05))[1],\n    (preds$fit+preds$se.fit*qnorm(0.95))[1]\n   )\n\n        1         1 \n 9.623448 10.204195 \n\n\n\n\n  CI.Normal=confint(model1.0, level=0.9)\n  CI.Normal\n\n                 5 %     95 %\n(Intercept) 9.620705 10.20694"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping",
    "href": "FW680A4/VariableComb.html#bootstrapping",
    "title": "Linear Regression",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nInstead of relying on the 95% intervals from an assumed normal distribution, we will create a distribution by resampling our data.\n\nSee, Stats4Ecologists"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-idea",
    "href": "FW680A4/VariableComb.html#bootstrapping-idea",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-idea-1",
    "href": "FW680A4/VariableComb.html#bootstrapping-idea-1",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-idea-2",
    "href": "FW680A4/VariableComb.html#bootstrapping-idea-2",
    "title": "Linear Regression",
    "section": "Bootstrapping (idea)",
    "text": "Bootstrapping (idea)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-code",
    "href": "FW680A4/VariableComb.html#bootstrapping-code",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)\n\n# Setup\n  nboot &lt;- 1000 # number of bootstrap samples\n  nobs &lt;- length(y)\n  bootcoefs &lt;- rep(NA, nboot)\n# Start loop  \nfor(i in 1:nboot){\n  set.seed(43243+i)\n  # Create bootstrap data set by sampling original observations w/ replacement  \n  bootdat &lt;- y[sample(1:nobs, nobs, replace=TRUE)] \n  # Calculate bootstrap statistic\n  glmboot &lt;- glm(bootdat ~ 1)\n  bootcoefs[i] &lt;- coef(glmboot)\n}"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-code-1",
    "href": "FW680A4/VariableComb.html#bootstrapping-code-1",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)\n\npar(mfrow = c(1, 1))\nhist(bootcoefs, main = expression(paste(\"Bootstrap distribution of \", hat(beta)[0])), xlab = \"\")"
  },
  {
    "objectID": "FW680A4/VariableComb.html#bootstrapping-code-2",
    "href": "FW680A4/VariableComb.html#bootstrapping-code-2",
    "title": "Linear Regression",
    "section": "Bootstrapping (code)",
    "text": "Bootstrapping (code)\n\n# Calculate bootstrap standard errors\n  boot.se = sd(bootcoefs)\n\n# boostrap-normal CI\n  boot.normal = c(\n        (preds$fit+boot.se*qnorm(0.05))[1],\n        (preds$fit+boot.se*qnorm(0.95))[1]\n        )\n\n# bootstrap percentile\nconfdat.boot.pct &lt;- quantile(bootcoefs, probs = c(0.05, 0.95))"
  },
  {
    "objectID": "FW680A4/VariableComb.html#comparison",
    "href": "FW680A4/VariableComb.html#comparison",
    "title": "Linear Regression",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "FW680A4/VariableComb.html#section-4",
    "href": "FW680A4/VariableComb.html#section-4",
    "title": "Linear Regression",
    "section": "",
    "text": "Case Study / Independent Variables"
  },
  {
    "objectID": "FW680A4/VariableComb.html#prairie-dog-calling",
    "href": "FW680A4/VariableComb.html#prairie-dog-calling",
    "title": "Linear Regression",
    "section": "Prairie Dog Calling",
    "text": "Prairie Dog Calling\n\n\n\n\n\n\n\ny = # of calls per 5 minute at a prairie dog colony\ntemp = temperature, degrees F\ndist.human = distance of nearest human activity to colony\n\n\n  head(dat)\n\n           y     temp dist.human\n1 0.38129119 39.96298   11.75578\n2 0.57770546 47.95317   14.63583\n3 0.00347806 56.13182   22.89228\n4 0.00000000 29.76491   21.14168\n5 2.67643282 40.25998   32.41442\n6 1.71519689 38.31469   35.99573"
  },
  {
    "objectID": "FW680A4/VariableComb.html#exploratory",
    "href": "FW680A4/VariableComb.html#exploratory",
    "title": "Linear Regression",
    "section": "Exploratory",
    "text": "Exploratory"
  },
  {
    "objectID": "FW680A4/VariableComb.html#model-fitting-1",
    "href": "FW680A4/VariableComb.html#model-fitting-1",
    "title": "Linear Regression",
    "section": "Model Fitting 1",
    "text": "Model Fitting 1\n\n  model = lm(y ~ temp+dist.human, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp + dist.human, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -8.312197   1.074281  -7.737 9.65e-12 ***\ntemp         0.156393   0.024605   6.356 6.75e-09 ***\ndist.human   0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/VariableComb.html#model-notation-1",
    "href": "FW680A4/VariableComb.html#model-notation-1",
    "title": "Linear Regression",
    "section": "Model Notation 1",
    "text": "Model Notation 1\n\nequatiomatic::extract_eq(model)\n\n\\[\n\\operatorname{y} = \\alpha + \\beta_{1}(\\operatorname{temp}) + \\beta_{2}(\\operatorname{dist.human}) + \\epsilon\n\\]\n\nequatiomatic::extract_eq(model, use_coefs = TRUE)\n\n\\[\n\\operatorname{\\widehat{y}} = -8.31 + 0.16(\\operatorname{temp}) + 0.04(\\operatorname{dist.human})\n\\]"
  },
  {
    "objectID": "FW680A4/VariableComb.html#model-fitting-2",
    "href": "FW680A4/VariableComb.html#model-fitting-2",
    "title": "Linear Regression",
    "section": "Model Fitting 2",
    "text": "Model Fitting 2\nMean-center the intercept. Slopes do not change.\n\n  model = lm(y ~ I(temp - mean(temp)) + dist.human, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ I(temp - mean(temp)) + dist.human, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n                     Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)          2.614311   0.895284   2.920  0.00435 ** \nI(temp - mean(temp)) 0.156393   0.024605   6.356 6.75e-09 ***\ndist.human           0.036010   0.003388  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/VariableComb.html#normalizing-x",
    "href": "FW680A4/VariableComb.html#normalizing-x",
    "title": "Linear Regression",
    "section": "Normalizing x",
    "text": "Normalizing x\nMean-center and standardize by std. deviation\n\n  dat$temp.sc = scale(dat$temp, center=TRUE, scale = TRUE)\n  dat$dist.sc = scale(dat$dist.human, center=TRUE, scale = TRUE)\n\n\n\n  mean(dat$temp.sc)\n\n[1] 1.40337e-16\n\n  sd(dat$temp.sc)\n\n[1] 1"
  },
  {
    "objectID": "FW680A4/VariableComb.html#comparison-1",
    "href": "FW680A4/VariableComb.html#comparison-1",
    "title": "Linear Regression",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "FW680A4/VariableComb.html#model-fitting-3",
    "href": "FW680A4/VariableComb.html#model-fitting-3",
    "title": "Linear Regression",
    "section": "Model Fitting 3",
    "text": "Model Fitting 3\nWhat does the slope mean now?\n\\[\n\\mu_{i} = \\beta_0 + \\beta_1 \\times 1 + \\beta_2 \\times 0\n\\]\n\n  model = lm(y ~ temp.sc + dist.sc, data=dat)\n  summary(model)\n\n\nCall:\nlm(formula = y ~ temp.sc + dist.sc, data = dat)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.6714 -1.6690 -0.1506  1.4910  5.0041 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  11.8002     0.2338  50.471  &lt; 2e-16 ***\ntemp.sc       3.0958     0.4871   6.356 6.75e-09 ***\ndist.sc       5.1771     0.4871  10.629  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.338 on 97 degrees of freedom\nMultiple R-squared:  0.9233,    Adjusted R-squared:  0.9217 \nF-statistic: 583.8 on 2 and 97 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "FW680A4/VariableComb.html#marginal-predictions",
    "href": "FW680A4/VariableComb.html#marginal-predictions",
    "title": "Linear Regression",
    "section": "Marginal Predictions",
    "text": "Marginal Predictions\n\\[\n\\hat{\\mu_{i}} = \\hat{\\beta_{0}} + \\hat{\\beta_{1}}\\times 0 +  \\hat{\\beta_{2}} \\times \\text{dist.human}_i\n\\]\n\n\n\n\n# Plot marginal predictions of dist.human\n  marginaleffects::plot_predictions(model, condition=c(\"dist.human\"))"
  },
  {
    "objectID": "FW680A4/VariableComb.html#add-data-points",
    "href": "FW680A4/VariableComb.html#add-data-points",
    "title": "Linear Regression",
    "section": "Add data points",
    "text": "Add data points\n\n# Plot marginal predictions of dist.human\n  plot1 = marginaleffects::plot_predictions(model, condition=c(\"dist.human\"))\n  plot1+geom_point(data=dat, aes(x=dist.human,y=y))"
  },
  {
    "objectID": "FW680A4/VariableComb.html#combined-predictions",
    "href": "FW680A4/VariableComb.html#combined-predictions",
    "title": "Linear Regression",
    "section": "Combined Predictions",
    "text": "Combined Predictions\n\nmarginaleffects::plot_predictions(model, condition=list(\"temp\",\"dist.human\"))"
  },
  {
    "objectID": "FW680A4/VariableComb.html#combined-predictions-1",
    "href": "FW680A4/VariableComb.html#combined-predictions-1",
    "title": "Linear Regression",
    "section": "Combined Predictions",
    "text": "Combined Predictions\n\nmarginaleffects::plot_predictions(model, condition=list(\"temp\",\"dist.human\" = 0:5))"
  },
  {
    "objectID": "FW680A4/VariableComb.html#taking-control",
    "href": "FW680A4/VariableComb.html#taking-control",
    "title": "Linear Regression",
    "section": "Taking Control",
    "text": "Taking Control\n\nnewdata = expand.grid(dat$temp,0:5)\ncolnames(newdata)=c(\"temp\",\"dist.human\")\n\npreds = predict(model,newdata = newdata,interval=\"confidence\", level=0.95)\n\npred.plot = data.frame(newdata,preds)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#combined-predictions-2",
    "href": "FW680A4/VariableComb.html#combined-predictions-2",
    "title": "Linear Regression",
    "section": "Combined Predictions 2",
    "text": "Combined Predictions 2"
  },
  {
    "objectID": "FW680A4/VariableComb.html#evaluating-assumptions",
    "href": "FW680A4/VariableComb.html#evaluating-assumptions",
    "title": "Linear Regression",
    "section": "Evaluating Assumptions",
    "text": "Evaluating Assumptions\nLargely done based on the residuals\n\\(y_{i} - \\hat{y}_{i}\\)\n\nhist(model$residuals)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#linearity-assumption",
    "href": "FW680A4/VariableComb.html#linearity-assumption",
    "title": "Linear Regression",
    "section": "Linearity Assumption",
    "text": "Linearity Assumption\n\nplot(model,1)\n\n\n\n\n\n\n\nIdeally, there will be no pattern and the red line should be roughly horizontal near zero."
  },
  {
    "objectID": "FW680A4/VariableComb.html#homogeneity-of-variance",
    "href": "FW680A4/VariableComb.html#homogeneity-of-variance",
    "title": "Linear Regression",
    "section": "Homogeneity of Variance",
    "text": "Homogeneity of Variance\n\nplot(model,3)\n\n\n\n\n\n\n\nResiduals should be spread equally along the ranges of predictors. We want a horizontal red line; otherwise, suggests a non-constant variances in the residuals (i.e., heteroscedasticity)."
  },
  {
    "objectID": "FW680A4/VariableComb.html#normality-of-residuals",
    "href": "FW680A4/VariableComb.html#normality-of-residuals",
    "title": "Linear Regression",
    "section": "Normality of Residuals",
    "text": "Normality of Residuals\n\nplot(model,2)\n\n\n\n\n\n\n\nShows theoretical quantiles versus empirical quantiles of the residuals. We want to see cicles on the dotted line."
  },
  {
    "objectID": "FW680A4/VariableComb.html#outliers",
    "href": "FW680A4/VariableComb.html#outliers",
    "title": "Linear Regression",
    "section": "Outliers",
    "text": "Outliers\n\npar(mfrow=c(1,2))\nplot(model,4)\nplot(model,5)\n\n\n\n\n\n\n\nOutlier: extreme value that can affect the \\(\\beta\\) estimate. Leverage plot: points in the upper right and lower right corner."
  },
  {
    "objectID": "FW680A4/VariableComb.html#exploring-assumptions",
    "href": "FW680A4/VariableComb.html#exploring-assumptions",
    "title": "Linear Regression",
    "section": "Exploring Assumptions",
    "text": "Exploring Assumptions\nNicer looking Plots\n\nlibrary(ggResidpanel)\nresid_panel(model)"
  },
  {
    "objectID": "FW680A4/VariableComb.html#go-to-lab",
    "href": "FW680A4/VariableComb.html#go-to-lab",
    "title": "Linear Regression",
    "section": "Go to Lab",
    "text": "Go to Lab"
  },
  {
    "objectID": "classfiles/variableCombs/VariableCombs_BDG.html",
    "href": "classfiles/variableCombs/VariableCombs_BDG.html",
    "title": "Variable Combinations",
    "section": "",
    "text": "Data\n\n\n\n    weight age.years        lat   site\n1 12615.13        41   2.690077 Site 1\n2 12539.55        50   2.974857 Site 2\n3 13753.97        21  -4.868759 Site 1\n4 17269.26        50 -28.437431 Site 2\n5 16945.27        16 -26.414605 Site 1\n6 14723.24        39 -11.392111 Site 2\n\n\nQuestions\n1. What model syntax allows for the effect of age.years to be different at each level of site?\n\nfirst = glm(weight~age.years+site+age.years:site)\nsecond = glm(weight~age.years+site)\nthird = glm(weight~age.years*site)\nfourth = glm(weight~poly(age.years,2)+site\n\nFirst and Third\n\n2. Draw an x-y plot showing the relationship b/w weight and the additive effect of site and age.years. Assume a negative slope of age.years with weight and two levels of the variable site. Assume the intercept mle is 13000 and the estimated effect of siteSite2 = -2000. Label axes and slopes for each site.\n\nglm(weight~age.years+site)\n\n The plot should have weight on the y-axis and age.years on the x-axis. There should be two lines, representing the slopes of age.years for each site. The slopes should be parallel with site 2 lower than site 1. \n\n3. Looking at the data table above, write out the design matrix for the two models below.\n\nglm(weight~age.years+site)\nglm(weight~age.years*site)\n\n\n\n  (Intercept) age.years siteSite 2\n1           1        41          0\n2           1        50          1\n3           1        21          0\n4           1        50          1\n5           1        16          0\n6           1        39          1\n\n\n  (Intercept) age.years siteSite 2 age.years:siteSite 2\n1           1        41          0                    0\n2           1        50          1                   50\n3           1        21          0                    0\n4           1        50          1                   50\n5           1        16          0                    0\n6           1        39          1                   39\n\n\n4. When might it be good to assume an additive effect b/w a categorical and continuous variable over an interaction?\n When there are many levels of the categorical variable and not a lot of replicate data at each or some levels. Also, when the hypothesis is an effect of difference by each level, but the same slope. \n\n5. Define what each coefficient means. Make sure to make clear the units.\n\ndat$age.yeras.sc = scale(dat$age.years,center=TRUE, scale=FALSE)\nsummary(glm(weight~age.yeras.sc*site,data=dat))\n\n\nCall:\nglm(formula = weight ~ age.yeras.sc * site, data = dat)\n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             14574.77     241.92  60.245  &lt; 2e-16 ***\nage.yeras.sc              -65.32      24.35  -2.682  0.00861 ** \nsiteSite 2               -188.06     342.00  -0.550  0.58367    \nage.yeras.sc:siteSite 2   108.48      32.14   3.375  0.00107 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for gaussian family taken to be 2908337)\n\n    Null deviance: 313494594  on 99  degrees of freedom\nResidual deviance: 279200364  on 96  degrees of freedom\nAIC: 1778\n\nNumber of Fisher Scoring iterations: 2\n\n\nIntercept = the mean weight of elephants at the observed mean age of elephants at site 1\nage.yeras.sc = the one year change in mean weight of elephants at site 1\nsiteSite 2 = the mean weight effect difference of site 2 from site 1 (intercept) at the mean observed age of elephants.\nage.yeras.sc:siteSite 2 - the change in the slope or one year change in mean weight of elephants at site 2 from site 1"
  },
  {
    "objectID": "FW680A4/week8.html",
    "href": "FW680A4/week8.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "What was the objective of the modeling, and how do you feel the authors did in addressing the objective?\nHow did the authors address potential problems that come from using presence-only data (e.g., spatial autocorrelation, pseudo-absences)? Was this effort adequate?\nWhat other aspects of ecological processes are not addressed by the objectives? Could these have been incorporated in this study?\nWere their any findings you found particularly important? Anything that stood out to you, good or bad, in the methodology or interpretation?\nIs the study area and scale of analysis relevant to each of the 4 salamanders?\nAre the prediction maps useful or relevant for salamander conservation?\n\n\n\n\nWhat is a SDM?\nWhat are they used for?\nWhat are the types of data used and how does that change the inference/predictions?\nWhat are the three joint probabilities that determine whether a site is recorded as a detection in a dataset?\nWhat is the difference/importance of being able to estimate occurrence probability and occurence relative likelihood?\nWhat are some specific model types or algorithms commonly used for fitting a SDM?\n\n\n\nReadings for next class:\n\nWildman et al 2024\nKery and Schaub Ch 7 (sections 7.1-7.3)\n\n\n\n\n\n\nGroups work on defining the CJS model using constant parameters and then with sex effect on survival, but not detection. From the reading, what is so important about the initial values in this type of model?\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"stringr\",\"coda\",\"runjags\"))\n\n\n\nReadings for next class:\n\nRoyle et al. 2018\n\n\nBackground Reading (not required):\n\nBorchers and Marques 2017\nRoyle et al 2011"
  },
  {
    "objectID": "FW680A4/week8.html#week-7",
    "href": "FW680A4/week8.html#week-7",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture: Board Work on Mark Recapture\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\n\n\n\nReadings for next class:"
  },
  {
    "objectID": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html",
    "href": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html",
    "title": "Bayesian Assignment",
    "section": "",
    "text": "95% CI interpretation: There is a 95% probability that the true parameter value lies within the reported 95% credible interval.\n\n\n        Prior1lemurs1 Prior2lemurs1 Prior2lemurs2 Prior2lemurs2\nMLE         0.5555556     0.5555556     0.4545455     0.4545455\nmean        0.9640434     0.7931241     0.7291829     0.5037267\nlow.ci      0.7862633     0.4447163     0.6164777     0.3793931\nhigh.ci     1.1533789     1.2407402     0.8532128     0.6454779\n\n\nThe highly informative prior had a strong influence on the posterior distribution of the small sample size data set and a bit less, but still a strong influence on the large sample size data set. The less informative prior had a moderate effect on the low sample size data and very little effect on the large sample size data set."
  },
  {
    "objectID": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-means-and-95-cis",
    "href": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-means-and-95-cis",
    "title": "Bayesian Assignment",
    "section": "",
    "text": "95% CI interpretation: There is a 95% probability that the true parameter value lies within the reported 95% credible interval.\n\n\n        Prior1lemurs1 Prior2lemurs1 Prior2lemurs2 Prior2lemurs2\nMLE         0.5555556     0.5555556     0.4545455     0.4545455\nmean        0.9640434     0.7931241     0.7291829     0.5037267\nlow.ci      0.7862633     0.4447163     0.6164777     0.3793931\nhigh.ci     1.1533789     1.2407402     0.8532128     0.6454779\n\n\nThe highly informative prior had a strong influence on the posterior distribution of the small sample size data set and a bit less, but still a strong influence on the large sample size data set. The less informative prior had a moderate effect on the low sample size data and very little effect on the large sample size data set."
  },
  {
    "objectID": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-distributions",
    "href": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-distributions",
    "title": "Bayesian Assignment",
    "section": "Posterior distributions",
    "text": "Posterior distributions\n\n#JAGS data lists (different for 2 datasets)\n  data1 &lt;- list(\n            lemurs1=lemurs1[,1],\n            N1=length(lemurs1[,1])\n            )\n\n  data2 &lt;- list(\n            lemurs2=lemurs2[,1],\n            N2=length(lemurs2)\n            )\n\n#MCMC inputs  (same across priors and datasets)\n  n.chains = 2\n  n.adapt = 1000\n  n.iter = 10000\n  thin = 2\n  burn = 5000\n\n# Model Parameters to save values of (same across priors and datasets)\n  parms &lt;- c(\"p\")   \n\n\n# Setup the Models\n  jm1 &lt;- jags.model(file=\"model.jags1.r\", data = data1, n.chains = n.chains)\n  jm2 &lt;- jags.model(file=\"model.jags2.r\", data = data1, n.chains = n.chains)\n  jm3 &lt;- jags.model(file=\"model.jags3.r\", data = data2, n.chains = n.chains)\n  jm4 &lt;- jags.model(file=\"model.jags4.r\", data = data2, n.chains = n.chains)\n\n# Update the models with the burnin\n  update(jm1, n.iter = burn, n.adapt = n.adapt)\n  update(jm2, n.iter = burn, n.adapt = n.adapt)\n  update(jm3, n.iter = burn, n.adapt = n.adapt)\n  update(jm4, n.iter = burn, n.adapt = n.adapt)\n\n# Fit the models\n  post1=coda.samples(jm1, variable.names = parms, n.iter = n.iter, thin = thin)\n  post2=coda.samples(jm2, variable.names = parms, n.iter = n.iter, thin = thin)\n  post3=coda.samples(jm3, variable.names = parms, n.iter = n.iter, thin = thin)\n  post4=coda.samples(jm4, variable.names = parms, n.iter = n.iter, thin = thin)\n\n# Plots of posteriors for lambda\n  par(mfrow = c(2,2))\n  hist(as.matrix(post1), main = \"Prior 1, Dataset 1\")\n  hist(as.matrix(post2), main = \"Prior 2, Dataset 1\")\n  hist(as.matrix(post3), main = \"Prior 1, Dataset 2\")\n  hist(as.matrix(post4), main = \"Prior 2, Dataset 2\")"
  },
  {
    "objectID": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-means-and-95-cis-1",
    "href": "classfiles/bayeslab/My Results for the HW/Bayeslab_BDG.html#posterior-means-and-95-cis-1",
    "title": "Bayesian Assignment",
    "section": "Posterior means and 95% CIs",
    "text": "Posterior means and 95% CIs\n\n\n        Prior1lemurs1 Prior2lemurs1 Prior2lemurs2 Prior2lemurs2\nMLE         0.5555556     0.5555556     0.4545455    0.45454545\nmean       49.9368464    19.8976887     0.4946738    0.19839566\nlow.ci     16.3523063     2.3961125     0.1621196    0.02443574\nhigh.ci   102.5103574    55.9200630     1.0261025    0.54544397"
  },
  {
    "objectID": "FW680A4/week8.html#week-8",
    "href": "FW680A4/week8.html#week-8",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "What was the objective of the modeling, and how do you feel the authors did in addressing the objective?\nHow did the authors address potential problems that come from using presence-only data (e.g., spatial autocorrelation, pseudo-absences)? Was this effort adequate?\nWhat other aspects of ecological processes are not addressed by the objectives? Could these have been incorporated in this study?\nWere their any findings you found particularly important? Anything that stood out to you, good or bad, in the methodology or interpretation?\nIs the study area and scale of analysis relevant to each of the 4 salamanders?\nAre the prediction maps useful or relevant for salamander conservation?\n\n\n\n\nWhat is a SDM?\nWhat are they used for?\nWhat are the types of data used and how does that change the inference/predictions?\nWhat are the three joint probabilities that determine whether a site is recorded as a detection in a dataset?\nWhat is the difference/importance of being able to estimate occurrence probability and occurence relative likelihood?\nWhat are some specific model types or algorithms commonly used for fitting a SDM?\n\n\n\nReadings for next class:\n\nWildman et al 2024\nKery and Schaub Ch 7 (sections 7.1-7.3)\n\n\n\n\n\n\nGroups work on defining the CJS model using constant parameters and then with sex effect on survival, but not detection. From the reading, what is so important about the initial values in this type of model?\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"stringr\",\"coda\",\"runjags\"))\n\n\n\nReadings for next class:\n\nRoyle et al. 2018\n\n\nBackground Reading (not required):\n\nBorchers and Marques 2017\nRoyle et al 2011"
  },
  {
    "objectID": "classfiles/cjslab/cjslab.BDG.html",
    "href": "classfiles/cjslab/cjslab.BDG.html",
    "title": "Survival Estimation with Capture-Recapture Data",
    "section": "",
    "text": "We will estimate the annual survival probability of European Dipper using capture-recapture data via a hierarchical Bayesian version of the cormack-jolly-seber model.\nLoad the necessary packages.\n\n  library(stringr)\n  library(rjags)\n  library(coda)\n\nNext, read in the data. The first column is the capture-history. The second column indicates males (0) and females (1). The third column indicate females (1) and males (0). The fourth column are just semi-colons…it’s MARK thing.\n\n#Load the Data\n  dipper = read.table(\"DIPPER.INP\", skip = 2,sep=\"\", colClasses = \"character\")\n  head(dipper)\n\n       V1 V2 V3 V4\n1 1111110  1  0  ;\n2 1111100  0  1  ;\n3 1111000  1  0  ;\n4 1111000  0  1  ;\n5 1101110  0  1  ;\n6 1100000  1  0  ;\n\n#The number of individuals marked\n  nrow(dipper)\n\n[1] 294\n\n\nNext, lets manipulate the inputted data to create capture-histories in columns, which we will use to fit our model.\n\n# split column 1 into columns\n  CH = matrix(as.integer(str_split_fixed(dipper[,1],\"\",7)),nrow=nrow(dipper))\n  head(CH)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7]\n[1,]    1    1    1    1    1    1    0\n[2,]    1    1    1    1    1    0    0\n[3,]    1    1    1    1    0    0    0\n[4,]    1    1    1    1    0    0    0\n[5,]    1    1    0    1    1    1    0\n[6,]    1    1    0    0    0    0    0\n\n#  Sex variable: female = 1; male = 0\n  sex = as.integer(dipper$V3)\n\nWe can see that there are 7 columns in the capture-history, 1 for each year. So, this study has 7 years of data total.\nNext, we need to setup two specialized functions. ‘get.first’ will identify the first occasion each individual was initially captured. The next function will use the capture history to create logical designations of when we know individuals are alive to be used to initialize the state parameter z.\n\n# Create vector with occasion of marking for each individual (row of CH)\n  get.first &lt;- function(x) min(which(x!=0))\n  f &lt;- apply(CH, 1, get.first)\n\n  z.init &lt;- matrix(NA, nrow = nrow(CH), ncol = ncol(CH))\n  for(i in 1:dim(z.init)[1]){\n    z.init[i, f[i]:dim(z.init)[2]] &lt;- 1\n    z.init[i,f[i]] &lt;- NA\n  }"
  },
  {
    "objectID": "classfiles/cjslab/cjslab.BDG.html#step-1",
    "href": "classfiles/cjslab/cjslab.BDG.html#step-1",
    "title": "Survival Estimation with Capture-Recapture Data",
    "section": "Step 1",
    "text": "Step 1\nFit a CJS survival model that includes a sex effect on survival probability. Adapt the jags model code in the other file and implementation code that is above.\n\n# MCMC settings\n  ni &lt;- 15000 # number of iterations\n  nt &lt;- 2     # number of iterations to thin by\n  nb &lt;- 5000  # number of iterations to burn (to toss out initially)\n  na &lt;- 2000  # number of iterations to use to adapt to sample efficiently\n  nc &lt;- 3     # number of chains\n\n\n# Parameters monitored\n  parameters &lt;- c(\"beta0\",\"beta1\", \"p\")\n  \n  inits &lt;- function(){list(beta0 = rnorm(1),\n                           beta1 = rnorm(1),\n                           p = runif(1, 0, 1), \n                           z = z.init)}\n  \n# Bundle data\n  jags.data &lt;- list(y = CH, f = f, nind = dim(CH)[1], n.occasions = dim(CH)[2],\n                    sex=sex)\n  \n# Setup the Model\n  jm &lt;- jags.model(file=\"cjs2.r\", data=jags.data,n.chains=nc,n.adapt=na,inits=inits)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 848\n   Unobserved stochastic nodes: 851\n   Total graph size: 4950\n\nInitializing model\n\n# Update the model with the burnin\n  update(jm, n.iter=nb)\n  \n#Fit the model\n  post2 &lt;- coda.samples(jm, variable.names=parameters, n.iter=ni, thin=nt)\n  \n#Look at the results\n  summary(post2)  \n\n\nIterations = 7002:22000\nThinning interval = 2 \nNumber of chains = 3 \nSample size per chain = 7500 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n          Mean      SD  Naive SE Time-series SE\nbeta0  0.28613 0.14316 0.0009544      0.0015897\nbeta1 -0.07281 0.19453 0.0012969      0.0020880\np      0.89578 0.02908 0.0001939      0.0003323\n\n2. Quantiles for each variable:\n\n          2.5%     25%      50%     75%  97.5%\nbeta0  0.00734  0.1881  0.28634 0.38261 0.5700\nbeta1 -0.45277 -0.2024 -0.07386 0.05708 0.3125\np      0.83343  0.8776  0.89804 0.91661 0.9454\n\n\nThe summary output shows us the quantiles of each model paramter that was defined in the variable parameters."
  },
  {
    "objectID": "classfiles/cjslab/cjslab.BDG.html#step-2",
    "href": "classfiles/cjslab/cjslab.BDG.html#step-2",
    "title": "Survival Estimation with Capture-Recapture Data",
    "section": "Step 2",
    "text": "Step 2\nCheck that parameters have converged. Show evidence of this by plotting and calculating the gelman-rubin convergence diagnostic, i.e, function gelman.diag.\n\n  plot(post2)\n\n\n\n\n\n\n  gelman.diag(post2)\n\nPotential scale reduction factors:\n\n      Point est. Upper C.I.\nbeta0          1          1\nbeta1          1          1\np              1          1\n\nMultivariate psrf\n\n1\n\n\nWe see the diagnostic statistic (gelman-rubin statistics; known as \\(\\hat{R}\\)) are at 1, indicating no sign of lack of convergence. Also, the posterior distribution traceplots look like fuzzy caterpillars and are overlapping, also demonstrating no signs of convergence issues."
  },
  {
    "objectID": "FW680A4/week9.html",
    "href": "FW680A4/week9.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "How are data different than a typical capture-recapture study?\nWhat is an ‘activity center’?\nWhat makes this model ‘spatial’? Think about this assumption. When will it be appropriate or not to assume?\nWhat are the two components that control ‘detection probability’?\nIf using a SCR model, how might your sampling strategy change?\nWhat is the exact meaning of abundance in this type of model?\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"secr\",\"sf\"))\n\n\n\nReadings for next class:\n\nKery and Schaub Ch13 (sections 13.1 to 13.4)\n\n\n\n\n\nBoard work defining the occupancy model hierarchically\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"ubms\",\"unmarked\"))\n\n\n\nReadings for next class:\n\nZipkin and Saunders 2018 (lines 153-208, AKA section 3)\nZipkin et al. 2021\nPowell and Gale ch 18"
  },
  {
    "objectID": "FW680A4/week9.html#week-9",
    "href": "FW680A4/week9.html#week-9",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "How are data different than a typical capture-recapture study?\nWhat is an ‘activity center’?\nWhat makes this model ‘spatial’? Think about this assumption. When will it be appropriate or not to assume?\nWhat are the two components that control ‘detection probability’?\nIf using a SCR model, how might your sampling strategy change?\nWhat is the exact meaning of abundance in this type of model?\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"secr\",\"sf\"))\n\n\n\nReadings for next class:\n\nKery and Schaub Ch13 (sections 13.1 to 13.4)\n\n\n\n\n\nBoard work defining the occupancy model hierarchically\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"ubms\",\"unmarked\"))\n\n\n\nReadings for next class:\n\nZipkin and Saunders 2018 (lines 153-208, AKA section 3)\nZipkin et al. 2021\nPowell and Gale ch 18"
  },
  {
    "objectID": "FW680A4/week10.html",
    "href": "FW680A4/week10.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture (updated) \nIPM Script \n\n\nReadings for next class:\n\nMcCaffery et al. 2016 \nKery and Kellner ch20 (section 20.1) \n\n\nBackground Reading (not required):\n\nKery 2018\nLink et al 2018\nBarker et al 2018\n\n\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"VGAM\"))\n\n\n\nReadings for next class:\n\n Huggler et al. 2022 \n Wittemyer et al. 2019"
  },
  {
    "objectID": "FW680A4/week10.html#week-10",
    "href": "FW680A4/week10.html#week-10",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Lecture (updated) \nIPM Script \n\n\nReadings for next class:\n\nMcCaffery et al. 2016 \nKery and Kellner ch20 (section 20.1) \n\n\nBackground Reading (not required):\n\nKery 2018\nLink et al 2018\nBarker et al 2018\n\n\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"VGAM\"))\n\n\n\nReadings for next class:\n\n Huggler et al. 2022 \n Wittemyer et al. 2019"
  },
  {
    "objectID": "FW680A4/week16.html",
    "href": "FW680A4/week16.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Noel Clark\nLibby Mojica\nSean Ingram\nAlex Badeaux\n\n\n\n\n\n\n\n\n\n\n\nTravis Rainey\nBijoya Paul\nWaverly Davis\nLisa Roerk\nBecca Windell\nSarah Gaulke\nCat Adams\nJeremy Alder\nElke Tukker"
  },
  {
    "objectID": "FW680A4/week16.html#week-16",
    "href": "FW680A4/week16.html#week-16",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Noel Clark\nLibby Mojica\nSean Ingram\nAlex Badeaux\n\n\n\n\n\n\n\n\n\n\n\nTravis Rainey\nBijoya Paul\nWaverly Davis\nLisa Roerk\nBecca Windell\nSarah Gaulke\nCat Adams\nJeremy Alder\nElke Tukker"
  },
  {
    "objectID": "FW680A4/week11.html",
    "href": "FW680A4/week11.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Readings for next class:\n\nBackground Reading (not required):\n\nNathan et al 2008 - Foundational bit of science\nNathan et al. 2022 - Big data science\nSigner et al 2018 - amt R package \nCalabrese et al. 2016 - ctmm R packageguide\nSilva et al. 2021 - autocorrelated kernel density (AKDE) home range review\nMcClintock et al. 2018 - momentuHMM R package\n\n\n\nBackground Videos (not required):\n\n\nMovement Ecology Théo Michelot. February 7, 2022; Code\n\nIntro. Animal Movement Ecology - Josh Cullen\n\n\n\nBackground Resources (not required):\n\nAnimove Resources\nContinuous-time movement modeling\n\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"amt\",\"tidygraph\",\"ctmm\",\"ggraph\"))\n\n\n\nReadings for next class:\n\n Smith et al. 2022.pdf\nNorthrup et al. 2022 (Intro through ‘How are selection functions fit?’)"
  },
  {
    "objectID": "FW680A4/week11.html#week-11",
    "href": "FW680A4/week11.html#week-11",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Readings for next class:\n\nBackground Reading (not required):\n\nNathan et al 2008 - Foundational bit of science\nNathan et al. 2022 - Big data science\nSigner et al 2018 - amt R package \nCalabrese et al. 2016 - ctmm R packageguide\nSilva et al. 2021 - autocorrelated kernel density (AKDE) home range review\nMcClintock et al. 2018 - momentuHMM R package\n\n\n\nBackground Videos (not required):\n\n\nMovement Ecology Théo Michelot. February 7, 2022; Code\n\nIntro. Animal Movement Ecology - Josh Cullen\n\n\n\nBackground Resources (not required):\n\nAnimove Resources\nContinuous-time movement modeling\n\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"amt\",\"tidygraph\",\"ctmm\",\"ggraph\"))\n\n\n\nReadings for next class:\n\n Smith et al. 2022.pdf\nNorthrup et al. 2022 (Intro through ‘How are selection functions fit?’)"
  },
  {
    "objectID": "publications/articles/Crockett2024.html",
    "href": "publications/articles/Crockett2024.html",
    "title": "Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines",
    "section": "",
    "text": "Crockett, J. G., C. Brown, and B. D. Gerber. 2024. Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines. Journal of Wildlife Management e22668. https://doi.org/10.1002/jwmg.22668"
  },
  {
    "objectID": "publications/articles/Crockett2024.html#citation",
    "href": "publications/articles/Crockett2024.html#citation",
    "title": "Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines",
    "section": "",
    "text": "Crockett, J. G., C. Brown, and B. D. Gerber. 2024. Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines. Journal of Wildlife Management e22668. https://doi.org/10.1002/jwmg.22668"
  },
  {
    "objectID": "publications/articles/Crockett2024.html#abstract",
    "href": "publications/articles/Crockett2024.html#abstract",
    "title": "Muskrat occurrence in Rhode Island shows little evidence of land use change driving declines",
    "section": "Abstract",
    "text": "Abstract\nMuskrat (Ondatra zibethicus) populations have been in apparent decline across their native range in North America for decades. Several hypotheses exist for the causes of these declines, including loss of wetlands. We used time-to-detection data from 925 surveys from 276 sites across Rhode Island, USA, between 2021–2023 to fit an occupancy model that related the probability of muskrat occupancy at a site to land cover classification. We found that muskrat occupancy was higher in areas with more open water, urban land cover, or a second-order or larger stream, and lower in areas with salt water. We estimated changes in wetland area throughout Rhode Island using the National Land Cover Database classifications from 2001 and 2019 and found a net loss in wetland cover of 219 ha. We calculated the distance between wetland patches in each of these periods and found that patches were closer together than the dispersal distance of muskrats, suggesting isolation is unlikely to be driving muskrat declines. Additionally, when we used our model to predict changes in muskrat occupancy between 2001 and 2019, both mean and median predicted occupancy changed by &lt;0.005. These results indicate that muskrat declines are not driven by habitat loss, and suggest future research is needed that focuses on other hypothesized mechanisms of muskrat declines such as disease, declining habitat quality, predation, and competition."
  },
  {
    "objectID": "publications/articles/Ganoe2024b.html",
    "href": "publications/articles/Ganoe2024b.html",
    "title": "Fisher activity patterns show potential for behavioral adaptations to human modified landscapes",
    "section": "",
    "text": "Ganoe, L.S., Mayer, A. E., Brown, C., and Gerber, B. D.. 2024. Fisher activity patterns show potential for behavioral adaptations to human modified landscapes. Global Ecology and Conservation e03225. https://doi.org/10.1016/j.gecco.2024.e03225"
  },
  {
    "objectID": "publications/articles/Ganoe2024b.html#citation",
    "href": "publications/articles/Ganoe2024b.html#citation",
    "title": "Fisher activity patterns show potential for behavioral adaptations to human modified landscapes",
    "section": "",
    "text": "Ganoe, L.S., Mayer, A. E., Brown, C., and Gerber, B. D.. 2024. Fisher activity patterns show potential for behavioral adaptations to human modified landscapes. Global Ecology and Conservation e03225. https://doi.org/10.1016/j.gecco.2024.e03225"
  },
  {
    "objectID": "publications/articles/Ganoe2024b.html#abstract",
    "href": "publications/articles/Ganoe2024b.html#abstract",
    "title": "Fisher activity patterns show potential for behavioral adaptations to human modified landscapes",
    "section": "Abstract",
    "text": "Abstract\nAnimals alter their diel activity in response to physiological constraints and ecological conditions. Fisher (Pekania pennanti) activity is known to vary through the diel cycle and change in response to cold stress and generally through both the climatic and biological seasons. However, less is known whether thermoregulatory effects impact fisher activity in milder climates and in areas of high human disturbance. We focused on two distinct research objectives to understand the 1) physiological constraints, and 2) ecological components of fisher activity in a highly disturbed landscape with a relatively mild climate. We used accelerometer data from 34 individual live-captured fisher in Rhode Island, USA from 2021 to 2023. We found that fisher activity patterns were primarily driven by diel cycle with higher activity levels at night than during the day. We did not observe any physiological influence of ambient temperature on fisher activity; daily minimum temperatures did not constrain fisher activity in the colder months, nor did daily maximum temperatures in warmer months. We did find that female activity levels differed by breeding status with non-pregnant females having higher activity levels than pregnant females. Considering ecological components, we found fisher decreased activity levels in higher road density areas during warmer months that coincide with higher traffic volumes. For fisher living in areas with lower road densities, we saw higher activity in the breeding season and summer than in winter. In contrast, fisher living in areas with high road densities had lower activity in the breeding season and summer than in winter. We conclude that fisher largely do not shift their activity to mitigate thermoregulatory costs in areas where temperatures do not reach extremes for extended periods of time. However, our findings suggest that behavioral shifts in activity are impacted by human disturbance and fisher minimize activity in risky areas."
  },
  {
    "objectID": "classfiles/movement/p1_getting_started.html",
    "href": "classfiles/movement/p1_getting_started.html",
    "title": "Getting started with amt\n",
    "section": "",
    "text": "The basic building blocks of amt are tracks. Tracks are tibbles with at least two columns that contain the coordinates: x_ and y_. A track behaves exactly like a tibble (the only difference being that we added an other S3 class). Below is an example of creating a track with some dummy locations.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(amt)\ndf1 &lt;- tibble(x = 1:3, y = 1:3)\nis.data.frame(df1)\n\n[1] TRUE\n\ndf1\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# Now we can create a track\ntr1 &lt;- make_track(df1, x, y)\nis.data.frame(tr1)\n\n[1] TRUE\n\ntr1\n\n# A tibble: 3 × 2\n     x_    y_\n* &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n\nAt the moment amt supports two types of tracks:\n\n\ntrack_xy is a track that only has coordinates, and\n\ntrack_xyt is a track that has a timestamp associated to each coordinate pair.\n\nIf a track_xy or track_xyt is created with the function make_track, is determined whether or not a timestamp is passed as a third argument (called .t) to the function make_track. In the previous example we only passed x and y coordinates. Hence a track_xy was created.\n\nclass(tr1)\n\n[1] \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTo create a track_xyt we could do the following\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2))\ntr2 &lt;- make_track(df1, x, y, t)\nclass(tr2)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nFrom the output above we see that a track_xyt is also a track_xy. This means that all methods for track_xy also work for a track_xyt (but not the reverse).\n\nWe can also add additional information for each relocation (e.g., the id of the animal, or some other sensor information such as the DOP). Any number of additional named columns can be passed to make_track. By named we mean, that columns should always be passed in the form of column_name = content to avoid confusion with coordinates and time stamp. We will extend the dummy example from above, by passing 2 more columns (the id of animal and the age).\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2), \n                  id = 1, age = 4)\n\n# first we only create a track_xy\ntr3 &lt;- make_track(df1, x, y, id = id, age = age)\ntr3\n\n# A tibble: 3 × 4\n     x_    y_    id   age\n* &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1     4\n2     2     2     1     4\n3     3     3     1     4\n\n# now lets create a track_xyt\ntr4 &lt;- make_track(df1, x, y, t, id = id, age = age)\ntr4\n\n# A tibble: 3 × 5\n     x_    y_ t_            id   age\n* &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1     1 2017-01-01     1     4\n2     2     2 2017-01-02     1     4\n3     3     3 2017-01-03     1     4\n\n\n\nmake_track has one further optional argument (crs), which allows the user to set a coordinate reference system (CRS) of the track. The CRS needs to be provided as valid EPSG code.\n\nIn the amt relocation data of one red deer from northern Germany is included. We will use this data set to to illustrate how to create a track.\nWe begin with loading and inspecting the data.\n\ndata(sh)\nhead(sh)\n\n  x_epsg31467 y_epsg31467        day     time\n1     3558403     5999400 2009-02-13 00:02:23\n2     3558548     5999099 2009-02-13 06:02:21\n3     3558541     5999019 2009-02-13 12:01:51\n4     3558453     5999026 2009-02-13 18:00:55\n5     3558566     5999365 2009-02-14 00:01:36\n6     3557836     5999185 2009-02-14 06:02:24\n\n\nBefore creating a track, we have to do some data cleaning:\n\ncheck if any coordinates are missing (and if so, remove the relocation),\nparse the date and time,\ncreate a time stamp,\ncheck for duplicated time stamps, and\ncreate two new columns for the id and month of the year.\n\n\n# check if all observations are complete\nall(complete.cases(sh)) # no action required\n\n[1] TRUE\n\n# parse date and time and create time stamps\nsh$ts &lt;- as.POSIXct(lubridate::ymd(sh$day) +\n                      lubridate::hms(sh$time))\n\n# check for duplicated time stamps\nany(duplicated(sh$ts))\n\n[1] TRUE\n\n# We have some duplicated time stamps, these need to be removed prior to\n# creating a track.\nsh &lt;- sh[!duplicated(sh$ts), ]\n\n# create new columns\nsh$id &lt;- \"Animal 1\"\nsh$month &lt;- lubridate::month(sh$ts)\n\nNow we can create a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month)\n\nThe column names of the data set already indicate the CRS of the data. We can add this information when creating a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month, \n                crs = 31467)\n\n\namt was heavily inspired through workflows suggested by the popular packages from the tidyverse. The above steps could easily be connected using pipes. Note that result will be exactly the same.\n\ndata(sh)\ntr2 &lt;- sh |&gt; filter(complete.cases(sh)) |&gt; \n  mutate(\n    ts = as.POSIXct(lubridate::ymd(day) + lubridate::hms(time)), \n    id = \"Animal 1\", \n    month = lubridate::month(ts)\n  ) |&gt; \n  filter(!duplicated(ts)) |&gt; \n  make_track(x_epsg31467, y_epsg31467, ts, id = id, month = month, \n           crs = 31467)\ntr2\n\n# A tibble: 1,493 × 5\n        x_      y_ t_                  id       month\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3\n 5 3558495 5999051 2008-03-30 18:25:56 Animal 1     3\n 6 3558493 5999052 2008-03-30 18:26:05 Animal 1     3\n 7 3558489 5999051 2008-03-30 18:26:14 Animal 1     3\n 8 3558486 5999046 2008-03-30 18:26:24 Animal 1     3\n 9 3558484 5999052 2008-03-30 18:26:33 Animal 1     3\n10 3558317 5998989 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows"
  },
  {
    "objectID": "classfiles/movement/p1_getting_started.html#basics",
    "href": "classfiles/movement/p1_getting_started.html#basics",
    "title": "Getting started with amt\n",
    "section": "",
    "text": "The basic building blocks of amt are tracks. Tracks are tibbles with at least two columns that contain the coordinates: x_ and y_. A track behaves exactly like a tibble (the only difference being that we added an other S3 class). Below is an example of creating a track with some dummy locations.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(amt)\ndf1 &lt;- tibble(x = 1:3, y = 1:3)\nis.data.frame(df1)\n\n[1] TRUE\n\ndf1\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# Now we can create a track\ntr1 &lt;- make_track(df1, x, y)\nis.data.frame(tr1)\n\n[1] TRUE\n\ntr1\n\n# A tibble: 3 × 2\n     x_    y_\n* &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n\nAt the moment amt supports two types of tracks:\n\n\ntrack_xy is a track that only has coordinates, and\n\ntrack_xyt is a track that has a timestamp associated to each coordinate pair.\n\nIf a track_xy or track_xyt is created with the function make_track, is determined whether or not a timestamp is passed as a third argument (called .t) to the function make_track. In the previous example we only passed x and y coordinates. Hence a track_xy was created.\n\nclass(tr1)\n\n[1] \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTo create a track_xyt we could do the following\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2))\ntr2 &lt;- make_track(df1, x, y, t)\nclass(tr2)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nFrom the output above we see that a track_xyt is also a track_xy. This means that all methods for track_xy also work for a track_xyt (but not the reverse).\n\nWe can also add additional information for each relocation (e.g., the id of the animal, or some other sensor information such as the DOP). Any number of additional named columns can be passed to make_track. By named we mean, that columns should always be passed in the form of column_name = content to avoid confusion with coordinates and time stamp. We will extend the dummy example from above, by passing 2 more columns (the id of animal and the age).\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2), \n                  id = 1, age = 4)\n\n# first we only create a track_xy\ntr3 &lt;- make_track(df1, x, y, id = id, age = age)\ntr3\n\n# A tibble: 3 × 4\n     x_    y_    id   age\n* &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1     4\n2     2     2     1     4\n3     3     3     1     4\n\n# now lets create a track_xyt\ntr4 &lt;- make_track(df1, x, y, t, id = id, age = age)\ntr4\n\n# A tibble: 3 × 5\n     x_    y_ t_            id   age\n* &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1     1 2017-01-01     1     4\n2     2     2 2017-01-02     1     4\n3     3     3 2017-01-03     1     4\n\n\n\nmake_track has one further optional argument (crs), which allows the user to set a coordinate reference system (CRS) of the track. The CRS needs to be provided as valid EPSG code.\n\nIn the amt relocation data of one red deer from northern Germany is included. We will use this data set to to illustrate how to create a track.\nWe begin with loading and inspecting the data.\n\ndata(sh)\nhead(sh)\n\n  x_epsg31467 y_epsg31467        day     time\n1     3558403     5999400 2009-02-13 00:02:23\n2     3558548     5999099 2009-02-13 06:02:21\n3     3558541     5999019 2009-02-13 12:01:51\n4     3558453     5999026 2009-02-13 18:00:55\n5     3558566     5999365 2009-02-14 00:01:36\n6     3557836     5999185 2009-02-14 06:02:24\n\n\nBefore creating a track, we have to do some data cleaning:\n\ncheck if any coordinates are missing (and if so, remove the relocation),\nparse the date and time,\ncreate a time stamp,\ncheck for duplicated time stamps, and\ncreate two new columns for the id and month of the year.\n\n\n# check if all observations are complete\nall(complete.cases(sh)) # no action required\n\n[1] TRUE\n\n# parse date and time and create time stamps\nsh$ts &lt;- as.POSIXct(lubridate::ymd(sh$day) +\n                      lubridate::hms(sh$time))\n\n# check for duplicated time stamps\nany(duplicated(sh$ts))\n\n[1] TRUE\n\n# We have some duplicated time stamps, these need to be removed prior to\n# creating a track.\nsh &lt;- sh[!duplicated(sh$ts), ]\n\n# create new columns\nsh$id &lt;- \"Animal 1\"\nsh$month &lt;- lubridate::month(sh$ts)\n\nNow we can create a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month)\n\nThe column names of the data set already indicate the CRS of the data. We can add this information when creating a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month, \n                crs = 31467)\n\n\namt was heavily inspired through workflows suggested by the popular packages from the tidyverse. The above steps could easily be connected using pipes. Note that result will be exactly the same.\n\ndata(sh)\ntr2 &lt;- sh |&gt; filter(complete.cases(sh)) |&gt; \n  mutate(\n    ts = as.POSIXct(lubridate::ymd(day) + lubridate::hms(time)), \n    id = \"Animal 1\", \n    month = lubridate::month(ts)\n  ) |&gt; \n  filter(!duplicated(ts)) |&gt; \n  make_track(x_epsg31467, y_epsg31467, ts, id = id, month = month, \n           crs = 31467)\ntr2\n\n# A tibble: 1,493 × 5\n        x_      y_ t_                  id       month\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3\n 5 3558495 5999051 2008-03-30 18:25:56 Animal 1     3\n 6 3558493 5999052 2008-03-30 18:26:05 Animal 1     3\n 7 3558489 5999051 2008-03-30 18:26:14 Animal 1     3\n 8 3558486 5999046 2008-03-30 18:26:24 Animal 1     3\n 9 3558484 5999052 2008-03-30 18:26:33 Animal 1     3\n10 3558317 5998989 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows"
  },
  {
    "objectID": "classfiles/movement/p1_getting_started.html#working-with-tracks",
    "href": "classfiles/movement/p1_getting_started.html#working-with-tracks",
    "title": "Getting started with amt\n",
    "section": "Working with tracks",
    "text": "Working with tracks\nUtility functions\nBasic manipulation\nRemember, that a track_xy* behaves like regular a data.frame. This means that we can use all data manipulation verbs that we are used to from base R or the tidyverse. For example, we can filter a track based on some characteristic. As an example we extract all relocations from the month May.\n\ntr3 &lt;- tr2 |&gt; filter(month == 5)\n\n# we are left with a track\nclass(tr3)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTransforming CRS\nIf we set the CRS when creating a track (we can verify this with has_crs), we can transform the CRS of the coordinates with the function transform_coords (a wrapper around sf::st_transform()). For illustration, we will transform the CRS of tr2 to geographical coordinates (EPSG:4326).\n\ntransform_coords(tr2, 4326)\n\n# A tibble: 1,493 × 5\n      x_    y_ t_                  id       month\n * &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1  9.89  54.1 2008-03-30 00:01:47 Animal 1     3\n 2  9.89  54.1 2008-03-30 06:00:54 Animal 1     3\n 3  9.89  54.1 2008-03-30 12:01:47 Animal 1     3\n 4  9.89  54.1 2008-03-30 18:01:24 Animal 1     3\n 5  9.89  54.1 2008-03-30 18:25:56 Animal 1     3\n 6  9.89  54.1 2008-03-30 18:26:05 Animal 1     3\n 7  9.89  54.1 2008-03-30 18:26:14 Animal 1     3\n 8  9.89  54.1 2008-03-30 18:26:24 Animal 1     3\n 9  9.89  54.1 2008-03-30 18:26:33 Animal 1     3\n10  9.89  54.1 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows\n\n\nSome initial data exploration\nSeveral functions for calculating derived quantities are available. We will start with looking at step length. The function step_lengths can be used for this.\n\ntr2 &lt;- tr2 |&gt; mutate(sl_ = step_lengths(tr2))\n\nIf we look at a summary of sl_ we note two things:\n\nsummary(tr2$sl_)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   35.01  105.33  249.07  297.75 4727.86       1 \n\n\nNote, 1) there is a NA for the last step length, this is expected because we are still in a point representation (i.e., there is no step length for the last relocation). 2) the range is fairly large ranging from 0 to almost 5 km. Before looking at step lengths in any further detail, we will have to make sure the sampling rate is more or less regular (i.e., the same time step between any two points).\nThe function summarize_sampling_rate provides an easy way to look at the sampling rate.\n\nsummarize_sampling_rate(tr2)\n\n# A tibble: 1 × 9\n     min    q1 median  mean    q3   max    sd     n unit \n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;\n1 0.0025  2.00   2.01  6.34  6.00 3924.  102.  1492 hour \n\n\nThis suggests that a sampling rate for 6 hours might be adequate. We can then use the function track_resample to resample the track and only keep relocations that are approximately 6 hours apart (within some tolerance, that can be specified). We will use the function lubridate::hours to specify the sampling rate and lubridate::minutes to specify the tolerance. Both arguments rate and tolerance are expected to be a Period.\n\ntr3 &lt;- tr2 |&gt; track_resample(rate = hours(6), tolerance = minutes(20))\ntr3\n\n# A tibble: 826 × 7\n        x_      y_ t_                  id       month    sl_ burst_\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3  41.8       1\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3 104.        1\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3  95.3       1\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3  22.8       1\n 5 3557474 5999130 2008-03-31 00:01:23 Animal 1     3 155.        1\n 6 3557319 5999127 2008-03-31 06:01:45 Animal 1     3   6.08      1\n 7 3557313 5999126 2008-03-31 12:01:11 Animal 1     3   4.47      1\n 8 3557317 5999128 2008-03-31 18:01:55 Animal 1     3 113.        1\n 9 3557204 5999130 2008-04-01 00:01:24 Animal 1     4 187.        1\n10 3557108 5999291 2008-04-01 06:00:54 Animal 1     4   6.32      1\n# ℹ 816 more rows\n\n\ntr3 still a track, but with two differences compared to tr2. 1) the number of rows is reduced from 1493 to 826, because only relocations that are 6 hours +/- the tolerance apart of each other are retained; 2) tr3 has one new column called burst_. A burst is sequence of relocations with equal sampling rates. Consider the following hypothetical example: 5 relocations are all 6 hours apart. Then there is a gap of 12 hours because one relocation failed and afterwards then there are an other 10 relocations all 6 hours apart. Then we would consider the first 5 relocations as a burst and the second 10 relocations (after the 12 hour gap) as a second burst.\nFrom tracks to steps\nIn many situations we are more interested in steps (that is the animal moving from one relocation to an other, or the straight line between a start and a end point), that in the individual relocations. amt supports steps as an other way to represent movement data. The transition from a track to steps can be done via two functions.\n\n\nsteps(): Takes as an input a track, converts the track to step and calculating some derived quantities (e.g., step lengths, turning angles). The function steps() expects a track with regular sampling rates.\n\nsteps_by_burst(): Takes as an input a resampled track (i.e., a track with several bursts) and will calculate derived quantities per burst."
  },
  {
    "objectID": "classfiles/movement/p1_getting_started.html#how-to-deal-with-several-animals",
    "href": "classfiles/movement/p1_getting_started.html#how-to-deal-with-several-animals",
    "title": "Getting started with amt\n",
    "section": "How to deal with several animals",
    "text": "How to deal with several animals\nUp to now we have only considered situations with one animal. However, in most telemetry studies more than one animal are tracked and we often want to calculated movement relevant characteristics for several animals individually. amt does not provide a infrastructure for dealing with several animal, however, list-columns from the tidyverse can be used to manage many animals. Because a track is just a tibble all tidyverse verbs can be used. The general strategy consists of three steps:\n\nNest a track by one or more columns. This retains the unique values of the grouping variable(s) and creates a new list-column with tracks.\nNow we can perform operations on the grouped data creating a new list column. This can be done in a combination with mutate and map (instead of map also lapply could be used).\nSelect the relevant columns and unnest. With select() we can select columns of interest and reverse the nesting with the function unnest().\n\nAs an example we will use a second data set included in amt on tracks of four fishers. We will load the data, create a track, resample the tracks individually to 30 min and create a histogram of step lengths (accounting for bursts).\nWe start by loading the data and creating a track of all individuals together\n\ndata(\"amt_fisher\")\ntrk &lt;- amt_fisher |&gt; make_track(x_, y_, t_, id = id)\n\nNext, we group the track by id and nest the track.\n\ntrk1 &lt;- trk |&gt; nest(data = -\"id\")\ntrk1\n\n# A tibble: 4 × 2\n  id    data                  \n  &lt;chr&gt; &lt;list&gt;                \n1 M1    &lt;trck_xyt [919 × 3]&gt;  \n2 M4    &lt;trck_xyt [8,958 × 3]&gt;\n3 F2    &lt;trck_xyt [3,004 × 3]&gt;\n4 F1    &lt;trck_xyt [1,349 × 3]&gt;\n\n\nWe now want to resample each track to 30 minutes with a tolerance of 5 minutes and create steps for each animal. For the first animal we would do as follows:\n\n# get the data for the first animal\nx &lt;- trk1$data[[1]]\n\n# apply the data analysis\nx |&gt; track_resample(rate = minutes(30), tolerance = minutes(5)) |&gt;\n  steps_by_burst()\n\n# A tibble: 412 × 11\n   burst_      x1_      x2_      y1_      y2_   sl_ direction_p   ta_\n *  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1      1 1782673. 1782683. 2402297. 2402292. 10.6       -0.427 NA   \n 2      1 1782683. 1782681. 2402292. 2402297.  4.96       2.08   2.51\n 3      1 1782681. 1782683. 2402297. 2402298.  2.19       0.464 -1.62\n 4      1 1782683. 1782682. 2402298. 2402290.  7.50      -1.68  -2.15\n 5      1 1782682. 1782684. 2402290. 2402298.  8.01       1.24   2.92\n 6      1 1782684. 1782685. 2402298. 2402274. 24.2       -1.54  -2.78\n 7      1 1782685. 1782669. 2402274. 2402309. 38.8        1.98  -2.76\n 8      1 1782669. 1782679. 2402309. 2402299. 13.6       -0.825 -2.80\n 9      1 1782679. 1782679. 2402299. 2402304.  5.26       1.52   2.34\n10      1 1782679. 1782699. 2402304. 2402273. 37.2       -1.00  -2.52\n# ℹ 402 more rows\n# ℹ 3 more variables: t1_ &lt;dttm&gt;, t2_ &lt;dttm&gt;, dt_ &lt;drtn&gt;\n\n\nWe now want to apply exactly the same logic to all animals. We can do this by using a map and save the results to a new column using mutate.\n\ntrk2 &lt;- trk1 |&gt; \n  mutate(steps = map(data, function(x) \n    x |&gt; track_resample(rate = minutes(30), tolerance = minutes(5)) |&gt; steps_by_burst()))\n\ntrk2\n\n# A tibble: 4 × 3\n  id    data                   steps                \n  &lt;chr&gt; &lt;list&gt;                 &lt;list&gt;               \n1 M1    &lt;trck_xyt [919 × 3]&gt;   &lt;brstd_s_ [412 × 11]&gt;\n2 M4    &lt;trck_xyt [8,958 × 3]&gt; &lt;brstd_s_ [850 × 11]&gt;\n3 F2    &lt;trck_xyt [3,004 × 3]&gt; &lt;brstd_s_ [308 × 11]&gt;\n4 F1    &lt;trck_xyt [1,349 × 3]&gt; &lt;brstd_s_ [413 × 11]&gt;\n\n\nFinally, we can select id and steps, unnest the new data_frame and create a plot of the step-length distributions.\n\ntrk2 |&gt; select(id, steps) |&gt; unnest(cols = steps) |&gt; \n  ggplot(aes(sl_, fill = factor(id))) + geom_density(alpha = 0.4)"
  },
  {
    "objectID": "classfiles/movement/p1_getting_started.html#session",
    "href": "classfiles/movement/p1_getting_started.html#session",
    "title": "Getting started with amt\n",
    "section": "Session",
    "text": "Session\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.1 (2024-06-14 ucrt)\n os       Windows 11 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       America/Denver\n date     2024-10-15\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package     * version date (UTC) lib source\n amt         * 0.2.2.0 2024-04-01 [1] CRAN (R 4.4.1)\n backports     1.5.0   2024-05-23 [1] CRAN (R 4.4.0)\n checkmate     2.3.1   2023-12-04 [1] CRAN (R 4.4.1)\n class         7.3-22  2023-05-03 [1] CRAN (R 4.4.1)\n classInt      0.4-10  2023-09-05 [1] CRAN (R 4.4.1)\n cli           3.6.2   2023-12-11 [1] CRAN (R 4.4.0)\n colorspace    2.1-0   2023-01-23 [1] CRAN (R 4.4.0)\n data.table    1.15.4  2024-03-30 [1] CRAN (R 4.4.0)\n DBI           1.2.3   2024-06-02 [1] CRAN (R 4.4.1)\n digest        0.6.36  2024-06-23 [1] CRAN (R 4.4.1)\n dplyr       * 1.1.4   2023-11-17 [1] CRAN (R 4.4.1)\n e1071         1.7-14  2023-12-06 [1] CRAN (R 4.4.1)\n evaluate      0.24.0  2024-06-10 [1] CRAN (R 4.4.1)\n fansi         1.0.6   2023-12-08 [1] CRAN (R 4.4.0)\n farver        2.1.2   2024-05-13 [1] CRAN (R 4.4.0)\n fastmap       1.2.0   2024-05-15 [1] CRAN (R 4.4.1)\n generics      0.1.3   2022-07-05 [1] CRAN (R 4.4.0)\n ggplot2     * 3.5.1   2024-04-23 [1] CRAN (R 4.4.0)\n glue          1.7.0   2024-01-09 [1] CRAN (R 4.4.0)\n gtable        0.3.5   2024-04-22 [1] CRAN (R 4.4.0)\n htmltools     0.5.8.1 2024-04-04 [1] CRAN (R 4.4.1)\n htmlwidgets   1.6.4   2023-12-06 [1] CRAN (R 4.4.1)\n jsonlite      1.8.8   2023-12-04 [1] CRAN (R 4.4.1)\n KernSmooth    2.23-24 2024-05-17 [1] CRAN (R 4.4.1)\n knitr         1.47    2024-05-29 [1] CRAN (R 4.4.1)\n labeling      0.4.3   2023-08-29 [1] CRAN (R 4.4.0)\n lattice       0.22-6  2024-03-20 [1] CRAN (R 4.4.1)\n lifecycle     1.0.4   2023-11-07 [1] CRAN (R 4.4.0)\n lubridate     1.9.3   2023-09-27 [1] CRAN (R 4.4.0)\n magrittr      2.0.3   2022-03-30 [1] CRAN (R 4.4.0)\n Matrix        1.7-0   2024-04-26 [1] CRAN (R 4.4.1)\n munsell       0.5.1   2024-04-01 [1] CRAN (R 4.4.0)\n pillar        1.9.0   2023-03-22 [1] CRAN (R 4.4.0)\n pkgconfig     2.0.3   2019-09-22 [1] CRAN (R 4.4.0)\n proxy         0.4-27  2022-06-09 [1] CRAN (R 4.4.1)\n purrr         1.0.2   2023-08-10 [1] CRAN (R 4.4.1)\n R6            2.5.1   2021-08-19 [1] CRAN (R 4.4.0)\n rbibutils     2.3     2024-10-04 [1] CRAN (R 4.4.1)\n Rcpp          1.0.12  2024-01-09 [1] CRAN (R 4.4.0)\n Rdpack        2.6.1   2024-08-06 [1] CRAN (R 4.4.1)\n rlang         1.1.4   2024-06-04 [1] CRAN (R 4.4.0)\n rmarkdown     2.27    2024-05-17 [1] CRAN (R 4.4.1)\n rstudioapi    0.16.0  2024-03-24 [1] CRAN (R 4.4.1)\n scales        1.3.0   2023-11-28 [1] CRAN (R 4.4.0)\n sessioninfo   1.2.2   2021-12-06 [1] CRAN (R 4.4.1)\n sf            1.0-16  2024-03-24 [1] CRAN (R 4.4.1)\n survival      3.6-4   2024-04-24 [1] CRAN (R 4.4.1)\n tibble        3.2.1   2023-03-20 [1] CRAN (R 4.4.0)\n tidyr         1.3.1   2024-01-24 [1] CRAN (R 4.4.1)\n tidyselect    1.2.1   2024-03-11 [1] CRAN (R 4.4.1)\n timechange    0.3.0   2024-01-18 [1] CRAN (R 4.4.0)\n units         0.8-5   2023-11-28 [1] CRAN (R 4.4.1)\n utf8          1.2.4   2023-10-22 [1] CRAN (R 4.4.0)\n vctrs         0.6.5   2023-12-01 [1] CRAN (R 4.4.0)\n withr         3.0.0   2024-01-16 [1] CRAN (R 4.4.0)\n xfun          0.45    2024-06-16 [1] CRAN (R 4.4.1)\n yaml          2.3.8   2023-12-11 [1] CRAN (R 4.4.0)\n\n [1] C:/Users/C825033651/AppData/Local/Programs/R/R-4.4.1/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html",
    "href": "classfiles/movement/amt_hr_overlap.html",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "",
    "text": "Several different indices have been proposed for measuring home-range overlap. These are reviewed by Fieberg & Kochanny (2005). There are two general approaches used to calculate home-range overlap: 1) calculate the percentage overlap at a given isopleth level (this works for geometric and probabilistic home ranges) or 2) calculate an index of similarity between the two utilization distributions (UD; this only works for probabilistic estimators)1.\n1 For a discussion of geometric vs. probabilistic estimators see here: https://www.biorxiv.org/content/10.1101/2020.08.19.256859v2"
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#background",
    "href": "classfiles/movement/amt_hr_overlap.html#background",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "",
    "text": "Several different indices have been proposed for measuring home-range overlap. These are reviewed by Fieberg & Kochanny (2005). There are two general approaches used to calculate home-range overlap: 1) calculate the percentage overlap at a given isopleth level (this works for geometric and probabilistic home ranges) or 2) calculate an index of similarity between the two utilization distributions (UD; this only works for probabilistic estimators)1.\n1 For a discussion of geometric vs. probabilistic estimators see here: https://www.biorxiv.org/content/10.1101/2020.08.19.256859v2"
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#implementation-in-amt",
    "href": "classfiles/movement/amt_hr_overlap.html#implementation-in-amt",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "Implementation in amt\n",
    "text": "Implementation in amt\n\namt currently implements all methods to calculate overlaps that were reviewed by Fieberg and Kochany (2005). These are:\n\n\nhr: That is the proportion of the home range of instance \\(i\\) that overlaps with the home range of instance \\(j\\). This measure does not rely on a UD and is directional (i.e., \\(HR_{i,j} \\ne HR_{j,i}\\)) and bound between 0 (no overlap) and 1 (complete overlap)\n\nphr: Is the probability of instance \\(j\\) being located in the home range of instance \\(i\\). phr is also directional and bounded between 0 (no overlap) and 1 (complete overlap)\n\nvi: The volumetric intersection between two UDs.\n\nba: The Bhattacharyya’s affinity between two UDs.\n\nudoi: A UD overlap index.\n\nhd: Hellinger’s distance between two UDs.\n\nThese overlap indices can be calculated with the function hr_overlap. The type of overlap measure an be controlled with the argument type.\nAll of these estimators can be calculated for a given home-range level (i.e., using conditional UDs). Whether or not a conditional overlap is desired or not, can be controlled with the argument conditional. For hr, the argument conditional has no effect and the isopleths used for home-range estimation will always be used for the overlap calculation.\nThe function hr_overlap() can also be provided with a list of home-range estimates in situations when overlap between many different instances are required. Currently, there are three options for calculating overlap among multiple instances: which = \"all\" calculates overlap for each pair of home ranges, which = \"one_to_all\" calculates overlap between the first element in the list and all others, and which = \"consecutive\" will calculate overlap between consecutive elements in the list."
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#examples",
    "href": "classfiles/movement/amt_hr_overlap.html#examples",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "Examples",
    "text": "Examples\nFirst we need to load the required packages:\n\nlibrary(amt)\nlibrary(ggplot2)\nlibrary(tidygraph)\nlibrary(ggraph)\n\nTwo instances\nWe will use tracking data from Fishers from New York State, USA.\n\nleroy &lt;- amt_fisher |&gt; filter(name == \"Leroy\")\nlupe &lt;- amt_fisher |&gt; filter(name == \"Lupe\")\n\nCreate a template raster for the KDE\n\ntrast &lt;- make_trast(amt_fisher |&gt; filter(name %in% c(\"Leroy\", \"Lupe\")), res = 50)\n\nAnd estimate home-ranges for both fishers\n\nhr_leroy &lt;- hr_kde(leroy, trast = trast, levels = c(0.5, 0.9))\nhr_lupe &lt;- hr_kde(lupe, trast = trast, levels = c(0.5, 0.9))\n\nhr and phr are directional, this means the order matters. For all other overlap measures the order does not matter.\n\nhr_overlap(hr_leroy, hr_lupe, type = \"hr\") \n\n# A tibble: 2 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1    0.9   0.309\n2    0.5   0.191\n\nhr_overlap(hr_lupe, hr_leroy, type = \"hr\")\n\n# A tibble: 2 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1    0.9   0.986\n2    0.5   0.574\n\n\nBy default conditional = FALSE and the full UD is used.\n\nhr_overlap(hr_leroy, hr_lupe, type = \"phr\", conditional = FALSE) \n\n# A tibble: 1 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1      1       1\n\nhr_overlap(hr_lupe, hr_leroy, type = \"phr\", conditional = FALSE)\n\n# A tibble: 1 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1      1   0.736\n\n\nIf we set conditional = TRUE, the overlap is measured at home-range levels that were specified during estimation.\n\nhr_overlap(hr_leroy, hr_lupe, type = \"phr\", conditional = TRUE) \n\n# A tibble: 2 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1    0.5   0.580\n2    0.9   0.992\n\nhr_overlap(hr_lupe, hr_leroy, type = \"phr\", conditional = TRUE)\n\n# A tibble: 2 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1    0.5   0.221\n2    0.9   0.401\n\n\nNote, for the remaining overlap measures the order does not matter. Below we show this for the volumnic intersection (type = \"vi\") as an example.\n\nhr_overlap(hr_lupe, hr_leroy, type = \"vi\", conditional = FALSE)\n\n# A tibble: 1 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1      1   0.439\n\nhr_overlap(hr_leroy, hr_lupe, type = \"vi\", conditional = FALSE)\n\n# A tibble: 1 × 2\n  levels overlap\n   &lt;dbl&gt;   &lt;dbl&gt;\n1      1   0.439\n\n\n\n\\(&gt; 2\\) instances\nLets calculate daily ranges for Lupe and then and then see how different ranges overlap with each other.\nWe have to use the same template raster in order to make ranges comparable.\n\ntrast &lt;- make_trast(lupe, res = 50)\n\nThen we add a new column with day and calculate for each day a KDE home range.\n\ndat &lt;- lupe |&gt; \n  mutate(week = lubridate::floor_date(t_, \"week\")) |&gt; \n  nest(data = -week) |&gt; \n  mutate(kde = map(data, hr_kde, trast = trast, levels = c(0.5, 0.95, 0.99)))\n\nNow we can use the list column with the home-range estimates to calculate overlap between the different home-ranges. By default which = \"consecutive\", this means for each list entry (= home-range estimate) the overlap to the next entry will be calculated.\n\nhr_overlap(dat$kde, type = \"vi\")\n\n# A tibble: 3 × 4\n   from    to levels overlap\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1     2      1  0.0431\n2     2     3      1  0.551 \n3     3     4      1  0.612 \n\n\nThis works as well, if we set conditional = TRUE:\n\nhr_overlap(dat$kde, type = \"vi\", conditional = TRUE)\n\n# A tibble: 9 × 4\n   from    to levels overlap\n  &lt;int&gt; &lt;int&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n1     1     2   0.5   0     \n2     1     2   0.95  0.0264\n3     1     2   0.99  0.0357\n4     2     3   0.5   0.264 \n5     2     3   0.95  0.528 \n6     2     3   0.99  0.547 \n7     3     4   0.5   0.318 \n8     3     4   0.95  0.592 \n9     3     4   0.99  0.608 \n\n\nSometimes it can be useful to provide meaningful labels. We can do this with the labels argument.\n\nhr_overlap(dat$kde, type = \"vi\", labels = dat$week)\n\n# A tibble: 3 × 4\n  from       to         levels overlap\n  &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt;\n1 2010-12-12 2010-12-19      1  0.0431\n2 2010-12-19 2010-12-26      1  0.551 \n3 2010-12-26 2011-01-02      1  0.612 \n\n\nDifferent options exist for the argument which. For example, which = \"one_to_all\" calculates the overlap between the first and all other home ranges."
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#overlap-between-a-home-range-and-a-simple-feature",
    "href": "classfiles/movement/amt_hr_overlap.html#overlap-between-a-home-range-and-a-simple-feature",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "Overlap between a home range and a simple feature",
    "text": "Overlap between a home range and a simple feature\nThe function hr_overlap_feature allows to calculate percentage overlap (\\(HR\\) index) between a home. To illustrate this feature, we will use again the data from lupe and calculate the intersection with an arbitrary polygon.\n\npoly &lt;- amt::bbox(lupe, buffer = -500, sf = TRUE)\npoly1 &lt;- amt::bbox(lupe, sf = TRUE)\nhr &lt;- hr_mcp(lupe)\nggplot() + geom_sf(data = hr_isopleths(hr)) + \n  geom_sf(data = poly, fill = NA, col = \"red\") +\n  geom_sf(data = poly1, fill = NA, col = \"blue\")\n\n\n\n\n\n\n\n\nhr_overlap_feature(hr, poly, direction = \"hr_with_feature\")\n\n# A tibble: 1 × 3\n   from    to overlap\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1  0.95     1   0.828\n\nhr_overlap_feature(hr, poly1, direction = \"hr_with_feature\")\n\n# A tibble: 1 × 3\n   from    to overlap\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1  0.95     1    1.00\n\nhr_overlap_feature(hr, poly, direction = \"feature_with_hr\")\n\n# A tibble: 1 × 3\n   from    to overlap\n  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     1  0.95   0.854\n\nhr_overlap_feature(hr, poly1, direction = \"feature_with_hr\")\n\n# A tibble: 1 × 3\n   from    to overlap\n  &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n1     1  0.95   0.542\n\n\nThe same work with several home-range levels:\n\nhr &lt;- hr_mcp(lupe, levels = c(0.5, 0.9, 0.95))\nhr_overlap_feature(hr, poly, direction = \"hr_with_feature\")\n\n# A tibble: 3 × 3\n   from    to overlap\n  &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;\n1  0.5      1   0.828\n2  0.9      1   0.860\n3  0.95     1   0.990"
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#references",
    "href": "classfiles/movement/amt_hr_overlap.html#references",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "References",
    "text": "References\n\nFieberg, J., & Kochanny, C. O. (2005). Quantifying home‐range overlap: the importance of the utilization distribution. The Journal of Wildlife Management, 69(4), 1346-1359."
  },
  {
    "objectID": "classfiles/movement/amt_hr_overlap.html#session",
    "href": "classfiles/movement/amt_hr_overlap.html#session",
    "title": "Calculating home-range overlaps with amt\n",
    "section": "Session",
    "text": "Session\n\nsessioninfo::session_info()\n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.4.1 (2024-06-14 ucrt)\n os       Windows 11 x64 (build 22631)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  English_United States.utf8\n ctype    English_United States.utf8\n tz       America/Denver\n date     2024-10-17\n pandoc   3.2 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package      * version  date (UTC) lib source\n amt          * 0.2.2.0  2024-04-01 [1] CRAN (R 4.4.1)\n backports      1.5.0    2024-05-23 [1] CRAN (R 4.4.0)\n cachem         1.1.0    2024-05-16 [1] CRAN (R 4.4.1)\n checkmate      2.3.1    2023-12-04 [1] CRAN (R 4.4.1)\n class          7.3-22   2023-05-03 [1] CRAN (R 4.4.1)\n classInt       0.4-10   2023-09-05 [1] CRAN (R 4.4.1)\n cli            3.6.2    2023-12-11 [1] CRAN (R 4.4.0)\n codetools      0.2-20   2024-03-31 [1] CRAN (R 4.4.1)\n colorspace     2.1-0    2023-01-23 [1] CRAN (R 4.4.0)\n DBI            1.2.3    2024-06-02 [1] CRAN (R 4.4.1)\n digest         0.6.36   2024-06-23 [1] CRAN (R 4.4.1)\n dplyr          1.1.4    2023-11-17 [1] CRAN (R 4.4.1)\n e1071          1.7-14   2023-12-06 [1] CRAN (R 4.4.1)\n evaluate       0.24.0   2024-06-10 [1] CRAN (R 4.4.1)\n fansi          1.0.6    2023-12-08 [1] CRAN (R 4.4.0)\n farver         2.1.2    2024-05-13 [1] CRAN (R 4.4.0)\n fastmap        1.2.0    2024-05-15 [1] CRAN (R 4.4.1)\n generics       0.1.3    2022-07-05 [1] CRAN (R 4.4.0)\n ggforce        0.4.2    2024-02-19 [1] CRAN (R 4.4.1)\n ggplot2      * 3.5.1    2024-04-23 [1] CRAN (R 4.4.0)\n ggraph       * 2.2.1    2024-03-07 [1] CRAN (R 4.4.1)\n ggrepel        0.9.5    2024-01-10 [1] CRAN (R 4.4.1)\n glue           1.7.0    2024-01-09 [1] CRAN (R 4.4.0)\n graphlayouts   1.2.0    2024-09-24 [1] CRAN (R 4.4.1)\n gridExtra      2.3      2017-09-09 [1] CRAN (R 4.4.0)\n gtable         0.3.5    2024-04-22 [1] CRAN (R 4.4.0)\n htmltools      0.5.8.1  2024-04-04 [1] CRAN (R 4.4.1)\n htmlwidgets    1.6.4    2023-12-06 [1] CRAN (R 4.4.1)\n igraph         2.0.3    2024-03-13 [1] CRAN (R 4.4.1)\n jsonlite       1.8.8    2023-12-04 [1] CRAN (R 4.4.1)\n KernSmooth     2.23-24  2024-05-17 [1] CRAN (R 4.4.1)\n knitr          1.47     2024-05-29 [1] CRAN (R 4.4.1)\n lattice        0.22-6   2024-03-20 [1] CRAN (R 4.4.1)\n lifecycle      1.0.4    2023-11-07 [1] CRAN (R 4.4.0)\n lubridate      1.9.3    2023-09-27 [1] CRAN (R 4.4.0)\n magrittr       2.0.3    2022-03-30 [1] CRAN (R 4.4.0)\n MASS           7.3-60.2 2024-04-26 [1] CRAN (R 4.4.1)\n Matrix         1.7-0    2024-04-26 [1] CRAN (R 4.4.1)\n memoise        2.0.1    2021-11-26 [1] CRAN (R 4.4.1)\n munsell        0.5.1    2024-04-01 [1] CRAN (R 4.4.0)\n pillar         1.9.0    2023-03-22 [1] CRAN (R 4.4.0)\n pkgconfig      2.0.3    2019-09-22 [1] CRAN (R 4.4.0)\n polyclip       1.10-6   2023-09-27 [1] CRAN (R 4.4.0)\n proxy          0.4-27   2022-06-09 [1] CRAN (R 4.4.1)\n purrr          1.0.2    2023-08-10 [1] CRAN (R 4.4.1)\n R6             2.5.1    2021-08-19 [1] CRAN (R 4.4.0)\n rbibutils      2.3      2024-10-04 [1] CRAN (R 4.4.1)\n Rcpp           1.0.12   2024-01-09 [1] CRAN (R 4.4.0)\n Rdpack         2.6.1    2024-08-06 [1] CRAN (R 4.4.1)\n rlang          1.1.4    2024-06-04 [1] CRAN (R 4.4.0)\n rmarkdown      2.27     2024-05-17 [1] CRAN (R 4.4.1)\n rstudioapi     0.16.0   2024-03-24 [1] CRAN (R 4.4.1)\n scales         1.3.0    2023-11-28 [1] CRAN (R 4.4.0)\n sessioninfo    1.2.2    2021-12-06 [1] CRAN (R 4.4.1)\n sf             1.0-16   2024-03-24 [1] CRAN (R 4.4.1)\n survival       3.6-4    2024-04-24 [1] CRAN (R 4.4.1)\n terra          1.7-78   2024-05-22 [1] CRAN (R 4.4.0)\n tibble         3.2.1    2023-03-20 [1] CRAN (R 4.4.0)\n tidygraph    * 1.3.1    2024-01-30 [1] CRAN (R 4.4.1)\n tidyr          1.3.1    2024-01-24 [1] CRAN (R 4.4.1)\n tidyselect     1.2.1    2024-03-11 [1] CRAN (R 4.4.1)\n timechange     0.3.0    2024-01-18 [1] CRAN (R 4.4.0)\n tweenr         2.0.3    2024-02-26 [1] CRAN (R 4.4.1)\n units          0.8-5    2023-11-28 [1] CRAN (R 4.4.1)\n utf8           1.2.4    2023-10-22 [1] CRAN (R 4.4.0)\n vctrs          0.6.5    2023-12-01 [1] CRAN (R 4.4.0)\n viridis        0.6.5    2024-01-29 [1] CRAN (R 4.4.0)\n viridisLite    0.4.2    2023-05-02 [1] CRAN (R 4.4.0)\n withr          3.0.0    2024-01-16 [1] CRAN (R 4.4.0)\n xfun           0.45     2024-06-16 [1] CRAN (R 4.4.1)\n yaml           2.3.8    2023-12-11 [1] CRAN (R 4.4.0)\n\n [1] C:/Users/C825033651/AppData/Local/Programs/R/R-4.4.1/library\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "classfiles/movement/amt_getting_started.html",
    "href": "classfiles/movement/amt_getting_started.html",
    "title": "Getting started with amt\n",
    "section": "",
    "text": "The basic building blocks of amt are tracks. Tracks are tibbles with at least two columns that contain the coordinates: x_ and y_. A track behaves exactly like a tibble (the only difference being that we added an other S3 class). Below is an example of creating a track with some dummy locations.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(amt)\ndf1 &lt;- tibble(x = 1:3, y = 1:3)\nis.data.frame(df1)\n\n[1] TRUE\n\ndf1\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# Now we can create a track\ntr1 &lt;- make_track(df1, x, y)\nis.data.frame(tr1)\n\n[1] TRUE\n\ntr1\n\n# A tibble: 3 × 2\n     x_    y_\n* &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n\nAt the moment amt supports two types of tracks:\n\n\ntrack_xy is a track that only has coordinates, and\n\ntrack_xyt is a track that has a timestamp associated to each coordinate pair.\n\nIf a track_xy or track_xyt is created with the function make_track, is determined whether or not a timestamp is passed as a third argument (called .t) to the function make_track. In the previous example we only passed x and y coordinates. Hence a track_xy was created.\n\nclass(tr1)\n\n[1] \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTo create a track_xyt we could do the following\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2))\ntr2 &lt;- make_track(df1, x, y, t)\nclass(tr2)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nFrom the output above we see that a track_xyt is also a track_xy. This means that all methods for track_xy also work for a track_xyt (but not the reverse).\n\nWe can also add additional information for each relocation (e.g., the id of the animal, or some other sensor information such as the DOP). Any number of additional named columns can be passed to make_track. By named we mean, that columns should always be passed in the form of column_name = content to avoid confusion with coordinates and time stamp. We will extend the dummy example from above, by passing 2 more columns (the id of animal and the age).\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2), \n                  id = 1, age = 4)\n\n# first we only create a track_xy\ntr3 &lt;- make_track(df1, x, y, id = id, age = age)\ntr3\n\n# A tibble: 3 × 4\n     x_    y_    id   age\n* &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1     4\n2     2     2     1     4\n3     3     3     1     4\n\n# now lets create a track_xyt\ntr4 &lt;- make_track(df1, x, y, t, id = id, age = age)\ntr4\n\n# A tibble: 3 × 5\n     x_    y_ t_            id   age\n* &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1     1 2017-01-01     1     4\n2     2     2 2017-01-02     1     4\n3     3     3 2017-01-03     1     4\n\n\n\nmake_track has one further optional argument (crs), which allows the user to set a coordinate reference system (CRS) of the track. The CRS needs to be provided as valid EPSG code.\n\nIn the amt relocation data of one red deer from northern Germany is included. We will use this data set to to illustrate how to create a track.\nWe begin with loading and inspecting the data.\n\ndata(sh)\nhead(sh)\n\n  x_epsg31467 y_epsg31467        day     time\n1     3558403     5999400 2009-02-13 00:02:23\n2     3558548     5999099 2009-02-13 06:02:21\n3     3558541     5999019 2009-02-13 12:01:51\n4     3558453     5999026 2009-02-13 18:00:55\n5     3558566     5999365 2009-02-14 00:01:36\n6     3557836     5999185 2009-02-14 06:02:24\n\n\nBefore creating a track, we have to do some data cleaning:\n\ncheck if any coordinates are missing (and if so, remove the relocation),\nparse the date and time,\ncreate a time stamp,\ncheck for duplicated time stamps, and\ncreate two new columns for the id and month of the year.\n\n\n# check if all observations are complete\nall(complete.cases(sh)) # no action required\n\n[1] TRUE\n\n# parse date and time and create time stamps\nsh$ts &lt;- as.POSIXct(lubridate::ymd(sh$day) +\n                      lubridate::hms(sh$time))\n\n# check for duplicated time stamps\nany(duplicated(sh$ts))\n\n[1] TRUE\n\n# We have some duplicated time stamps, these need to be removed prior to\n# creating a track.\nsh &lt;- sh[!duplicated(sh$ts), ]\n\n# create new columns\nsh$id &lt;- \"Animal 1\"\nsh$month &lt;- lubridate::month(sh$ts)\n\nNow we can create a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month)\n\nThe column names of the data set already indicate the CRS of the data. We can add this information when creating a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month, \n                crs = 31467)\n\n\namt was heavily inspired through workflows suggested by the popular packages from the tidyverse. The above steps could easily be connected using pipes. Note that result will be exactly the same.\n\ndata(sh)\ntr2 &lt;- sh |&gt; filter(complete.cases(sh)) |&gt; \n  mutate(\n    ts = as.POSIXct(lubridate::ymd(day) + lubridate::hms(time)), \n    id = \"Animal 1\", \n    month = lubridate::month(ts)\n  ) |&gt; \n  filter(!duplicated(ts)) |&gt; \n  make_track(x_epsg31467, y_epsg31467, ts, id = id, month = month, \n           crs = 31467)\ntr2\n\n# A tibble: 1,493 × 5\n        x_      y_ t_                  id       month\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3\n 5 3558495 5999051 2008-03-30 18:25:56 Animal 1     3\n 6 3558493 5999052 2008-03-30 18:26:05 Animal 1     3\n 7 3558489 5999051 2008-03-30 18:26:14 Animal 1     3\n 8 3558486 5999046 2008-03-30 18:26:24 Animal 1     3\n 9 3558484 5999052 2008-03-30 18:26:33 Animal 1     3\n10 3558317 5998989 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows"
  },
  {
    "objectID": "classfiles/movement/amt_getting_started.html#basics",
    "href": "classfiles/movement/amt_getting_started.html#basics",
    "title": "Getting started with amt\n",
    "section": "",
    "text": "The basic building blocks of amt are tracks. Tracks are tibbles with at least two columns that contain the coordinates: x_ and y_. A track behaves exactly like a tibble (the only difference being that we added an other S3 class). Below is an example of creating a track with some dummy locations.\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(amt)\ndf1 &lt;- tibble(x = 1:3, y = 1:3)\nis.data.frame(df1)\n\n[1] TRUE\n\ndf1\n\n# A tibble: 3 × 2\n      x     y\n  &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n# Now we can create a track\ntr1 &lt;- make_track(df1, x, y)\nis.data.frame(tr1)\n\n[1] TRUE\n\ntr1\n\n# A tibble: 3 × 2\n     x_    y_\n* &lt;int&gt; &lt;int&gt;\n1     1     1\n2     2     2\n3     3     3\n\n\nAt the moment amt supports two types of tracks:\n\n\ntrack_xy is a track that only has coordinates, and\n\ntrack_xyt is a track that has a timestamp associated to each coordinate pair.\n\nIf a track_xy or track_xyt is created with the function make_track, is determined whether or not a timestamp is passed as a third argument (called .t) to the function make_track. In the previous example we only passed x and y coordinates. Hence a track_xy was created.\n\nclass(tr1)\n\n[1] \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTo create a track_xyt we could do the following\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2))\ntr2 &lt;- make_track(df1, x, y, t)\nclass(tr2)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nFrom the output above we see that a track_xyt is also a track_xy. This means that all methods for track_xy also work for a track_xyt (but not the reverse).\n\nWe can also add additional information for each relocation (e.g., the id of the animal, or some other sensor information such as the DOP). Any number of additional named columns can be passed to make_track. By named we mean, that columns should always be passed in the form of column_name = content to avoid confusion with coordinates and time stamp. We will extend the dummy example from above, by passing 2 more columns (the id of animal and the age).\n\ndf1 &lt;- tibble(x = 1:3, y = 1:3, t = lubridate::ymd(\"2017-01-01\") + lubridate::days(0:2), \n                  id = 1, age = 4)\n\n# first we only create a track_xy\ntr3 &lt;- make_track(df1, x, y, id = id, age = age)\ntr3\n\n# A tibble: 3 × 4\n     x_    y_    id   age\n* &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1     1     4\n2     2     2     1     4\n3     3     3     1     4\n\n# now lets create a track_xyt\ntr4 &lt;- make_track(df1, x, y, t, id = id, age = age)\ntr4\n\n# A tibble: 3 × 5\n     x_    y_ t_            id   age\n* &lt;int&gt; &lt;int&gt; &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1     1 2017-01-01     1     4\n2     2     2 2017-01-02     1     4\n3     3     3 2017-01-03     1     4\n\n\n\nmake_track has one further optional argument (crs), which allows the user to set a coordinate reference system (CRS) of the track. The CRS needs to be provided as valid EPSG code.\n\nIn the amt relocation data of one red deer from northern Germany is included. We will use this data set to to illustrate how to create a track.\nWe begin with loading and inspecting the data.\n\ndata(sh)\nhead(sh)\n\n  x_epsg31467 y_epsg31467        day     time\n1     3558403     5999400 2009-02-13 00:02:23\n2     3558548     5999099 2009-02-13 06:02:21\n3     3558541     5999019 2009-02-13 12:01:51\n4     3558453     5999026 2009-02-13 18:00:55\n5     3558566     5999365 2009-02-14 00:01:36\n6     3557836     5999185 2009-02-14 06:02:24\n\n\nBefore creating a track, we have to do some data cleaning:\n\ncheck if any coordinates are missing (and if so, remove the relocation),\nparse the date and time,\ncreate a time stamp,\ncheck for duplicated time stamps, and\ncreate two new columns for the id and month of the year.\n\n\n# check if all observations are complete\nall(complete.cases(sh)) # no action required\n\n[1] TRUE\n\n# parse date and time and create time stamps\nsh$ts &lt;- as.POSIXct(lubridate::ymd(sh$day) +\n                      lubridate::hms(sh$time))\n\n# check for duplicated time stamps\nany(duplicated(sh$ts))\n\n[1] TRUE\n\n# We have some duplicated time stamps, these need to be removed prior to\n# creating a track.\nsh &lt;- sh[!duplicated(sh$ts), ]\n\n# create new columns\nsh$id &lt;- \"Animal 1\"\nsh$month &lt;- lubridate::month(sh$ts)\n\nNow we can create a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month)\n\nThe column names of the data set already indicate the CRS of the data. We can add this information when creating a track.\n\ntr1 &lt;- make_track(sh, x_epsg31467, y_epsg31467, ts, id = id, month = month, \n                crs = 31467)\n\n\namt was heavily inspired through workflows suggested by the popular packages from the tidyverse. The above steps could easily be connected using pipes. Note that result will be exactly the same.\n\ndata(sh)\ntr2 &lt;- sh |&gt; filter(complete.cases(sh)) |&gt; \n  mutate(\n    ts = as.POSIXct(lubridate::ymd(day) + lubridate::hms(time)), \n    id = \"Animal 1\", \n    month = lubridate::month(ts)\n  ) |&gt; \n  filter(!duplicated(ts)) |&gt; \n  make_track(x_epsg31467, y_epsg31467, ts, id = id, month = month, \n           crs = 31467)\ntr2\n\n# A tibble: 1,493 × 5\n        x_      y_ t_                  id       month\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3\n 5 3558495 5999051 2008-03-30 18:25:56 Animal 1     3\n 6 3558493 5999052 2008-03-30 18:26:05 Animal 1     3\n 7 3558489 5999051 2008-03-30 18:26:14 Animal 1     3\n 8 3558486 5999046 2008-03-30 18:26:24 Animal 1     3\n 9 3558484 5999052 2008-03-30 18:26:33 Animal 1     3\n10 3558317 5998989 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows"
  },
  {
    "objectID": "classfiles/movement/amt_getting_started.html#working-with-tracks",
    "href": "classfiles/movement/amt_getting_started.html#working-with-tracks",
    "title": "Getting started with amt\n",
    "section": "Working with tracks",
    "text": "Working with tracks\nUtility functions\nBasic manipulation\nRemember, that a track_xy* behaves like regular a data.frame. This means that we can use all data manipulation verbs that we are used to from base R or the tidyverse. For example, we can filter a track based on some characteristic. As an example we extract all relocations from the month May.\n\ntr3 &lt;- tr2 |&gt; filter(month == 5)\n\n# we are left with a track\nclass(tr3)\n\n[1] \"track_xyt\"  \"track_xy\"   \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\nTransforming CRS\nIf we set the CRS when creating a track (we can verify this with has_crs), we can transform the CRS of the coordinates with the function transform_coords (a wrapper around sf::st_transform()). For illustration, we will transform the CRS of tr2 to geographical coordinates (EPSG:4326).\n\ntransform_coords(tr2, 4326)\n\n# A tibble: 1,493 × 5\n      x_    y_ t_                  id       month\n * &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;\n 1  9.89  54.1 2008-03-30 00:01:47 Animal 1     3\n 2  9.89  54.1 2008-03-30 06:00:54 Animal 1     3\n 3  9.89  54.1 2008-03-30 12:01:47 Animal 1     3\n 4  9.89  54.1 2008-03-30 18:01:24 Animal 1     3\n 5  9.89  54.1 2008-03-30 18:25:56 Animal 1     3\n 6  9.89  54.1 2008-03-30 18:26:05 Animal 1     3\n 7  9.89  54.1 2008-03-30 18:26:14 Animal 1     3\n 8  9.89  54.1 2008-03-30 18:26:24 Animal 1     3\n 9  9.89  54.1 2008-03-30 18:26:33 Animal 1     3\n10  9.89  54.1 2008-03-30 18:38:01 Animal 1     3\n# ℹ 1,483 more rows\n\n\nSome initial data exploration\nSeveral functions for calculating derived quantities are available. We will start with looking at step length. The function step_lengths can be used for this.\n\ntr2 &lt;- tr2 |&gt; mutate(sl_ = step_lengths(tr2),ta_=direction_rel(tr2,zero_dir = \"N\"))\n\nIf we look at a summary of sl_ we note two things:\n\nsummary(tr2$sl_)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n   0.00   35.01  105.33  249.07  297.75 4727.86       1 \n\nhist(tr2$sl_,main=\"Step Lengths\")\n\n\n\n\n\n\n\nNote, 1) there is a NA for the last step length, this is expected because we are still in a point representation (i.e., there is no step length for the last relocation). 2) the range is fairly large ranging from 0 to almost 5 km. Before looking at step lengths in any further detail, we will have to make sure the sampling rate is more or less regular (i.e., the same time step between any two points).\nLet’s also look at the distrubtion of turning angles.\n\nsummary(tr2$ta_)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n-3.13682 -1.60461 -0.10206 -0.06197  1.47769  3.14042        4 \n\nhist(tr2$ta_,main=\"Turning Angles\")\n\n\n\n\n\n\n\nThe function summarize_sampling_rate provides an easy way to look at the sampling rate.\n\nsummarize_sampling_rate(tr2)\n\n# A tibble: 1 × 9\n     min    q1 median  mean    q3   max    sd     n unit \n   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;\n1 0.0025  2.00   2.01  6.34  6.00 3924.  102.  1492 hour \n\n\nThis suggests that a sampling rate for 6 hours might be adequate. We can then use the function track_resample to resample the track and only keep relocations that are approximately 6 hours apart (within some tolerance, that can be specified). We will use the function lubridate::hours to specify the sampling rate and lubridate::minutes to specify the tolerance. Both arguments rate and tolerance are expected to be a Period.\n\ntr3 &lt;- tr2 |&gt; track_resample(rate = hours(6), tolerance = minutes(20))\ntr3\n\n# A tibble: 826 × 8\n        x_      y_ t_                  id       month    sl_    ta_ burst_\n *   &lt;int&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 3558528 5999094 2008-03-30 00:01:47 Animal 1     3  41.8  NA          1\n 2 3558513 5999055 2008-03-30 06:00:54 Animal 1     3 104.    3.00       1\n 3 3558564 5999146 2008-03-30 12:01:47 Animal 1     3  95.3   2.97       1\n 4 3558504 5999072 2008-03-30 18:01:24 Animal 1     3  22.8   0.276      1\n 5 3557474 5999130 2008-03-31 00:01:23 Animal 1     3 155.    0.189      1\n 6 3557319 5999127 2008-03-31 06:01:45 Animal 1     3   6.08  0.146      1\n 7 3557313 5999126 2008-03-31 12:01:11 Animal 1     3   4.47 -2.84       1\n 8 3557317 5999128 2008-03-31 18:01:55 Animal 1     3 113.    2.66       1\n 9 3557204 5999130 2008-04-01 00:01:24 Animal 1     4 187.   -1.02       1\n10 3557108 5999291 2008-04-01 06:00:54 Animal 1     4   6.32 -0.216      1\n# ℹ 816 more rows\n\n\ntr3 still a track, but with two differences compared to tr2. 1) the number of rows is reduced from 1493 to 826, because only relocations that are 6 hours +/- the tolerance apart of each other are retained; 2) tr3 has one new column called burst_. A burst is sequence of relocations with equal sampling rates. Consider the following hypothetical example: 5 relocations are all 6 hours apart. Then there is a gap of 12 hours because one relocation failed and afterwards then there are an other 10 relocations all 6 hours apart. Then we would consider the first 5 relocations as a burst and the second 10 relocations (after the 12 hour gap) as a second burst.\nFrom tracks to steps\nIn many situations we are more interested in steps (that is the animal moving from one relocation to an other, or the straight line between a start and a end point), than in the individual relocations. amt supports steps as an other way to represent movement data. The transition from a track to steps can be done via two functions.\n\n\nsteps(): Takes as an input a track, converts the track to step and calculating some derived quantities (e.g., step lengths, turning angles). The function steps() expects a track with regular sampling rates.\n\nsteps_by_burst(): Takes as an input a resampled track (i.e., a track with several bursts) and will calculate derived quantities per burst."
  },
  {
    "objectID": "classfiles/movement/amt_getting_started.html#how-to-deal-with-several-animals",
    "href": "classfiles/movement/amt_getting_started.html#how-to-deal-with-several-animals",
    "title": "Getting started with amt\n",
    "section": "How to deal with several animals",
    "text": "How to deal with several animals\nUp to now we have only considered situations with one animal. However, in most telemetry studies more than one animal are tracked and we often want to calculated movement relevant characteristics for several animals individually. amt does not provide a infrastructure for dealing with several animal, however, list-columns from the tidyverse can be used to manage many animals. Because a track is just a tibble all tidyverse verbs can be used. The general strategy consists of three steps:\n\nNest a track by one or more columns. This retains the unique values of the grouping variable(s) and creates a new list-column with tracks.\nNow we can perform operations on the grouped data creating a new list column. This can be done in a combination with mutate and map (instead of map also lapply could be used).\nSelect the relevant columns and unnest. With select() we can select columns of interest and reverse the nesting with the function unnest().\n\nAs an example we will use a second data set included in amt on tracks of four fishers. We will load the data, create a track, resample the tracks individually to 30 min and create a histogram of step lengths (accounting for bursts).\nWe start by loading the data and creating a track of all individuals together\n\ndata(\"amt_fisher\")\ntrk &lt;- amt_fisher |&gt; make_track(x_, y_, t_, id = id,crs=4326)\n\nNext, we group the track by id and nest the track.\n\ntrk1 &lt;- trk |&gt; nest(data = -\"id\")\ntrk1\n\n# A tibble: 4 × 2\n  id    data                  \n  &lt;chr&gt; &lt;list&gt;                \n1 M1    &lt;trck_xyt [919 × 3]&gt;  \n2 M4    &lt;trck_xyt [8,958 × 3]&gt;\n3 F2    &lt;trck_xyt [3,004 × 3]&gt;\n4 F1    &lt;trck_xyt [1,349 × 3]&gt;\n\n\nWe now want to resample each track to 30 minutes with a tolerance of 5 minutes and create steps for each animal. For the first animal we would do as follows:\n\n# get the data for the first animal\nx &lt;- trk1$data[[1]]\n\n# apply the data analysis\nx |&gt; track_resample(rate = minutes(30), tolerance = minutes(5)) |&gt;\n  steps_by_burst()\n\n# A tibble: 412 × 11\n   burst_      x1_      x2_      y1_      y2_   sl_ direction_p   ta_\n *  &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1      1 1782673. 1782683. 2402297. 2402292. 10.6       -0.427 NA   \n 2      1 1782683. 1782681. 2402292. 2402297.  4.96       2.08   2.51\n 3      1 1782681. 1782683. 2402297. 2402298.  2.19       0.464 -1.62\n 4      1 1782683. 1782682. 2402298. 2402290.  7.50      -1.68  -2.15\n 5      1 1782682. 1782684. 2402290. 2402298.  8.01       1.24   2.92\n 6      1 1782684. 1782685. 2402298. 2402274. 24.2       -1.54  -2.78\n 7      1 1782685. 1782669. 2402274. 2402309. 38.8        1.98  -2.76\n 8      1 1782669. 1782679. 2402309. 2402299. 13.6       -0.825 -2.80\n 9      1 1782679. 1782679. 2402299. 2402304.  5.26       1.52   2.34\n10      1 1782679. 1782699. 2402304. 2402273. 37.2       -1.00  -2.52\n# ℹ 402 more rows\n# ℹ 3 more variables: t1_ &lt;dttm&gt;, t2_ &lt;dttm&gt;, dt_ &lt;drtn&gt;\n\n\nWe now want to apply exactly the same logic to all animals. We can do this by using a map and save the results to a new column using mutate.\n\ntrk2 &lt;- trk1 |&gt; \n  mutate(steps = map(data, function(x) \n    x |&gt; track_resample(rate = minutes(30), tolerance = minutes(5)) |&gt; steps_by_burst()))\n\ntrk3=trk2\n\nFinally, we can select id and steps, unnest the new data_frame and create a plot of the step-length distributions.\n\ntrk2 |&gt; select(id, steps) |&gt; unnest(cols = steps) |&gt; \n  ggplot(aes(sl_, fill = factor(id))) + geom_density(alpha = 0.4)"
  },
  {
    "objectID": "FW680A4/week12.html",
    "href": "FW680A4/week12.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Readings for next class:\n\nA plain language review for modeling animal habitat-selection (draft) \n\n\n\nThe assigned reading is a draft manuscript that I am looking for feedback. Please feel free to make comments directly on the google doc. I am looking for areas of confusion, areas of flow or introduction of concepts that may be out of order, and areas that we can cut/de-emphasize, and areas that need expanding. This manuscript is not so much a review, but a modern synthesis to give some important context/opinion and then point the reader to modern papers.\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"terra\",\"raster\",\"amt\",\"MASS\"))\n\n\n\nWright et al 2020"
  },
  {
    "objectID": "FW680A4/week12.html#week-12",
    "href": "FW680A4/week12.html#week-12",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Readings for next class:\n\nA plain language review for modeling animal habitat-selection (draft) \n\n\n\nThe assigned reading is a draft manuscript that I am looking for feedback. Please feel free to make comments directly on the google doc. I am looking for areas of confusion, areas of flow or introduction of concepts that may be out of order, and areas that we can cut/de-emphasize, and areas that need expanding. This manuscript is not so much a review, but a modern synthesis to give some important context/opinion and then point the reader to modern papers.\n\n\n\n\nDownloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"terra\",\"raster\",\"amt\",\"MASS\"))\n\n\n\nWright et al 2020"
  },
  {
    "objectID": "FW680A4/week13.html",
    "href": "FW680A4/week13.html",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Statistcal Model\nBayesian Community Occupancy Model via Stan\nFor details, see the books Applied Hierarchical Modeling in Ecology, Chapter 11 and Hierarchical Modeling and Inference in Ecology, Chapter 12.\n\n\n\n\n\nSpecies Richness vs Species Diversity?\nThe vegan R package has a number of common community metrics.\n\n\n\n\n\n\n\n\n\n\nNo class or lab assignment today due to the issues with coming to campus today (11/15) and generally to reduce overall workload and provide more time for you to focus on your class project."
  },
  {
    "objectID": "FW680A4/week13.html#week-14",
    "href": "FW680A4/week13.html#week-14",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Downloads: Files\nInstall R packages:\n\n\n# CRAN packages\ninstall.packages(c(\"\"))"
  },
  {
    "objectID": "FW680A4/week13.html#week-13",
    "href": "FW680A4/week13.html#week-13",
    "title": "Brian D. Gerber",
    "section": "",
    "text": "Statistcal Model\nBayesian Community Occupancy Model via Stan\nFor details, see the books Applied Hierarchical Modeling in Ecology, Chapter 11 and Hierarchical Modeling and Inference in Ecology, Chapter 12.\n\n\n\n\n\nSpecies Richness vs Species Diversity?\nThe vegan R package has a number of common community metrics.\n\n\n\n\n\n\n\n\n\n\nNo class or lab assignment today due to the issues with coming to campus today (11/15) and generally to reduce overall workload and provide more time for you to focus on your class project."
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html",
    "href": "classfiles/habsel/amt.vignette.habsel.html",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "",
    "text": "This vignette briefly introduces how one can fit a Resource-Selection Function (RSF) with the amt package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map."
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#about",
    "href": "classfiles/habsel/amt.vignette.habsel.html#about",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "",
    "text": "This vignette briefly introduces how one can fit a Resource-Selection Function (RSF) with the amt package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map."
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#getting-the-data-ready",
    "href": "classfiles/habsel/amt.vignette.habsel.html#getting-the-data-ready",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "Getting the data ready",
    "text": "Getting the data ready\nFirst we load the required libraries and the relocation data (called deer)\n\nlibrary(amt)\nlibrary(terra)\ndata(\"deer\")\ndeer\n\n# A tibble: 826 × 4\n         x_       y_ t_                  burst_\n *    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;               &lt;dbl&gt;\n 1 4314068. 3445807. 2008-03-30 00:01:47      1\n 2 4314053. 3445768. 2008-03-30 06:00:54      1\n 3 4314105. 3445859. 2008-03-30 12:01:47      1\n 4 4314044. 3445785. 2008-03-30 18:01:24      1\n 5 4313015. 3445858. 2008-03-31 00:01:23      1\n 6 4312860. 3445857. 2008-03-31 06:01:45      1\n 7 4312854. 3445856. 2008-03-31 12:01:11      1\n 8 4312858. 3445858. 2008-03-31 18:01:55      1\n 9 4312745. 3445862. 2008-04-01 00:01:24      1\n10 4312651. 3446024. 2008-04-01 06:00:54      1\n# ℹ 816 more rows\n\n\nNext, we have to get the environmental covariates. A forest layer is included in the package. Note, that this a regular SpatRast.\n\nforest.cover = readRDS(\"sp.layer.forest\")\nplot(forest.cover,main=\"Forest Cover\")\npoints(deer$x_,deer$y_,col=0)\n\n\n\n\n\n\n\nLoad additinal layer\n\nshrub.cover = readRDS(\"sp.layer.shrub\")\nplot(shrub.cover,main=\"Standaradized Shrub Cover\")\npoints(deer$x_,deer$y_,col=0)"
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#prepare-data-for-rsf",
    "href": "classfiles/habsel/amt.vignette.habsel.html#prepare-data-for-rsf",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "Prepare Data for RSF",
    "text": "Prepare Data for RSF\nRandom Points\nBefore fitting a RSF we have to do some data preparation. We have to generate random points, points that we think the animal could have used. The random points define the availability domain. In amt the function random_points is designed to do just that. The function can be used in 3 different ways, depending to the type of object that is passed to the function call.\n\nA track_* (such as the deer object) can be passed to the function random_points. The function then calculates a home range (the home-range estimator can be controlled with argument hr). Within this home range n random points are generated. The default value of n is ten times the number of present points.\nIf a hr-object (i.e., the result of a home-range estimation in amt) is passed to random_points, points are generated within the home range. This allows to generate random points within any home range that was previously estimated in amt. Note, that this could be a home range of multiple animals. In this case, the function random_points has one additional argument called presence. This argument takes a trk_* with the presence points and adds these points for convenience to the random points.\nA SpatialPolygons*-object or sf-object. The latter must contain POLYGONs or MULTIPOLYGONs as features. This can be useful in situation where a home range needs to be buffered, or when other geographical features are considered as the availability domain. As before, this method for random_points also takes the argument presence to optionally add the observed points to the output.\n\nLets now illustrate the three different situations. First we take random points from a track_xy\n\nr1 &lt;- random_points(deer)\nplot(r1)\n\n\n\n\n\n\n\nWith the argument n we can control the number of random points (remember that the default is ten times as many points as we observed points).\n\nr1 &lt;- random_points(deer, n = 100)\nplot(r1)\n\n\n\n\n\n\n\nHere, we can also add the observed points:\n\nhr &lt;- hr_mcp(deer)\nr1 &lt;- random_points(hr, n = 500, presence = deer)\nplot(r1)\n\n\n\n\n\n\n\nFinally, we can work with the home range and for example a buffer and then generate random points within the this new polygon.\n\nhr &lt;- hr_mcp(deer) |&gt; hr_isopleths() |&gt; \n  sf::st_buffer(dist =3e4) # add a 30km buffer\nr1 &lt;- random_points(hr, n = 500)\nplot(r1)\n\n\n\n\n\n\n\nAnd we can also add the observed points.\n\nhr &lt;- hr_mcp(deer) |&gt; hr_isopleths() |&gt; \n  sf::st_buffer(dist =3e4) # add a 30km buffer\nr1 &lt;- random_points(hr, n = 500, presence = deer)\nplot(r1)\n\n\n\n\n\n\n\nOf course we are not restricted to the sf::st_buffer function. All geometric operations from the sf package can be used to generate arbitrarily complex availability domains.\nExtract covariates\nAs the next step we have to extract the covariates at point. We can do this with extract_covariates.\n\nset.seed(5454)\nrsf1 &lt;- deer |&gt; random_points(n=20000, presence = deer) |&gt; \n  extract_covariates(forest.cover)  |&gt; \n  extract_covariates(shrub.cover) \ntable(rsf1$case_)\n\n\nFALSE  TRUE \n20000   826"
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#fitting-rsf",
    "href": "classfiles/habsel/amt.vignette.habsel.html#fitting-rsf",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "Fitting RSF",
    "text": "Fitting RSF\nNow all pieces are there to fit a RSF. We will use fit_rsf, which is just a wrapper around stats::glm with family = binomial(link = \"logit\").\n\nrsf1 |&gt; fit_rsf(case_ ~ forest+shrub.cover) |&gt; \n  summary()\n\n\nCall:\nstats::glm(formula = formula, family = stats::binomial(link = \"logit\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.14260    0.05440 -57.770  &lt; 2e-16 ***\nforest       0.15508    0.12828   1.209 0.226676    \nshrub.cover -0.15246    0.04483  -3.401 0.000671 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6950.4  on 20825  degrees of freedom\nResidual deviance: 6931.6  on 20823  degrees of freedom\nAIC: 6937.6\n\nNumber of Fisher Scoring iterations: 6"
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#additional-bdg",
    "href": "classfiles/habsel/amt.vignette.habsel.html#additional-bdg",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "Additional (BDG)",
    "text": "Additional (BDG)\nFit the same model with the glm function directly\n\n  rsf2 = glm(case_~forest+shrub.cover, \n             data=rsf1,\n             family=binomial(link=\"logit\"))\n  summary(rsf2)\n\n\nCall:\nglm(formula = case_ ~ forest + shrub.cover, family = binomial(link = \"logit\"), \n    data = rsf1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.14260    0.05440 -57.770  &lt; 2e-16 ***\nforest       0.15508    0.12828   1.209 0.226676    \nshrub.cover -0.15246    0.04483  -3.401 0.000671 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 6950.4  on 20825  degrees of freedom\nResidual deviance: 6931.6  on 20823  degrees of freedom\nAIC: 6937.6\n\nNumber of Fisher Scoring iterations: 6\n\n\nLet’s next interpret the coefficients. For a full understading, please see\nFieberg, J., Signer, J., Smith, B., & Avgar, T. (2021). A ’How to’guide for interpreting parameters in habitat‐selection analyses. Journal of Animal Ecology, 90(5), 1027-1043.\nWe are modeling the relative intensity of selection. Since we are defining the zeros here, it turns out that the intercept has no meaningful interpretation. The intercept is related to the ratio of used to available locations and that’s all. We can interpret the slope coefficients! Here, a coefficient at or really close to zero (no statistically clarity) indicate that the variable is being selected for in proportion to available.\nLooking at our results, we can see that the coefficient for percent forest is positive, thus as percent forest cover increases, the relative intensity of selection increases. In other words, in relative terms, more cover is selected for more than less cover. The opposite is true for the effects of shrub cover, which the coefficient is negative. Remember, this covariate is standardized. As shrub cover increases from the mean, we expect that deer will increasing select for these areas less than available. Also, as shrub cover decreases from the mean, we expect increasing selection to what is available by the deer.\nPlot Predicted Relative Selection\n\n# Decide on covariate values to predict to. Here we will create a plot of how relative intensity of selection\n# varies by forest cover at the mean value of shrub cover.\n\n newdata =  data.frame(shrub.cover=0,forest=seq(0,1,by=0.01))\n\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  \n  rsf2$coefficients[1] = 0 \n  coef(rsf2)\n\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \nplot(newdata$forest,relative.prob,type=\"l\",lwd=3,xlab=\"Forest Cover\",ylab=\"Relative Intensity of Selection\")\n\n\n\n\n\n\n\nA common output of interest is the relative selection strength (RSS) between two areas or values of covariate. See,\nAvgar T, Lele SR, Keim JL, Boyce MS. Relative Selection Strength: Quantifying effect size in habitat- and step-selection inference. Ecol Evol. 2017; 7: 5322–5330. https://doi.org/10.1002/ece3.3122\n\n# Let's compare the RSS between a location with complete forest cover (1) and no forest cover (0) at the mean value of shrub cover (0).\n\n#See formula in Avgar et al. 2017, section 2.1\n  exp(coef(rsf2)[2] * (1-0) + coef(rsf2)[3]*0)\n\n  forest \n1.167756 \n\n\nThis value indicates that there is a 1.16 increase in relative selection at complete forest cover versus no cover. Not a large difference in relative selection! Also, looking at the statistical clarity, there is not clear evidence that forest is selected for or against more than available.\nNext, lets conisder shrub cover relative selection and relative selection strength.\n\n# Here we will create a plot of how relative intensity of selection\n# varies by shrub cover at the mean value of forest cover.\n\n newdata =  data.frame(shrub.cover=seq(-3,3,by=0.1),forest=mean(values(forest.cover)))\n\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  rsf2$coefficients[1] = 0 \n  coef(rsf2)\n\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \nplot(newdata$shrub.cover,relative.prob,type=\"l\",lwd=3,xlab=\"Forest Cover\",ylab=\"Relative Intensity of Selection\")\nabline(h=1,lwd=2,lty=3,col=2)\ntext(2.5, 1.1,\"Selection\")\ntext(2.5, 0.9,\"Avoidance\")\n\n\n\n\n\n\n\n\n# Let's compare the RSS between a location with very low shrub cover (-3) and very high shrub cover (3) at the mean value of forest cover (0).\n\n#See formula in Avgar et al. 2017, section 2.1\n  exp(coef(rsf2)[2] * mean(values(forest.cover)) + coef(rsf2)[3]*(-3 - 3))\n\n  forest \n2.526219 \n\n\nAn area with very low shrub cover is much more likely to be selected than high shrub cover with a RSS of 2.5.\n\n# Decide on covariate values to predict to. Here we will use all values from both\n# covariates, so we can predict relative intesnsity of selection to the whole landscape\n newdata =  data.frame(shrub.cover=values(shrub.cover),forest=values(forest.cover))\n#Predict to the link scale- do not predict to probability scale, as\n#we are actually fitting an exponential linked model\n  \nrsf2$coefficients[1] = 0 \ncoef(rsf2)\n\n(Intercept)      forest shrub.cover \n  0.0000000   0.1550837  -0.1524609 \n\n  preds.link = predict(rsf2,newdata=newdata,\n                       type=\"link\")\n  \n  relative.prob = exp(preds.link)\n  \n# Create new spatial layer and then\n# plug in the predictions\n  preds.map = forest.cover\n  values(preds.map) = relative.prob\n  plot(preds.map,main=\"Relative Probability of Selection\")\n\n\n\n\n\n\n\nValues below 1 indicate avoidance (use less than available) and values greater than 1 indicate selection (use greater than selection). These values are called the relative intenity of selection or relative probability of selection."
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#this-model-fitting-process-is-sensitive-to-the-number-available-locations-0s-or-false",
    "href": "classfiles/habsel/amt.vignette.habsel.html#this-model-fitting-process-is-sensitive-to-the-number-available-locations-0s-or-false",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "This model fitting process is sensitive to the number available locations (0’s or ‘FALSE’)",
    "text": "This model fitting process is sensitive to the number available locations (0’s or ‘FALSE’)\n\n# Draw random available samples (0's) in equal proportion to the number of deer locations\nset.seed(5454)\nrsf.data1 &lt;- random_points(deer, n = nrow(deer), presence = deer) |&gt; \n  extract_covariates(forest.cover)|&gt;\n  extract_covariates(shrub.cover) \n\nhead(rsf.data1)\n\n# A tibble: 6 × 5\n  case_       x_       y_ forest shrub.cover\n* &lt;lgl&gt;    &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;\n1 FALSE 4310495. 3444563. 0.0156     -0.969 \n2 FALSE 4314429. 3447738. 0           1.31  \n3 FALSE 4312423. 3447310. 0           0.794 \n4 FALSE 4318130. 3450293. 0.0278      0.963 \n5 FALSE 4311328. 3443957. 0.732       0.0435\n6 FALSE 4312433. 3446426. 0.403       0.656 \n\ntable(rsf.data1$case_)\n\n\nFALSE  TRUE \n  826   826 \n\nrsf.fit1 = glm(case_~forest+shrub.cover, data=rsf.data1,family=binomial(link=\"logit\"))\nsummary(rsf.fit1)\n\n\nCall:\nglm(formula = case_ ~ forest + shrub.cover, family = binomial(link = \"logit\"), \n    data = rsf.data1)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)   \n(Intercept)  0.04698    0.07606   0.618  0.53682   \nforest       0.19889    0.17533   1.134  0.25664   \nshrub.cover -0.17372    0.06437  -2.699  0.00696 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2290.2  on 1651  degrees of freedom\nResidual deviance: 2277.7  on 1649  degrees of freedom\nAIC: 2283.7\n\nNumber of Fisher Scoring iterations: 3\n\n\nNote that these estimated slope coefficients are not the same as when fitting the same model using the data from rsf1 where there are 20,000 available samples. The intercept is very noticeably has the biggest difference, which is something we expect. The intercept is not meaningfully interpretable in this type of model. It essentially represents the ratio of used to available samples. As we increase the available sample, the intercept will get smaller. What we should be concerned about are the slope coefficient estimates. As we increase the available sample, we should see these estimates stabilize, as with their p-values."
  },
  {
    "objectID": "classfiles/habsel/amt.vignette.habsel.html#assignment",
    "href": "classfiles/habsel/amt.vignette.habsel.html#assignment",
    "title": "Resource Selection Functions (RSF) with amt\n",
    "section": "Assignment",
    "text": "Assignment\nConduct a sensitivity analysis to investigate how many available samples are needed for the slope coeficient estimates to stabilize. Essentially, you want to increase the available sample until the estimated slopes no longer change. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coeficients for the variables ‘forest’ and ‘shurb.cover’. Create a table of coeficient estimates along with the available sample size used. Determine generally when the coefficient estimates stabilize. A common recommendation in the literature is to used a 1:1 ratio between used locations and available samples. If you had only fit the model with this size of available, how would your estimates compare to the estimates you get when using a very large available sample?\nNote\nHow you setup this sensitivity analysis will affect your ability to get estimates to converge. For example, if you take separate random samples, it might take a very large number to get the estimates to converge. This is because there is not consistency between random draws. This stochasticity adds some additional variation when estimating. Ideally, we would create systematic samples at smaller and smaller cell sizes"
  },
  {
    "objectID": "classfiles/occlab/hboccu.BDG.html",
    "href": "classfiles/occlab/hboccu.BDG.html",
    "title": "Hierarchical Bayesian Occupancy Lab",
    "section": "",
    "text": "# Libraries\n  library(rjags)\n  library(brms)\n  library(bayesplot)\n  library(ubms)  \n  library(unmarked)  \n\n#Read data\n  bunny=read.csv(\"detection_nondetection_bunny.csv\")\n  bunny.data = cbind(bunny$Observed1,  bunny$Observed2)\n\n\n#Look at the data\n  head(bunny)\n\n  ShrubHabitat  Veg Observed1 Observed2\n1            1 0.45         1         1\n2            1 0.08         0         0\n3            1 0.84         0         0\n4            1 0.01         0         0\n5            0 0.96         0         0\n6            0 0.55         0         0\n\n\n\n\n\n# Date setup with covaraite\n  data=list(\n    y=bunny.data,\n    n.sites=nrow(bunny.data),\n    n.visits=ncol(bunny.data),\n    veg = bunny$Veg\n  )\n\n\n  params=c(\"a0\",\"a1\",\"b0\",\"b1\")\n\n  inits &lt;- function(){list(z=apply(bunny.data, 1, max), a0=rnorm(1), b0=rnorm(1),a1=rnorm(1), b1=rnorm(1))}\n\n# Settings for MCMC chains\n  nchains&lt;-3\n  niter&lt;-5000\n  nburn&lt;-1000\n  nthin&lt;-1\n\n  jm=jags.model(file=\"occ.model.cov.JAGS.R\", data=data, inits=inits, n.chains=nchains, n.adapt=2000)\n\n# Run the burn-in portion of the model\n  update(jm, n.iter=nburn)\n\n# Sample from the posterior\n  M3 = coda.samples(jm, variable.names=params, n.iter=niter, thin=nthin)\n  #save(M3,file=\"M3\")\n\n\n\nUMF &lt;- unmarkedFrameOccu(y=bunny.data,siteCovs=data.frame(veg = bunny$Veg))\n\n# use R package to fit the same model in stan\n  model5.stan = stan_occu(~veg ~veg, data=UMF, chains=3, iter=5000)\n  #save(model5.stan, file=\"model5.stan\")"
  },
  {
    "objectID": "classfiles/occlab/hboccu.BDG.html#setup-data-and-packages",
    "href": "classfiles/occlab/hboccu.BDG.html#setup-data-and-packages",
    "title": "Hierarchical Bayesian Occupancy Lab",
    "section": "",
    "text": "# Libraries\n  library(rjags)\n  library(brms)\n  library(bayesplot)\n  library(ubms)  \n  library(unmarked)  \n\n#Read data\n  bunny=read.csv(\"detection_nondetection_bunny.csv\")\n  bunny.data = cbind(bunny$Observed1,  bunny$Observed2)\n\n\n#Look at the data\n  head(bunny)\n\n  ShrubHabitat  Veg Observed1 Observed2\n1            1 0.45         1         1\n2            1 0.08         0         0\n3            1 0.84         0         0\n4            1 0.01         0         0\n5            0 0.96         0         0\n6            0 0.55         0         0\n\n\n\n\n\n# Date setup with covaraite\n  data=list(\n    y=bunny.data,\n    n.sites=nrow(bunny.data),\n    n.visits=ncol(bunny.data),\n    veg = bunny$Veg\n  )\n\n\n  params=c(\"a0\",\"a1\",\"b0\",\"b1\")\n\n  inits &lt;- function(){list(z=apply(bunny.data, 1, max), a0=rnorm(1), b0=rnorm(1),a1=rnorm(1), b1=rnorm(1))}\n\n# Settings for MCMC chains\n  nchains&lt;-3\n  niter&lt;-5000\n  nburn&lt;-1000\n  nthin&lt;-1\n\n  jm=jags.model(file=\"occ.model.cov.JAGS.R\", data=data, inits=inits, n.chains=nchains, n.adapt=2000)\n\n# Run the burn-in portion of the model\n  update(jm, n.iter=nburn)\n\n# Sample from the posterior\n  M3 = coda.samples(jm, variable.names=params, n.iter=niter, thin=nthin)\n  #save(M3,file=\"M3\")\n\n\n\nUMF &lt;- unmarkedFrameOccu(y=bunny.data,siteCovs=data.frame(veg = bunny$Veg))\n\n# use R package to fit the same model in stan\n  model5.stan = stan_occu(~veg ~veg, data=UMF, chains=3, iter=5000)\n  #save(model5.stan, file=\"model5.stan\")"
  },
  {
    "objectID": "classfiles/occlab/hboccu.BDG.html#challenge",
    "href": "classfiles/occlab/hboccu.BDG.html#challenge",
    "title": "Hierarchical Bayesian Occupancy Lab",
    "section": "Challenge",
    "text": "Challenge\nStep 1\nIgnore detection probability and fit a Bayesian logistic regression model. Use brm or JAGS to fit the model. Compare this slope to your findings from your Bayesian occupancy model slopes - either model5.stan or M3. How are the results different? Think about the issue of ignoring detection probability and what this might mean for your interpretation of an ecological effect?\n\nbunny.ignore.det = apply(bunny.data,1,sum)\nbunny.ignore.det[which(bunny.ignore.det==2)]=1\n\n# Now, we have site level observation without replication. A 1 indicates a detection in either column 1 or column 2 or both.\n# A zero is no detection for other observation.\n\n# Fit the Bayesian logistic regression model and estimate a slope for the effect of veg (bunny$veg)\nbunny.ignore.det\n\n  [1] 1 0 0 0 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0\n [38] 0 0 1 0 1 1 1 1 1 1 0 1 1 0 0 1 0 0 0 1 0 0 1 0 1 0 0 1 1 0 1 1 0 0 1 0 0\n [75] 0 1 1 0 1 1 1 0 0 1 0 0 0 1 1 0 1 1 0 0 0 0 0 0 1 1 0 0 1 0 1 0 0 0 0 0 0\n[112] 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0 1\n[149] 0 1 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 1 1 0 0\n[186] 0 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 0 1 1 0 0\n[223] 1 1 1 0 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1\n[260] 1 0 0 1 1 0 0 0 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 1 0 1\n[297] 0 0 1 0 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 0 0 0 0 1 0\n[334] 0 0 0 0 1 0 1 0 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 1 1 0 1 0 1\n[371] 0 1 0 1 0 0 0 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 1 1 0\n\n\nLogistic Regression with brm\n\n#Setup a dataframe with the new occurrence data and veg covariate\ndat = data.frame(y=bunny.ignore.det, veg=bunny$Veg)\n\n# Use brms to fit a logistic regression model\nbrm.fit = brm(formula =  y~ veg,  \n              data = dat, \n              family = bernoulli(link = \"logit\"),\n              warmup = 2000, \n              iter = 5000, \n              chains = 3, \n              sample_prior = FALSE\n)\n#save(brm.fit,file=\"brm.fit\")\n\nExamine posteriors and traceplots\n\nplot(brm.fit)\n\n\n\n\n\n\n#Extract posterior samples\nb_veg = as_draws(brm.fit,variable=\"b_veg\")\n\n#plot posterior samples manually\n#plot(density(b_veg[[1]]$b_veg),lwd=3)\n\nLogistic Regression with JAGS\n\n# Need to include are covaraite\ndat = data.frame(y=bunny.ignore.det, veg=bunny$Veg)\n\ndata=list(\n  y=dat$y,\n  n.sites=length(dat$y),\n  veg = dat$veg\n)\n\n\nparams=c(\"b0\",\"b1\")\n\ninits &lt;- function(){list(b0=rnorm(1), b1=rnorm(1))}\n\njm=jags.model(file=\"logistic.model.cov.JAGS.R\", data=data, inits=inits, n.chains=nchains, n.adapt=2000)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 400\n   Unobserved stochastic nodes: 2\n   Total graph size: 1108\n\nInitializing model\n\n# Run the burn-in portion of the model\nupdate(jm, n.iter=nburn)\n\n# Sample from the posterior\njags.fit.logistic = coda.samples(jm, variable.names=params, n.iter=niter, thin=nthin)\n\nplot(jags.fit.logistic)\n\n\n\n\n\n\n\nTake-Home\nTo really see the issue, we should plot the posterior distributions of the slope of vegetation when accounting for detection and ignoring detection. In the below plots, if we ignore detection probability, we see the effect of veg is negative (top plot). However, when we separate detection and occupancy (model M3 and model5.stan), the effect of veg on occupancy is positive. Our conclusion about the the effect of veg is opposite. The differences of the posteriors within each plot are simply due to not running the MCMC iterations long enogugh and different priors.\n\n\n\n\n\n\n\n\nStep 2\nUse model5.stan or M3 to make a prediction plot of occupancy (y-axis) and veg (x-axis).\nUsing ubms/stan\nThe predict function works with ubms to get predictions\n\n#We can use the predict function to get predictions of the 'state' or occurence probabiltiy\n  preds=predict(model5.stan,submodel=\"state\")\n  \n#Create dataframe and reorder for plotting  \n  preds=data.frame(preds,veg=bunny$Veg)\n  preds=preds[order(preds$veg),]\n\n# plot predictions and 95% credible intervals    \n  plot(preds$veg,preds$Predicted,lwd=4,col=2,type=\"l\",ylim=c(0,1))\n  lines(preds$veg,preds$X2.5.,lwd=4,col=3)\n  lines(preds$veg,preds$X97.5.,lwd=4,col=3)\n\n\n\n\n\n\n\nUsing JAGS model\nUsing Jags, we need to backtransform parameters ourselves. There is no function to do this for us.\n\n  beta0=M3[[1]][,3]\n  beta1=M3[[1]][,4]\n\n# loop over covariate value and get a posterior distribution for each value\n# of veg\npreds.veg= matrix(0, ncol=length(beta1),nrow=length(bunny$Veg))  \n  for( i in 1:length(bunny$Veg)){\n   preds.veg[i,] = beta0+beta1*bunny$Veg[i]  \n  }\n\ndim(preds.veg)\n\n[1]  400 5000\n\n#Get quantiles from prediction posterior distributions\npreds.quantile = apply(preds.veg,1,quantile,probs=c(0.025,0.5,0.975))\npreds.quantile = plogis(preds.quantile)\n\npreds.quantile = data.frame(t(preds.quantile),veg=bunny$Veg)\nhead(preds.quantile)\n\n      X2.5.      X50.    X97.5.  veg\n1 0.5387980 0.6454013 0.7674074 0.45\n2 0.4382571 0.5345797 0.6277029 0.08\n3 0.5258638 0.7495458 0.9138909 0.84\n4 0.3937687 0.5128651 0.6227004 0.01\n5 0.5174074 0.7760901 0.9388150 0.96\n6 0.5379086 0.6745990 0.8152814 0.55\n\npreds.quantile=preds.quantile[order(preds.quantile$veg),]\nplot(preds.quantile$veg,preds.quantile$X50.,lwd=4,col=2,type=\"l\",ylim=c(0,1))\nlines(preds.quantile$veg,preds.quantile$X2.5.,lwd=4,col=3)\nlines(preds.quantile$veg,preds.quantile$X97.5.,lwd=4,col=3)"
  },
  {
    "objectID": "classfiles/habsel/habitat.selection.BDG.html",
    "href": "classfiles/habsel/habitat.selection.BDG.html",
    "title": "Habitat Selection Availability Sensitivity",
    "section": "",
    "text": "#Look at deer data and spatial layers to be used as covariates\nforest.cover = readRDS(\"sp.layer.forest\")\nplot(forest.cover,main=\"Forest Cover\")\npoints(deer)\n\n\n\n\n\n\nshrub.cover = readRDS(\"sp.layer.shrub\")\nplot(shrub.cover,main=\"Standaradized Shrub Cover\")"
  },
  {
    "objectID": "classfiles/habsel/habitat.selection.BDG.html#getting-the-data-ready",
    "href": "classfiles/habsel/habitat.selection.BDG.html#getting-the-data-ready",
    "title": "Habitat Selection Availability Sensitivity",
    "section": "",
    "text": "#Look at deer data and spatial layers to be used as covariates\nforest.cover = readRDS(\"sp.layer.forest\")\nplot(forest.cover,main=\"Forest Cover\")\npoints(deer)\n\n\n\n\n\n\nshrub.cover = readRDS(\"sp.layer.shrub\")\nplot(shrub.cover,main=\"Standaradized Shrub Cover\")"
  },
  {
    "objectID": "classfiles/habsel/habitat.selection.BDG.html#assignment",
    "href": "classfiles/habsel/habitat.selection.BDG.html#assignment",
    "title": "Habitat Selection Availability Sensitivity",
    "section": "Assignment",
    "text": "Assignment\nConduct a sensitivity analysis to investigate how many available samples are needed for the slope coeficients to be estimated with minimal approximation error. Consider a range of sizes for the available sample between 50 and 500,000. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coeficients for the variables ‘forest’ and ‘cover’. Creat an x-y line plot with these estimates (y-axis) and the size of the available sample (x-axis). Determine generally when the coefficient estimates stabilize. A common recommendation in the literature is to used a 1:1 ratio between used locations and available samples. If you had only fit the model with this size of available how off would your estimates be from the correct/converged/well approximated estimates when using a large available sample.\n\n# Take a really large sample of available locations (the zeros)\n  rsf.dat.large &lt;- random_points(deer, n = 4000000) |&gt; \n                   extract_covariates(forest.cover) |&gt;\n                   extract_covariates(shrub.cover) \n\n# Decide on how to subset the available samples\n  availables = c(50,100,500,1000,10000,100000,1000000,2000000,3000000,4000000)\n\n# Find the indices of where the deer locations are (index.1)  and the available samples (index.0)\n  index.0 = which(rsf.dat.large$case_==0)\n  index.1 = which(rsf.dat.large$case_==1)\n  coef.mat=NULL\n\n# Loop through the numbers of available samples and iteratively grab an increase set of zeros. Combine\n# these zeros with the used locations of deer and then fit the model \n  for(i in 1:length(availables)){\n    rsf.smaller =  rbind(rsf.dat.large[index.1,],rsf.dat.large[index.0[1:availables[i]],])\n    fit = glm(case_~forest+shrub.cover, data=rsf.smaller,family=binomial(link=\"logit\"))\n    coef.mat=rbind(coef.mat,coef(fit)[c(2,3)])\n  }\n\nknitr::kable(cbind(availables,coef.mat))\n\n\n\navailables\nforest\nshrub.cover\n\n\n\n5e+01\n-0.6887266\n0.0406996\n\n\n1e+02\n-0.5134734\n-0.3117284\n\n\n5e+02\n0.2009326\n-0.1663946\n\n\n1e+03\n0.1970181\n-0.1573290\n\n\n1e+04\n0.1684757\n-0.1455294\n\n\n1e+05\n0.1836227\n-0.1433593\n\n\n1e+06\n0.1935036\n-0.1421465\n\n\n2e+06\n0.1926889\n-0.1429547\n\n\n3e+06\n0.1894583\n-0.1426449\n\n\n4e+06\n0.1905065\n-0.1420496\n\n\n\n\n\nWe can see that the first and second decimal place values converges for both coefficients by 100,000 available samples.\nNext, lets specifically compare the converged estimated coefficients to estimates when using a 1:1 ratio of used:available.\n\nrsf.dat &lt;- random_points(deer, n = nrow(deer)) |&gt; \n             extract_covariates(forest.cover) |&gt;\n             extract_covariates(shrub.cover) \n\nfit = glm(case_~forest+shrub.cover, \n          data=rsf.dat,\n          family=binomial(link=\"logit\"))\nsummary(fit)\n\n\nCall:\nglm(formula = case_ ~ forest + shrub.cover, family = binomial(link = \"logit\"), \n    data = rsf.dat)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)  0.01344    0.07583   0.177    0.859\nforest       0.15616    0.17513   0.892    0.373\nshrub.cover -0.09752    0.06461  -1.509    0.131\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2290.2  on 1651  degrees of freedom\nResidual deviance: 2285.4  on 1649  degrees of freedom\nAIC: 2291.4\n\nNumber of Fisher Scoring iterations: 3\n\n# Absolute difference b/w converged and non-converged estimates\n(coef.mat[10,] - coef(fit)[2:3])\n\n     forest shrub.cover \n 0.03434588 -0.04453154 \n\n\nWe can see that if we had used a 1:1 ratio of used to available, we would have underestimated the effect of forest and overestimated the effect of shrub cover."
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html",
    "href": "classfiles/habsel/ssf.amt.html",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "",
    "text": "This vignette briefly introduces how one can fit a Step-Selection Function (SSF) with the amt package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map. For a more through discussion see also Fieberg et al. 20201 and supplement B.\n1 https://www.biorxiv.org/content/10.1101/2020.11.12.379834v4"
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html#about",
    "href": "classfiles/habsel/ssf.amt.html#about",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "",
    "text": "This vignette briefly introduces how one can fit a Step-Selection Function (SSF) with the amt package. We will be using the example data of one red deer from northern Germany and one covariate: a forest cover map. For a more through discussion see also Fieberg et al. 20201 and supplement B.\n1 https://www.biorxiv.org/content/10.1101/2020.11.12.379834v4"
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html#getting-the-data-ready",
    "href": "classfiles/habsel/ssf.amt.html#getting-the-data-ready",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "Getting the data ready",
    "text": "Getting the data ready\nFirst we load the required libraries and the relocation data (called deer)\n\nlibrary(lubridate)\nlibrary(amt)\ndata(\"deer\")\ndeer\n\n# A tibble: 826 × 4\n         x_       y_ t_                  burst_\n *    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;               &lt;dbl&gt;\n 1 4314068. 3445807. 2008-03-30 00:01:47      1\n 2 4314053. 3445768. 2008-03-30 06:00:54      1\n 3 4314105. 3445859. 2008-03-30 12:01:47      1\n 4 4314044. 3445785. 2008-03-30 18:01:24      1\n 5 4313015. 3445858. 2008-03-31 00:01:23      1\n 6 4312860. 3445857. 2008-03-31 06:01:45      1\n 7 4312854. 3445856. 2008-03-31 12:01:11      1\n 8 4312858. 3445858. 2008-03-31 18:01:55      1\n 9 4312745. 3445862. 2008-04-01 00:01:24      1\n10 4312651. 3446024. 2008-04-01 06:00:54      1\n# ℹ 816 more rows\n\n\nIn order to continue, we need a regular sampling rate. To check the current sampling rate, we use summarize_sampling_rate:\n\nsummarize_sampling_rate(deer)\n\n# A tibble: 1 × 9\n    min    q1 median  mean    q3   max    sd     n unit \n  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;\n1  5.96  6.00   6.01  11.5  6.02 3924.  137.   825 hour \n\n\nThe median sampling rate is 6h, which is what we aimed for.\nNext, we have to get the environmental covariates. A forest layer is included in the package. Note, that this a regular SpatRast.\n\nsh_forest &lt;- get_sh_forest()\nsh_forest\n\nclass       : SpatRaster \ndimensions  : 720, 751, 1  (nrow, ncol, nlyr)\nresolution  : 25, 25  (x, y)\nextent      : 4304725, 4323500, 3437725, 3455725  (xmin, xmax, ymin, ymax)\ncoord. ref. : +proj=laea +lat_0=52 +lon_0=10 +x_0=4321000 +y_0=3210000 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nsource(s)   : memory\nname        : forest \nmin value   :      0 \nmax value   :      1"
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html#prepare-data-for-ssf",
    "href": "classfiles/habsel/ssf.amt.html#prepare-data-for-ssf",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "Prepare Data for SSF",
    "text": "Prepare Data for SSF\nSteps\nBefore fitting a SSF we have to do some data preparation. First, we change from a point representation to a step representation, using the function steps_by_burst, which in contrast to the steps function accounts for bursts.\n\nssf1 &lt;- deer |&gt; steps_by_burst()\n\nControl/random steps\nThe generic function random_steps provides a methods for a track_xy*, where each observed step is paired with n_control control steps (i.e., steps that share the same starting location but have different turn angles and step lengths). The distributions for drawing step lengths and turning angles are usually obtained by fitting known parametric distribution to the observed step length and turn angles.\nThe function random_steps has seven arguments. For most use cases the defaults are just fine, but there might situation where the user wants to adjust some of the arguments. The arguments are:\n\n\nx: This is the track_xy* for which the random steps are created. That is, for each step in x n_control random steps are created.\n\nn_control: The number of random steps that should be created for each observed step.\n\nsl_distr: This is the distribution of the step lengths. By default a gamma distribution is fit to the observed step lengths of the x. But any amt_distr is suitable here. 2\n\n\nta_distr: This is the turn angle distribution, with the default being a von Mises distribution.\n\nrand_sl: These are the random step lengths, by default 1e5 random numbers from the distribution fitted in 33.\n\nrand_ta: These are the random turn angles, by default 1e4 random numbers from the distribution fitted in 4.\n\ninclude_observed: This argument is by default TRUE and indicates if the observed steps should be included or not.\n\n2 See also ?fit_distr.3 Note, this possible because of the Glivenko-Cantelli theorem and works as long as the sample from the original distribution (the sample you provide here) is large enough.The default situation\nIn most situations the following code snippet should work4.\n4 And how it was implemented in amt up to version 0.0.6. This should be backward compatible and not break existing code.\nssf1 &lt;- ssf1 |&gt; random_steps(n_control = 15)\n\nA exponential distribution for step lengths\ntodo\nExtract covariates\nAs a last step, we have to extract the covariates at the end point of each step. We can do this with extract_covariates.\n\nssf1 &lt;- ssf1 |&gt; extract_covariates(sh_forest) \n\nSince the forest layers is coded as 1 = forest and 2 != forest, we create a factor with appropriate levels. We also calculate the log of the step length and the cosine of the turn angle, which we may use later for a integrated step selection function.\n\nssf1 &lt;- ssf1 |&gt; \n  mutate(forest = factor(forest, levels = 1:0, labels = c(\"forest\", \"non-forest\")), \n         cos_ta = cos(ta_), \n        log_sl = log(sl_))"
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html#fitting-ssf",
    "href": "classfiles/habsel/ssf.amt.html#fitting-ssf",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "Fitting SSF",
    "text": "Fitting SSF\nNow all pieces are there to fit a SSF. We will use fit_clogit, which is a wrapper around survival::clogit.\n\nm0 &lt;- ssf1 |&gt; fit_clogit(case_ ~ forest + strata(step_id_))\nm1 &lt;- ssf1 |&gt; fit_clogit(case_ ~ forest + forest:cos_ta + forest:log_sl + log_sl * cos_ta + strata(step_id_))\nm2 &lt;- ssf1 |&gt; fit_clogit(case_ ~ forest + forest:cos_ta + forest:log_sl + log_sl + cos_ta + strata(step_id_))\nsummary(m0)\n\nCall:\ncoxph(formula = Surv(rep(1, 12096L), case_) ~ forest + strata(step_id_), \n    data = data, method = \"exact\")\n\n  n= 12096, number of events= 756 \n\n                    coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nforestnon-forest -0.5145    0.5978   0.1088 -4.727 2.28e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                 exp(coef) exp(-coef) lower .95 upper .95\nforestnon-forest    0.5978      1.673     0.483      0.74\n\nConcordance= 0.529  (se = 0.007 )\nLikelihood ratio test= 21.65  on 1 df,   p=3e-06\nWald test            = 22.34  on 1 df,   p=2e-06\nScore (logrank) test = 22.44  on 1 df,   p=2e-06\n\nsummary(m1)\n\nCall:\ncoxph(formula = Surv(rep(1, 12096L), case_) ~ forest + forest:cos_ta + \n    forest:log_sl + log_sl * cos_ta + strata(step_id_), data = data, \n    method = \"exact\")\n\n  n= 12096, number of events= 756 \n\n                            coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nforestnon-forest         0.83934   2.31483  0.32799  2.559 0.010497 *  \nlog_sl                   0.17416   1.19025  0.04958  3.513 0.000443 ***\ncos_ta                  -0.20329   0.81604  0.20531 -0.990 0.322092    \nforestnon-forest:cos_ta -0.31159   0.73228  0.11769 -2.648 0.008106 ** \nforestnon-forest:log_sl -0.25554   0.77450  0.05786 -4.416    1e-05 ***\nlog_sl:cos_ta            0.01656   1.01669  0.03450  0.480 0.631313    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                        exp(coef) exp(-coef) lower .95 upper .95\nforestnon-forest           2.3148     0.4320    1.2171    4.4026\nlog_sl                     1.1902     0.8402    1.0800    1.3117\ncos_ta                     0.8160     1.2254    0.5457    1.2203\nforestnon-forest:cos_ta    0.7323     1.3656    0.5814    0.9223\nforestnon-forest:log_sl    0.7745     1.2912    0.6915    0.8675\nlog_sl:cos_ta              1.0167     0.9836    0.9502    1.0878\n\nConcordance= 0.609  (se = 0.013 )\nLikelihood ratio test= 90.25  on 6 df,   p=&lt;2e-16\nWald test            = 88.38  on 6 df,   p=&lt;2e-16\nScore (logrank) test = 90.65  on 6 df,   p=&lt;2e-16\n\nsummary(m2)\n\nCall:\ncoxph(formula = Surv(rep(1, 12096L), case_) ~ forest + forest:cos_ta + \n    forest:log_sl + log_sl + cos_ta + strata(step_id_), data = data, \n    method = \"exact\")\n\n  n= 12096, number of events= 756 \n\n                            coef exp(coef) se(coef)      z Pr(&gt;|z|)    \nforestnon-forest         0.84859   2.33635  0.32724  2.593 0.009510 ** \nlog_sl                   0.17369   1.18969  0.04956  3.505 0.000457 ***\ncos_ta                  -0.11644   0.89008  0.09693 -1.201 0.229614    \nforestnon-forest:cos_ta -0.31497   0.72981  0.11750 -2.681 0.007348 ** \nforestnon-forest:log_sl -0.25707   0.77331  0.05776 -4.451 8.56e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                        exp(coef) exp(-coef) lower .95 upper .95\nforestnon-forest           2.3363     0.4280    1.2302    4.4370\nlog_sl                     1.1897     0.8406    1.0796    1.3111\ncos_ta                     0.8901     1.1235    0.7361    1.0763\nforestnon-forest:cos_ta    0.7298     1.3702    0.5797    0.9188\nforestnon-forest:log_sl    0.7733     1.2931    0.6905    0.8660\n\nConcordance= 0.609  (se = 0.013 )\nLikelihood ratio test= 90.02  on 5 df,   p=&lt;2e-16\nWald test            = 87.6  on 5 df,   p=&lt;2e-16\nScore (logrank) test = 89.63  on 5 df,   p=&lt;2e-16\n\n\nInterpretation of coefficients\nSee the discussion in Fieberg et al 2021."
  },
  {
    "objectID": "classfiles/habsel/ssf.amt.html#a-note-on-piping",
    "href": "classfiles/habsel/ssf.amt.html#a-note-on-piping",
    "title": "Fitting Step-Selection Functions with amt\n",
    "section": "A note on piping",
    "text": "A note on piping\nAll steps described above, could easily be wrapped into one piped workflow:\n\nm1 &lt;- deer |&gt; \n  steps_by_burst() |&gt; random_steps(n = 15) |&gt; \n  extract_covariates(sh_forest) |&gt; \n  mutate(forest = factor(forest, levels = 1:0, labels = c(\"forest\", \"non-forest\")), \n         cos_ta = cos(ta_), \n         log_sl = log(sl_)) |&gt; \n  fit_clogit(case_ ~ forest + forest:cos_ta + forest:sl_ + sl_ * cos_ta + strata(step_id_))\n\n\nsummary(m1)\n\nCall:\ncoxph(formula = Surv(rep(1, 12096L), case_) ~ forest + forest:cos_ta + \n    forest:sl_ + sl_ * cos_ta + strata(step_id_), data = data, \n    method = \"exact\")\n\n  n= 12096, number of events= 756 \n\n                              coef  exp(coef)   se(coef)      z Pr(&gt;|z|)    \nforestnon-forest        -0.1036793  0.9015144  0.1407961 -0.736  0.46150    \nsl_                      0.0006758  1.0006760  0.0001538  4.394 1.11e-05 ***\ncos_ta                  -0.3355283  0.7149603  0.1098064 -3.056  0.00225 ** \nforestnon-forest:cos_ta -0.2134928  0.8077580  0.1183237 -1.804  0.07118 .  \nforestnon-forest:sl_    -0.0009751  0.9990253  0.0001986 -4.909 9.14e-07 ***\nsl_:cos_ta               0.0003849  1.0003850  0.0001271  3.027  0.00247 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                        exp(coef) exp(-coef) lower .95 upper .95\nforestnon-forest           0.9015     1.1092    0.6841    1.1880\nsl_                        1.0007     0.9993    1.0004    1.0010\ncos_ta                     0.7150     1.3987    0.5765    0.8866\nforestnon-forest:cos_ta    0.8078     1.2380    0.6406    1.0186\nforestnon-forest:sl_       0.9990     1.0010    0.9986    0.9994\nsl_:cos_ta                 1.0004     0.9996    1.0001    1.0006\n\nConcordance= 0.603  (se = 0.013 )\nLikelihood ratio test= 105.2  on 6 df,   p=&lt;2e-16\nWald test            = 107.8  on 6 df,   p=&lt;2e-16\nScore (logrank) test = 116.5  on 6 df,   p=&lt;2e-16"
  },
  {
    "objectID": "classfiles/habsel/habsel.assignment.html",
    "href": "classfiles/habsel/habsel.assignment.html",
    "title": "Habitat Selection Lab",
    "section": "",
    "text": "When we fit a habitat selection model (commonly called a resource selection function) we are often using convenient and general software/code to approximate the true underlying model. Specifically, we commonly use logistic regression to approximate the spatial point process model we are actually interested in fitting. To make sure our approximation of the point process model is done with minimal approximation error, we need to have a very large available sample (i.e., we need many zeros and their associated environmental covaraites) taken from the area/landscape/home range we are considering available to the individual(s).\n\nConduct a sensitivity analysis to investigate how large the available sample needs to be for the slope coefficient estimates to stabilize. Essentially, you want to increase the available sample size until the estimated coefficients no longer change. How you create your available sample (e.g., random sampling, systematic sampling) will determine when the estimated coefficients stop changing. The other factor is the error tolerance that you will accept. Lets use an error tolerance of 2 decimal places. Meaning, you want to increase the available sample until the first two decimal places of the estimated coefficients no longer change.\nYou will need to create several/many datasets with different sizes of the available sample (i.e, the number of zeros). Remember, the number of used locations (1’s) is the same for each dataset. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coefficients for the variables ‘forest’ and ‘shurb.cover’. Create a table of coefficient estimates along with the size of the available sample used (i.e., columns of 1) Size of available sample, 2) coef for forest, and 3) coef for shrub). Looking at the table, decide on whether the coefficient estimates have stabilized. Make sure to use a wide range of sizes of available samples. If you are unsure if they have converged, keep increasing the available sample size.\nSecondly, compare the converged coeficient estimates to a model fit using a 1:1 ratio of used locations to available locations. This is a common recommendation in the literature. If you had only fit the model with this size of available locations, how would your estimates compare to the estimates you get when using a very large available sample (converged estimates)? If there is any difference, this is due to approximation error. State how much error there is and whether it is a meaningful amount.\n\nHow you setup this sensitivity analysis will affect your ability to get estimates to converge. For example, if you take separate random samples, it might take a very large number (maybe more than a million) to get the estimates to converge. This is because there is no consistency between random draws of available sample. This stochasticity adds some additional variation when estimating. Another option would be to create a very large sample of available locations first and then create smaller subsets of these.\n\nUse the deer data provided in the amt package to fit a new habitat selection model that we have not considered yet. I would like you to fit a model where you hypothesize that selection for the proportion of forest changes depending on the time of day. Specifically, during daytime and nighttime. The idea being that risk changes to the deer depending on the time of day because of changes in predator and human activity. Please fit a model where there is an interaction between time of day (see code below how to get this covariate) and percent of forest cover. Please interpret your findings in terms of the estimated coefficients. If you want to go a bit further, make predictions of the relative intensity of selection for relevant covariate combinations. In terms of the available sample, use a very large available sample, but you do not need to conduct a sensitivity analysis.\nSince time of day is not a spatial variable, it is a bit different to include as a covariate. We have the time of day (day, night) for each used location, but we need to combined two sets of available samples: one with our spatial variables that are defined during the day, and the second with the same spatial variables but that are defined at night.\n\n### Setup environment\n# Include time of day variable\n  deer = time_of_day(deer)\n  head(deer)\n\n# A tibble: 6 × 5\n        x_       y_ t_                  burst_ tod_ \n*    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;               &lt;dbl&gt; &lt;fct&gt;\n1 4314068. 3445807. 2008-03-30 00:01:47      1 night\n2 4314053. 3445768. 2008-03-30 06:00:54      1 day  \n3 4314105. 3445859. 2008-03-30 12:01:47      1 day  \n4 4314044. 3445785. 2008-03-30 18:01:24      1 night\n5 4313015. 3445858. 2008-03-31 00:01:23      1 night\n6 4312860. 3445857. 2008-03-31 06:01:45      1 day  \n\n\n\n\n# Create MCP home rnage with 5000 m bufer\nhr &lt;- hr_mcp(deer) |&gt; hr_isopleths() |&gt; \n  sf::st_buffer(dist =5000)\n\n\n# Draw random available samples\n  set.seed(5454)\n  rsf1 &lt;- random_points(hr, n=20000, presence = deer) |&gt; \n    extract_covariates(forest.cover)  \n  table(rsf1$case_)\n\n\nFALSE  TRUE \n20000   826 \n\nplot(rsf1)\n\n\n\n\n\n\n\n\n\n# Find where the used locations are and the available locations\n  index.1=which(rsf1$case_==1)\n  index.0=which(rsf1$case_==0)\n\n# Create a new column for 'time of day', tod\n# Put temporary values\n  rsf1$tod=\"temp\"\n\n#For the used locations, put in the observed time of day\n  rsf1$tod[index.1] = as.character(deer$tod_)\n  \n#For the available samples make these all 'day'  \n  rsf1$tod[index.0] = \"day\"\n\n#Now, we need to replicate the available sample but for 'night'\n  temp = rsf1[index.0,]\n  temp$tod=\"night\"\n\n#Combine the used locations, available sample with 'day', and the available sample with 'night'  \n  rsf.combined = rbind(rsf1,temp)\n\nThe object rsf.combined can not be used to fit the model with forest and tod."
  },
  {
    "objectID": "classfiles/habsel/habsel.assignment.html#assignment-part-1",
    "href": "classfiles/habsel/habsel.assignment.html#assignment-part-1",
    "title": "Habitat Selection Lab",
    "section": "",
    "text": "Conduct a sensitivity analysis to investigate how large the available sample needs to be for the slope coefficient estimates to stabilize. Essentially, you want to increase the available sample size until the estimated coefficients no longer change. How you create your available sample (e.g., random sampling, systematic sampling) will determine when the estimated coefficients stop changing. The other factor is the error tolerance that you will accept. Lets use an error tolerance of 2 decimal places. Meaning, you want to increase the available sample until the first two decimal places of the estimated coefficients no longer change.\nYou will need to create several/many datasets with different sizes of the available sample (i.e, the number of zeros). Remember, the number of used locations (1’s) is the same for each dataset. Fit the same model (case_ ~ forest + cover) to each of these datasets. Extract the slope coefficients for the variables ‘forest’ and ‘shurb.cover’. Create a table of coefficient estimates along with the size of the available sample used (i.e., columns of 1) Size of available sample, 2) coef for forest, and 3) coef for shrub). Looking at the table, decide on whether the coefficient estimates have stabilized. Make sure to use a wide range of sizes of available samples. If you are unsure if they have converged, keep increasing the available sample size.\nSecondly, compare the converged coeficient estimates to a model fit using a 1:1 ratio of used locations to available locations. This is a common recommendation in the literature. If you had only fit the model with this size of available locations, how would your estimates compare to the estimates you get when using a very large available sample (converged estimates)? If there is any difference, this is due to approximation error. State how much error there is and whether it is a meaningful amount.\n\nHow you setup this sensitivity analysis will affect your ability to get estimates to converge. For example, if you take separate random samples, it might take a very large number (maybe more than a million) to get the estimates to converge. This is because there is no consistency between random draws of available sample. This stochasticity adds some additional variation when estimating. Another option would be to create a very large sample of available locations first and then create smaller subsets of these."
  },
  {
    "objectID": "classfiles/habsel/habsel.assignment.html#assignment-part-2",
    "href": "classfiles/habsel/habsel.assignment.html#assignment-part-2",
    "title": "Habitat Selection Lab",
    "section": "",
    "text": "Use the deer data provided in the amt package to fit a new habitat selection model that we have not considered yet. I would like you to fit a model where you hypothesize that selection for the proportion of forest changes depending on the time of day. Specifically, during daytime and nighttime. The idea being that risk changes to the deer depending on the time of day because of changes in predator and human activity. Please fit a model where there is an interaction between time of day (see code below how to get this covariate) and percent of forest cover. Please interpret your findings in terms of the estimated coefficients. If you want to go a bit further, make predictions of the relative intensity of selection for relevant covariate combinations. In terms of the available sample, use a very large available sample, but you do not need to conduct a sensitivity analysis.\nSince time of day is not a spatial variable, it is a bit different to include as a covariate. We have the time of day (day, night) for each used location, but we need to combined two sets of available samples: one with our spatial variables that are defined during the day, and the second with the same spatial variables but that are defined at night.\n\n### Setup environment\n# Include time of day variable\n  deer = time_of_day(deer)\n  head(deer)\n\n# A tibble: 6 × 5\n        x_       y_ t_                  burst_ tod_ \n*    &lt;dbl&gt;    &lt;dbl&gt; &lt;dttm&gt;               &lt;dbl&gt; &lt;fct&gt;\n1 4314068. 3445807. 2008-03-30 00:01:47      1 night\n2 4314053. 3445768. 2008-03-30 06:00:54      1 day  \n3 4314105. 3445859. 2008-03-30 12:01:47      1 day  \n4 4314044. 3445785. 2008-03-30 18:01:24      1 night\n5 4313015. 3445858. 2008-03-31 00:01:23      1 night\n6 4312860. 3445857. 2008-03-31 06:01:45      1 day  \n\n\n\n\n# Create MCP home rnage with 5000 m bufer\nhr &lt;- hr_mcp(deer) |&gt; hr_isopleths() |&gt; \n  sf::st_buffer(dist =5000)\n\n\n# Draw random available samples\n  set.seed(5454)\n  rsf1 &lt;- random_points(hr, n=20000, presence = deer) |&gt; \n    extract_covariates(forest.cover)  \n  table(rsf1$case_)\n\n\nFALSE  TRUE \n20000   826 \n\nplot(rsf1)\n\n\n\n\n\n\n\n\n\n# Find where the used locations are and the available locations\n  index.1=which(rsf1$case_==1)\n  index.0=which(rsf1$case_==0)\n\n# Create a new column for 'time of day', tod\n# Put temporary values\n  rsf1$tod=\"temp\"\n\n#For the used locations, put in the observed time of day\n  rsf1$tod[index.1] = as.character(deer$tod_)\n  \n#For the available samples make these all 'day'  \n  rsf1$tod[index.0] = \"day\"\n\n#Now, we need to replicate the available sample but for 'night'\n  temp = rsf1[index.0,]\n  temp$tod=\"night\"\n\n#Combine the used locations, available sample with 'day', and the available sample with 'night'  \n  rsf.combined = rbind(rsf1,temp)\n\nThe object rsf.combined can not be used to fit the model with forest and tod."
  },
  {
    "objectID": "publications/articles/Iannarilli2024.html",
    "href": "publications/articles/Iannarilli2024.html",
    "title": "A ‘how-to’ guide for estimating animal diel activity usinghierarchical models",
    "section": "",
    "text": "Iannarilli, F., Gerber, B. D., Erb, J., & Fieberg, J. R. (2024). A ‘how-to’ guide for estimating animal diel activity using hierarchical models. Journal of Animal Ecology, 00, 1–13. https://doi.org/10.1111/1365-2656.14213."
  },
  {
    "objectID": "publications/articles/Iannarilli2024.html#citation",
    "href": "publications/articles/Iannarilli2024.html#citation",
    "title": "A ‘how-to’ guide for estimating animal diel activity usinghierarchical models",
    "section": "",
    "text": "Iannarilli, F., Gerber, B. D., Erb, J., & Fieberg, J. R. (2024). A ‘how-to’ guide for estimating animal diel activity using hierarchical models. Journal of Animal Ecology, 00, 1–13. https://doi.org/10.1111/1365-2656.14213."
  },
  {
    "objectID": "publications/articles/Iannarilli2024.html#abstract",
    "href": "publications/articles/Iannarilli2024.html#abstract",
    "title": "A ‘how-to’ guide for estimating animal diel activity usinghierarchical models",
    "section": "Abstract",
    "text": "Abstract\nAnimal diel activity patterns can aid understanding of (a) how species behaviourally adapt to anthropogenic and natural disturbances, (b) mechanisms of species co-existence through temporal partitioning, and (c) community or ecosystem effects of diel activity shifts. Activity patterns often vary spatially, a feature ignored by the kernel density estimators (KDEs) currently used for estimating diel activity. Ignoring this source of heterogeneity may lead to biased estimates of uncertainty and misleading conclusions regarding the drivers of diel activity. Thus, there is a need for more flexible statistical approaches for estimating activity patterns and testing hypotheses regarding their biotic and abiotic drivers. We illustrate how trigonometric terms and cyclic cubic splines combined with hierarchical models can provide a valuable alternative to KDEs. Like KDEs, these models accommodate circular data, but they can also account for site-to-site and other sources of variability, correlation amongst repeated measures, and variable sampling effort. They can also more readily quantify and test hypotheses related to the effects of covariates on activity patterns. Through empirical case studies, we illustrate how hierarchical models can quantify changes in activity levels due to seasonality and in response to biotic and abiotic factors (e.g. anthropogenic stressors and co-occurrence). We also describe frequentist and Bayesian approaches for quantifying site-specific (conditional) and population-averaged (marginal) activity patterns. We provide guidelines and tutorials with detailed step-by-step instructions for fitting and interpreting hierarchical models applied to time-stamped data, such as those recorded by camera traps and audio recorders. We conclude that this approach offers a viable, flexible, and effective alternative to KDEs when modelling animal activity patterns."
  },
  {
    "objectID": "news.html",
    "href": "news.html",
    "title": "Past News",
    "section": "",
    "text": "December, 2023\n\nNew Publication: Forest carnivores living on the edge with invasive predators from the ever persistent Erin Wampole. Download. We found free-roaming dogs and cats interact with their surrounding environment (i.e., forest edge) to shape native carnivore species response differently than within interior forest.\n\n\n\nNovember, 2023\n\nBrian heads to the annual Wildlife Society conference to talk about a recent paper in Animal Conservation about the robustness of optimal decision making in the context of known-unknown meta-population dynamics.\nNew OA Publication: Diel activity structures the occurrence of a mammal community in a human-dominated landscape led by Amy Mayer from the University of Rhode Island. We found that mammals shift their use of spatial locations and the time of day they are active at these locations to adapt to landscapes with anthropogenic activity. Data and code can be found on Zenodo. The methods used to implement this modeling framework are outlined by Rivera et al. 2022 with code on Github.\n\n\n\nSeptember, 2023\n\nNew Publication: Differential impacts of spruce beetle outbreaks on snowshoe hares and red squirrels in the southern Rocky Mountains led by Jake Ivan from the Colorado Parks and Wilddife. Download.\n\n\n\nAugust, 2023\n\nBrian starts with the Colorado Cooperative Fish and Wildlife Research Unit with USGS at Colorado State University. Prior, I was an associate professor at the University of Rhode Island in the Department of Natural Resources Science."
  }
]